{"2025-12-19T00:00:00Z":{"Distributed, Parallel, and Cluster Computing":[{"id":"http://arxiv.org/abs/2512.17885v1","updated":"2025-12-19T18:36:39Z","published":"2025-12-19T18:36:39Z","title":"Asymptotic behaviour of galactic small-scale dynamos at modest magnetic Prandtl number","summary":"Magnetic fields are critical at many scales to galactic dynamics and structure, including multiphase pressure balance, dust processing, and star formation. Dynamo action determines their dynamical structure and strength. Simulations of combined large- and small-scale dynamos have successfully developed mean fields with strength and topology consistent with observations but with turbulent fields much weaker than observed, while simulations of small-scale dynamos with parameters relevant to the interstellar medium yield turbulent fields an order of magnitude below the values observed or expected theoretically. We use the Pencil Code accelerated on GPUs with Astaroth to perform high-resolution simulations of a supernova-driven galactic dynamo including heating and cooling in a periodic domain. Our models show that the strength of the turbulent field produced by the small-scale dynamo approaches an asymptote at only modest magnetic Prandtl numbers. This allows us to use these models to suggest the essential characteristics of this constituent of the magnetic field for inclusion in global galactic models. The asymptotic limit occurs already at magnetic Prandtl number of only a few hundred, many orders of magnitude below physical values in the the interstellar medium and consistent with previous findings for isothermal compressible flows.","authors":["Frederick A. Gent","Mordecai-Mark Mac Low","Maarit J. Korpi-Lagg","Touko Puro","Matthias Reinhardt"],"pdf_url":"","comment":"10 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2509.11512v2","updated":"2025-12-19T17:47:28Z","published":"2025-09-15T01:53:30Z","title":"Machine Learning-Driven Predictive Resource Management in Complex Science Workflows","summary":"The collaborative efforts of large communities in science experiments, often comprising thousands of global members, reflect a monumental commitment to exploration and discovery. Recently, advanced and complex data processing has gained increasing importance in science experiments. Data processing workflows typically consist of multiple intricate steps, and the precise specification of resource requirements is crucial for each step to allocate optimal resources for effective processing. Estimating resource requirements in advance is challenging due to a wide range of analysis scenarios, varying skill levels among community members, and the continuously increasing spectrum of computing options. One practical approach to mitigate these challenges involves initially processing a subset of each step to measure precise resource utilization from actual processing profiles before completing the entire step. While this two-staged approach enables processing on optimal resources for most of the workflow, it has drawbacks such as initial inaccuracies leading to potential failures and suboptimal resource usage, along with overhead from waiting for initial processing completion, which is critical for fast-turnaround analyses. In this context, our study introduces a novel pipeline of machine learning models within a comprehensive workflow management system, the Production and Distributed Analysis (PanDA) system. These models employ advanced machine learning techniques to predict key resource requirements, overcoming challenges posed by limited upfront knowledge of characteristics at each step. Accurate forecasts of resource requirements enable informed and proactive decision-making in workflow management, enhancing the efficiency of handling diverse, complex workflows across heterogeneous resources.","authors":["Tasnuva Chowdhury","Tadashi Maeno","Fatih Furkan Akman","Joseph Boudreau","Sankha Dutta","Shengyu Feng","Adolfy Hoisie","Kuan-Chieh Hsu","Raees Khan","Jaehyung Kim","Ozgur O. Kilic","Scott Klasky","Alexei Klimentov","Tatiana Korchuganova","Verena Ingrid Martinez Outschoorn","Paul Nilsson","David K. Park","Norbert Podhorszki","Yihui Ren","John Rembrandt Steele","Frédéric Suter","Sairam Sri Vatsavai","Torre Wenaus","Wei Yang","Yiming Yang","Shinjae Yoo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.24444v2","updated":"2025-12-19T15:31:25Z","published":"2025-09-29T08:26:52Z","title":"BugMagnifier: TON Transaction Simulator for Revealing Smart Contract Vulnerabilities","summary":"The Open Network (TON) blockchain employs an asynchronous execution model that introduces unique security challenges for smart contracts, particularly race conditions arising from unpredictable message processing order. While previous work established vulnerability patterns through static analysis of audit reports, dynamic detection of temporal dependencies through systematic testing remains an open problem. We present BugMagnifier, a transaction simulation framework that systematically reveals vulnerabilities in TON smart contracts through controlled message orchestration. Built atop TON Sandbox and integrated with the TON Virtual Machine (TVM), our tool combines precise message queue manipulation with differential state analysis and probabilistic permutation testing to detect asynchronous execution flaws. Experimental evaluation demonstrates BugMagnifier's effectiveness through extensive parametric studies on purpose-built vulnerable contracts, revealing message ratio-dependent detection complexity that aligns with theoretical predictions. This quantitative model enables predictive vulnerability assessment while shifting discovery from manual expert analysis to automated evidence generation. By providing reproducible test scenarios for temporal vulnerabilities, BugMagnifier addresses a critical gap in the TON security tooling, offering practical support for safer smart contract development in asynchronous blockchain environments.","authors":["Yury Yanovich","Victoria Kovalevskaya","Maksim Egorov","Elizaveta Smirnova","Matvey Mishuris","Yash Madhwal","Kirill Ziborov","Vladimir Gorgadze","Subodh Sharma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.12068v2","updated":"2025-12-19T15:19:22Z","published":"2025-12-12T22:30:31Z","title":"TreeVQA: A Tree-Structured Execution Framework for Shot Reduction in Variational Quantum Algorithms","summary":"Variational Quantum Algorithms (VQAs) are promising for near- and intermediate-term quantum computing, but their execution cost is substantial. Each task requires many iterations and numerous circuits per iteration, and real-world applications often involve multiple tasks, scaling with the precision needed to explore the application's energy landscape. This demands an enormous number of execution shots, making practical use prohibitively expensive. We observe that VQA costs can be significantly reduced by exploiting execution similarities across an application's tasks. Based on this insight, we propose TreeVQA, a tree-based execution framework that begins by executing tasks jointly and progressively branches only as their quantum executions diverge. Implemented as a VQA wrapper, TreeVQA integrates with typical VQA applications. Evaluations on scientific and combinatorial benchmarks show shot count reductions of $25.9\\times$ on average and over $100\\times$ for large-scale problems at the same target accuracy. The benefits grow further with increasing problem size and precision requirements.","authors":["Yuewen Hou","Dhanvi Bharadwaj","Gokul Subramanian Ravi"],"pdf_url":"","comment":"To appear at 31st ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS 2026)"},{"id":"http://arxiv.org/abs/2512.15659v2","updated":"2025-12-19T14:19:18Z","published":"2025-12-17T18:11:39Z","title":"LeaseGuard: Raft Leases Done Right","summary":"Raft is a leading consensus algorithm for replicating writes in distributed databases. However, distributed databases also require consistent reads. To guarantee read consistency, a Raft-based system must either accept the high communication overhead of a safety check for each read, or implement leader leases. Prior lease protocols are vaguely specified and hurt availability, so most Raft systems implement them incorrectly or not at all. We introduce LeaseGuard, a novel lease algorithm that relies on guarantees specific to Raft elections. LeaseGuard is simple, rigorously specified in TLA+, and includes two novel optimizations that maximize availability during leader failover. The first optimization restores write throughput quickly, and the second improves read availability. We evaluate LeaseGuard with a simulation in Python and an implementation in LogCabin, the C++ reference implementation of Raft. By replacing LogCabin's default consistency mechanism (quorum checks), LeaseGuard reduces the overhead of consistent reads from one to zero network roundtrips. It also improves write throughput from ~1000 to ~10,000 writes per second, by eliminating contention between writes and quorum reads. Whereas traditional leases ban all reads on a new leader while it waits for a lease, in our LeaseGuard test the new leader instantly allows 99% of reads to succeed.","authors":["A. Jesse Jiryu Davis","Murat Demirbas","Lingzhi Deng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17589v1","updated":"2025-12-19T13:57:25Z","published":"2025-12-19T13:57:25Z","title":"Torrent: A Distributed DMA for Efficient and Flexible Point-to-Multipoint Data Movement","summary":"The growing disparity between computational power and on-chip communication bandwidth is a critical bottleneck in modern Systems-on-Chip (SoCs), especially for data-parallel workloads like AI. Efficient point-to-multipoint (P2MP) data movement, such as multicast, is essential for high performance. However, native multicast support is lacking in standard interconnect protocols. Existing P2MP solutions, such as multicast-capable Network-on-Chip (NoC), impose additional overhead to the network hardware and require modifications to the interconnect protocol, compromising scalability and compatibility.\n  This paper introduces Torrent, a novel distributed DMA architecture that enables efficient P2MP data transfers without modifying NoC hardware and interconnect protocol. Torrent conducts P2MP data transfers by forming logical chains over the NoC, where the data traverses through targeted destinations resembling a linked list. This Chainwrite mechanism preserves the P2P nature of every data transfer while enabling flexible data transfers to an unlimited number of destinations. To optimize the performance and energy consumption of Chainwrite, two scheduling algorithms are developed to determine the optimal chain order based on NoC topology.\n  Our RTL and FPGA prototype evaluations using both synthetic and real workloads demonstrate significant advantages in performance, flexibility, and scalability over network-layer multicast. Compared to the unicast baseline, Torrent achieves up to a 7.88x speedup. ASIC synthesis on 16nm technology confirms the architecture's minimal footprint in area (1.2%) and power (2.3%). Thanks to the Chainwrite, Torrent delivers scalable P2MP data transfers with a small cycle overhead of 82CC and area overhead of 207um2 per destination.","authors":["Yunhao Deng","Fanchen Kong","Xiaoling Yi","Ryan Antonio","Marian Verhelst"],"pdf_url":"","comment":"7 pages, 11 figures, Proceeded by the 2026 Design, Automation and Test in Europe Conference (DATE 26)"},{"id":"http://arxiv.org/abs/2512.16683v2","updated":"2025-12-19T13:54:52Z","published":"2025-12-18T15:49:28Z","title":"Efficient Bitcoin Meta-Protocol Transaction and Data Discovery Through nLockTime Field Repurposing","summary":"We describe the Lockchain Protocol, a lightweight Bitcoin meta-protocol that enables highly efficient transaction discovery at zero marginal block space cost, and data verification without introducing any new on-chain storage mechanism. The protocol repurposes the mandatory 4-byte nLockTime field of every Bitcoin transaction as a compact metadata header. By constraining values to an unused range of past Unix timestamps greater than or equal to 500,000,000, the field can encode a protocol signal, type, variant, and sequence identifier while remaining fully valid under Bitcoin consensus and policy rules. The primary contribution of the protocol is an efficient discovery layer. Indexers can filter candidate transactions by examining a fixed-size header field, independent of transaction payload size, and only then selectively inspect heavier data such as OP RETURN outputs or witness fields. The Lockchain Protocol applies established protocol design patterns to an under-optimised problem domain, namely transaction discovery at scale, and does not claim new cryptographic primitives or storage methods.","authors":["Nikodem Tomczak"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17574v1","updated":"2025-12-19T13:40:13Z","published":"2025-12-19T13:40:13Z","title":"Enabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing","summary":"Multimodal large language models (MLLMs) extend LLMs with visual understanding through a three-stage pipeline: multimodal preprocessing, vision encoding, and LLM inference. While these stages enhance capability, they introduce significant system bottlenecks. First, multimodal preprocessing-especially video decoding-often dominates Time-to-First-Token (TTFT). Most systems rely on CPU-based decoding, which severely limits throughput, while existing GPU-based approaches prioritize throughput-oriented parallelism and fail to meet the latency-sensitive requirements of MLLM inference. Second, the vision encoder is a standalone, compute-intensive stage that produces visual embeddings and cannot be co-batched with LLM prefill or decoding. This heterogeneity forces inter-stage blocking and increases token-generation latency. Even when deployed on separate GPUs, these stages underutilize available compute and memory resources, reducing overall utilization and constraining system throughput.\n  To address these challenges, we present FlashCodec and UnifiedServe, two complementary designs that jointly optimize the end-to-end MLLM pipeline. FlashCodec accelerates the multimodal preprocessing stage through collaborative multi-GPU video decoding, reducing decoding latency while preserving high throughput. UnifiedServe optimizes the vision-to-text and inference stages using a logically decoupled their execution to eliminate inter-stage blocking, yet physically sharing GPU resources to maximize GPU system utilization. By carefully orchestrating execution across stages and minimizing interference, UnifiedServe Together, our proposed framework forms an end-to-end optimized stack that can serve up to 3.0$\\times$ more requests or enforce 1.5$\\times$ tighter SLOs, while achieving up to 4.4$\\times$ higher throughput compared to state-of-the-art systems.","authors":["Lingxiao Zhao","Haoran Zhou","Yuezhi Che","Dazhao Cheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17506v1","updated":"2025-12-19T12:16:02Z","published":"2025-12-19T12:16:02Z","title":"The HEAL Data Platform","summary":"Objective: The objective was to develop a cloud-based, federated system to serve as a single point of search, discovery and analysis for data generated under the NIH Helping to End Addiction Long-term (HEAL) Initiative.\n  Materials and methods: The HEAL Data Platform is built on the open source Gen3 platform, utilizing a small set of framework services and exposed APIs to interoperate with both NIH and non-NIH data repositories. Framework services include those for authentication and authorization, creating persistent identifiers for data objects, and adding and updating metadata.\n  Results: The HEAL Data Platform serves as a single point of discovery of over one thousand studies funded under the HEAL Initiative. With hundreds of users per month, the HEAL Data Platform provides rich metadata and interoperates with data repositories and commons to provide access to shared datasets. Secure, cloud-based compute environments that are integrated with STRIDES facilitate secondary analysis of HEAL data. The HEAL Data Platform currently interoperates with nineteen data repositories.\n  Discussion: Studies funded under the HEAL Initiative generate a wide variety of data types, which are deposited across multiple NIH and third-party data repositories. The mesh architecture of the HEAL Data Platform provides a single point of discovery of these data resources, accelerating and facilitating secondary use.\n  Conclusion: The HEAL Data Platform enables search, discovery, and analysis of data that are deposited in connected data repositories and commons. By ensuring that these data are fully Findable, Accessible, Interoperable and Reusable (FAIR), the HEAL Data Platform maximizes the value of data generated under the HEAL Initiative.","authors":["Brienna M. Larrick","L. Philip Schumm","Mingfei Shao","Craig Barnes","Anthony Juehne","Hara Prasad Juvvla","Michael B. Kranz","Michael Lukowski","Clint Malson","Jessica N. Mazerik","Christopher G. Meyer","Jawad Qureshi","Erin Spaniol","Andrea Tentner","Alexander VanTol","Peter Vassilatos","Sara Volk de Garcia","Robert L. Grossman"],"pdf_url":"","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2512.17429v1","updated":"2025-12-19T10:29:43Z","published":"2025-12-19T10:29:43Z","title":"Democratizing Scalable Cloud Applications: Transactional Stateful Functions on Streaming Dataflows","summary":"Web applications underpin much of modern digital life, yet building scalable and consistent cloud applications remains difficult, requiring expertise across cloud computing, distributed systems, databases, and software engineering. These demands restrict development to a small number of highly specialized engineers. This thesis aims to democratize cloud application development by addressing three challenges: programmability, high-performance fault-tolerant serializable transactions, and serverless semantics.\n  The thesis identifies strong parallels between cloud applications and the streaming dataflow execution model. It first explores this connection through T-Statefun, a transactional extension of Apache Flink Statefun, demonstrating that dataflow systems can support transactional cloud applications via a stateful functions-as-a-service API. However, this approach revealed significant limitations in programmability and performance.\n  To overcome these issues, the thesis introduces Stateflow, a high-level object-oriented programming model that compiles applications into stateful dataflow graphs with minimal boilerplate. Building on this model, the thesis presents Styx, a distributed streaming dataflow engine that provides deterministic, multi-partition, serializable transactions with strong fault tolerance guarantees. Styx eliminates explicit transaction failure handling and significantly outperforms state-of-the-art systems.\n  Finally, the thesis extends Styx with transactional state migration to support elasticity under dynamic workloads.","authors":["Kyriakos Psarakis"],"pdf_url":"","comment":"PhD Dissertation at TU Delft"},{"id":"http://arxiv.org/abs/2512.17352v1","updated":"2025-12-19T08:48:36Z","published":"2025-12-19T08:48:36Z","title":"Adaptive Graph Pruning with Sudden-Events Evaluation for Traffic Prediction using Online Semi-Decentralized ST-GNNs","summary":"Spatio-Temporal Graph Neural Networks (ST-GNNs) are well-suited for processing high-frequency data streams from geographically distributed sensors in smart mobility systems. However, their deployment at the edge across distributed compute nodes (cloudlets) createssubstantial communication overhead due to repeated transmission of overlapping node features between neighbouring cloudlets. To address this, we propose an adaptive pruning algorithm that dynamically filters redundant neighbour features while preserving the most informative spatial context for prediction. The algorithm adjusts pruning rates based on recent model performance, allowing each cloudlet to focus on regions experiencing traffic changes without compromising accuracy. Additionally, we introduce the Sudden Event Prediction Accuracy (SEPA), a novel event-focused metric designed to measure responsiveness to traffic slowdowns and recoveries, which are often missed by standard error metrics. We evaluate our approach in an online semi-decentralized setting with traditional FL, server-free FL, and Gossip Learning on two large-scale traffic datasets, PeMS-BAY and PeMSD7-M, across short-, mid-, and long-term prediction horizons. Experiments show that, in contrast to standard metrics, SEPA exposes the true value of spatial connectivity in predicting dynamic and irregular traffic. Our adaptive pruning algorithm maintains prediction accuracy while significantly lowering communication cost in all online semi-decentralized settings, demonstrating that communication can be reduced without compromising responsiveness to critical traffic events.","authors":["Ivan Kralj","Lodovico Giaretta","Gordan Ježić","Ivana Podnar Žarko","Šarūnas Girdzijauskas"],"pdf_url":"","comment":"19 pages, 6 figures, 5 tables, journal"},{"id":"http://arxiv.org/abs/2512.17264v1","updated":"2025-12-19T06:29:03Z","published":"2025-12-19T06:29:03Z","title":"Scalable Distributed Vector Search via Accuracy Preserving Index Construction","summary":"Scaling Approximate Nearest Neighbor Search (ANNS) to billions of vectors requires distributed indexes that balance accuracy, latency, and throughput. Yet existing index designs struggle with this tradeoff. This paper presents SPIRE, a scalable vector index based on two design decisions. First, it identifies a balanced partition granularity that avoids read-cost explosion. Second, it introduces an accuracy-preserving recursive construction that builds a multi-level index with predictable search cost and stable accuracy. In experiments with up to 8 billion vectors across 46 nodes, SPIRE achieves high scalability and up to 9.64X higher throughput than state-of-the-art systems.","authors":["Yuming Xu","Qianxi Zhang","Qi Chen","Baotong Lu","Menghao Li","Philip Adams","Mingqin Li","Zengzhong Li","Jing Liu","Cheng Li","Fan Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17254v1","updated":"2025-12-19T05:52:35Z","published":"2025-12-19T05:52:35Z","title":"Practical Framework for Privacy-Preserving and Byzantine-robust Federated Learning","summary":"Federated Learning (FL) allows multiple clients to collaboratively train a model without sharing their private data. However, FL is vulnerable to Byzantine attacks, where adversaries manipulate client models to compromise the federated model, and privacy inference attacks, where adversaries exploit client models to infer private data. Existing defenses against both backdoor and privacy inference attacks introduce significant computational and communication overhead, creating a gap between theory and practice. To address this, we propose ABBR, a practical framework for Byzantine-robust and privacy-preserving FL. We are the first to utilize dimensionality reduction to speed up the private computation of complex filtering rules in privacy-preserving FL. Additionally, we analyze the accuracy loss of vector-wise filtering in low-dimensional space and introduce an adaptive tuning strategy to minimize the impact of malicious models that bypass filtering on the global model. We implement ABBR with state-of-the-art Byzantine-robust aggregation rules and evaluate it on public datasets, showing that it runs significantly faster, has minimal communication overhead, and maintains nearly the same Byzantine-resilience as the baselines.","authors":["Baolei Zhang","Minghong Fang","Zhuqing Liu","Biao Yi","Peizhao Zhou","Yuan Wang","Tong Li","Zheli Liu"],"pdf_url":"","comment":"Accepted for publication in IEEE Transactions on Information Forensics and Security"},{"id":"http://arxiv.org/abs/2508.19009v3","updated":"2025-12-19T03:29:08Z","published":"2025-08-26T13:14:29Z","title":"Dual-Distilled Heterogeneous Federated Learning with Adaptive Margins for Trainable Global Prototypes","summary":"Heterogeneous Federated Learning (HFL) has gained significant attention for its capacity to handle both model and data heterogeneity across clients. Prototype-based HFL methods emerge as a promising solution to address statistical and model heterogeneity as well as privacy challenges, paving the way for new advancements in HFL research. This method focuses on sharing class-representative prototypes among heterogeneous clients. However, aggregating these prototypes via standard weighted averaging often yields sub-optimal global knowledge. Specifically, the averaging approach induces a shrinking of the aggregated prototypes' decision margins, thereby degrading model performance in scenarios with model heterogeneity and non-IID data distributions. The propose FedProtoKD in a Heterogeneous Federated Learning setting, utilizing an enhanced dual-knowledge distillation mechanism to enhance system performance by leveraging clients' logits and prototype feature representations. The proposed framework aims to resolve the prototype margin-shrinking problem using a contrastive learning-based trainable server prototype by leveraging a class-wise adaptive prototype margin. Furthermore, the framework assess the importance of public samples using the closeness of the sample's prototype to its class representative prototypes, which enhances learning performance. FedProtoKD improved test accuracy by an average of 1.13% and up to 34.13% across various settings, significantly outperforming existing state-of-the-art HFL methods.","authors":["Fatema Siddika","Md Anwar Hossen","Wensheng Zhang","Anuj Sharma","Juan Pablo Muñoz","Ali Jannesari"],"pdf_url":"","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2507.20116v2","updated":"2025-12-19T02:09:53Z","published":"2025-07-27T03:45:07Z","title":"PeerSync: Accelerating Containerized Service Delivery at the Network Edge","summary":"Efficient container image distribution is crucial for enabling machine learning inference at the network edge, where resource limitations and dynamic network conditions create significant challenges. In this paper, we present PeerSync, a decentralized P2P-based system designed to optimize image distribution in edge environments. PeerSync employs a popularity- and network-aware download engine that dynamically adapts to content popularity and real-time network conditions. PeerSync further integrates automated tracker election for rapid peer discovery and dynamic cache management for efficient storage utilization. We implement PeerSync with 8000+ lines of Rust code and test its performance extensively on both large-scale Docker-based emulations and physical edge devices. Experimental results show that PeerSync delivers a remarkable speed increase of 2.72$\\times$, 1.79$\\times$, and 1.28$\\times$ compared to the Baseline solution, Dragonfly, and Kraken, respectively, while significantly reducing cross-network traffic by 90.72% under congested and varying network conditions.","authors":["Yinuo Deng","Hailiang Zhao","Dongjing Wang","Peng Chen","Wenzhuo Qian","Jianwei Yin","Schahram Dustdar","Shuiguang Deng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.11542v2","updated":"2025-12-19T00:18:20Z","published":"2025-11-14T18:25:35Z","title":"Beyond Exascale: Dataflow Domain Translation on a Cerebras Cluster","summary":"Simulation of physical systems is essential across scientific and engineering domains. Commonly used domain decomposition methods are unable to simultaneously deliver both high simulation rate and high utilization in network computing environments. In particular, Exascale systems deliver only a small fraction their peak performance for these workloads. This paper introduces the novel Domain Translation algorithm, designed to overcome these limitations. On a cluster of 64 Cerebras CS-3 systems, we use this method to demonstrate unprecedented cluster performance across a range of metrics: we show simulations running in excess of 1.6 million time steps per second; we also demonstrate perfect weak scaling at 88% of peak performance. At this cluster scale, our implementation provides 112 PFLOP/s in a power-unconstrained environment, and 57 GFLOP/J in a power-limited environment. We illustrate the method by applying the shallow-water equations to model a tsunami following an asteroid impact at 460m-resolution on a planetary scale.","authors":["Tomas Oppelstrup","Nicholas Giamblanco","Delyan Z. Kalchev","Ilya Sharapov","Mark Taylor","Dirk Van Essendelft","Sivasankaran Rajamanickam","Michael James"],"pdf_url":"","comment":"12 pages, 11 figures. Accepted for HPC/Asia 2026"},{"id":"http://arxiv.org/abs/2512.18141v1","updated":"2025-12-19T23:46:25Z","published":"2025-12-19T23:46:25Z","title":"Constrained Cuts, Flows, and Lattice-Linearity","summary":"In a capacitated directed graph, it is known that the set of all min-cuts forms a distributive lattice [1], [2]. Here, we describe this lattice as a regular predicate whose forbidden elements can be advanced in constant parallel time after precomputing a max-flow, so as to obtain parallel algorithms for min-cut problems with additional constraints encoded by lattice-linear predicates [3]. Some nice algorithmic applications follow. First, we use these methods to compute the irreducibles of the sublattice of min-cuts satisfying a regular predicate. By Birkhoff's theorem [4] this gives a succinct representation of such cuts, and so we also obtain a general algorithm for enumerating this sublattice. Finally, though we prove computing min-cuts satisfying additional constraints is NP-hard in general, we use poset slicing [5], [6] for exact algorithms with constraints not necessarily encoded by lattice-linear predicates) with better complexity than exhaustive search. We also introduce $k$-transition predicates and strong advancement for improved complexity analyses of lattice-linear predicate algorithms in parallel settings, which is of independent interest.","authors":["Robert Streit","Vijay K. Garg"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18127v1","updated":"2025-12-19T23:08:04Z","published":"2025-12-19T23:08:04Z","title":"ACE-Sync: An Adaptive Cloud-Edge Synchronization Framework for Communication-Efficient Large-Scale Distributed Model Training","summary":"Large-scale deep learning models impose substantial communication overh ead in distributed training, particularly in bandwidth-constrained or heterogeneous clo ud-edge environments. Conventional synchronous or fixed-compression techniques o ften struggle to balance communication cost, convergence stability, and model accura cy. To address these challenges, we propose ACE-Sync, an Adaptive Cloud-Edge Sy nchronization Framework that integrates (1) an attention-based gradient importance p redictor, (2) a differentiated parameter compression strategy, and (3) a hierarchical cl oud-edge coordination mechanism. ACE-Sync dynamically selects which parameter groups to synchronize and determines appropriate compression levels under per-devic e bandwidth budgets. A knapsack-based optimization strategy is adopted to maximize important gradient preservation while reducing redundant communication. Furthermo re, residual-based error compensation and device clustering ensure long-term converg ence and cross-device personalization. Experiments show that ACE-Sync substantiall y reduces communication overhead while maintaining competitive accuracy. Compar ed with FullSync, ACE-Sync lowers communication cost from 112.5 GB to 44.7 GB (a 60% reduction) and shortens convergence from 41 to 39 epochs. Despite aggressiv e communication reduction, ACE-Sync preserves high model quality, achieving 82. 1% Top-1 accuracy-only 0.3% below the full-synchronization baseline-demonstrating its efficiency and scalability for large-scale distributed training. These results indicate that ACE-Sync provides a scalable, communication-efficient, and accuracy-preservin g solution for large-scale cloud-edge distributed model training.","authors":["Yi Yang","Ziyu Lin","Liesheng Wei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.10096v3","updated":"2025-12-19T21:40:04Z","published":"2025-04-14T11:02:36Z","title":"Solvers for the Hermitian and the pseudo-Hermitian Bethe-Salpeter equation in the Yambo code: Implementation and Performance","summary":"We analyze the performance of two strategies in solving the structured eigenvalue problem deriving from the Bethe-Salpeter equation (BSE) in condensed matter physics. The BSE matrix is constructed with the Yambo code, and the two strategies are implemented by interfacing Yambo with the ScaLAPACK and ELPA libraries for direct diagonalization, and with the SLEPc library for the iterative approach. We consider both the Hermitian (Tamm-Dancoff approximation) and pseudo-Hermitian forms, addressing dense matrices of three different sizes. A description of the implementation is also provided, with details for the pseudo-Hermitian case. Timing and memory utilization are analyzed on both CPU and GPU clusters. Our results demonstrate that it is now feasible to handle dense BSE matrices of the order of 10^5.","authors":["Petru Milev","Blanca Mellado-Pinto","Muralidhar Nalabothula","Ali Esquembre Kucukalic","Fernando Alvarruiz","Enrique Ramos","Francesco Filippone","Alejandro Molina-Sanchez","Ludger Wirtz","Jose E. Roman","Davide Sangalli"],"pdf_url":"","comment":"Submitted to SciPost Physics Codebases"}],"Computation and Language":[{"id":"http://arxiv.org/abs/2512.17901v1","updated":"2025-12-19T18:59:11Z","published":"2025-12-19T18:59:11Z","title":"When Reasoning Meets Its Laws","summary":"Despite the superior performance of Large Reasoning Models (LRMs), their reasoning behaviors are often counterintuitive, leading to suboptimal reasoning capabilities. To theoretically formalize the desired reasoning behaviors, this paper presents the Laws of Reasoning (LoRe), a unified framework that characterizes intrinsic reasoning patterns in LRMs. We first propose compute law with the hypothesis that the reasoning compute should scale linearly with question complexity. Beyond compute, we extend LoRe with a supplementary accuracy law. Since the question complexity is difficult to quantify in practice, we examine these hypotheses by two properties of the laws, monotonicity and compositionality. We therefore introduce LoRe-Bench, a benchmark that systematically measures these two tractable properties for large reasoning models. Evaluation shows that most reasoning models exhibit reasonable monotonicity but lack compositionality. In response, we develop an effective finetuning approach that enforces compute-law compositionality. Extensive empirical studies demonstrate that better compliance with compute laws yields consistently improved reasoning performance on multiple benchmarks, and uncovers synergistic effects across properties and laws. Project page: https://lore-project.github.io/","authors":["Junyu Zhang","Yifan Sun","Tianang Leng","Jingyan Shen","Liu Ziyin","Paul Pu Liang","Huan Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.07892v2","updated":"2025-12-19T18:46:41Z","published":"2024-11-12T15:56:48Z","title":"Mapping the Podcast Ecosystem with the Structured Podcast Research Corpus","summary":"Podcasts provide highly diverse content to a massive listener base through a unique on-demand modality. However, limited data has prevented large-scale computational analysis of the podcast ecosystem. To fill this gap, we introduce a massive dataset of over 1.1M podcast transcripts that is largely comprehensive of all English language podcasts available through public RSS feeds from May and June of 2020. This data is not limited to text, but rather includes audio features and speaker turns for a subset of 370K episodes, and speaker role inferences and other metadata for all 1.1M episodes. Using this data, we also conduct a foundational investigation into the content, structure, and responsiveness of this ecosystem. Together, our data and analyses open the door to continued computational research of this popular and impactful medium.","authors":["Benjamin Litterer","David Jurgens","Dallas Card"],"pdf_url":"","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2511.12712v2","updated":"2025-12-19T18:24:09Z","published":"2025-11-16T17:52:32Z","title":"Adaptive Focus Memory for Language Models","summary":"Large language models (LLMs) are increasingly deployed in multi-turn dialogue settings, yet their behavior remains bottlenecked by naive history management strategies. Replaying the full conversation at every turn is simple but costly, while recency-based truncation or static summarization often causes early, high-impact user constraints to drift out of effective context. As a result, models may retain text without reliably applying it when it matters.\n  We present Adaptive Focus Memory (AFM), a lightweight context management system that dynamically assigns each past message one of three fidelity levels: Full, Compressed, or Placeholder, based on semantic relevance, temporal decay, and importance classification. AFM packs messages chronologically under a fixed token budget, preserving critical constraints at high fidelity while allowing low-importance context to degrade gracefully.\n  We evaluate AFM on two multi-turn dialogue benchmarks designed to stress long-horizon constraint preservation: a safety-critical travel scenario involving a user with a severe peanut allergy, and a policy-critical tax compliance scenario involving an illegal evasion request. Under strict grading that requires both explicit constraint recall and appropriately conditioned generation, AFM succeeds in 83.3 percent of allergy runs where all baseline strategies fail, and preserves correct refusal behavior on the tax benchmark.\n  These results demonstrate that effective dialogue memory requires more than retaining prior text. Selectively allocating fidelity across past messages enables reliable constraint preservation under bounded context growth, without modifying model weights or introducing external retrieval infrastructure. We release an open-source implementation of AFM compatible with OpenAI-style chat APIs to support reproducible research and practical deployment.","authors":["Christopher Cruz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.22983v2","updated":"2025-12-19T18:19:10Z","published":"2025-09-26T22:33:19Z","title":"Same Content, Different Representations: A Controlled Study for Table QA","summary":"Table Question Answering (Table QA) in real-world settings must operate over both structured databases and semi-structured tables containing textual fields. However, existing benchmarks are tied to fixed data formats and have not systematically examined how representation itself affects model performance. We present the first controlled study that isolates the role of table representation by holding content constant while varying structure. Using a verbalization pipeline, we generate paired structured and semi-structured tables, enabling direct comparisons across modeling paradigms. To support detailed analysis, we introduce RePairTQA, a diagnostic benchmark with splits along table size, join requirements, query complexity, and schema quality. Our experiments reveal consistent trade-offs: SQL-based methods achieve high accuracy on structured inputs but degrade on semi-structured data, LLMs exhibit flexibility but reduced precision, and hybrid approaches strike a balance, particularly under noisy schemas. These effects intensify with larger tables and more complex queries. Ultimately, no single method excels across all conditions, and we highlight the central role of representation in shaping Table QA performance. Our findings provide actionable insights for model selection and design, paving the way for more robust hybrid approaches suited for diverse real-world data formats.","authors":["Yue Zhang","Seiji Maekawa","Nikita Bhutani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17843v1","updated":"2025-12-19T17:47:53Z","published":"2025-12-19T17:47:53Z","title":"ShareChat: A Dataset of Chatbot Conversations in the Wild","summary":"While Large Language Models (LLMs) have evolved into distinct platforms with unique interface designs and capabilities, existing public datasets treat models as generic text generators, stripping away the interface context that actively shapes user interaction. To address this limitation, we present ShareChat, a large-scale, cross-platform corpus comprising 142,808 conversations and over 660,000 turns collected from publicly shared URLs across five major platforms: ChatGPT, Claude, Gemini, Perplexity, and Grok. ShareChat distinguishes itself by preserving native platform affordances often lost in standard logs, including reasoning traces, source links, and code artifacts, while spanning 101 languages over the period from April 2023 to October 2025. Furthermore, ShareChat offers substantially longer context windows and greater interaction depth than prior datasets. We demonstrate the dataset's multifaceted utility through three representative analyses: (1) analyzing conversation completeness to measure user intent satisfaction; (2) evaluating source citation behaviors in content generation; and (3) conducting temporal analysis to track evolving usage patterns. This work provides the community with a vital and timely resource for understanding authentic user-LLM chatbot interactions in the wild.","authors":["Yueru Yan","Tuc Nguyen","Bo Su","Melissa Lieffers","Thai Le"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.22219v3","updated":"2025-12-19T17:35:31Z","published":"2025-07-29T20:35:35Z","title":"RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation","summary":"Preference-learning methods for machine translation (MT), such as Direct Preference Optimization (DPO), have shown strong gains but typically rely on large, carefully curated preference triplets and often struggle to generalize beyond their tuning domains. We propose Reinforcement Learning from Teacher-Model Refinement (RLfR), which replaces static triplets with on-policy, actor-conditioned refinements produced by a frozen teacher. At each step, the actor samples candidate translations, the teacher performs a minimal local edit of each draft, and the actor is reinforced to close the gap using a composite reward that combines scaled negative edit distance for lexical and structural fidelity with COMET for semantic adequacy. This formulation yields a stable, model-aware learning signal without requiring explicit preference datasets. Experiments on FLORES-200 (English to German, Spanish, Chinese, Korean, and Japanese) show that RLfR consistently outperforms strong MT-SFT, DPO, and fixed-reference RL baselines, improving semantic quality and entity preservation, and also achieves superior performance under LLM-based judge evaluations.","authors":["Dongyub Jude Lee","Zhenyi Ye","Pengcheng He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.10892v3","updated":"2025-12-19T17:14:07Z","published":"2025-06-12T16:55:35Z","title":"The Diffusion Duality","summary":"Uniform-state discrete diffusion models hold the promise of fast text generation due to their inherent ability to self-correct. However, they are typically outperformed by autoregressive models and masked diffusion models. In this work, we narrow this performance gap by leveraging a key insight: Uniform-state diffusion processes naturally emerge from an underlying Gaussian diffusion. Our method, Duo, transfers powerful techniques from Gaussian diffusion to improve both training and sampling. First, we introduce a curriculum learning strategy guided by the Gaussian process, doubling training speed by reducing variance. Models trained with curriculum learning surpass autoregressive models in zero-shot perplexity on 3 of 7 benchmarks. Second, we present Discrete Consistency Distillation, which adapts consistency distillation from the continuous to the discrete setting. This algorithm unlocks few-step generation in diffusion language models by accelerating sampling by two orders of magnitude. We provide the code, model checkpoints, and video tutorials on the project page: http://s-sahoo.github.io/duo","authors":["Subham Sekhar Sahoo","Justin Deschenaux","Aaron Gokaslan","Guanghan Wang","Justin Chiu","Volodymyr Kuleshov"],"pdf_url":"","comment":"ICML 2025. We provide the code at: https://github.com/s-sahoo/duo [v3] includes improved theory, clearer presentation, and a new future work section"},{"id":"http://arxiv.org/abs/2512.17776v1","updated":"2025-12-19T16:46:20Z","published":"2025-12-19T16:46:20Z","title":"DEER: A Comprehensive and Reliable Benchmark for Deep-Research Expert Reports","summary":"As large language models (LLMs) advance, deep research systems can generate expert-level reports via multi-step reasoning and evidence-based synthesis, but evaluating such reports remains challenging. Existing benchmarks often lack systematic criteria for expert reporting, evaluations that rely heavily on LLM judges can fail to capture issues that require expert judgment, and source verification typically covers only a limited subset of explicitly cited statements rather than report-wide factual reliability. We introduce DEER, a benchmark for evaluating expert-level deep research reports. DEER comprises 50 report-writing tasks spanning 13 domains and an expert-grounded evaluation taxonomy (7 dimensions, 25 sub-dimension) operationalized into 130 fine-grained rubric items. DEER further provides task-specific expert guidance to help LLM judges assess expert-level report quality more consistently. Complementing rubric-based assessment, we propose a document-level fact-checking architecture that extracts and verifies all claims across the entire report, including both cited and uncited ones, and quantifies external-evidence quality. DEER correlates closely with human expert judgments and yields interpretable diagnostics of system strengths and weaknesses.","authors":["Janghoon Han","Heegyu Kim","Changho Lee","Dahm Lee","Min Hyung Park","Hosung Song","Stanley Jungkyu Choi","Moontae Lee","Honglak Lee"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2512.17769v1","updated":"2025-12-19T16:41:16Z","published":"2025-12-19T16:41:16Z","title":"Bangla MedER: Multi-BERT Ensemble Approach for the Recognition of Bangla Medical Entity","summary":"Medical Entity Recognition (MedER) is an essential NLP task for extracting meaningful entities from the medical corpus. Nowadays, MedER-based research outcomes can remarkably contribute to the development of automated systems in the medical sector, ultimately enhancing patient care and outcomes. While extensive research has been conducted on MedER in English, low-resource languages like Bangla remain underexplored. Our work aims to bridge this gap. For Bangla medical entity recognition, this study first examined a number of transformer models, including BERT, DistilBERT, ELECTRA, and RoBERTa. We also propose a novel Multi-BERT Ensemble approach that outperformed all baseline models with the highest accuracy of 89.58%. Notably, it provides an 11.80% accuracy improvement over the single-layer BERT model, demonstrating its effectiveness for this task. A major challenge in MedER for low-resource languages is the lack of annotated datasets. To address this issue, we developed a high-quality dataset tailored for the Bangla MedER task. The dataset was used to evaluate the effectiveness of our model through multiple performance metrics, demonstrating its robustness and applicability. Our findings highlight the potential of Multi-BERT Ensemble models in improving MedER for Bangla and set the foundation for further advancements in low-resource medical NLP.","authors":["Tanjim Taharat Aurpa","Farzana Akter","Md. Mehedi Hasan","Shakil Ahmed","Shifat Ara Rafiq","Fatema Khan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.00496v2","updated":"2025-12-19T16:38:02Z","published":"2025-08-30T13:37:28Z","title":"ResearchQA: Evaluating Scholarly Question Answering at Scale Across 75 Fields with Survey-Mined Questions and Rubrics","summary":"Evaluating long-form responses to research queries heavily relies on expert annotators, restricting attention to areas like AI where researchers can conveniently enlist colleagues. Yet, research expertise is abundant: survey articles consolidate knowledge spread across the literature. We introduce ResearchQA, a resource for evaluating LLM systems by distilling survey articles from 75 research fields into 21K queries and 160K rubric items. Queries and rubrics are jointly derived from survey sections, where rubric items list query-specific answer evaluation criteria, i.e., citing papers, making explanations, and describing limitations. 31 Ph.D. annotators in 8 fields judge that 90% of queries reflect Ph.D. information needs and 87% of rubric items warrant emphasis of a sentence or longer. We leverage ResearchQA to evaluate 18 systems in 7.6K head-to-heads. No parametric or retrieval-augmented system we evaluate exceeds 70% on covering rubric items, and the highest-ranking system shows 75% coverage. Error analysis reveals that the highest-ranking system fully addresses less than 11% of citation rubric items, 48% of limitation items, and 49% of comparison items. We release our data to facilitate more comprehensive multi-field evaluations.","authors":["Li S. Yifei","Allen Chang","Chaitanya Malaviya","Mark Yatskar"],"pdf_url":"","comment":"12 pages main, 40 pages total, 15 figures"},{"id":"http://arxiv.org/abs/2506.09147v4","updated":"2025-12-19T16:35:50Z","published":"2025-06-10T18:01:42Z","title":"LLM-as-a-qualitative-judge: automating error analysis in natural language generation","summary":"Prompting large language models (LLMs) to evaluate generated text, known as LLM-as-a-judge, has become a standard evaluation approach in natural language generation (NLG), but is primarily used as a quantitative tool, i.e. with numerical scores as main outputs. In this work, we propose LLM-as-a-qualitative-judge, an LLM-based evaluation approach with the main output being a structured report of common issue types in the NLG system outputs. Our approach is targeted at providing developers with meaningful insights on what improvements can be done to a given NLG system and consists of two main steps, namely open-ended per-instance issue analysis and clustering of the discovered issues using an intuitive cumulative algorithm. We also introduce a strategy for evaluating the proposed approach, coupled with ~300 annotations of issues in instances from 12 NLG datasets. Our results show that instance-specific issues output by LLM-as-a-qualitative-judge match those annotated by humans in 2/3 cases, and that LLM-as-a-qualitative-judge is capable of producing error type reports resembling the reports composed by human annotators. We also demonstrate in a case study how the use of LLM-as-a-qualitative-judge can substantially improve NLG systems performance. Our code and data are publicly available at https://github.com/tunde-ajayi/llm-as-a-qualitative-judge.","authors":["Nadezhda Chirkova","Tunde Oluwaseyi Ajayi","Seth Aycock","Zain Muhammad Mujahid","Vladana Perlić","Ekaterina Borisova","Markarit Vartampetian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.10882v2","updated":"2025-12-19T16:35:45Z","published":"2025-12-11T18:11:46Z","title":"Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity","summary":"Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze emotions, the emergence of multimodal generative Artificial Intelligence (AI) promises great advances. However, we lack evidence about the effectiveness of multimodal AI in analyzing emotions in political communication. This paper addresses this gap by evaluating current multimodal large language models (mLLMs) in the video-based analysis of emotional arousal, using two complementary datasets of human-labeled video recordings. It finds that under ideal circumstances, mLLMs' emotional arousal ratings are highly reliable and exhibit little to no demographic bias. However, in recordings of real-world parliamentary debates, mLLMs' arousal ratings fail to deliver on this promise with potential negative consequences for downstream statistical inferences. This study therefore underscores the need for continued, thorough evaluation of emerging generative AI methods in multimodal political analysis and contributes a suitable replicable framework.","authors":["Hauke Licht"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17756v1","updated":"2025-12-19T16:28:57Z","published":"2025-12-19T16:28:57Z","title":"AncientBench: Towards Comprehensive Evaluation on Excavated and Transmitted Chinese Corpora","summary":"Comprehension of ancient texts plays an important role in archaeology and understanding of Chinese history and civilization. The rapid development of large language models needs benchmarks that can evaluate their comprehension of ancient characters. Existing Chinese benchmarks are mostly targeted at modern Chinese and transmitted documents in ancient Chinese, but the part of excavated documents in ancient Chinese is not covered. To meet this need, we propose the AncientBench, which aims to evaluate the comprehension of ancient characters, especially in the scenario of excavated documents. The AncientBench is divided into four dimensions, which correspond to the four competencies of ancient character comprehension: glyph comprehension, pronunciation comprehension, meaning comprehension, and contextual comprehension. The benchmark also contains ten tasks, including radical, phonetic radical, homophone, cloze, translation, and more, providing a comprehensive framework for evaluation. We convened archaeological researchers to conduct experimental evaluations, proposed an ancient model as baseline, and conducted extensive experiments on the currently best-performing large language models. The experimental results reveal the great potential of large language models in ancient textual scenarios as well as the gap with humans. Our research aims to promote the development and application of large language models in the field of archaeology and ancient Chinese language.","authors":["Zhihan Zhou","Daqian Shi","Rui Song","Lida Shi","Xiaolei Diao","Hao Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17752v1","updated":"2025-12-19T16:26:21Z","published":"2025-12-19T16:26:21Z","title":"Affect, Body, Cognition, Demographics, and Emotion: The ABCDE of Text Features for Computational Affective Science","summary":"Work in Computational Affective Science and Computational Social Science explores a wide variety of research questions about people, emotions, behavior, and health. Such work often relies on language data that is first labeled with relevant information, such as the use of emotion words or the age of the speaker. Although many resources and algorithms exist to enable this type of labeling, discovering, accessing, and using them remains a substantial impediment, particularly for practitioners outside of computer science. Here, we present the ABCDE dataset (Affect, Body, Cognition, Demographics, and Emotion), a large-scale collection of over 400 million text utterances drawn from social media, blogs, books, and AI-generated sources. The dataset is annotated with a wide range of features relevant to computational affective and social science. ABCDE facilitates interdisciplinary research across numerous fields, including affective science, cognitive science, the digital humanities, sociology, political science, and computational linguistics.","authors":["Jan Philip Wahle","Krishnapriya Vishnubhotla","Bela Gipp","Saif M. Mohammad"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.21041v2","updated":"2025-12-19T16:18:06Z","published":"2024-10-28T13:58:04Z","title":"Clean Up the Mess: Addressing Data Pollution in Cryptocurrency Abuse Reporting Services","summary":"Cryptocurrency abuse reporting services are a valuable data source about abusive blockchain addresses, prevalent types of cryptocurrency abuse, and their financial impact on victims. However, they may suffer data pollution due to their crowd-sourced nature. This work analyzes the extent and impact of data pollution in cryptocurrency abuse reporting services and proposes a novel LLM-based defense to address the pollution. We collect 289K abuse reports submitted over 6 years to two popular services and use them to answer three research questions. RQ1 analyzes the extent and impact of pollution. We show that spam reports will eventually flood unchecked abuse reporting services, with BitcoinAbuse receiving 75% of spam before stopping operations. We build a public dataset of 19,443 abuse reports labeled with 19 popular abuse types and use it to reveal the inaccuracy of user-reported abuse types. We identified 91 (0.1%) benign addresses reported, responsible for 60% of all the received funds. RQ2 examines whether we can automate identifying valid reports and their classification into abuse types. We propose an unsupervised LLM-based classifier that achieves an F1 score of 0.95 when classifying reports, an F1 of 0.89 when classifying out-of-distribution data, and an F1 of 0.99 when identifying spam reports. Our unsupervised LLM-based classifier clearly outperforms two baselines: a supervised classifier and a naive usage of the LLM. Finally, RQ3 demonstrates the usefulness of our LLM-based classifier for quantifying the financial impact of different cryptocurrency abuse types. We show that victim-reported losses heavily underestimate cybercriminal revenue by estimating a 29 times higher revenue from deposit transactions. We identified that investment scams have the highest financial impact and that extortions have lower conversion rates but compensate for them with massive email campaigns.","authors":["Gibran Gomez","Kevin van Liebergen","Davide Sanvito","Giuseppe Siracusano","Roberto Gonzalez","Juan Caballero"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.12508v4","updated":"2025-12-19T16:18:03Z","published":"2025-09-15T23:19:36Z","title":"Fun-ASR Technical Report","summary":"In recent years, automatic speech recognition (ASR) has witnessed transformative advancements driven by three complementary paradigms: data scaling, model size scaling, and deep integration with large language models (LLMs). However, LLMs are prone to hallucination, which can significantly degrade user experience in real-world ASR applications. In this paper, we present Fun-ASR, a large-scale, LLM-based ASR system that synergistically combines massive data, large model capacity, LLM integration, and reinforcement learning to achieve state-of-the-art performance across diverse and complex speech recognition scenarios. Moreover, Fun-ASR is specifically optimized for practical deployment, with enhancements in streaming capability, noise robustness, code-switching, hotword customization, and satisfying other real-world application requirements. Experimental results show that while most LLM-based ASR systems achieve strong performance on open-source benchmarks, they often underperform on real industry evaluation sets. Thanks to production-oriented optimizations, Fun-ASR achieves state-of-the-art performance on real application datasets, demonstrating its effectiveness and robustness in practical settings. The code and models are accessible at https://github.com/FunAudioLLM/Fun-ASR .","authors":["Keyu An","Yanni Chen","Zhigao Chen","Chong Deng","Zhihao Du","Changfeng Gao","Zhifu Gao","Bo Gong","Xiangang Li","Yabin Li","Ying Liu","Xiang Lv","Yunjie Ji","Yiheng Jiang","Bin Ma","Haoneng Luo","Chongjia Ni","Zexu Pan","Yiping Peng","Zhendong Peng","Peiyao Wang","Hao Wang","Haoxu Wang","Wen Wang","Wupeng Wang","Yuzhong Wu","Biao Tian","Zhentao Tan","Nan Yang","Bin Yuan","Jieping Ye","Jixing Yu","Qinglin Zhang","Kun Zou","Han Zhao","Shengkui Zhao","Jingren Zhou","Yanqiao Zhu"],"pdf_url":"","comment":"Authors are listed in alphabetical order. Work in progress"},{"id":"http://arxiv.org/abs/2512.17738v1","updated":"2025-12-19T16:17:23Z","published":"2025-12-19T16:17:23Z","title":"When the Gold Standard isn't Necessarily Standard: Challenges of Evaluating the Translation of User-Generated Content","summary":"User-generated content (UGC) is characterised by frequent use of non-standard language, from spelling errors to expressive choices such as slang, character repetitions, and emojis. This makes evaluating UGC translation particularly challenging: what counts as a \"good\" translation depends on the level of standardness desired in the output. To explore this, we examine the human translation guidelines of four UGC datasets, and derive a taxonomy of twelve non-standard phenomena and five translation actions (NORMALISE, COPY, TRANSFER, OMIT, CENSOR). Our analysis reveals notable differences in how UGC is treated, resulting in a spectrum of standardness in reference translations. Through a case study on large language models (LLMs), we show that translation scores are highly sensitive to prompts with explicit translation instructions for UGC, and that they improve when these align with the dataset's guidelines. We argue that when preserving UGC style is important, fair evaluation requires both models and metrics to be aware of translation guidelines. Finally, we call for clear guidelines during dataset creation and for the development of controllable, guideline-aware evaluation frameworks for UGC translation.","authors":["Lydia Nishimwe","Benoît Sagot","Rachel Bawden"],"pdf_url":"","comment":"10 pages, 19 pages with references and appendices"},{"id":"http://arxiv.org/abs/2412.17669v2","updated":"2025-12-19T15:52:00Z","published":"2024-12-23T15:54:15Z","title":"Generating Completions for Broca's Aphasic Sentences Using Large Language Models","summary":"Broca's aphasia is a type of aphasia characterized by non-fluent, effortful and agrammatic speech production with relatively good comprehension. Since traditional aphasia treatment methods are often time-consuming, labour-intensive, and do not reflect real-world conversations, applying natural language processing based approaches such as Large Language Models (LLMs) could potentially contribute to improving existing treatment approaches. To address this issue, we explore the use of sequence-to-sequence LLMs for completing Broca's aphasic sentences. We first generate synthetic Broca's aphasic data using a rule-based system designed to mirror the linguistic characteristics of Broca's aphasic speech. Using this synthetic data (without authentic aphasic samples), we then fine-tune four pre-trained LLMs on the task of completing agrammatic sentences. We evaluate our fine-tuned models on both synthetic and authentic Broca's aphasic data. We demonstrate LLMs' capability for reconstructing agrammatic sentences, with the models showing improved performance with longer input utterances. Our result highlights the LLMs' potential in advancing communication aids for individuals with Broca's aphasia and possibly other clinical populations.","authors":["Sijbren van Vaals","Yevgen Matusevych","Frank Tsiwah"],"pdf_url":"","comment":"in IEEE Journal of Biomedical and Health Informatics"},{"id":"http://arxiv.org/abs/2512.17677v1","updated":"2025-12-19T15:17:19Z","published":"2025-12-19T15:17:19Z","title":"Toward Ethical AI Through Bayesian Uncertainty in Neural Question Answering","summary":"We explore Bayesian reasoning as a means to quantify uncertainty in neural networks for question answering. Starting with a multilayer perceptron on the Iris dataset, we show how posterior inference conveys confidence in predictions. We then extend this to language models, applying Bayesian inference first to a frozen head and finally to LoRA-adapted transformers, evaluated on the CommonsenseQA benchmark. Rather than aiming for state-of-the-art accuracy, we compare Laplace approximations against maximum a posteriori (MAP) estimates to highlight uncertainty calibration and selective prediction. This allows models to abstain when confidence is low. An ``I don't know'' response not only improves interpretability but also illustrates how Bayesian methods can contribute to more responsible and ethical deployment of neural question-answering systems.","authors":["Riccardo Di Sipio"],"pdf_url":"","comment":"14 pages, 8 figures,"},{"id":"http://arxiv.org/abs/2512.17657v1","updated":"2025-12-19T14:56:28Z","published":"2025-12-19T14:56:28Z","title":"Peeking Into The Future For Contextual Biasing","summary":"While end-to-end (E2E) automatic speech recognition (ASR) models excel at general transcription, they struggle to recognize rare or unseen named entities (e.g., contact names, locations), which are critical for downstream applications like virtual assistants. In this paper, we propose a contextual biasing method for attention based encoder decoder (AED) models using a list of candidate named entities. Instead of predicting only the next token, we simultaneously predict multiple future tokens, enabling the model to \"peek into the future\" and score potential candidate entities in the entity list. Moreover, our approach leverages the multi-token prediction logits directly without requiring additional entity encoders or cross-attention layers, significantly reducing architectural complexity. Experiments on Librispeech demonstrate that our approach achieves up to 50.34% relative improvement in named entity word error rate compared to the baseline AED model.","authors":["Ramaneswaran Selvakumar","Cindy Tseng","Eesung Kim","Vijendra Raj Apsingekar","Yun Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17648v1","updated":"2025-12-19T14:48:59Z","published":"2025-12-19T14:48:59Z","title":"Simulstream: Open-Source Toolkit for Evaluation and Demonstration of Streaming Speech-to-Text Translation Systems","summary":"Streaming Speech-to-Text Translation (StreamST) requires producing translations concurrently with incoming speech, imposing strict latency constraints and demanding models that balance partial-information decision-making with high translation quality. Research efforts on the topic have so far relied on the SimulEval repository, which is no longer maintained and does not support systems that revise their outputs. In addition, it has been designed for simulating the processing of short segments, rather than long-form audio streams, and it does not provide an easy method to showcase systems in a demo. As a solution, we introduce simulstream, the first open-source framework dedicated to unified evaluation and demonstration of StreamST systems. Designed for long-form speech processing, it supports not only incremental decoding approaches, but also re-translation methods, enabling for their comparison within the same framework both in terms of quality and latency. In addition, it also offers an interactive web interface to demo any system built within the tool.","authors":["Marco Gaido","Sara Papi","Mauro Cettolo","Matteo Negri","Luisa Bentivogli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17639v1","updated":"2025-12-19T14:41:09Z","published":"2025-12-19T14:41:09Z","title":"Linear Personality Probing and Steering in LLMs: A Big Five Study","summary":"Large language models (LLMs) exhibit distinct and consistent personalities that greatly impact trust and engagement. While this means that personality frameworks would be highly valuable tools to characterize and control LLMs' behavior, current approaches remain either costly (post-training) or brittle (prompt engineering). Probing and steering via linear directions has recently emerged as a cheap and efficient alternative. In this paper, we investigate whether linear directions aligned with the Big Five personality traits can be used for probing and steering model behavior. Using Llama 3.3 70B, we generate descriptions of 406 fictional characters and their Big Five trait scores. We then prompt the model with these descriptions and questions from the Alpaca questionnaire, allowing us to sample hidden activations that vary along personality traits in known, quantifiable ways. Using linear regression, we learn a set of per-layer directions in activation space, and test their effectiveness for probing and steering model behavior. Our results suggest that linear directions aligned with trait-scores are effective probes for personality detection, while their steering capabilities strongly depend on context, producing reliable effects in forced-choice tasks but limited influence in open-ended generation or when additional context is present in the prompt.","authors":["Michel Frising","Daniel Balcells"],"pdf_url":"","comment":"29 pages, 6 figures"},{"id":"http://arxiv.org/abs/2512.17630v1","updated":"2025-12-19T14:33:14Z","published":"2025-12-19T14:33:14Z","title":"Confidence-Credibility Aware Weighted Ensembles of Small LLMs Outperform Large LLMs in Emotion Detection","summary":"This paper introduces a confidence-weighted, credibility-aware ensemble framework for text-based emotion detection, inspired by Condorcet's Jury Theorem (CJT). Unlike conventional ensembles that often rely on homogeneous architectures, our approach combines architecturally diverse small transformer-based large language models (sLLMs) - BERT, RoBERTa, DistilBERT, DeBERTa, and ELECTRA, each fully fine-tuned for emotion classification. To preserve error diversity, we minimize parameter convergence while taking advantage of the unique biases of each model. A dual-weighted voting mechanism integrates both global credibility (validation F1 score) and local confidence (instance-level probability) to dynamically weight model contributions. Experiments on the DAIR-AI dataset demonstrate that our credibility-confidence ensemble achieves a macro F1 score of 93.5 percent, surpassing state-of-the-art benchmarks and significantly outperforming large-scale LLMs, including Falcon, Mistral, Qwen, and Phi, even after task-specific Low-Rank Adaptation (LoRA). With only 595M parameters in total, our small LLMs ensemble proves more parameter-efficient and robust than models up to 7B parameters, establishing that carefully designed ensembles of small, fine-tuned models can outperform much larger LLMs in specialized natural language processing (NLP) tasks such as emotion detection.","authors":["Menna Elgabry","Ali Hamdi"],"pdf_url":"","comment":"Accepted at IRICT 2025"},{"id":"http://arxiv.org/abs/2507.06261v6","updated":"2025-12-19T14:25:46Z","published":"2025-07-07T17:36:04Z","title":"Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities","summary":"In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that excels at multimodal understanding and it is now able to process up to 3 hours of video content. Its unique combination of long context, multimodal and reasoning capabilities can be combined to unlock new agentic workflows. Gemini 2.5 Flash provides excellent reasoning abilities at a fraction of the compute and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high performance at low latency and cost. Taken together, the Gemini 2.X model generation spans the full Pareto frontier of model capability vs cost, allowing users to explore the boundaries of what is possible with complex agentic problem solving.","authors":["Gheorghe Comanici","Eric Bieber","Mike Schaekermann","Ice Pasupat","Noveen Sachdeva","Inderjit Dhillon","Marcel Blistein","Ori Ram","Dan Zhang","Evan Rosen","Luke Marris","Sam Petulla","Colin Gaffney","Asaf Aharoni","Nathan Lintz","Tiago Cardal Pais","Henrik Jacobsson","Idan Szpektor","Nan-Jiang Jiang","Krishna Haridasan","Ahmed Omran","Nikunj Saunshi","Dara Bahri","Gaurav Mishra","Eric Chu","Toby Boyd","Brad Hekman","Aaron Parisi","Chaoyi Zhang","Kornraphop Kawintiranon","Tania Bedrax-Weiss","Oliver Wang","Ya Xu","Ollie Purkiss","Uri Mendlovic","Ilaï Deutel","Nam Nguyen","Adam Langley","Flip Korn","Lucia Rossazza","Alexandre Ramé","Sagar Waghmare","Helen Miller","Nathan Byrd","Ashrith Sheshan","Raia Hadsell","Sangnie Bhardwaj","Pawel Janus","Tero Rissa","Dan Horgan","Alvin Abdagic","Lior Belenki","James Allingham","Anima Singh","Theo Guidroz","Srivatsan Srinivasan","Herman Schmit","Kristen Chiafullo","Andre Elisseeff","Nilpa Jha","Prateek Kolhar","Leonard Berrada","Frank Ding","Xiance Si","Shrestha Basu Mallick","Franz Och","Sofia Erell","Eric Ni","Tejasi Latkar","Sherry Yang","Petar Sirkovic","Ziqiang Feng","Robert Leland","Rachel Hornung","Gang Wu","Charles Blundell","Hamidreza Alvari","Po-Sen Huang","Cathy Yip","Sanja Deur","Li Liu","Gabriela Surita","Pablo Duque","Dima Damen","Johnson Jia","Arthur Guez","Markus Mircea","Animesh Sinha","Alberto Magni","Paweł Stradomski","Tal Marian","Vlado Galić","Wenhu Chen","Hisham Husain","Achintya Singhal","Dominik Grewe","François-Xavier Aubet","Shuang Song","Lorenzo Blanco","Leland Rechis","Lewis Ho","Rich Munoz","Kelvin Zheng","Jessica Hamrick","Kevin Mather","Hagai Taitelbaum","Eliza Rutherford","Yun Lei","Kuangyuan Chen","Anand Shukla","Erica Moreira","Eric Doi","Berivan Isik","Nir Shabat","Dominika Rogozińska","Kashyap Kolipaka","Jason Chang","Eugen Vušak","Srinivasan Venkatachary","Shadi Noghabi","Tarun Bharti","Younghoon Jun","Aleksandr Zaks","Simon Green","Jeshwanth Challagundla","William Wong","Muqthar Mohammad","Dean Hirsch","Yong Cheng","Iftekhar Naim","Lev Proleev","Damien Vincent","Aayush Singh","Maxim Krikun","Dilip Krishnan","Zoubin Ghahramani","Aviel Atias","Rajeev Aggarwal","Christo Kirov","Dimitrios Vytiniotis","Christy Koh","Alexandra Chronopoulou","Pawan Dogra","Vlad-Doru Ion","Gladys Tyen","Jason Lee","Felix Weissenberger","Trevor Strohman","Ashwin Balakrishna","Jack Rae","Marko Velic","Raoul de Liedekerke","Oded Elyada","Wentao Yuan","Canoee Liu","Lior Shani","Sergey Kishchenko","Bea Alessio","Yandong Li","Richard Song","Sam Kwei","Orion Jankowski","Aneesh Pappu","Youhei Namiki","Yenai Ma","Nilesh Tripuraneni","Colin Cherry","Marissa Ikonomidis","Yu-Cheng Ling","Colin Ji","Beka Westberg","Auriel Wright","Da Yu","David Parkinson","Swaroop Ramaswamy","Jerome Connor","Soheil Hassas Yeganeh","Snchit Grover","George Kenwright","Lubo Litchev","Chris Apps","Alex Tomala","Felix Halim","Alex Castro-Ros","Zefei Li","Anudhyan Boral","Pauline Sho","Michal Yarom","Eric Malmi","David Klinghoffer","Rebecca Lin","Alan Ansell","Pradeep Kumar S","Shubin Zhao","Siqi Zuo","Adam Santoro","Heng-Tze Cheng","Solomon Demmessie","Yuchi Liu","Nicole Brichtova","Allie Culp","Nathaniel Braun","Dan Graur","Will Ng","Nikhil Mehta","Aaron Phillips","Patrik Sundberg","Varun Godbole","Fangyu Liu","Yash Katariya","David Rim","Mojtaba Seyedhosseini","Sean Ammirati","Jonas Valfridsson","Mahan Malihi","Timothy Knight","Andeep Toor","Thomas Lampe","Abe Ittycheriah","Lewis Chiang","Chak Yeung","Alexandre Fréchette","Jinmeng Rao","Huisheng Wang","Himanshu Srivastava","Richard Zhang","Rocky Rhodes","Ariel Brand","Dean Weesner","Ilya Figotin","Felix Gimeno","Rachana Fellinger","Pierre Marcenac","José Leal","Eyal Marcus","Victor Cotruta","Rodrigo Cabrera","Sheryl Luo","Dan Garrette","Vera Axelrod","Sorin Baltateanu","David Barker","Dongkai Chen","Horia Toma","Ben Ingram","Jason Riesa","Chinmay Kulkarni","Yujing Zhang","Hongbin Liu","Chao Wang","Martin Polacek","Will Wu","Kai Hui","Adrian N Reyes","Yi Su","Megan Barnes","Ishaan Malhi","Anfal Siddiqui","Qixuan Feng","Mihai Damaschin","Daniele Pighin","Andreas Steiner","Samuel Yang","Ramya Sree Boppana","Simeon Ivanov","Arun Kandoor","Aditya Shah","Asier Mujika","Da Huang","Christopher A. Choquette-Choo","Mohak Patel","Tianhe Yu","Toni Creswell"," Jerry"," Liu","Catarina Barros","Yasaman Razeghi","Aurko Roy","Phil Culliton","Binbin Xiong","Jiaqi Pan","Thomas Strohmann","Tolly Powell","Babi Seal","Doug DeCarlo","Pranav Shyam","Kaan Katircioglu","Xuezhi Wang","Cassidy Hardin","Immanuel Odisho","Josef Broder","Oscar Chang","Arun Nair","Artem Shtefan","Maura O'Brien","Manu Agarwal","Sahitya Potluri","Siddharth Goyal","Amit Jhindal","Saksham Thakur","Yury Stuken","James Lyon","Kristina Toutanova","Fangxiaoyu Feng","Austin Wu","Ben Horn","Alek Wang","Alex Cullum","Gabe Taubman","Disha Shrivastava","Chongyang Shi","Hamish Tomlinson","Roma Patel","Tao Tu","Ada Maksutaj Oflazer","Francesco Pongetti","Mingyao Yang","Adrien Ali Taïga","Vincent Perot","Nuo Wang Pierse","Feng Han","Yoel Drori","Iñaki Iturrate","Ayan Chakrabarti","Legg Yeung","Dave Dopson","Yi-ting Chen","Apoorv Kulshreshtha","Tongfei Guo","Philip Pham","Tal Schuster","Junquan Chen","Alex Polozov","Jinwei Xing","Huanjie Zhou","Praneeth Kacham","Doron Kukliansky","Antoine Miech","Sergey Yaroshenko","Ed Chi","Sholto Douglas","Hongliang Fei","Mathieu Blondel","Preethi Myla","Lior Madmoni","Xing Wu","Daniel Keysers","Kristian Kjems","Isabela Albuquerque","Lijun Yu","Joel D'sa","Michelle Plantan","Vlad Ionescu","Jaume Sanchez Elias","Abhirut Gupta","Manish Reddy Vuyyuru","Fred Alcober","Tong Zhou","Kaiyang Ji","Florian Hartmann","Subha Puttagunta","Hugo Song","Ehsan Amid","Anca Stefanoiu","Andrew Lee","Paul Pucciarelli","Emma Wang","Amit Raul","Slav Petrov","Isaac Tian","Valentin Anklin","Nana Nti","Victor Gomes","Max Schumacher","Grace Vesom","Alex Panagopoulos","Konstantinos Bousmalis","Daniel Andor","Josh Jacob","Yuan Zhang","Bill Rosgen","Matija Kecman","Matthew Tung","Alexandra Belias","Noah Goodman","Paul Covington","Brian Wieder","Nikita Saxena","Elnaz Davoodi","Muhuan Huang","Sharath Maddineni","Vincent Roulet","Folawiyo Campbell-Ajala","Pier Giuseppe Sessa"," Xintian"," Wu","Guangda Lai","Paul Collins","Alex Haig","Vytenis Sakenas","Xiaowei Xu","Marissa Giustina","Laurent El Shafey","Pichi Charoenpanit","Shefali Garg","Joshua Ainslie","Boone Severson","Montse Gonzalez Arenas","Shreya Pathak","Sujee Rajayogam","Jie Feng","Michiel Bakker","Sheng Li","Nevan Wichers","Jamie Rogers","Xinyang Geng","Yeqing Li","Rolf Jagerman","Chao Jia","Nadav Olmert","David Sharon","Matthew Mauger","Sandeep Mariserla","Hongxu Ma","Megha Mohabey","Kyuyeun Kim","Alek Andreev","Scott Pollom","Juliette Love","Vihan Jain","Priyanka Agrawal","Yannick Schroecker","Alisa Fortin","Manfred Warmuth","Ji Liu","Andrew Leach","Irina Blok","Ganesh Poomal Girirajan","Roee Aharoni","Benigno Uria","Andrei Sozanschi","Dan Goldberg","Lucian Ionita","Marco Tulio Ribeiro","Martin Zlocha","Vighnesh Birodkar","Sami Lachgar","Liangzhe Yuan","Himadri Choudhury","Matt Ginsberg","Fei Zheng","Gregory Dibb","Emily Graves","Swachhand Lokhande","Gabriel Rasskin","George-Cristian Muraru","Corbin Quick","Sandeep Tata","Pierre Sermanet","Aditya Chawla","Itay Karo","Yan Wang","Susan Zhang","Orgad Keller","Anca Dragan","Guolong Su","Ian Chou","Xi Liu","Yiqing Tao","Shruthi Prabhakara","Marc Wilson","Ruibo Liu","Shibo Wang","Georgie Evans","David Du","Alfonso Castaño","Gautam Prasad","Mona El Mahdy","Sebastian Gerlach","Machel Reid","Jarrod Kahn","Amir Zait","Thanumalayan Sankaranarayana Pillai","Thatcher Ulrich","Guanyu Wang","Jan Wassenberg","Efrat Farkash","Kiran Yalasangi","Congchao Wang","Maria Bauza","Simon Bucher","Ting Liu","Jun Yan","Gary Leung","Vikas Sindhwani","Parker Barnes","Avi Singh","Ivan Jurin","Jichuan Chang","Niket Kumar Bhumihar","Sivan Eiger","Gui Citovsky","Ben Withbroe","Zhang Li","Siyang Xue","Niccolò Dal Santo","Georgi Stoyanov","Yves Raimond","Steven Zheng","Yilin Gao","Vít Listík","Sławek Kwasiborski","Rachel Saputro","Adnan Ozturel","Ganesh Mallya","Kushal Majmundar","Ross West","Paul Caron","Jinliang Wei","Lluis Castrejon","Sharad Vikram","Deepak Ramachandran","Nikhil Dhawan","Jiho Park","Sara Smoot","George van den Driessche","Yochai Blau","Chase Malik","Wei Liang","Roy Hirsch","Cicero Nogueira dos Santos","Eugene Weinstein","Aäron van den Oord","Sid Lall","Nicholas FitzGerald","Zixuan Jiang","Xuan Yang","Dale Webster","Ali Elqursh","Aedan Pope","Georges Rotival","David Raposo","Wanzheng Zhu","Jeff Dean","Sami Alabed","Dustin Tran","Arushi Gupta","Zach Gleicher","Jessica Austin","Edouard Rosseel","Megh Umekar","Dipanjan Das","Yinghao Sun","Kai Chen","Karolis Misiunas","Xiang Zhou","Yixian Di","Alyssa Loo","Josh Newlan","Bo Li","Vinay Ramasesh","Ying Xu","Alex Chen","Sudeep Gandhe","Radu Soricut","Nikita Gupta","Shuguang Hu","Seliem El-Sayed","Xavier Garcia","Idan Brusilovsky","Pu-Chin Chen","Andrew Bolt","Lu Huang","Alex Gurney","Zhiying Zhang","Alexander Pritzel","Jarek Wilkiewicz","Bryan Seybold","Bhargav Kanagal Shamanna","Felix Fischer","Josef Dean","Karan Gill","Ross Mcilroy","Abhishek Bhowmick","Jeremy Selier","Antoine Yang","Derek Cheng","Vladimir Magay","Jie Tan","Dhriti Varma","Christian Walder","Tomas Kocisky","Ryo Nakashima","Paul Natsev","Mike Kwong","Ionel Gog","Chiyuan Zhang","Sander Dieleman","Thomas Jimma","Andrey Ryabtsev","Siddhartha Brahma","David Steiner","Dayou Du","Ante Žužul","Mislav Žanić","Mukund Raghavachari","Willi Gierke","Zeyu Zheng","Dessie Petrova","Yann Dauphin","Yuchuan Liu","Ido Kessler","Steven Hand","Chris Duvarney","Seokhwan Kim","Hyo Lee","Léonard Hussenot","Jeffrey Hui","Josh Smith","Deepali Jain","Jiawei Xia","Gaurav Singh Tomar","Keyvan Amiri","Du Phan","Fabian Fuchs","Tobias Weyand","Nenad Tomasev","Alexandra Cordell","Xin Liu","Jonathan Mallinson","Pankaj Joshi","Andy Crawford","Arun Suggala","Steve Chien","Nick Fernando","Mariella Sanchez-Vargas","Duncan Williams","Phil Crone","Xiyang Luo","Igor Karpov","Jyn Shan","Terry Thurk","Robin Strudel","Paul Voigtlaender","Piyush Patil","Tim Dozat","Ali Khodaei","Sahil Singla","Piotr Ambroszczyk","Qiyin Wu","Yifan Chang","Brian Roark","Chaitra Hegde","Tianli Ding","Angelos Filos","Zhongru Wu","André Susano Pinto","Shuang Liu","Saarthak Khanna","Aditya Pandey","Siobhan Mcloughlin","Qiujia Li","Sam Haves","Allan Zhou","Elena Buchatskaya","Isabel Leal","Peter de Boursac","Nami Akazawa","Nina Anderson","Terry Chen","Krishna Somandepalli","Chen Liang","Sheela Goenka","Stephanie Winkler","Alexander Grushetsky","Yifan Ding","Jamie Smith","Fan Ye","Jordi Pont-Tuset","Eric Li","Ruichao Li","Tomer Golany","Dawid Wegner","Tao Jiang","Omer Barak","Yuan Shangguan","Eszter Vértes","Renee Wong","Jörg Bornschein","Alex Tudor","Michele Bevilacqua","Tom Schaul","Ankit Singh Rawat","Yang Zhao","Kyriakos Axiotis","Lei Meng","Cory McLean","Jonathan Lai","Jennifer Beattie","Nate Kushman","Yaxin Liu","Blair Kutzman","Fiona Lang","Jingchen Ye","Praneeth Netrapalli","Pushkar Mishra","Myriam Khan","Megha Goel","Rob Willoughby","David Tian","Honglei Zhuang","JD Chen","Zak Tsai","Tasos Kementsietsidis","Arjun Khare","James Keeling","Keyang Xu","Nathan Waters","Florent Altché","Ashok Popat","Bhavishya Mittal","David Saxton","Dalia El Badawy","Michael Mathieu","Zheng Zheng","Hao Zhou","Nishant Ranka","Richard Shin","Qingnan Duan","Tim Salimans","Ioana Mihailescu","Uri Shaham","Ming-Wei Chang","Yannis Assael","Nishanth Dikkala","Martin Izzard","Vincent Cohen-Addad","Cat Graves","Vlad Feinberg","Grace Chung","DJ Strouse","Danny Karmon","Sahand Sharifzadeh","Zoe Ashwood","Khiem Pham","Jon Blanton","Alex Vasiloff","Jarred Barber","Mark Geller","Aurick Zhou","Fedir Zubach","Tzu-Kuo Huang","Lei Zhang","Himanshu Gupta","Matt Young","Julia Proskurnia","Ronny Votel","Valentin Gabeur","Gabriel Barcik","Aditya Tripathi","Hongkun Yu","Geng Yan","Beer Changpinyo","Filip Pavetić","Amy Coyle","Yasuhisa Fujii","Jorge Gonzalez Mendez","Tianhao Zhou","Harish Rajamani","Blake Hechtman","Eddie Cao","Da-Cheng Juan","Yi-Xuan Tan","Valentin Dalibard","Yilun Du","Natalie Clay","Kaisheng Yao","Wenhao Jia","Dimple Vijaykumar","Yuxiang Zhou","Xinyi Bai","Wei-Chih Hung","Steven Pecht","Georgi Todorov","Nikhil Khadke","Pramod Gupta","Preethi Lahoti","Arnaud Autef","Karthik Duddu","James Lee-Thorp","Alexander Bykovsky","Tautvydas Misiunas","Sebastian Flennerhag","Santhosh Thangaraj","Jed McGiffin","Zack Nado","Markus Kunesch","Andreas Noever","Amir Hertz","Marco Liang","Victor Stone","Evan Palmer","Samira Daruki","Arijit Pramanik","Siim Põder","Austin Kyker","Mina Khan","Evgeny Sluzhaev","Marvin Ritter","Avraham Ruderman","Wenlei Zhou","Chirag Nagpal","Kiran Vodrahalli","George Necula","Paul Barham","Ellie Pavlick","Jay Hartford","Izhak Shafran","Long Zhao","Maciej Mikuła","Tom Eccles","Hidetoshi Shimokawa","Kanav Garg","Luke Vilnis","Hanwen Chen","Ilia Shumailov","Kuang-Huei Lee","Abdelrahman Abdelhamed","Meiyan Xie","Vered Cohen","Ester Hlavnova","Dan Malkin","Chawin Sitawarin","James Lottes","Pauline Coquinot","Tianli Yu","Sandeep Kumar","Jingwei Zhang","Aroma Mahendru","Zafarali Ahmed","James Martens","Tao Chen","Aviel Boag","Daiyi Peng","Coline Devin","Arseniy Klimovskiy","Mary Phuong","Danny Vainstein","Jin Xie","Bhuvana Ramabhadran","Nathan Howard","Xinxin Yu","Gitartha Goswami","Jingyu Cui","Sam Shleifer","Mario Pinto","Chih-Kuan Yeh","Ming-Hsuan Yang","Sara Javanmardi","Dan Ethier","Chace Lee","Jordi Orbay","Suyog Kotecha","Carla Bromberg","Pete Shaw","James Thornton","Adi Gerzi Rosenthal","Shane Gu","Matt Thomas","Ian Gemp","Aditya Ayyar","Asahi Ushio","Aarush Selvan","Joel Wee","Chenxi Liu","Maryam Majzoubi","Weiren Yu","Jake Abernethy","Tyler Liechty","Renke Pan","Hoang Nguyen"," Qiong"," Hu","Sarah Perrin","Abhinav Arora","Emily Pitler","Weiyi Wang","Kaushik Shivakumar","Flavien Prost","Ben Limonchik","Jing Wang","Yi Gao","Timothee Cour","Shyamal Buch","Huan Gui","Maria Ivanova","Philipp Neubeck","Kelvin Chan","Lucy Kim","Huizhong Chen","Naman Goyal","Da-Woon Chung","Lu Liu","Yao Su","Anastasia Petrushkina","Jiajun Shen","Armand Joulin","Yuanzhong Xu","Stein Xudong Lin","Yana Kulizhskaya","Ciprian Chelba","Shobha Vasudevan","Eli Collins","Vasilisa Bashlovkina","Tony Lu","Doug Fritz","Jongbin Park","Yanqi Zhou","Chen Su","Richard Tanburn","Mikhail Sushkov","Mitchelle Rasquinha","Jinning Li","Jennifer Prendki","Yiming Li","Pallavi LV","Shriya Sharma","Hen Fitoussi","Hui Huang","Andrew Dai","Phuong Dao","Mike Burrows","Henry Prior","Danfeng Qin","Golan Pundak","Lars Lowe Sjoesund","Art Khurshudov","Zhenkai Zhu","Albert Webson","Elizabeth Kemp","Tat Tan","Saurabh Agrawal","Susie Sargsyan","Liqun Cheng","Jim Stephan","Tom Kwiatkowski","David Reid","Arunkumar Byravan","Assaf Hurwitz Michaely","Nicolas Heess","Luowei Zhou","Sonam Goenka","Viral Carpenter","Anselm Levskaya","Bo Wang","Reed Roberts","Rémi Leblond","Sharat Chikkerur","Stav Ginzburg","Max Chang","Robert Riachi"," Chuqiao"," Xu","Zalán Borsos","Michael Pliskin","Julia Pawar","Morgane Lustman","Hannah Kirkwood","Ankit Anand","Aditi Chaudhary","Norbert Kalb","Kieran Milan","Sean Augenstein","Anna Goldie","Laurel Prince","Karthik Raman","Yanhua Sun","Vivian Xia","Aaron Cohen","Zhouyuan Huo","Josh Camp","Seher Ellis","Lukas Zilka","David Vilar Torres","Lisa Patel","Sho Arora","Betty Chan","Jonas Adler","Kareem Ayoub","Jacky Liang","Fayaz Jamil","Jiepu Jiang","Simon Baumgartner","Haitian Sun","Yael Karov","Yaroslav Akulov","Hui Zheng","Irene Cai","Claudio Fantacci","James Rubin","Alex Rav Acha","Mengchao Wang","Nina D'Souza","Rohit Sathyanarayana","Shengyang Dai","Simon Rowe","Andrey Simanovsky","Omer Goldman","Yuheng Kuang","Xiaoyue Pan","Andrew Rosenberg","Tania Rojas-Esponda","Praneet Dutta","Amy Zeng","Irina Jurenka","Greg Farquhar","Yamini Bansal","Shariq Iqbal","Becca Roelofs","Ga-Young Joung","Parker Beak","Changwan Ryu","Ryan Poplin","Yan Wu","Jean-Baptiste Alayrac","Senaka Buthpitiya","Olaf Ronneberger","Caleb Habtegebriel","Wei Li","Paul Cavallaro","Aurora Wei","Guy Bensky","Timo Denk","Harish Ganapathy","Jeff Stanway","Pratik Joshi","Francesco Bertolini","Jessica Lo","Olivia Ma","Zachary Charles","Geta Sampemane","Himanshu Sahni","Xu Chen","Harry Askham","David Gaddy","Peter Young","Jiewen Tan","Matan Eyal","Arthur Bražinskas","Li Zhong","Zhichun Wu","Mark Epstein","Kai Bailey","Andrew Hard","Kamyu Lee","Sasha Goldshtein","Alex Ruiz","Mohammed Badawi","Matthias Lochbrunner","JK Kearns","Ashley Brown","Fabio Pardo","Theophane Weber","Haichuan Yang","Pan-Pan Jiang","Berkin Akin","Zhao Fu","Marcus Wainwright","Chi Zou","Meenu Gaba","Pierre-Antoine Manzagol","Wendy Kan","Yang Song","Karina Zainullina","Rui Lin","Jeongwoo Ko","Salil Deshmukh","Apoorv Jindal","James Svensson","Divya Tyam","Heri Zhao","Christine Kaeser-Chen","Scott Baird","Pooya Moradi","Jamie Hall","Qiuchen Guo","Vincent Tsang","Bowen Liang","Fernando Pereira","Suhas Ganesh","Ivan Korotkov","Jakub Adamek","Sridhar Thiagarajan","Vinh Tran","Charles Chen","Chris Tar","Sanil Jain","Ishita Dasgupta","Taylan Bilal","David Reitter","Kai Zhao","Giulia Vezzani","Yasmin Gehman","Pulkit Mehta","Lauren Beltrone","Xerxes Dotiwalla","Sergio Guadarrama","Zaheer Abbas","Stefani Karp","Petko Georgiev","Chun-Sung Ferng","Marc Brockschmidt","Liqian Peng","Christoph Hirnschall","Vikas Verma","Yingying Bi","Ying Xiao","Avigail Dabush","Kelvin Xu","Phil Wallis","Randall Parker","Qifei Wang","Yang Xu","Ilkin Safarli","Dinesh Tewari","Yin Zhang","Seungyeon Kim","Andrea Gesmundo","Mackenzie Thomas","Sergey Levi","Ahmed Chowdhury","Kanishka Rao","Peter Garst","Sam Conway-Rahman","Helen Ran","Kay McKinney","Zhisheng Xiao","Wenhao Yu","Rohan Agrawal","Axel Stjerngren","Catalin Ionescu","Jingjing Chen","Vivek Sharma","Justin Chiu","Fei Liu","Ken Franko","Clayton Sanford","Xingyu Cai","Paul Michel","Sanjay Ganapathy","Jane Labanowski","Zachary Garrett","Ben Vargas","Sean Sun","Bryan Gale","Thomas Buschmann","Guillaume Desjardins","Nimesh Ghelani","Palak Jain","Mudit Verma","Chulayuth Asawaroengchai","Julian Eisenschlos","Jitendra Harlalka","Hideto Kazawa","Don Metzler","Joshua Howland","Ying Jian","Jake Ades","Viral Shah","Tynan Gangwani","Seungji Lee","Roman Ring","Steven M. Hernandez","Dean Reich","Amer Sinha","Ashutosh Sathe","Joe Kovac","Ashleah Gill","Ajay Kannan","Andrea D'olimpio","Martin Sevenich","Jay Whang","Been Kim","Khe Chai Sim","Jilin Chen","Jiageng Zhang","Shuba Lall","Yossi Matias","Bill Jia","Abe Friesen","Sara Nasso","Ashish Thapliyal","Bryan Perozzi","Ting Yu","Anna Shekhawat","Safeen Huda","Peter Grabowski","Eric Wang","Ashwin Sreevatsa","Hilal Dib","Mehadi Hassen","Parker Schuh","Vedrana Milutinovic","Chris Welty","Michael Quinn","Ali Shah","Bangju Wang","Gabe Barth-Maron","Justin Frye","Natalie Axelsson","Tao Zhu","Yukun Ma","Irene Giannoumis","Hanie Sedghi","Chang Ye","Yi Luan","Kevin Aydin","Bilva Chandra","Vivek Sampathkumar","Ronny Huang","Victor Lavrenko","Ahmed Eleryan","Zhi Hong","Steven Hansen","Sara Mc Carthy","Bidisha Samanta","Domagoj Ćevid","Xin Wang","Fangtao Li","Michael Voznesensky","Matt Hoffman","Andreas Terzis","Vikash Sehwag","Gil Fidel","Luheng He","Mu Cai","Yanzhang He","Alex Feng","Martin Nikoltchev","Samrat Phatale","Jason Chase","Rory Lawton","Ming Zhang","Tom Ouyang","Manuel Tragut","Mehdi Hafezi Manshadi","Arjun Narayanan","Jiaming Shen","Xu Gao","Tolga Bolukbasi","Nick Roy","Xin Li","Daniel Golovin","Liviu Panait","Zhen Qin","Guangxing Han","Thomas Anthony","Sneha Kudugunta","Viorica Patraucean","Aniket Ray","Xinyun Chen","Xiaochen Yang","Tanuj Bhatia","Pranav Talluri","Alex Morris","Andrija Ražnatović","Bethanie Brownfield","James An","Sheng Peng","Patrick Kane","Ce Zheng","Nico Duduta","Joshua Kessinger","James Noraky","Siqi Liu","Keran Rong","Petar Veličković","Keith Rush","Alex Goldin","Fanny Wei","Shiva Mohan Reddy Garlapati","Caroline Pantofaru","Okwan Kwon","Jianmo Ni","Eric Noland","Julia Di Trapani","Françoise Beaufays","Abhijit Guha Roy","Yinlam Chow","Aybuke Turker","Geoffrey Cideron","Lantao Mei","Jon Clark","Qingyun Dou","Matko Bošnjak","Ralph Leith","Yuqing Du","Amir Yazdanbakhsh","Milad Nasr","Chester Kwak","Suraj Satishkumar Sheth","Alex Kaskasoli","Ankesh Anand","Balaji Lakshminarayanan","Sammy Jerome","David Bieber","Chun-Te Chu","Alexandre Senges","Tianxiao Shen","Mukund Sridhar","Ndaba Ndebele","Benjamin Beyret","Shakir Mohamed","Mia Chen","Markus Freitag","Jiaxian Guo","Luyang Liu","Paul Roit","Heng Chen","Shen Yan","Tom Stone","JD Co-Reyes","Jeremy Cole","Salvatore Scellato","Shekoofeh Azizi","Hadi Hashemi","Alicia Jin","Anand Iyer","Marcella Valentine","András György","Arun Ahuja","Daniel Hernandez Diaz","Chen-Yu Lee","Nathan Clement","Weize Kong","Drew Garmon","Ishaan Watts","Kush Bhatia","Khyatti Gupta","Matt Miecnikowski","Hugo Vallet","Ankur Taly","Edward Loper","Saket Joshi","James Atwood","Jo Chick","Mark Collier","Fotis Iliopoulos","Ryan Trostle","Beliz Gunel","Ramiro Leal-Cavazos","Arnar Mar Hrafnkelsson","Michael Guzman","Xiaoen Ju","Andy Forbes","Jesse Emond","Kushal Chauhan","Ben Caine","Li Xiao","Wenjun Zeng","Alexandre Moufarek","Daniel Murphy","Maya Meng","Nitish Gupta","Felix Riedel","Anil Das","Elijah Lawal","Shashi Narayan","Tiberiu Sosea","James Swirhun","Linda Friso","Behnam Neyshabur","Jing Lu","Sertan Girgin","Michael Wunder","Edouard Yvinec","Aroonalok Pyne","Victor Carbune","Shruti Rijhwani","Yang Guo","Tulsee Doshi","Anton Briukhov","Max Bain","Ayal Hitron","Xuanhui Wang","Ashish Gupta","Ke Chen","Cosmo Du","Weiyang Zhang","Dhruv Shah","Arjun Akula","Max Dylla","Ashyana Kachra","Weicheng Kuo","Tingting Zou","Lily Wang","Luyao Xu","Jifan Zhu","Justin Snyder","Sachit Menon","Orhan Firat","Igor Mordatch","Yuan Yuan","Natalia Ponomareva","Rory Blevins","Lawrence Moore","Weijun Wang","Phil Chen","Martin Scholz","Artur Dwornik","Jason Lin","Sicheng Li","Diego Antognini","Te I","Xiaodan Song","Matt Miller","Uday Kalra","Adam Raveret","Oscar Akerlund","Felix Wu","Andrew Nystrom","Namrata Godbole","Tianqi Liu","Hannah DeBalsi","Jewel Zhao","Buhuang Liu","Avi Caciularu","Lauren Lax","Urvashi Khandelwal","Victoria Langston","Eric Bailey","Silvio Lattanzi","Yufei Wang","Neel Kovelamudi","Sneha Mondal","Guru Guruganesh","Nan Hua","Ofir Roval","Paweł Wesołowski","Rishikesh Ingale","Jonathan Halcrow","Tim Sohn","Christof Angermueller","Bahram Raad","Eli Stickgold","Eva Lu","Alec Kosik","Jing Xie","Timothy Lillicrap","Austin Huang","Lydia Lihui Zhang","Dominik Paulus","Clement Farabet","Alex Wertheim","Bing Wang","Rishabh Joshi","Chu-ling Ko","Yonghui Wu","Shubham Agrawal","Lily Lin","XiangHai Sheng","Peter Sung","Tyler Breland-King","Christina Butterfield","Swapnil Gawde","Sumeet Singh","Qiao Zhang","Raj Apte","Shilpa Shetty","Adrian Hutter","Tao Li","Elizabeth Salesky","Federico Lebron","Jonni Kanerva","Michela Paganini","Arthur Nguyen","Rohith Vallu","Jan-Thorsten Peter","Sarmishta Velury","David Kao","Jay Hoover","Anna Bortsova","Colton Bishop","Shoshana Jakobovits","Alessandro Agostini","Alekh Agarwal","Chang Liu","Charles Kwong","Sasan Tavakkol","Ioana Bica","Alex Greve","Anirudh GP","Jake Marcus","Le Hou","Tom Duerig","Rivka Moroshko","Dave Lacey","Andy Davis","Julien Amelot","Guohui Wang","Frank Kim","Theofilos Strinopoulos","Hui Wan","Charline Le Lan","Shankar Krishnan","Haotian Tang","Peter Humphreys","Junwen Bai","Idan Heimlich Shtacher","Diego Machado","Chenxi Pang","Ken Burke","Dangyi Liu","Renga Aravamudhan","Yue Song","Ed Hirst","Abhimanyu Singh","Brendan Jou","Liang Bai","Francesco Piccinno","Chuyuan Kelly Fu","Robin Alazard","Barak Meiri","Daniel Winter","Charlie Chen","Mingda Zhang","Jens Heitkaemper","John Lambert","Jinhyuk Lee","Alexander Frömmgen","Sergey Rogulenko","Pranav Nair","Paul Niemczyk","Anton Bulyenov","Bibo Xu","Hadar Shemtov","Morteza Zadimoghaddam","Serge Toropov","Mateo Wirth","Hanjun Dai","Sreenivas Gollapudi","Daniel Zheng","Alex Kurakin","Chansoo Lee","Kalesha Bullard","Nicolas Serrano","Ivana Balazevic","Yang Li","Johan Schalkwyk","Mark Murphy","Mingyang Zhang","Kevin Sequeira","Romina Datta","Nishant Agrawal","Charles Sutton","Nithya Attaluri","Mencher Chiang","Wael Farhan","Gregory Thornton","Kate Lin","Travis Choma","Hung Nguyen","Kingshuk Dasgupta","Dirk Robinson","Iulia Comşa","Michael Riley","Arjun Pillai","Basil Mustafa","Ben Golan","Amir Zandieh","Jean-Baptiste Lespiau","Billy Porter","David Ross","Sujeevan Rajayogam","Mohit Agarwal","Subhashini Venugopalan","Bobak Shahriari","Qiqi Yan","Hao Xu","Taylor Tobin","Pavel Dubov","Hongzhi Shi","Adrià Recasens","Anton Kovsharov","Sebastian Borgeaud","Lucio Dery","Shanthal Vasanth","Elena Gribovskaya","Linhai Qiu","Mahdis Mahdieh","Wojtek Skut","Elizabeth Nielsen","CJ Zheng","Adams Yu","Carrie Grimes Bostock","Shaleen Gupta","Aaron Archer","Chris Rawles","Elinor Davies","Alexey Svyatkovskiy","Tomy Tsai","Yoni Halpern","Christian Reisswig","Bartek Wydrowski","Bo Chang","Joan Puigcerver","Mor Hazan Taege","Jian Li","Eva Schnider","Xinjian Li","Dragos Dena","Yunhan Xu","Umesh Telang","Tianze Shi","Heiga Zen","Kyle Kastner","Yeongil Ko","Neesha Subramaniam","Aviral Kumar","Pete Blois","Zhuyun Dai","John Wieting","Yifeng Lu","Yoel Zeldes","Tian Xie","Anja Hauth","Alexandru Ţifrea","Yuqi Li","Sam El-Husseini","Dan Abolafia","Howard Zhou","Wen Ding","Sahra Ghalebikesabi","Carlos Guía","Andrii Maksai","Ágoston Weisz","Sercan Arik","Nick Sukhanov","Aga Świetlik","Xuhui Jia","Luo Yu","Weiyue Wang","Mark Brand","Dawn Bloxwich","Sean Kirmani","Zhe Chen","Alec Go","Pablo Sprechmann","Nithish Kannen","Alen Carin","Paramjit Sandhu","Isabel Edkins","Leslie Nooteboom","Jai Gupta","Loren Maggiore","Javad Azizi","Yael Pritch","Pengcheng Yin","Mansi Gupta","Danny Tarlow","Duncan Smith","Desi Ivanov","Mohammad Babaeizadeh","Ankita Goel","Satish Kambala","Grace Chu","Matej Kastelic","Michelle Liu","Hagen Soltau","Austin Stone","Shivani Agrawal","Min Kim","Kedar Soparkar","Srinivas Tadepalli","Oskar Bunyan","Rachel Soh","Arvind Kannan","DY Kim","Blake JianHang Chen","Afief Halumi","Sudeshna Roy","Yulong Wang","Olcan Sercinoglu","Gena Gibson","Sijal Bhatnagar","Motoki Sano","Daniel von Dincklage","Qingchun Ren","Blagoj Mitrevski","Mirek Olšák","Jennifer She","Carl Doersch"," Jilei"," Wang","Bingyuan Liu","Qijun Tan","Tamar Yakar","Tris Warkentin","Alex Ramirez","Carl Lebsack","Josh Dillon","Rajiv Mathews","Tom Cobley","Zelin Wu","Zhuoyuan Chen","Jon Simon","Swaroop Nath","Tara Sainath","Alexei Bendebury","Ryan Julian","Bharath Mankalale","Daria Ćurko","Paulo Zacchello","Adam R. Brown","Kiranbir Sodhia","Heidi Howard","Sergi Caelles","Abhinav Gupta","Gareth Evans","Anna Bulanova","Lesley Katzen","Roman Goldenberg","Anton Tsitsulin","Joe Stanton","Benoit Schillings","Vitaly Kovalev","Corey Fry","Rushin Shah","Kuo Lin","Shyam Upadhyay","Cheng Li","Soroush Radpour","Marcello Maggioni","Jing Xiong","Lukas Haas","Jenny Brennan","Aishwarya Kamath","Nikolay Savinov","Arsha Nagrani","Trevor Yacovone","Ryan Kappedal","Kostas Andriopoulos","Li Lao","YaGuang Li","Grigory Rozhdestvenskiy","Kazuma Hashimoto","Andrew Audibert","Sophia Austin","Daniel Rodriguez","Anian Ruoss","Garrett Honke","Deep Karkhanis","Xi Xiong","Qing Wei","James Huang","Zhaoqi Leng","Vittal Premachandran","Stan Bileschi","Georgios Evangelopoulos","Thomas Mensink","Jay Pavagadhi","Denis Teplyashin","Paul Chang","Linting Xue","Garrett Tanzer","Sally Goldman","Kaushal Patel","Shixin Li","Jeremy Wiesner","Ivy Zheng","Ian Stewart-Binks","Jie Han","Zhi Li","Liangchen Luo","Karel Lenc","Mario Lučić","Fuzhao Xue","Ryan Mullins","Alexey Guseynov","Chung-Ching Chang","Isaac Galatzer-Levy","Adam Zhang","Garrett Bingham","Grace Hu","Ale Hartman","Yue Ma","Jordan Griffith","Alex Irpan","Carey Radebaugh","Summer Yue","Lijie Fan","Victor Ungureanu","Christina Sorokin","Hannah Teufel","Peiran Li","Rohan Anil","Dimitris Paparas","Todd Wang","Chu-Cheng Lin","Hui Peng","Megan Shum","Goran Petrovic","Demetra Brady","Richard Nguyen","Klaus Macherey","Zhihao Li","Harman Singh","Madhavi Yenugula","Mariko Iinuma","Xinyi Chen","Kavya Kopparapu","Alexey Stern","Shachi Dave","Chandu Thekkath","Florence Perot","Anurag Kumar","Fangda Li","Yang Xiao","Matthew Bilotti","Mohammad Hossein Bateni","Isaac Noble","Lisa Lee","Amelio Vázquez-Reina","Julian Salazar","Xiaomeng Yang","Boyu Wang","Ela Gruzewska","Anand Rao","Sindhu Raghuram","Zheng Xu","Eyal Ben-David","Jieru Mei","Sid Dalmia","Zhaoyi Zhang","Yuchen Liu","Gagan Bansal","Helena Pankov","Steven Schwarcz","Andrea Burns","Christine Chan","Sumit Sanghai","Ricky Liang","Ethan Liang","Antoine He","Amy Stuart","Arun Narayanan","Yukun Zhu","Christian Frank","Bahar Fatemi","Amit Sabne","Oran Lang","Indro Bhattacharya","Shane Settle","Maria Wang","Brendan McMahan","Andrea Tacchetti","Livio Baldini Soares","Majid Hadian","Serkan Cabi","Timothy Chung","Nikita Putikhin","Gang Li","Jeremy Chen","Austin Tarango","Henryk Michalewski","Mehran Kazemi","Hussain Masoom","Hila Sheftel","Rakesh Shivanna","Archita Vadali","Ramona Comanescu","Doug Reid","Joss Moore","Arvind Neelakantan","Michaël Sander","Jonathan Herzig","Aviv Rosenberg","Mostafa Dehghani","JD Choi","Michael Fink","Reid Hayes","Eric Ge","Shitao Weng","Chia-Hua Ho","John Karro","Kalpesh Krishna","Lam Nguyen Thiet","Amy Skerry-Ryan","Daniel Eppens","Marco Andreetto","Navin Sarma","Silvano Bonacina","Burcu Karagol Ayan","Megha Nawhal","Zhihao Shan","Mike Dusenberry","Shantanu Thakoor","Sagar Gubbi","Duc Dung Nguyen","Reut Tsarfaty","Samuel Albanie","Jovana Mitrović","Meet Gandhi","Bo-Juen Chen","Alessandro Epasto","Georgi Stephanov","Ye Jin","Samuel Gehman","Aida Amini","Jack Weber","Feryal Behbahani","Shawn Xu","Miltos Allamanis","Xi Chen","Myle Ott","Claire Sha","Michal Jastrzebski","Hang Qi","David Greene","Xinyi Wu","Abodunrinwa Toki","Daniel Vlasic","Jane Shapiro","Ragha Kotikalapudi","Zhe Shen","Takaaki Saeki","Sirui Xie","Albin Cassirer","Shikhar Bharadwaj","Tatsuya Kiyono","Srinadh Bhojanapalli","Elan Rosenfeld","Sam Ritter","Jieming Mao","João Gabriel Oliveira","Zoltan Egyed","Bernd Bandemer","Emilio Parisotto","Keisuke Kinoshita","Juliette Pluto","Petros Maniatis","Steve Li","Yaohui Guo","Golnaz Ghiasi","Jean Tarbouriech","Srimon Chatterjee","Julie Jin"," Katrina"," Xu","Jennimaria Palomaki","Séb Arnold","Madhavi Sewak","Federico Piccinini","Mohit Sharma","Ben Albrecht","Sean Purser-haskell","Ashwin Vaswani","Chongyan Chen","Matheus Wisniewski","Qin Cao","John Aslanides","Nguyet Minh Phu","Maximilian Sieb","Lauren Agubuzu","Anne Zheng","Daniel Sohn","Marco Selvi","Anders Andreassen","Krishan Subudhi","Prem Eruvbetine","Oliver Woodman","Tomas Mery","Sebastian Krause","Xiaoqi Ren","Xiao Ma","Jincheng Luo","Dawn Chen","Wei Fan","Henry Griffiths","Christian Schuler","Alice Li","Shujian Zhang","Jean-Michel Sarr","Shixin Luo","Riccardo Patana","Matthew Watson","Dani Naboulsi","Michael Collins","Sailesh Sidhwani","Emiel Hoogeboom","Sharon Silver","Emily Caveness","Xiaokai Zhao","Mikel Rodriguez","Maxine Deines","Libin Bai","Patrick Griffin","Marco Tagliasacchi","Emily Xue","Spandana Raj Babbula","Bo Pang","Nan Ding","Gloria Shen","Elijah Peake","Remi Crocker","Shubha Srinivas Raghvendra","Danny Swisher","Woohyun Han","Richa Singh","Ling Wu","Vladimir Pchelin","Tsendsuren Munkhdalai","Dana Alon","Geoff Bacon","Efren Robles","Jannis Bulian","Melvin Johnson","George Powell","Felipe Tiengo Ferreira","Yaoyiran Li","Frederik Benzing","Mihajlo Velimirović","Hubert Soyer","William Kong"," Tony"," Nguyên","Zhen Yang","Jeremiah Liu","Joost van Amersfoort","Daniel Gillick","Baochen Sun","Nathalie Rauschmayr","Katie Zhang","Serena Zhan","Tao Zhou","Alexey Frolov","Chengrun Yang","Denis Vnukov","Louis Rouillard","Hongji Li","Amol Mandhane","Nova Fallen","Rajesh Venkataraman","Clara Huiyi Hu","Jennifer Brennan","Jenny Lee","Jerry Chang","Martin Sundermeyer","Zhufeng Pan","Rosemary Ke","Simon Tong","Alex Fabrikant","William Bono","Jindong Gu","Ryan Foley","Yiran Mao","Manolis Delakis","Dhruva Bhaswar","Roy Frostig","Nick Li","Avital Zipori","Cath Hope","Olga Kozlova","Swaroop Mishra","Josip Djolonga","Craig Schiff","Majd Al Merey","Eleftheria Briakou","Peter Morgan","Andy Wan","Avinatan Hassidim","RJ Skerry-Ryan","Kuntal Sengupta","Mary Jasarevic","Praveen Kallakuri","Paige Kunkle","Hannah Brennan","Tom Lieber","Hassan Mansoor","Julian Walker","Bing Zhang","Annie Xie","Goran Žužić","Adaeze Chukwuka","Alex Druinsky","Donghyun Cho","Rui Yao","Ferjad Naeem","Shiraz Butt","Eunyoung Kim","Zhipeng Jia","Mandy Jordan","Adam Lelkes","Mark Kurzeja","Sophie Wang","James Zhao","Andrew Over","Abhishek Chakladar","Marcel Prasetya","Neha Jha","Sriram Ganapathy","Yale Cong","Prakash Shroff","Carl Saroufim","Sobhan Miryoosefi","Mohamed Hammad","Tajwar Nasir","Weijuan Xi","Yang Gao","Young Maeng","Ben Hora","Chin-Yi Cheng","Parisa Haghani","Yoad Lewenberg","Caden Lu","Martin Matysiak","Naina Raisinghani","Huiyu Wang","Lexi Baugher","Rahul Sukthankar","Minh Giang","John Schultz","Noah Fiedel","Minmin Chen","Cheng-Chun Lee","Tapomay Dey","Hao Zheng","Shachi Paul","Celine Smith","Andy Ly","Yicheng Wang","Rishabh Bansal","Bartek Perz","Susanna Ricco","Stasha Blank","Vaishakh Keshava","Deepak Sharma","Marvin Chow","Kunal Lad","Komal Jalan","Simon Osindero","Craig Swanson","Jacob Scott","Anastasija Ilić","Xiaowei Li","Siddhartha Reddy Jonnalagadda","Afzal Shama Soudagar","Yan Xiong","Bat-Orgil Batsaikhan","Daniel Jarrett","Naveen Kumar","Maulik Shah","Matt Lawlor","Austin Waters","Mark Graham","Rhys May","Sabela Ramos","Sandra Lefdal","Zeynep Cankara","Nacho Cano","Brendan O'Donoghue","Jed Borovik","Frederick Liu","Jordan Grimstad","Mahmoud Alnahlawi","Katerina Tsihlas","Tom Hudson","Nikolai Grigorev","Yiling Jia","Terry Huang","Tobenna Peter Igwe","Sergei Lebedev","Xiaodan Tang","Igor Krivokon","Frankie Garcia","Melissa Tan","Eric Jia","Peter Stys","Shikhar Vashishth","Yu Liang","Balaji Venkatraman","Chenjie Gu","Anastasios Kementsietsidis","Chen Zhu","Junehyuk Jung","Yunfei Bai","Mohammad Javad Hosseini","Faruk Ahmed","Aditya Gupta","Xin Yuan","Shereen Ashraf","Shitij Nigam","Gautam Vasudevan","Pranjal Awasthi","Adi Mayrav Gilady","Zelda Mariet","Ramy Eskander","Haiguang Li","Hexiang Hu","Guillermo Garrido","Philippe Schlattner","George Zhang","Rohun Saxena","Petar Dević","Kritika Muralidharan","Ashwin Murthy","Yiqian Zhou","Min Choi","Arissa Wongpanich","Zhengdong Wang","Premal Shah","Yuntao Xu","Yiling Huang","Stephen Spencer","Alice Chen","James Cohan","Junjie Wang","Jonathan Tompson","Junru Wu","Ruba Haroun","Haiqiong Li","Blanca Huergo","Fan Yang","Tongxin Yin","James Wendt","Michael Bendersky","Rahma Chaabouni","Javier Snaider","Johan Ferret","Abhishek Jindal","Tara Thompson","Andrew Xue","Will Bishop","Shubham Milind Phal","Archit Sharma","Yunhsuan Sung","Prabakar Radhakrishnan","Mo Shomrat","Reeve Ingle","Roopali Vij","Justin Gilmer","Mihai Dorin Istin","Sam Sobell","Yang Lu","Emily Nottage","Dorsa Sadigh","Jeremiah Willcock","Tingnan Zhang","Steve Xu","Sasha Brown","Katherine Lee","Gary Wang","Yun Zhu","Yi Tay","Cheolmin Kim","Audrey Gutierrez","Abhanshu Sharma","Yongqin Xian","Sungyong Seo","Claire Cui","Elena Pochernina","Cip Baetu","Krzysztof Jastrzębski","Mimi Ly","Mohamed Elhawaty","Dan Suh","Eren Sezener","Pidong Wang","Nancy Yuen","George Tucker","Jiahao Cai","Zuguang Yang","Cindy Wang","Alex Muzio","Hai Qian","Jae Yoo","Derek Lockhart","Kevin R. McKee","Mandy Guo","Malika Mehrotra","Artur Mendonça","Sanket Vaibhav Mehta","Sherry Ben","Chetan Tekur","Jiaqi Mu","Muye Zhu","Victoria Krakovna","Hongrae Lee","AJ Maschinot","Sébastien Cevey","HyunJeong Choe","Aijun Bai","Hansa Srinivasan","Derek Gasaway","Nick Young","Patrick Siegler","Dan Holtmann-Rice","Vihari Piratla","Kate Baumli","Roey Yogev","Alex Hofer","Hado van Hasselt","Svetlana Grant","Yuri Chervonyi","David Silver","Andrew Hogue","Ayushi Agarwal","Kathie Wang","Preeti Singh","Four Flynn","Josh Lipschultz","Robert David","Lizzetth Bellot","Yao-Yuan Yang","Long Le","Filippo Graziano","Kate Olszewska","Kevin Hui","Akanksha Maurya","Nikos Parotsidis","Weijie Chen","Tayo Oguntebi","Joe Kelley","Anirudh Baddepudi","Johannes Mauerer","Gregory Shaw","Alex Siegman","Lin Yang","Shravya Shetty","Subhrajit Roy","Yunting Song","Wojciech Stokowiec","Ryan Burnell","Omkar Savant","Robert Busa-Fekete","Jin Miao","Samrat Ghosh","Liam MacDermed","Phillip Lippe","Mikhail Dektiarev","Zach Behrman","Fabian Mentzer","Kelvin Nguyen","Meng Wei","Siddharth Verma","Chris Knutsen","Sudeep Dasari","Zhipeng Yan","Petr Mitrichev","Xingyu Wang","Virat Shejwalkar","Jacob Austin","Srinivas Sunkara","Navneet Potti","Yan Virin","Christian Wright","Gaël Liu","Oriana Riva","Etienne Pot","Greg Kochanski","Quoc Le","Gargi Balasubramaniam","Arka Dhar","Yuguo Liao","Adam Bloniarz","Divyansh Shukla","Elizabeth Cole","Jong Lee","Sheng Zhang","Sushant Kafle","Siddharth Vashishtha","Parsa Mahmoudieh","Grace Chen","Raphael Hoffmann","Pranesh Srinivasan","Agustin Dal Lago","Yoav Ben Shalom","Zi Wang","Michael Elabd","Anuj Sharma","Junhyuk Oh","Suraj Kothawade","Maigo Le","Marianne Monteiro","Shentao Yang","Kaiz Alarakyia","Robert Geirhos","Diana Mincu","Håvard Garnes","Hayato Kobayashi","Soroosh Mariooryad","Kacper Krasowiak"," Zhixin"," Lai","Shibl Mourad","Mingqiu Wang","Fan Bu","Ophir Aharoni","Guanjie Chen","Abhimanyu Goyal","Vadim Zubov","Ankur Bapna","Elahe Dabir","Nisarg Kothari","Kay Lamerigts","Nicola De Cao","Jeremy Shar","Christopher Yew","Nitish Kulkarni","Dre Mahaarachchi","Mandar Joshi","Zhenhai Zhu","Jared Lichtarge","Yichao Zhou","Hannah Muckenhirn","Vittorio Selo","Oriol Vinyals","Peter Chen","Anthony Brohan","Vaibhav Mehta","Sarah Cogan","Ruth Wang","Ty Geri","Wei-Jen Ko","Wei Chen","Fabio Viola","Keshav Shivam","Lisa Wang","Madeleine Clare Elish","Raluca Ada Popa","Sébastien Pereira","Jianqiao Liu","Raphael Koster","Donnie Kim","Gufeng Zhang","Sayna Ebrahimi","Partha Talukdar","Yanyan Zheng","Petra Poklukar","Ales Mikhalap","Dale Johnson","Anitha Vijayakumar","Mark Omernick","Matt Dibb","Ayush Dubey","Qiong Hu","Apurv Suman","Vaibhav Aggarwal","Ilya Kornakov","Fei Xia","Wing Lowe","Alexey Kolganov","Ted Xiao","Vitaly Nikolaev","Steven Hemingray","Bonnie Li","Joana Iljazi","Mikołaj Rybiński","Ballie Sandhu","Peggy Lu","Thang Luong","Rodolphe Jenatton","Vineetha Govindaraj"," Hui"," Li","Gabriel Dulac-Arnold","Wonpyo Park","Henry Wang","Abhinit Modi","Jean Pouget-Abadie","Kristina Greller","Rahul Gupta","Robert Berry","Prajit Ramachandran","Jinyu Xie","Liam McCafferty","Jianling Wang","Kilol Gupta","Hyeontaek Lim","Blaž Bratanič","Andy Brock","Ilia Akolzin","Jim Sproch","Dan Karliner","Duhyeon Kim","Adrian Goedeckemeyer","Noam Shazeer","Cordelia Schmid","Daniele Calandriello","Parul Bhatia","Krzysztof Choromanski","Ceslee Montgomery","Dheeru Dua","Ana Ramalho","Helen King","Yue Gao","Lynn Nguyen","David Lindner","Divya Pitta","Oleaser Johnson","Khalid Salama","Diego Ardila","Michael Han","Erin Farnese","Seth Odoom","Ziyue Wang","Xiangzhuo Ding","Norman Rink","Ray Smith","Harshal Tushar Lehri","Eden Cohen","Neera Vats","Tong He","Parthasarathy Gopavarapu","Adam Paszke","Miteyan Patel","Wouter Van Gansbeke","Lucia Loher","Luis Castro","Maria Voitovich","Tamara von Glehn","Nelson George","Simon Niklaus","Zach Eaton-Rosen","Nemanja Rakićević","Erik Jue","Sagi Perel","Carrie Zhang","Yuval Bahat","Angéline Pouget","Zhi Xing","Fantine Huot","Ashish Shenoy","Taylor Bos","Vincent Coriou","Bryan Richter","Natasha Noy","Yaqing Wang","Santiago Ontanon","Siyang Qin","Gleb Makarchuk","Demis Hassabis","Zhuowan Li","Mandar Sharma","Kumaran Venkatesan","Iurii Kemaev","Roxanne Daniel","Shiyu Huang","Saloni Shah","Octavio Ponce"," Warren"," Chen","Manaal Faruqui","Jialin Wu","Slavica Andačić","Szabolcs Payrits","Daniel McDuff","Tom Hume","Yuan Cao","MH Tessler","Qingze Wang","Yinan Wang","Ivor Rendulic","Eirikur Agustsson","Matthew Johnson","Tanya Lando","Andrew Howard","Sri Gayatri Sundara Padmanabhan","Mayank Daswani","Andrea Banino","Michael Kilgore","Jonathan Heek","Ziwei Ji","Alvaro Caceres","Conglong Li","Nora Kassner","Alexey Vlaskin","Zeyu Liu","Alex Grills","Yanhan Hou","Roykrong Sukkerd","Gowoon Cheon","Nishita Shetty","Larisa Markeeva","Piotr Stanczyk","Tejas Iyer","Yuan Gong","Shawn Gao","Keerthana Gopalakrishnan","Tim Blyth","Malcolm Reynolds","Avishkar Bhoopchand","Misha Bilenko","Dero Gharibian","Vicky Zayats","Aleksandra Faust","Abhinav Singh","Min Ma","Hongyang Jiao","Sudheendra Vijayanarasimhan","Lora Aroyo","Vikas Yadav","Sarah Chakera","Ashwin Kakarla","Vilobh Meshram","Karol Gregor","Gabriela Botea","Evan Senter","Dawei Jia","Geza Kovacs","Neha Sharma","Sebastien Baur","Kai Kang","Yifan He","Lin Zhuo","Marija Kostelac","Itay Laish","Songyou Peng","Louis O'Bryan","Daniel Kasenberg","Girish Ramchandra Rao","Edouard Leurent","Biao Zhang","Sage Stevens","Ana Salazar","Ye Zhang","Ivan Lobov","Jake Walker","Allen Porter","Morgan Redshaw","Han Ke","Abhishek Rao","Alex Lee","Hoi Lam","Michael Moffitt","Jaeyoun Kim","Siyuan Qiao","Terry Koo","Robert Dadashi","Xinying Song","Mukund Sundararajan","Peng Xu","Chizu Kawamoto","Yan Zhong","Clara Barbu","Apoorv Reddy","Mauro Verzetti","Leon Li","George Papamakarios","Hanna Klimczak-Plucińska","Mary Cassin","Koray Kavukcuoglu","Rigel Swavely","Alain Vaucher","Jeffrey Zhao","Ross Hemsley","Michael Tschannen","Heming Ge","Gaurav Menghani","Yang Yu","Natalie Ha","Wei He","Xiao Wu","Maggie Song","Rachel Sterneck","Stefan Zinke","Dan A. Calian","Annie Marsden","Alejandro Cruzado Ruiz","Matteo Hessel","Almog Gueta","Benjamin Lee","Brian Farris","Manish Gupta","Yunjie Li","Mohammad Saleh","Vedant Misra","Kefan Xiao","Piermaria Mendolicchio","Gavin Buttimore","Varvara Krayvanova","Nigamaa Nayakanti","Matthew Wiethoff","Yash Pande","Azalia Mirhoseini","Ni Lao","Jasmine Liu","Yiqing Hua","Angie Chen","Yury Malkov","Dmitry Kalashnikov","Shubham Gupta","Kartik Audhkhasi","Yuexiang Zhai","Sudhindra Kopalle","Prateek Jain","Eran Ofek","Clemens Meyer","Khuslen Baatarsukh","Hana Strejček","Jun Qian","James Freedman","Ricardo Figueira","Michal Sokolik","Olivier Bachem","Raymond Lin","Dia Kharrat","Chris Hidey","Pingmei Xu","Dennis Duan","Yin Li","Muge Ersoy","Richard Everett","Kevin Cen","Rebeca Santamaria-Fernandez","Amir Taubenfeld","Ian Mackinnon","Linda Deng","Polina Zablotskaia","Shashank Viswanadha","Shivanker Goel","Damion Yates","Yunxiao Deng","Peter Choy","Mingqing Chen","Abhishek Sinha","Alex Mossin","Yiming Wang","Arthur Szlam","Susan Hao","Paul Kishan Rubenstein","Metin Toksoz-Exley","Miranda Aperghis","Yin Zhong","Junwhan Ahn","Michael Isard","Olivier Lacombe","Florian Luisier","Chrysovalantis Anastasiou","Yogesh Kalley","Utsav Prabhu","Emma Dunleavy","Shaan Bijwadia","Justin Mao-Jones","Kelly Chen","Rama Pasumarthi","Emily Wood","Adil Dostmohamed","Nate Hurley","Jiri Simsa","Alicia Parrish","Mantas Pajarskas","Matt Harvey","Ondrej Skopek","Yony Kochinski","Javier Rey","Verena Rieser","Denny Zhou","Sun Jae Lee","Trilok Acharya","Guowang Li","Joe Jiang","Xiaofan Zhang","Bryant Gipson","Ethan Mahintorabi","Marco Gelmi","Nima Khajehnouri","Angel Yeh","Kayi Lee","Loic Matthey","Leslie Baker","Trang Pham","Han Fu","Alex Pak","Prakhar Gupta","Cristina Vasconcelos","Adam Sadovsky","Brian Walker","Sissie Hsiao","Patrik Zochbauer","Andreea Marzoca","Noam Velan","Junhao Zeng","Gilles Baechler","Danny Driess","Divya Jain","Yanping Huang","Lizzie Tao","John Maggs","Nir Levine","Jon Schneider","Erika Gemzer","Samuel Petit","Shan Han","Zach Fisher","Dustin Zelle","Courtney Biles","Eugene Ie","Asya Fadeeva","Casper Liu","Juliana Vicente Franco","Adrian Collister","Hao Zhang","Renshen Wang","Ruizhe Zhao","Leandro Kieliger","Kurt Shuster","Rui Zhu","Boqing Gong","Lawrence Chan","Ruoxi Sun","Sujoy Basu","Roland Zimmermann","Jamie Hayes","Abhishek Bapna","Jasper Snoek","Weel Yang","Puranjay Datta","Jad Al Abdallah","Kevin Kilgour","Lu Li","SQ Mah","Yennie Jun","Morgane Rivière","Abhijit Karmarkar","Tammo Spalink","Tao Huang","Lucas Gonzalez","Duc-Hieu Tran","Averi Nowak","John Palowitch","Martin Chadwick","Ellie Talius","Harsh Mehta","Thibault Sellam","Philipp Fränken","Massimo Nicosia","Kyle He","Aditya Kini","David Amos","Sugato Basu","Harrison Jobe","Eleni Shaw","Qiantong Xu","Colin Evans","Daisuke Ikeda","Chaochao Yan","Larry Jin","Lun Wang","Sachin Yadav","Ilia Labzovsky","Ramesh Sampath","Ada Ma","Candice Schumann","Aditya Siddhant","Rohin Shah","John Youssef","Rishabh Agarwal","Natalie Dabney","Alessio Tonioni","Moran Ambar","Jing Li","Isabelle Guyon","Benny Li","David Soergel","Boya Fang","Georgi Karadzhov","Cristian Udrescu","Trieu Trinh","Vikas Raunak","Seb Noury","Dee Guo","Sonal Gupta","Mara Finkelstein","Denis Petek","Lihao Liang","Greg Billock","Pei Sun","David Wood","Yiwen Song","Xiaobin Yu","Tatiana Matejovicova","Regev Cohen","Kalyan Andra","David D'Ambrosio","Zhiwei Deng","Vincent Nallatamby","Ebrahim Songhori","Rumen Dangovski","Andrew Lampinen","Pankil Botadra","Adam Hillier","Jiawei Cao","Nagabhushan Baddi","Adhi Kuncoro","Toshihiro Yoshino","Ankit Bhagatwala","Marcáurelio Ranzato","Rylan Schaeffer","Tianlin Liu","Shuai Ye","Obaid Sarvana","John Nham","Chenkai Kuang","Isabel Gao","Jinoo Baek","Shubham Mittal","Ayzaan Wahid","Anita Gergely","Bin Ni","Josh Feldman","Carrie Muir","Pascal Lamblin","Wolfgang Macherey","Ethan Dyer","Logan Kilpatrick","Víctor Campos","Mukul Bhutani","Stanislav Fort","Yanif Ahmad","Aliaksei Severyn","Kleopatra Chatziprimou","Oleksandr Ferludin","Mason Dimarco","Aditya Kusupati","Joe Heyward","Dan Bahir","Kevin Villela","Katie Millican","Dror Marcus","Sanaz Bahargam","Caglar Unlu","Nicholas Roth","Zichuan Wei","Siddharth Gopal","Deepanway Ghoshal","Edward Lee","Sharon Lin","Jennie Lees","Dayeong Lee","Anahita Hosseini","Connie Fan","Seth Neel","Marcus Wu","Yasemin Altun","Honglong Cai","Enrique Piqueras","Josh Woodward","Alessandro Bissacco","Salem Haykal","Mahyar Bordbar","Prasha Sundaram","Sarah Hodkinson","Daniel Toyama","George Polovets","Austin Myers","Anu Sinha","Tomer Levinboim","Kashyap Krishnakumar","Rachita Chhaparia","Tatiana Sholokhova","Nitesh Bharadwaj Gundavarapu","Ganesh Jawahar","Haroon Qureshi","Jieru Hu","Nikola Momchev","Matthew Rahtz","Renjie Wu","Aishwarya P S","Kedar Dhamdhere","Meiqi Guo","Umang Gupta","Ali Eslami","Mariano Schain","Michiel Blokzijl","David Welling","Dave Orr","Levent Bolelli","Nicolas Perez-Nieves","Mikhail Sirotenko","Aman Prasad","Arjun Kar","Borja De Balle Pigem","Tayfun Terzi","Gellért Weisz","Dipankar Ghosh","Aditi Mavalankar","Dhruv Madeka","Kaspar Daugaard","Hartwig Adam","Viraj Shah","Dana Berman","Maggie Tran","Steven Baker","Ewa Andrejczuk","Grishma Chole","Ganna Raboshchuk","Mahdi Mirzazadeh","Thais Kagohara","Shimu Wu","Christian Schallhart","Bernett Orlando","Chen Wang","Alban Rrustemi","Hao Xiong","Hao Liu","Arpi Vezer","Nolan Ramsden","Shuo-yiin Chang","Sidharth Mudgal","Yan Li","Nino Vieillard","Yedid Hoshen","Farooq Ahmad","Ambrose Slone","Amy Hua","Natan Potikha","Mirko Rossini","Jon Stritar","Sushant Prakash","Zifeng Wang","Xuanyi Dong","Alireza Nazari","Efrat Nehoran","Kaan Tekelioglu","Yinxiao Li","Kartikeya Badola","Tom Funkhouser","Yuanzhen Li","Varun Yerram","Ramya Ganeshan","Daniel Formoso","Karol Langner","Tian Shi","Huijian Li","Yumeya Yamamori","Amayika Panda","Alaa Saade","Angelo Scorza Scarpati","Chris Breaux","CJ Carey","Zongwei Zhou","Cho-Jui Hsieh","Sophie Bridgers","Alena Butryna","Nishesh Gupta","Vaibhav Tulsyan","Sanghyun Woo","Evgenii Eltyshev","Will Grathwohl","Chanel Parks","Seth Benjamin","Rina Panigrahy","Shenil Dodhia","Daniel De Freitas","Chris Sauer","Will Song","Ferran Alet","Jackson Tolins","Cosmin Paduraru","Xingyi Zhou","Brian Albert","Zizhao Zhang","Lei Shu","Mudit Bansal","Sarah Nguyen","Amir Globerson","Owen Xiao","James Manyika","Tom Hennigan","Rong Rong","Josip Matak","Anton Bakalov","Ankur Sharma","Danila Sinopalnikov","Andrew Pierson","Stephen Roller","Geoff Brown","Mingcen Gao","Toshiyuki Fukuzawa","Amin Ghafouri","Kenny Vassigh","Iain Barr","Zhicheng Wang","Anna Korsun","Rajesh Jayaram","Lijie Ren","Tim Zaman","Samira Khan","Yana Lunts","Dan Deutsch","Dave Uthus","Nitzan Katz","Masha Samsikova","Amr Khalifa","Nikhil Sethi","Jiao Sun","Luming Tang","Uri Alon","Xianghong Luo","Dian Yu","Abhishek Nayyar","Bryce Petrini","Will Truong","Vincent Hellendoorn","Nikolai Chinaev","Chris Alberti","Wei Wang","Jingcao Hu","Vahab Mirrokni","Ananth Balashankar","Avia Aharon","Aahil Mehta","Ahmet Iscen","Joseph Kready","Lucas Manning","Anhad Mohananey","Yuankai Chen","Anshuman Tripathi","Allen Wu","Igor Petrovski","Dawsen Hwang","Martin Baeuml","Shreyas Chandrakaladharan","Yuan Liu","Rey Coaguila","Maxwell Chen","Sally Ma","Pouya Tafti","Susheel Tatineni","Terry Spitz","Jiayu Ye","Paul Vicol","Mihaela Rosca","Adrià Puigdomènech","Zohar Yahav","Sanjay Ghemawat","Hanzhao Lin","Phoebe Kirk","Zaid Nabulsi","Sergey Brin","Bernd Bohnet","Ken Caluwaerts","Aditya Srikanth Veerubhotla","Dan Zheng","Zihang Dai","Petre Petrov","Yichong Xu","Ramin Mehran","Zhuo Xu","Luisa Zintgraf","Jiho Choi","Spurthi Amba Hombaiah","Romal Thoppilan","Sashank Reddi","Lukasz Lew","Li Li","Kellie Webster","KP Sawhney","Lampros Lamprou","Siamak Shakeri","Mayank Lunayach","Jianmin Chen","Sumit Bagri","Alex Salcianu","Ying Chen","Yani Donchev","Charlotte Magister","Signe Nørly","Vitor Rodrigues","Tomas Izo","Hila Noga","Joe Zou","Thomas Köppe","Wenxuan Zhou","Kenton Lee","Xiangzhu Long","Danielle Eisenbud","Anthony Chen","Connor Schenck","Chi Ming To","Peilin Zhong","Emanuel Taropa","Minh Truong","Omer Levy","Danilo Martins","Zhiyuan Zhang","Christopher Semturs","Kelvin Zhang","Alex Yakubovich","Pol Moreno","Lara McConnaughey","Di Lu","Sam Redmond","Lotte Weerts","Yonatan Bitton","Tiziana Refice","Nicolas Lacasse","Arthur Conmy","Corentin Tallec","Julian Odell","Hannah Forbes-Pollard","Arkadiusz Socala","Jonathan Hoech","Pushmeet Kohli","Alanna Walton","Rui Wang","Mikita Sazanovich","Kexin Zhu","Andrei Kapishnikov","Rich Galt","Matthew Denton","Ben Murdoch","Caitlin Sikora","Kareem Mohamed","Wei Wei","Uri First","Tim McConnell","Luis C. Cobo","James Qin","Thi Avrahami","Daniel Balle","Yu Watanabe","Annie Louis","Adam Kraft","Setareh Ariafar","Yiming Gu","Eugénie Rives","Charles Yoon","Andrei Rusu","James Cobon-Kerr","Chris Hahn","Jiaming Luo"," Yuvein"," Zhu","Niharika Ahuja","Rodrigo Benenson","Raphaël Lopez Kaufman","Honglin Yu","Lloyd Hightower","Junlin Zhang","Darren Ni","Lisa Anne Hendricks","Gabby Wang","Gal Yona","Lalit Jain","Pablo Barrio","Surya Bhupatiraju","Siva Velusamy","Allan Dafoe","Sebastian Riedel","Tara Thomas","Zhe Yuan","Mathias Bellaiche","Sheena Panthaplackel","Klemen Kloboves","Sarthak Jauhari","Canfer Akbulut","Todor Davchev","Evgeny Gladchenko","David Madras","Aleksandr Chuklin","Tyrone Hill","Quan Yuan","Mukundan Madhavan","Luke Leonhard","Dylan Scandinaro","Qihang Chen","Ning Niu","Arthur Douillard","Bogdan Damoc","Yasumasa Onoe","Fabian Pedregosa","Fred Bertsch","Chas Leichner","Joseph Pagadora","Jonathan Malmaud","Sameera Ponda","Andy Twigg","Oleksii Duzhyi","Jingwei Shen","Miaosen Wang","Roopal Garg","Jing Chen","Utku Evci","Jonathan Lee","Leon Liu","Koji Kojima","Masa Yamaguchi","Arunkumar Rajendran","AJ Piergiovanni","Vinodh Kumar Rajendran","Marco Fornoni","Gabriel Ibagon","Harry Ragan","Sadh MNM Khan","John Blitzer","Andrew Bunner","Guan Sun","Takahiro Kosakai","Scott Lundberg","Ndidi Elue","Kelvin Guu","SK Park","Jane Park","Arunachalam Narayanaswamy","Chengda Wu","Jayaram Mudigonda","Trevor Cohn","Hairong Mu","Ravi Kumar","Laura Graesser","Yichi Zhang","Richard Killam","Vincent Zhuang","Mai Giménez","Wael Al Jishi","Ruy Ley-Wild","Alex Zhai","Kazuki Osawa","Diego Cedillo","Jialu Liu","Mayank Upadhyay","Marcin Sieniek","Roshan Sharma","Tom Paine","Anelia Angelova","Sravanti Addepalli","Carolina Parada","Kingshuk Majumder","Avery Lamp","Sanjiv Kumar","Xiang Deng","Artiom Myaskovsky","Tea Sabolić","Jeffrey Dudek","Sarah York","Félix de Chaumont Quitry","Jiazhong Nie","Dee Cattle","Alok Gunjan","Bilal Piot","Waleed Khawaja","Seojin Bang","Simon Wang","Siavash Khodadadeh","Raghavender R","Praynaa Rawlani","Richard Powell","Kevin Lee","Johannes Griesser","GS Oh","Cesar Magalhaes","Yujia Li","Simon Tokumine","Hadas Natalie Vogel","Dennis Hsu","Arturo BC","Disha Jindal","Matan Cohen","Zi Yang","Junwei Yuan","Dario de Cesare","Tony Bruguier","Jun Xu","Monica Roy","Alon Jacovi","Dan Belov","Rahul Arya","Phoenix Meadowlark","Shlomi Cohen-Ganor","Wenting Ye","Patrick Morris-Suzuki","Praseem Banzal","Gan Song","Pranavaraj Ponnuramu","Fred Zhang","George Scrivener","Salah Zaiem","Alif Raditya Rochman","Kehang Han","Badih Ghazi","Kate Lee","Shahar Drath","Daniel Suo","Antonious Girgis","Pradeep Shenoy","Duy Nguyen","Douglas Eck","Somit Gupta","Le Yan","Joao Carreira","Anmol Gulati","Ruoxin Sang","Daniil Mirylenka","Emma Cooney","Edward Chou","Mingyang Ling","Cindy Fan","Ben Coleman","Guilherme Tubone","Ravin Kumar","Jason Baldridge","Felix Hernandez-Campos","Angeliki Lazaridou","James Besley","Itay Yona","Neslihan Bulut","Quentin Wellens","AJ Pierigiovanni","Jasmine George","Richard Green","Pu Han","Connie Tao","Geoff Clark","Chong You","Abbas Abdolmaleki","Justin Fu","Tongzhou Chen","Ashwin Chaugule","Angad Chandorkar","Altaf Rahman","Will Thompson","Penporn Koanantakool","Mike Bernico","Jie Ren","Andrey Vlasov","Sergei Vassilvitskii","Maciej Kula","Yizhong Liang","Dahun Kim","Yangsibo Huang","Chengxi Ye","Dmitry Lepikhin","Wesley Helmholz"],"pdf_url":"","comment":"72 pages, 17 figures"},{"id":"http://arxiv.org/abs/2512.17525v1","updated":"2025-12-19T12:50:39Z","published":"2025-12-19T12:50:39Z","title":"Computational analysis reveals historical trajectory of East-Polynesian lunar calendars","summary":"We investigate a type of lunar calendar known as lists of the 'nights of the moon', found throughout East Polynesia, including Rapa Nui (Easter Island). Using computational methods, we analyzed the lexical and structural divergence of 49 calendric lists from all major archipelagos, each containing about 30 night names. Our results, presented as a rooted phylogenetic tree, show a clear split into two main groups: one including lists from Rapa Nui, Mangareva, and the Marquesas; the other comprising lists from New Zealand, Hawaii, the Cook Islands, the Austral Islands, Tahiti, and the Tuamotu. This pattern aligns with a recent alternative classification of East Polynesian languages into 'Distal' (Marquesan, Mangarevan, Rapanui) and 'Proximal' (Maori, Hawaiian, Tahitian, etc.) subgroups. Since both language and lunar calendars are symbolic systems passed down and changed within communities - and given the geographic isolation of many archipelagos - we interpret this correspondence as evidence that the early divergence of East Polynesian lunar calendars mirrors early population movements and language splits in the region.","authors":["Miguel Valério","Fabio Tamburini","Michele Corazza"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.10787v2","updated":"2025-12-19T12:41:35Z","published":"2025-12-11T16:31:29Z","title":"Replace, Don't Expand: Mitigating Context Dilution in Multi-Hop RAG via Fixed-Budget Evidence Assembly","summary":"Retrieval-Augmented Generation (RAG) systems often fail on multi-hop queries when the initial retrieval misses a bridge fact. Prior corrective approaches, such as Self-RAG, CRAG, and Adaptive-$k$, typically address this by \\textit{adding} more context or pruning existing lists. However, simply expanding the context window often leads to \\textbf{context dilution}, where distractors crowd out relevant information. We propose \\textbf{SEAL-RAG}, a training-free controller that adopts a \\textbf{``replace, don't expand''} strategy to fight context dilution under a fixed retrieval depth $k$. SEAL executes a (\\textbf{S}earch $\\rightarrow$ \\textbf{E}xtract $\\rightarrow$ \\textbf{A}ssess $\\rightarrow$ \\textbf{L}oop) cycle: it performs on-the-fly, entity-anchored extraction to build a live \\textit{gap specification} (missing entities/relations), triggers targeted micro-queries, and uses \\textit{entity-first ranking} to actively swap out distractors for gap-closing evidence. We evaluate SEAL-RAG against faithful re-implementations of Basic RAG, CRAG, Self-RAG, and Adaptive-$k$ in a shared environment on \\textbf{HotpotQA} and \\textbf{2WikiMultiHopQA}. On HotpotQA ($k=3$), SEAL improves answer correctness by \\textbf{+3--13 pp} and evidence precision by \\textbf{+12--18 pp} over Self-RAG. On 2WikiMultiHopQA ($k=5$), it outperforms Adaptive-$k$ by \\textbf{+8.0 pp} in accuracy and maintains \\textbf{96\\%} evidence precision compared to 22\\% for CRAG. These gains are statistically significant ($p<0.001$). By enforcing fixed-$k$ replacement, SEAL yields a predictable cost profile while ensuring the top-$k$ slots are optimized for precision rather than mere breadth. We release our code and data at https://github.com/mosherino/SEAL-RAG.","authors":["Moshe Lahmy","Roi Yozevitch"],"pdf_url":"","comment":"24 pages, 2 figures"},{"id":"http://arxiv.org/abs/2512.01037v2","updated":"2025-12-19T11:00:50Z","published":"2025-11-30T19:11:45Z","title":"When Safety Blocks Sense: Measuring Semantic Confusion in LLM Refusals","summary":"Safety-aligned language models often refuse prompts that are actually harmless. Current evaluations mostly report global rates such as false rejection or compliance. These scores treat each prompt alone and miss local inconsistency, where a model accepts one phrasing of an intent but rejects a close paraphrase. This gap limits diagnosis and tuning. We introduce \"semantic confusion,\" a failure mode that captures such local inconsistency, and a framework to measure it. We build ParaGuard, a 10k-prompt corpus of controlled paraphrase clusters that hold intent fixed while varying surface form. We then propose three model-agnostic metrics at the token level: Confusion Index, Confusion Rate, and Confusion Depth. These metrics compare each refusal to its nearest accepted neighbors and use token embeddings, next-token probabilities, and perplexity signals. Experiments across diverse model families and deployment guards show that global false-rejection rate hides critical structure. Our metrics reveal globally unstable boundaries in some settings, localized pockets of inconsistency in others, and cases where stricter refusal does not increase inconsistency. We also show how confusion-aware auditing separates how often a system refuses from how sensibly it refuses. This gives developers a practical signal to reduce false refusals while preserving safety.","authors":["Riad Ahmed Anonto","Md Labid Al Nahiyan","Md Tanvir Hassan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.22376v4","updated":"2025-12-19T10:17:53Z","published":"2025-06-27T16:44:11Z","title":"OptScale: Probabilistic Optimality for Inference-time Scaling","summary":"Inference-time scaling has emerged as a powerful technique for enhancing the reasoning performance of Large Language Models (LLMs). However, existing approaches often rely on heuristic strategies for parallel sampling, lacking a principled foundation. To address this gap, we propose a probabilistic framework that formalizes the optimality of inference-time scaling under the assumption that parallel samples are independently and identically distributed (i.i.d.), and where the Best-of-$N$ selection strategy follows a probability distribution that can be estimated. Within this framework, we derive a theoretical lower bound on the required number of samples to achieve a target performance level, providing the first principled guidance for compute-efficient scaling. Leveraging this insight, we develop \\textsc{OptScale}, a practical algorithm that dynamically determines the optimal number of sampled responses. \\textsc{OptScale} employs a language model-based predictor to estimate probabilistic prior parameters, enabling the decision of the minimal number of samples needed that satisfy predefined performance thresholds and confidence levels. Extensive experiments on representative reasoning benchmarks (including MATH-500, GSM8K, AIME, and AMC) demonstrate that \\textsc{OptScale} significantly reduces sampling overhead while remaining better or on par with state-of-the-art reasoning performance. Our work offers both a theoretical foundation and a practical solution for principled inference-time scaling, addressing a critical gap in the efficient deployment of LLMs for complex reasoning.","authors":["Youkang Wang","Jian Wang","Rubing Chen","Xiao-Yong Wei"],"pdf_url":"","comment":"Accepted by AAAI-2026"},{"id":"http://arxiv.org/abs/2512.17419v1","updated":"2025-12-19T10:16:51Z","published":"2025-12-19T10:16:51Z","title":"SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories","summary":"Benchmarks like SWE-bench have standardized the evaluation of Large Language Models (LLMs) on repository-level software engineering tasks. However, these efforts remain limited by manual curation, static datasets, and a focus on Python-based bug fixes. We introduce SWE-Bench++, an automated framework that generates repository-level coding tasks from open-source GitHub projects. Unlike synthetic approaches, our pipeline harvests live pull requests to cover both bug fixes and feature requests across 11 languages. SWE-Bench++ turns GitHub pull requests (PRs) into reproducible, execution-based tasks via four stages: programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance. A final hint-guided trajectory synthesis step converts instances that strong models fail on into training trajectories. Our initial benchmark consists of 11,133 instances from 3,971 repositories across 11 languages. On a subset of 1,782 instances of this benchmark, today's strongest models perform as follows: claude-sonnet-4.5 achieves 36.20% pass@10, gpt-5-2025-08-07 34.57%, gemini/gemini-2.5-pro 24.92%, and gpt-4o 16.89%. We further demonstrate the utility of our dataset by showing that fine-tuning on SWE-Bench++ instances yields measurable improvements on the SWE-bench Multilingual benchmark. SWE-Bench++ provides a scalable, multilingual benchmark for evaluating and improving repository-level code generation.","authors":["Lilin Wang","Lucas Ramalho","Alan Celestino","Phuc Anthony Pham","Yu Liu","Umang Kumar Sinha","Andres Portillo","Onassis Osunwa","Gabriel Maduekwe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17396v1","updated":"2025-12-19T09:47:54Z","published":"2025-12-19T09:47:54Z","title":"RadImageNet-VQA: A Large-Scale CT and MRI Dataset for Radiologic Visual Question Answering","summary":"In this work, we introduce RadImageNet-VQA, a large-scale dataset designed to advance radiologic visual question answering (VQA) on CT and MRI exams. Existing medical VQA datasets are limited in scale, dominated by X-ray imaging or biomedical illustrations, and often prone to text-based shortcuts. RadImageNet-VQA is built from expert-curated annotations and provides 750K images paired with 7.5M question-answer samples. It covers three key tasks - abnormality detection, anatomy recognition, and pathology identification - spanning eight anatomical regions and 97 pathology categories, and supports open-ended, closed-ended, and multiple-choice questions. Extensive experiments show that state-of-the-art vision-language models still struggle with fine-grained pathology identification, particularly in open-ended settings and even after fine-tuning. Text-only analysis further reveals that model performance collapses to near-random without image inputs, confirming that RadImageNet-VQA is free from linguistic shortcuts. The full dataset and benchmark are publicly available at https://huggingface.co/datasets/raidium/RadImageNet-VQA.","authors":["Léo Butsanets","Charles Corbière","Julien Khlaut","Pierre Manceron","Corentin Dancette"],"pdf_url":"","comment":"Preprint, 23 pages, 12 figures, 7 tables"},{"id":"http://arxiv.org/abs/2512.17394v1","updated":"2025-12-19T09:47:38Z","published":"2025-12-19T09:47:38Z","title":"Are Vision Language Models Cross-Cultural Theory of Mind Reasoners?","summary":"Theory of Mind (ToM) -- the ability to attribute beliefs, desires, and emotions to others -- is fundamental for human social intelligence, yet remains a major challenge for artificial agents. Existing Vision-Language Models (VLMs) are increasingly applied in socially grounded tasks, but their capacity for cross-cultural ToM reasoning is largely unexplored. In this work, we introduce CulturalToM-VQA, a new evaluation benchmark containing 5095 questions designed to probe ToM reasoning across diverse cultural contexts through visual question answering. The dataset captures culturally grounded cues such as rituals, attire, gestures, and interpersonal dynamics, enabling systematic evaluation of ToM reasoning beyond Western-centric benchmarks. Our dataset is built through a VLM-assisted human-in-the-loop pipeline, where human experts first curate culturally rich images across traditions, rituals, and social interactions; a VLM then assist in generating structured ToM-focused scene descriptions, which are refined into question-answer pairs spanning a taxonomy of six ToM tasks and four graded complexity levels. The resulting dataset covers diverse theory of mind facets such as mental state attribution, false belief reasoning, non-literal communication, social norm violations, perspective coordination, and multi-agent reasoning.","authors":["Zabir Al Nazi","G M Shahariar","Abrar Hossain","Wei Peng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17387v1","updated":"2025-12-19T09:43:20Z","published":"2025-12-19T09:43:20Z","title":"CIFE: Code Instruction-Following Evaluation","summary":"Large Language Models (LLMs) are increasingly applied to real-world code generation, where functional correctness alone is insufficient for reliable deployment, developers also expect adherence to explicit requirements for robustness, formatting, and security. Existing benchmarks primarily assess correctness through test-case execution, offering limited insight into how reliably models follow such constraints. We introduce a benchmark of 1,000 Python tasks, each paired with an average of 7 developer-specified constraints spanning 13 categories. Constraints are curated through a four-stage human-LLM pipeline to ensure they are atomic, relevant, and objective. We evaluate 14 open- and closed-source models using complementary adherence metrics and propose the C2A Score, a composite measure that jointly captures correctness and constraint compliance. Results reveal a substantial gap between partial and strict satisfaction, while strong models achieve over 90% partial adherence, strict adherence remains between 39-66%. These findings highlight that trustworthy code generation requires not only correctness but also consistent adherence to developer intent.","authors":["Sravani Gunnu","Shanmukha Guttula","Hima Patel"],"pdf_url":"","comment":"20 pages, 22 figures, 2 tables"},{"id":"http://arxiv.org/abs/2512.17385v1","updated":"2025-12-19T09:42:04Z","published":"2025-12-19T09:42:04Z","title":"UCoder: Unsupervised Code Generation by Internal Probing of Large Language Models","summary":"Large language models (LLMs) have demonstrated remarkable capabilities in code generation tasks. However, their effectiveness heavily relies on supervised training with extensive labeled (e.g., question-answering pairs) or unlabeled datasets (e.g., code snippets), which are often expensive and difficult to obtain at scale. To address this limitation, this paper introduces a method IPC, an unsupervised framework that leverages Internal Probing of LLMs for Code generation without any external corpus, even unlabeled code snippets. We introduce the problem space probing, test understanding probing, solution space probing, and knowledge consolidation and reinforcement to probe the internal knowledge and confidence patterns existing in LLMs. Further, IPC identifies reliable code candidates through self-consistency mechanisms and representation-based quality estimation to train UCoder (coder with unsupervised learning). We validate the proposed approach across multiple code benchmarks, demonstrating that unsupervised methods can achieve competitive performance compared to supervised approaches while significantly reducing the dependency on labeled data and computational resources. Analytic experiments reveal that internal model states contain rich signals about code quality and correctness, and that properly harnessing these signals enables effective unsupervised learning for code generation tasks, opening new directions for training code LLMs in resource-constrained scenarios.","authors":["Jiajun Wu","Jian Yang","Wei Zhang","Lin Jing","Yuqing Ma","Ensheng Shi","Yuchi Ma","Zhoujun Li","Xianglong Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17375v1","updated":"2025-12-19T09:22:11Z","published":"2025-12-19T09:22:11Z","title":"AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens","summary":"Reward models and LLM-as-a-Judge systems are central to modern post-training pipelines such as RLHF, DPO, and RLAIF, where they provide scalar feedback and binary decisions that guide model selection and RL-based fine-tuning. We show that these judge systems exhibit a recurring vulnerability: short sequences of low-perplexity control tokens can flip many binary evaluations from correct ``No'' judgments to incorrect ``Yes'' judgments by steering the last-layer logit gap. These control tokens are patterns that a policy model could plausibly generate during post-training, and thus represent realistic reward-hacking risks rather than worst-case adversarial strings. Our method, AdvJudge-Zero, uses the model's next-token distribution and beam-search exploration to discover diverse control-token sequences from scratch, and our analysis shows that the induced hidden-state perturbations concentrate in a low-rank ``soft mode'' that is anti-aligned with the judge's refusal direction. Empirically, these tokens cause very high false positive rates when large open-weight and specialized judge models score incorrect answers on math and reasoning benchmarks. Finally, we show that LoRA-based adversarial training on small sets of control-token-augmented examples can markedly reduce these false positives while preserving evaluation quality.","authors":["Tung-Ling Li","Yuhao Wu","Hongliang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.25123v3","updated":"2025-12-19T09:09:46Z","published":"2025-09-29T17:44:27Z","title":"From $f(x)$ and $g(x)$ to $f(g(x))$: LLMs Learn New Skills in RL by Composing Old Ones","summary":"Does RL teach LLMs genuinely new skills, or does it merely activate existing ones? This question lies at the core of ongoing debates about the role of RL in LLM post-training. On one side, strong empirical results can be achieved with RL even without preceding supervised finetuning; on the other, critics argue that RL contributes little beyond reweighting existing reasoning strategies. This work provides concrete evidence that LLMs can acquire genuinely new skills during RL by composing existing ones, mirroring one of the central mechanisms by which humans acquire new cognitive skills. To mitigate data contamination and other confounding factors, and to allow precise control over task complexity, we develop a synthetic framework for our investigation. Specifically, we define a skill as the ability to infer the output of a string transformation function f(x) given x. When an LLM has already learned f and g prior to RL, our experiments reveal that RL enables it to learn unseen compositions of them h(x)=g(f(x)). Further, this compositional ability generalizes to more difficult problems such as compositions of >2 functions unseen during RL training. Surprisingly, our experiments show that compositional skill acquired on a source task transfers to a different target task. This transfer happens even without compositional training on the target, requiring only prior knowledge of the target's atomic skills. Our qualitative analysis shows that RL fundamentally changes the reasoning behaviors of the models. In contrast, next-token training with the same data yields none of these findings. Our systematic experiments provide fresh insights into LLM learning, suggesting the value of first building base models with basic skills, then using RL to incentivize advanced, generalizable skills for complex problems.","authors":["Lifan Yuan","Weize Chen","Yuchen Zhang","Ganqu Cui","Hanbin Wang","Ziming You","Ning Ding","Zhiyuan Liu","Maosong Sun","Hao Peng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.23358v2","updated":"2025-12-19T08:52:20Z","published":"2025-07-31T09:08:59Z","title":"Text-to-SQL Task-oriented Dialogue Ontology Construction","summary":"Large language models (LLMs) are widely used as general-purpose knowledge sources, but they rely on parametric knowledge, limiting explainability and trustworthiness. In task-oriented dialogue (TOD) systems, this separation is explicit, using an external database structured by an explicit ontology to ensure explainability and controllability. However, building such ontologies requires manual labels or supervised training. We introduce TeQoDO: a Text-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM autonomously builds a TOD ontology from scratch using only its inherent SQL programming capabilities combined with concepts from modular TOD systems provided in the prompt. We show that TeQoDO outperforms transfer learning approaches, and its constructed ontology is competitive on a downstream dialogue state tracking task. Ablation studies demonstrate the key role of modular TOD system concepts. TeQoDO also scales to allow construction of much larger ontologies, which we investigate on a Wikipedia and arXiv dataset. We view this as a step towards broader application of ontologies.","authors":["Renato Vukovic","Carel van Niekerk","Michael Heck","Benjamin Ruppik","Hsien-Chin Lin","Shutong Feng","Nurul Lubis","Milica Gasic"],"pdf_url":"","comment":"Accepted to Transactions of the Association for Computational Linguistics"},{"id":"http://arxiv.org/abs/2512.17351v1","updated":"2025-12-19T08:47:28Z","published":"2025-12-19T08:47:28Z","title":"Physics of Language Models: Part 4.1, Architecture Design and the Magic of Canon Layers","summary":"Understanding architectural differences in language models is challenging, especially at academic-scale pretraining (e.g., 1.3B parameters, 100B tokens), where results are often dominated by noise and randomness. To overcome this, we introduce controlled synthetic pretraining tasks that isolate and evaluate core model capabilities. Within this framework, we discover CANON LAYERS: lightweight architectural components -- named after the musical term \"canon\" -- that promote horizontal information flow across neighboring tokens. Canon layers compute weighted sums of nearby token representations and integrate seamlessly into Transformers, linear attention, state-space models, or any sequence architecture.\n  We present 12 key results. This includes how Canon layers enhance reasoning depth (e.g., by $2\\times$), reasoning breadth, knowledge manipulation, etc. They lift weak architectures like NoPE to match RoPE, and linear attention to rival SOTA linear models like Mamba2/GDN -- validated both through synthetic tasks and real-world academic-scale pretraining. This synthetic playground offers an economical, principled path to isolate core model capabilities often obscured at academic scales. Equipped with infinite high-quality data, it may even PREDICT how future architectures will behave as training pipelines improve -- e.g., through better data curation or RL-based post-training -- unlocking deeper reasoning and hierarchical inference.","authors":["Zeyuan Allen-Zhu"],"pdf_url":"","comment":"V1.1 appeared in NeurIPS 2025 main conference; V2 adds GDN experiments, tightens some experiments (for a stronger, fairer comparison), and re-organizes sections"},{"id":"http://arxiv.org/abs/2512.17347v1","updated":"2025-12-19T08:38:28Z","published":"2025-12-19T08:38:28Z","title":"Stakeholder Suite: A Unified AI Framework for Mapping Actors, Topics and Arguments in Public Debates","summary":"Public debates surrounding infrastructure and energy projects involve complex networks of stakeholders, arguments, and evolving narratives. Understanding these dynamics is crucial for anticipating controversies and informing engagement strategies, yet existing tools in media intelligence largely rely on descriptive analytics with limited transparency. This paper presents Stakeholder Suite, a framework deployed in operational contexts for mapping actors, topics, and arguments within public debates. The system combines actor detection, topic modeling, argument extraction and stance classification in a unified pipeline. Tested on multiple energy infrastructure projects as a case study, the approach delivers fine-grained, source-grounded insights while remaining adaptable to diverse domains. The framework achieves strong retrieval precision and stance accuracy, producing arguments judged relevant in 75% of pilot use cases. Beyond quantitative metrics, the tool has proven effective for operational use: helping project teams visualize networks of influence, identify emerging controversies, and support evidence-based decision-making.","authors":["Mohamed Chenene","Jeanne Rouhier","Jean Daniélou","Mihir Sarkar","Elena Cabrio"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17344v1","updated":"2025-12-19T08:35:51Z","published":"2025-12-19T08:35:51Z","title":"Governance-Aware Hybrid Fine-Tuning for Multilingual Large Language Models","summary":"We present a governance-aware hybrid fine-tuning framework for multilingual, low-resource adaptation of large language models. The core algorithm combines gradient-aligned low-rank updates with structured orthogonal transformations through layer-wise mixing and introduces unitary constraints in selected sub-layers to stabilize deep optimization. In tandem with lightweight, label-free data governance steps, including language identification, near-duplicate removal, and quality filtering, the framework targets accuracy, calibration, and cross-language parity under tight compute budgets. Across XNLI and FLORES, the hybrid approach delivers consistent gains over strong PEFT baselines while maintaining directional balance and improving probability calibration, as shown in Tables II and III. It is more resilient to lightweight orthographic variants, as shown in Table IV, and benefits additively from simple governance steps, as shown in Table V. Training footprint measurements indicate modest overhead and a favorable cost-quality frontier, as shown in Table VI and Figure 2. Together, these results show that hybrid and unitary PEFT provide a stable and accessible path to resource-efficient multilingual adaptation when paired with practical data governance.","authors":["Haomin Qi","Chengbo Huang","Zihan Dai","Yunkai Gao"],"pdf_url":"","comment":"11 pages, 4 figures, 6 tables. arXiv admin note: substantial text overlap with arXiv:2507.18076"},{"id":"http://arxiv.org/abs/2503.19041v4","updated":"2025-12-19T08:17:42Z","published":"2025-03-24T18:11:42Z","title":"LookAhead Tuning: Safer Language Models via Partial Answer Previews","summary":"Fine-tuning enables large language models (LLMs) to adapt to specific domains, but often compromises their previously established safety alignment. To mitigate the degradation of model safety during fine-tuning, we introduce LookAhead Tuning, a lightweight and effective data-driven approach that preserves safety during fine-tuning. The method introduces two simple strategies that modify training data by previewing partial answer prefixes, thereby minimizing perturbations to the model's initial token distributions and maintaining its built-in safety mechanisms. Comprehensive experiments demonstrate that LookAhead Tuning effectively maintains model safety without sacrificing robust performance on downstream tasks. Our findings position LookAhead Tuning as a reliable and efficient solution for the safe and effective adaptation of LLMs.","authors":["Kangwei Liu","Mengru Wang","Yujie Luo","Lin Yuan","Mengshu Sun","Lei Liang","Zhiqiang Zhang","Jun Zhou","Bryan Hooi","Shumin Deng"],"pdf_url":"","comment":"WSDM 2026 short"},{"id":"http://arxiv.org/abs/2502.01436v3","updated":"2025-12-19T08:17:09Z","published":"2025-02-03T15:19:28Z","title":"Towards Safer Chatbots: Automated Policy Compliance Evaluation of Custom GPTs","summary":"User-configured chatbots built on top of large language models are increasingly available through centralized marketplaces such as OpenAI's GPT Store. While these platforms enforce usage policies intended to prevent harmful or inappropriate behavior, the scale and opacity of customized chatbots make systematic policy enforcement challenging. As a result, policy-violating chatbots continue to remain publicly accessible despite existing review processes. This paper presents a fully automated method for evaluating the compliance of Custom GPTs with its marketplace usage policy using black-box interaction. The method combines large-scale GPT discovery, policy-driven red-teaming prompts, and automated compliance assessment using an LLM-as-a-judge. We focus on three policy-relevant domains explicitly addressed in OpenAI's usage policies: Romantic, Cybersecurity, and Academic GPTs. We validate our compliance assessment component against a human-annotated ground-truth dataset, achieving an F1 score of 0.975 for binary policy violation detection. We then apply the method in a large-scale empirical study of 782 Custom GPTs retrieved from the GPT Store. The results show that 58.7% of the evaluated GPTs exhibit at least one policy-violating response, with substantial variation across policy domains. A comparison with the base models (GPT-4 and GPT-4o) indicates that most violations originate from model-level behavior, while customization tends to amplify these tendencies rather than create new failure modes. Our findings reveal limitations in current review mechanisms for user-configured chatbots and demonstrate the feasibility of scalable, behavior-based policy compliance evaluation.","authors":["David Rodriguez","William Seymour","Jose M. Del Alamo","Jose Such"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.12218v2","updated":"2025-12-19T08:16:24Z","published":"2025-12-13T07:04:42Z","title":"Journey Before Destination: On the importance of Visual Faithfulness in Slow Thinking","summary":"Reasoning-augmented vision language models (VLMs) generate explicit chains of thought that promise greater capability and transparency but also introduce new failure modes: models may reach correct answers via visually unfaithful intermediate steps, or reason faithfully yet fail on the final prediction. Standard evaluations that only measure final-answer accuracy cannot distinguish these behaviors. We introduce the visual faithfulness of reasoning chains as a distinct evaluation dimension, focusing on whether the perception steps of a reasoning chain are grounded in the image. We propose a training- and reference-free framework that decomposes chains into perception versus reasoning steps and uses off-the-shelf VLM judges for step-level faithfulness, additionally verifying this approach through a human meta-evaluation. Building on this metric, we present a lightweight self-reflection procedure that detects and locally regenerates unfaithful perception steps without any training. Across multiple reasoning-trained VLMs and perception-heavy benchmarks, our method reduces Unfaithful Perception Rate while preserving final-answer accuracy, improving the reliability of multimodal reasoning.","authors":["Rheeya Uppaal","Phu Mon Htut","Min Bai","Nikolaos Pappas","Zheng Qi","Sandesh Swamy"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2512.17325v1","updated":"2025-12-19T08:14:21Z","published":"2025-12-19T08:14:21Z","title":"Task Schema and Binding: A Double Dissociation Study of In-Context Learning","summary":"We provide causal mechanistic validation that in-context learning (ICL) decomposes into two separable mechanisms: Task Schema (abstract task type recognition) and Binding (specific input-output associations). Through activation patching experiments across 9 models from 7 Transformer families plus Mamba (370M-13B parameters), we establish three key findings:\n  1. Double dissociation: Task Schema transfers at 100% via late MLP patching; Binding transfers at 62% via residual stream patching -- proving separable mechanisms\n  2. Prior-Schema trade-off: Schema reliance inversely correlates with prior knowledge (Spearman rho = -0.596, p < 0.001, N=28 task-model pairs)\n  3. Architecture generality: The mechanism operates across all tested architectures including the non-Transformer Mamba\n  These findings offer a mechanistic account of the ICL puzzle that contrasts with prior views treating ICL as a monolithic mechanism (whether retrieval-based, gradient descent-like, or purely Bayesian). By establishing that Schema and Binding are neurally dissociable -- not merely behavioral modes -- we provide causal evidence for dual-process theories of ICL. Models rely on Task Schema when prior knowledge is absent, but prior knowledge interferes through attentional mis-routing (72.7% recency bias) rather than direct output competition (0%). This explains why arbitrary mappings succeed (zero prior leads to full Schema reliance) while factual overrides fail -- and reveals that the true bottleneck is attentional, not output-level. Practical implications: Understanding these dual mechanisms enables more efficient prompt engineering -- reliable schema transfer reduces required demonstrations for novel tasks, while prior-aware design can mitigate the 38% binding failure rate in high-prior scenarios, improving ICL system reliability in production deployments.","authors":["Chaeha Kim"],"pdf_url":"","comment":"20pages, 2figures"},{"id":"http://arxiv.org/abs/2507.18076v2","updated":"2025-12-19T08:12:27Z","published":"2025-07-24T04:00:02Z","title":"Hybrid and Unitary PEFT for Resource-Efficient Large Language Models","summary":"Fine-tuning large language models (LLMs) remains a computational bottleneck due to their scale and memory demands. This paper presents a comprehensive evaluation of parameter-efficient fine-tuning (PEFT) techniques, including LoRA, BOFT, LoRA-GA, and uRNN, and introduces a novel hybrid strategy that dynamically integrates BOFT's orthogonal stability with LoRA-GA's gradient-aligned rapid convergence. By computing per-layer adaptive updates guided by gradient norms, the hybrid method achieves superior convergence efficiency and generalization across diverse tasks. We also explore, for the first time, the adaptation of unitary RNN (uRNN) principles to Transformer-based LLMs, enhancing gradient stability through structured unitary constraints. Across GLUE, GSM8K, MT-Bench, and HumanEval, using models ranging from 7B to 405B parameters, the hybrid approach yields consistent gains across three independent runs per task and model, approaching the quality of full fine-tuning while reducing training time by approximately 2.1 times and peak memory usage by nearly 50 percent, indicating practical significance under resource constraints. A compact multilingual and low-resource study on XNLI and FLORES, using 32 examples per language, further demonstrates consistent gains under the same budget with a small and stable footprint. These results indicate a practical and scalable path toward accessible LLM fine-tuning under resource constraints.","authors":["Haomin Qi","Zihan Dai","Chengbo Huang"],"pdf_url":"","comment":"11 pages, 2 figures and 7 table"},{"id":"http://arxiv.org/abs/2512.17308v1","updated":"2025-12-19T07:46:29Z","published":"2025-12-19T07:46:29Z","title":"Large Language Models as Pokémon Battle Agents: Strategic Play and Content Generation","summary":"Strategic decision-making in Pokémon battles presents a unique testbed for evaluating large language models. Pokémon battles demand reasoning about type matchups, statistical trade-offs, and risk assessment, skills that mirror human strategic thinking. This work examines whether Large Language Models (LLMs) can serve as competent battle agents, capable of both making tactically sound decisions and generating novel, balanced game content. We developed a turn-based Pokémon battle system where LLMs select moves based on battle state rather than pre-programmed logic. The framework captures essential Pokémon mechanics: type effectiveness multipliers, stat-based damage calculations, and multi-Pokémon team management. Through systematic evaluation across multiple model architectures we measured win rates, decision latency, type-alignment accuracy, and token efficiency. These results suggest LLMs can function as dynamic game opponents without domain-specific training, offering a practical alternative to reinforcement learning for turn-based strategic games. The dual capability of tactical reasoning and content creation, positions LLMs as both players and designers, with implications for procedural generation and adaptive difficulty systems in interactive entertainment.","authors":["Daksh Jain","Aarya Jain","Ashutosh Desai","Avyakt Verma","Ishan Bhanuka","Pratik Narang","Dhruv Kumar"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2506.09707v4","updated":"2025-12-19T07:32:25Z","published":"2025-06-11T13:21:06Z","title":"Fine-Tuning Large Audio-Language Models with LoRA for Precise Temporal Localization of Prolonged Exposure Therapy Elements","summary":"Prolonged Exposure (PE) therapy is an effective treatment for post-traumatic stress disorder (PTSD), but evaluating therapist fidelity remains labor-intensive due to the need for manual review of session recordings. We present a method for the automatic temporal localization of key PE fidelity elements, identifying their start and stop times, directly from session audio and transcripts. Our approach fine-tunes a large pre-trained audio-language model, Qwen2-Audio, using Low-Rank Adaptation (LoRA) to process focused 30-second windows of audio-transcript input. Fidelity labels for three core protocol phases, therapist orientation (P1), imaginal exposure (P2), and post-imaginal processing (P3), are generated via LLM-based prompting and verified by trained raters. The model is trained to predict normalized boundary offsets using soft supervision guided by task-specific prompts. On a dataset of 308 real PE sessions, our best configuration (LoRA rank 8, 30s windows) achieves a mean absolute error (MAE) of 5.3s across tasks, within typical rater tolerance for timestamp review, enabling practical fidelity QC. We further analyze the effects of window size and LoRA rank, highlighting the importance of context granularity and model adaptation. This work introduces a privacy-preserving, scalable framework for fidelity tracking in PE therapy, with potential to support clinician training, supervision, and quality assurance.","authors":["Suhas BN","Andrew M. Sherrill","Jyoti Alaparthi","Dominik Mattioli","Rosa I. Arriaga","Chris W. Wiese","Saeed Abdullah"],"pdf_url":"","comment":"5 pages, 2 figures"},{"id":"http://arxiv.org/abs/2512.13478v4","updated":"2025-12-19T07:21:39Z","published":"2025-12-15T16:14:32Z","title":"Non-Resolution Reasoning (NRR): A Computational Framework for Contextual Identity and Ambiguity Preservation","summary":"Current artificial intelligence systems, despite remarkable capabilities in text generation and pattern recognition, exhibit a fundamental architectural limitation: they resolve ambiguity prematurely. This premature semantic collapse -- the tendency to collapse multiple valid interpretations into a single output -- stems from classical identity assumptions embedded in standard neural architectures. We propose Non-Resolution Reasoning (NRR), a computational framework that treats ambiguity retention as a valid reasoning mode rather than a defect to be eliminated. NRR introduces three core principles: (1) Non-Identity ($A \\neq A$) -- the same symbol refers to different entities across contexts; (2) Approximate Identity ($A \\approx A$) -- entities share partial structural overlap without being identical; and (3) Non-Resolution -- conflicting interpretations can coexist without forced convergence. We formalize these principles through three architectural components: Multi-Vector Embeddings for context-dependent representation, Non-Collapsing Attention for parallel interpretation retention, and Contextual Identity Tracking (CIT) for maintaining $A \\neq A$ across inference. We demonstrate NRR's advantages through case studies in paradox handling, creative generation, and context-dependent reasoning. Crucially, we provide a minimal empirical validation on a synthetic context-shift task where an NRR-lite model achieves 90.9% out-of-distribution accuracy compared to 9.1% for standard architectures, demonstrating that ambiguity preservation enables structural generalization. NRR challenges the assumption that meaning must collapse to be useful, offering a foundation for AI systems capable of sophisticated ambiguity handling and creative reasoning. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.","authors":["Kei Saito"],"pdf_url":"","comment":"16 pages, 1 figure. Updated version with corrected references and aligned acknowledgments"},{"id":"http://arxiv.org/abs/2510.16882v2","updated":"2025-12-19T07:13:05Z","published":"2025-10-19T15:32:01Z","title":"Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning","summary":"Supervised fine-tuning (SFT) is a commonly used technique to adapt large language models (LLMs) to downstream tasks. In practice, SFT on a full dataset is computationally expensive and sometimes suffers from overfitting or bias amplification. This facilitates the rise of data curation in SFT, which prioritizes the most valuable data to optimze. This work studies the online batch selection family that dynamically scores and filters samples during the training process. However, existing popular methods often (i) rely merely on the utility of data to select a subset while neglecting other crucial factors like diversity, (ii) rely on external resources such as reference models or validation sets, and (iii) incur extra training time over full-dataset training. To address these limitations, this work develops \\textbf{UDS (Utility-Diversity Sampling)}, a framework for efficient online batch selection in SFT. UDS leverages the nuclear norm of the logits matrix to capture both data utility and intra-sample diversity, while estimating inter-sample diversity through efficient low-dimensional embedding comparisons with a lightweight memory buffer of historical samples. Such a design eliminates the need for external resources and unnecessary backpropagation, securing computational efficiency. Experiments on multiple benchmarks demonstrate that UDS consistently outperforms state-of-the-art online batch selection methods under varying data budgets, and significantly reduces training time compared to full-dataset fine-tuning. Code is available at https://github.com/gfyddha/UDS.","authors":["Heming Zou","Yixiu Mao","Yun Qu","Qi Wang","Xiangyang Ji"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17289v1","updated":"2025-12-19T07:11:50Z","published":"2025-12-19T07:11:50Z","title":"Subjective Question Generation and Answer Evaluation using NLP","summary":"Natural Language Processing (NLP) is one of the most revolutionary technologies today. It uses artificial intelligence to understand human text and spoken words. It is used for text summarization, grammar checking, sentiment analysis, and advanced chatbots and has many more potential use cases. Furthermore, it has also made its mark on the education sector. Much research and advancements have already been conducted on objective question generation; however, automated subjective question generation and answer evaluation are still in progress. An automated system to generate subjective questions and evaluate the answers can help teachers assess student work and enhance the student's learning experience by allowing them to self-assess their understanding after reading an article or a chapter of a book. This research aims to improve current NLP models or make a novel one for automated subjective question generation and answer evaluation from text input.","authors":["G. M. Refatul Islam","Safwan Shaheer","Yaseen Nur","Mohammad Rafid Hamid"],"pdf_url":"","comment":"5 pages, 5 figures, 2 tables, conference paper"},{"id":"http://arxiv.org/abs/2405.15877v4","updated":"2025-12-19T06:49:59Z","published":"2024-05-24T18:40:20Z","title":"Basis Selection: Low-Rank Decomposition of Pretrained Large Language Models for Target Applications","summary":"Large language models (LLMs) significantly enhance the performance of various applications, but they are computationally intensive and energy-demanding. This makes it challenging to deploy them on devices with limited resources, such as personal computers and mobile/wearable devices, and results in substantial inference costs in resource-rich environments like cloud servers. To extend the use of LLMs, we introduce a low-rank decomposition approach to effectively compress these models, tailored to the requirements of specific applications. We observe that LLMs pretrained on general datasets contain many redundant components not needed for particular applications. Our method focuses on identifying and removing these redundant parts, retaining only the necessary elements for the target applications. Specifically, we represent the weight matrices of LLMs as a linear combination of base components. We then prune the irrelevant bases and enhance the model with new bases beneficial for specific applications. Deep compression results on the Llama 2-7b and -13B models, conducted on target applications including mathematical reasoning and code generation, show that our method significantly reduces model size while maintaining comparable accuracy to state-of-the-art low-rank compression techniques.","authors":["Yang Li","Daniel Agyei Asante","Changsheng Zhao","Ernie Chang","Yangyang Shi","Vikas Chandra"],"pdf_url":"","comment":"Transactions on Machine Learning Research (TMLR), 2025"},{"id":"http://arxiv.org/abs/2511.11571v2","updated":"2025-12-19T06:48:56Z","published":"2025-11-14T18:59:59Z","title":"Optimizing Mixture of Block Attention","summary":"Mixture of Block Attention (MoBA) (Lu et al., 2025) is a promising building block for efficiently processing long contexts in LLMs by enabling queries to sparsely attend to a small subset of key-value blocks, drastically reducing computational cost. However, the design principles governing MoBA's performance are poorly understood, and it lacks an efficient GPU implementation, hindering its practical adoption. In this paper, we first develop a statistical model to analyze MoBA's underlying mechanics. Our model reveals that performance critically depends on the router's ability to accurately distinguish relevant from irrelevant blocks based on query-key affinities. We derive a signal-to-noise ratio that formally connects architectural parameters to this retrieval accuracy. Guided by our analysis, we identify two key pathways for improvement: using smaller block sizes and applying a short convolution on keys to cluster relevant signals, which enhances routing accuracy. While theoretically better, small block sizes are inefficient on GPUs. To bridge this gap, we introduce FlashMoBA, a hardware-aware CUDA kernel that enables efficient MoBA execution even with the small block sizes our theory recommends. We validate our insights by training LLMs from scratch, showing that our improved MoBA models match the performance of dense attention baselines. FlashMoBA achieves up to 14.7x speedup over FlashAttention-2 for small blocks, making our theoretically-grounded improvements practical. Code is available at: https://github.com/mit-han-lab/flash-moba.","authors":["Guangxuan Xiao","Junxian Guo","Kasra Mazaheri","Song Han"],"pdf_url":"","comment":"The first two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2512.17270v1","updated":"2025-12-19T06:37:44Z","published":"2025-12-19T06:37:44Z","title":"Understanding Generalization in Role-Playing Models via Information Theory","summary":"Role-playing models (RPMs) are widely used in real-world applications but underperform when deployed in the wild. This degradation can be attributed to distribution shifts, including user, character, and dialogue compositional shifts. Existing methods like LLM-as-a-judge fall short in providing a fine-grained diagnosis of how these shifts affect RPM generalization, and thus there lack formal frameworks to characterize RPM generalization behaviors. To bridge these gaps, we introduce an information-theoretic metric, named reasoning-based effective mutual information difference (R-EMID), to measure RPM performance degradation in an interpretable way. We also derive an upper bound on R-EMID to predict the worst-case generalization performance of RPMs and theoretically reveal how various shifts contribute to the RPM performance degradation. Moreover, we propose a co-evolving reinforcement learning framework to adaptively model the connection among user, character, and dialogue context and thus enhance the estimation of dialogue response generation probability, which is critical for calculating R-EMID. Finally, we evaluate the generalization performance of various RPMs using R-EMID, finding that user shift poses the highest risk among all shifts and reinforcement learning is the most effective approach for enhancing RPM generalization.","authors":["Yongqi Li","Hao Lang","Fei Huang","Tieyun Qian","Yongbin Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16189v2","updated":"2025-12-19T06:34:23Z","published":"2025-12-18T05:23:47Z","title":"Mitigating Hallucinations in Healthcare LLMs with Granular Fact-Checking and Domain-Specific Adaptation","summary":"In healthcare, it is essential for any LLM-generated output to be reliable and accurate, particularly in cases involving decision-making and patient safety. However, the outputs are often unreliable in such critical areas due to the risk of hallucinated outputs from the LLMs. To address this issue, we propose a fact-checking module that operates independently of any LLM, along with a domain-specific summarization model designed to minimize hallucination rates. Our model is fine-tuned using Low-Rank Adaptation (LoRa) on the MIMIC III dataset and is paired with the fact-checking module, which uses numerical tests for correctness and logical checks at a granular level through discrete logic in natural language processing (NLP) to validate facts against electronic health records (EHRs). We trained the LLM model on the full MIMIC-III dataset. For evaluation of the fact-checking module, we sampled 104 summaries, extracted them into 3,786 propositions, and used these as facts. The fact-checking module achieves a precision of 0.8904, a recall of 0.8234, and an F1-score of 0.8556. Additionally, the LLM summary model achieves a ROUGE-1 score of 0.5797 and a BERTScore of 0.9120 for summary quality.","authors":["Musarrat Zeba","Abdullah Al Mamun","Kishoar Jahan Tithee","Debopom Sutradhar","Mohaimenul Azam Khan Raiaan","Saddam Mukta","Reem E. Mohamed","Md Rafiqul Islam","Yakub Sebastian","Mukhtar Hussain","Sami Azam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17267v1","updated":"2025-12-19T06:32:46Z","published":"2025-12-19T06:32:46Z","title":"AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators","summary":"Evaluating user-facing AI applications remains a central challenge, especially in open-ended domains such as travel planning, clinical note generation, or dialogue. The gold standard is user feedback (e.g., thumbs up/down) or behavioral signals (e.g., retention), but these are often scarce in prototypes and research projects, or too-slow to use for system optimization. We present AutoMetrics, a framework for synthesizing evaluation metrics under low-data constraints. AutoMetrics combines retrieval from MetricBank, a collection of 48 metrics we curate, with automatically generated LLM-as-a-Judge criteria informed by lightweight human feedback. These metrics are composed via regression to maximize correlation with human signal. AutoMetrics takes you from expensive measures to interpretable automatic metrics. Across 5 diverse tasks, AutoMetrics improves Kendall correlation with human ratings by up to 33.4% over LLM-as-a-Judge while requiring fewer than 100 feedback points. We show that AutoMetrics can be used as a proxy reward to equal effect as a verifiable reward. We release the full AutoMetrics toolkit and MetricBank to accelerate adaptive evaluation of LLM applications.","authors":["Michael J. Ryan","Yanzhe Zhang","Amol Salunkhe","Yi Chu","Di Xu","Diyi Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.20112v3","updated":"2025-12-19T06:23:19Z","published":"2025-05-26T15:14:54Z","title":"ResSVD: Residual Compensated SVD for Large Language Model Compression","summary":"Large language models (LLMs) have demonstrated impressive capabilities in a wide range of downstream natural language processing tasks. Nevertheless, their considerable sizes and memory demands hinder practical deployment, underscoring the importance of developing efficient compression strategies. Singular value decomposition (SVD) decomposes a matrix into orthogonal components, enabling efficient low-rank approximation. This is particularly suitable for LLM compression, where weight matrices often exhibit significant redundancy. However, current SVD-based methods neglect the residual matrix from truncation, resulting in significant truncation loss. Additionally, compressing all layers of the model results in severe performance degradation. To overcome these limitations, we propose ResSVD, a new post-training SVD-based LLM compression method. Specifically, we leverage the residual matrix generated during the truncation process to reduce truncation loss. Moreover, under a fixed overall compression ratio, we selectively compress the last few layers of the model, which mitigates error propagation and significantly improves the performance of compressed models. Comprehensive evaluations of ResSVD on diverse LLM families and multiple benchmark datasets indicate that ResSVD consistently achieves superior performance over existing counterpart methods, demonstrating its practical effectiveness.","authors":["Haolei Bai","Siyong Jian","Tuo Liang","Yu Yin","Huan Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17260v1","updated":"2025-12-19T06:19:55Z","published":"2025-12-19T06:19:55Z","title":"Seed-Prover 1.5: Mastering Undergraduate-Level Theorem Proving via Learning from Experience","summary":"Large language models have recently made significant progress to generate rigorous mathematical proofs. In contrast, utilizing LLMs for theorem proving in formal languages (such as Lean) remains challenging and computationally expensive, particularly when addressing problems at the undergraduate level and beyond. In this work, we present \\textbf{Seed-Prover 1.5}, a formal theorem-proving model trained via large-scale agentic reinforcement learning, alongside an efficient test-time scaling (TTS) workflow. Through extensive interactions with Lean and other tools, the model continuously accumulates experience during the RL process, substantially enhancing the capability and efficiency of formal theorem proving. Furthermore, leveraging recent advancements in natural language proving, our TTS workflow efficiently bridges the gap between natural and formal languages. Compared to state-of-the-art methods, Seed-Prover 1.5 achieves superior performance with a smaller compute budget. It solves \\textbf{88\\% of PutnamBench} (undergraduate-level), \\textbf{80\\% of Fate-H} (graduate-level), and \\textbf{33\\% of Fate-X} (PhD-level) problems. Notably, using our system, we solved \\textbf{11 out of 12 problems} from Putnam 2025 within 9 hours. Our findings suggest that scaling learning from experience, driven by high-quality formal feedback, holds immense potential for the future of formal mathematical reasoning.","authors":["Jiangjie Chen","Wenxiang Chen","Jiacheng Du","Jinyi Hu","Zhicheng Jiang","Allan Jie","Xiaoran Jin","Xing Jin","Chenggang Li","Wenlei Shi","Zhihong Wang","Mingxuan Wang","Chenrui Wei","Shufa Wei","Huajian Xin","Fan Yang","Weihao Gao","Zheng Yuan","Tianyang Zhan","Zeyu Zheng","Tianxi Zhou","Thomas Hanwen Zhu"],"pdf_url":"","comment":"21 pages"},{"id":"http://arxiv.org/abs/2512.16248v2","updated":"2025-12-19T05:44:04Z","published":"2025-12-18T06:57:42Z","title":"Sigma-MoE-Tiny Technical Report","summary":"Mixture-of-Experts (MoE) has emerged as a promising paradigm for foundation models due to its efficient and powerful scalability. In this work, we present Sigma-MoE-Tiny, an MoE language model that achieves the highest sparsity compared to existing open-source models. Sigma-MoE-Tiny employs fine-grained expert segmentation with up to 96 experts per layer, while activating only one expert for each token, resulting in 20B total parameters with just 0.5B activated. The major challenge introduced by such extreme sparsity lies in expert load balancing. We find that the widely-used load balancing loss tends to become ineffective in the lower layers under this setting. To address this issue, we propose a progressive sparsification schedule aiming to balance expert utilization and training stability. Sigma-MoE-Tiny is pre-trained on a diverse and high-quality corpus, followed by post-training to further unlock its capabilities. The entire training process remains remarkably stable, with no occurrence of irrecoverable loss spikes. Comprehensive evaluations reveal that, despite activating only 0.5B parameters, Sigma-MoE-Tiny achieves top-tier performance among counterparts of comparable or significantly larger scale. In addition, we provide an in-depth discussion of load balancing in highly sparse MoE models, offering insights for advancing sparsity in future MoE architectures.\n  Project page: https://qghuxmu.github.io/Sigma-MoE-Tiny\n  Code: https://github.com/microsoft/ltp-megatron-lm","authors":["Qingguo Hu","Zhenghao Lin","Ziyue Yang","Yucheng Ding","Xiao Liu","Yuting Jiang","Ruizhe Wang","Tianyu Chen","Zhongxin Guo","Yifan Xiong","Rui Gao","Lei Qu","Jinsong Su","Peng Cheng","Yeyun Gong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17247v1","updated":"2025-12-19T05:26:50Z","published":"2025-12-19T05:26:50Z","title":"Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness in Persian Speech Recognition","summary":"Automatic Speech Recognition (ASR) systems suffer significant performance degradation in noisy environments, a challenge that is especially severe for low-resource languages such as Persian. Even state-of-the-art models such as Whisper struggle to maintain accuracy under varying signal-to-noise ratios (SNRs). This study presents a robust noise-sensitive ASR error correction framework that combines multiple hypotheses and noise-aware modeling. Using noisy Persian speech, we generate 5-best hypotheses from a modified Whisper-large decoder. Error Level Noise (ELN) is introduced as a representation that captures semantic- and token-level disagreement across hypotheses, quantifying the linguistic distortions caused by noise. ELN thus provides a direct measure of noise-induced uncertainty, enabling the LLM to reason about the reliability of each hypothesis during correction. Three models are evaluated: (1) a base LLaMA-2-7B model without fine-tuning, (2) a fine-tuned variant trained on text-only hypotheses, and (3) a noise-conditioned model integrating ELN embeddings at both sentence and word levels. Experimental results demonstrate that the ELN-conditioned model achieves substantial reductions in Word Error Rate (WER). Specifically, on the challenging Mixed Noise test set, the proposed Fine-tuned + ELN (Ours) model reduces the WER from a baseline of 31.10\\% (Raw Whisper) to 24.84\\%, significantly surpassing the Fine-tuned (No ELN) text-only baseline of 30.79\\%, whereas the original LLaMA-2-7B model increased the WER to 64.58\\%, demonstrating that it is unable to correct Persian errors on its own. This confirms the effectiveness of combining multiple hypotheses with noise-aware embeddings for robust Persian ASR in noisy real-world scenarios.","authors":["Zahra Rahmani","Hossein Sameti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.09030v4","updated":"2025-12-19T05:10:32Z","published":"2024-08-16T21:57:23Z","title":"Studying the Effects of Collaboration in Interactive Theme Discovery Systems","summary":"NLP-assisted solutions have gained considerable traction to support qualitative data analysis. However, there does not exist a unified evaluation framework that can account for the many different settings in which qualitative researchers may employ them. In this paper, we take a first step in this direction by proposing an evaluation framework to study the way in which different tools may result in different outcomes depending on the collaboration strategy employed. Specifically, we study the impact of synchronous vs. asynchronous collaboration using two different NLP-assisted qualitative research tools and present a comprehensive analysis of significant differences in the consistency, cohesiveness, and correctness of their outputs.","authors":["Alvin Po-Chun Chen","Rohan Das","Dananjay Srinivas","Alexandra Barry","Maksim Seniw","Maria Leonor Pacheco"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.07540v2","updated":"2025-12-19T04:16:55Z","published":"2025-12-08T13:21:44Z","title":"Minimum Bayes Risk Decoding for Error Span Detection in Reference-Free Automatic Machine Translation Evaluation","summary":"Error Span Detection (ESD) extends automatic machine translation (MT) evaluation by localizing translation errors and labeling their severity. Current generative ESD methods typically use Maximum a Posteriori (MAP) decoding, assuming that the model-estimated probabilities are perfectly correlated with similarity to the human annotation, but we often observe higher likelihood assigned to an incorrect annotation than to the human one. We instead apply Minimum Bayes Risk (MBR) decoding to generative ESD. We use a sentence- or span-level similarity function for MBR decoding, which selects candidate hypotheses based on their approximate similarity to the human annotation. Experimental results on the WMT24 Metrics Shared Task show that MBR decoding significantly improves span-level performance and generally matches or outperforms MAP at the system and sentence levels. To reduce the computational cost of MBR decoding, we further distill its decisions into a model decoded via greedy search, removing the inference-time latency bottleneck.","authors":["Boxuan Lyu","Haiyue Song","Hidetaka Kamigaito","Chenchen Ding","Hideki Tanaka","Masao Utiyama","Kotaro Funakoshi","Manabu Okumura"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17220v1","updated":"2025-12-19T04:08:29Z","published":"2025-12-19T04:08:29Z","title":"Mindscape-Aware Retrieval Augmented Generation for Improved Long Context Understanding","summary":"Humans understand long and complex texts by relying on a holistic semantic representation of the content. This global view helps organize prior knowledge, interpret new information, and integrate evidence dispersed across a document, as revealed by the Mindscape-Aware Capability of humans in psychology. Current Retrieval-Augmented Generation (RAG) systems lack such guidance and therefore struggle with long-context tasks. In this paper, we propose Mindscape-Aware RAG (MiA-RAG), the first approach that equips LLM-based RAG systems with explicit global context awareness. MiA-RAG builds a mindscape through hierarchical summarization and conditions both retrieval and generation on this global semantic representation. This enables the retriever to form enriched query embeddings and the generator to reason over retrieved evidence within a coherent global context. We evaluate MiA-RAG across diverse long-context and bilingual benchmarks for evidence-based understanding and global sense-making. It consistently surpasses baselines, and further analysis shows that it aligns local details with a coherent global representation, enabling more human-like long-context retrieval and reasoning.","authors":["Yuqing Li","Jiangnan Li","Zheng Lin","Ziyan Zhou","Junjie Wu","Weiping Wang","Jie Zhou","Mo Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.10689v2","updated":"2025-12-19T03:49:52Z","published":"2025-03-12T01:33:40Z","title":"Learning to Contextualize Web Pages for Enhanced Decision Making by LLM Agents","summary":"Recent advances in large language models (LLMs) have led to a growing interest in developing LLM-based agents for automating web tasks. However, these agents often struggle with even simple tasks on real-world websites due to their limited capability to understand and process complex web page structures. In this work, we introduce LCoW, a framework for Learning language models to Contextualize complex Web pages into a more comprehensible form, thereby enhancing decision making by LLM agents. LCoW decouples web page understanding from decision making by training a separate contextualization module to transform complex web pages into comprehensible format, which are then utilized by the decision-making agent. We demonstrate that our contextualization module effectively integrates with LLM agents of various scales to significantly enhance their decision-making capabilities in web automation tasks. Notably, LCoW improves the success rates of closed-source LLMs (e.g., Gemini-1.5-flash, GPT-4o, Claude-3.5-Sonnet) by an average of 15.6%, and demonstrates a 23.7% average improvement in success rates for open-source LMs (e.g., Llama-3.1-8B, Llama-3.1-70B) on the WorkArena benchmark. Moreover, the Gemini-1.5-flash agent with LCoW achieves state-of-the-art results on the WebShop benchmark, outperforming human experts. The relevant code materials are available at our project page: https://lcowiclr2025.github.io.","authors":["Dongjun Lee","Juyong Lee","Kyuyoung Kim","Jihoon Tack","Jinwoo Shin","Yee Whye Teh","Kimin Lee"],"pdf_url":"","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2509.07414v3","updated":"2025-12-19T03:05:26Z","published":"2025-09-09T05:51:34Z","title":"Language Self-Play For Data-Free Training","summary":"Large language models (LLMs) have advanced rapidly in recent years, driven by scale, abundant high-quality training data, and reinforcement learning. Yet this progress faces a fundamental bottleneck: the need for ever more data from which models can continue to learn. In this work, we propose a reinforcement learning approach that removes this dependency by enabling models to improve without additional data. Our method leverages a game-theoretic framework of self-play, where a model's capabilities are cast as performance in a competitive game and stronger policies emerge by having the model play against itself-a process we call Language Self-Play (LSP). Experiments with Llama-3.2-3B-Instruct on instruction-following, mathematics, and coding benchmarks show that pretrained models can be effectively improved with self-play alone.","authors":["Jakub Grudzien Kuba","Mengting Gu","Qi Ma","Yuandong Tian","Vijai Mohan","Jason Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17179v1","updated":"2025-12-19T02:37:30Z","published":"2025-12-19T02:37:30Z","title":"Enhancing Long Document Long Form Summarisation with Self-Planning","summary":"We introduce a novel approach for long context summarisation, highlight-guided generation, that leverages sentence-level information as a content plan to improve the traceability and faithfulness of generated summaries. Our framework applies self-planning methods to identify important content and then generates a summary conditioned on the plan. We explore both an end-to-end and two-stage variants of the approach, finding that the two-stage pipeline performs better on long and information-dense documents. Experiments on long-form summarisation datasets demonstrate that our method consistently improves factual consistency while preserving relevance and overall quality. On GovReport, our best approach has improved ROUGE-L by 4.1 points and achieves about 35% gains in SummaC scores. Qualitative analysis shows that highlight-guided summarisation helps preserve important details, leading to more accurate and insightful summaries across domains.","authors":["Xiaotang Du","Rohit Saxena","Laura Perez-Beltrachini","Pasquale Minervini","Ivan Titov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.07461v2","updated":"2025-12-19T02:34:49Z","published":"2025-12-08T11:39:43Z","title":"Native Parallel Reasoner: Reasoning in Parallelism via Self-Distilled Reinforcement Learning","summary":"We introduce Native Parallel Reasoner (NPR), a teacher-free framework that enables Large Language Models (LLMs) to self-evolve genuine parallel reasoning capabilities. NPR transforms the model from sequential emulation to native parallel cognition through three key innovations: 1) a self-distilled progressive training paradigm that transitions from ``cold-start'' format discovery to strict topological constraints without external supervision; 2) a novel Parallel-Aware Policy Optimization (PAPO) algorithm that optimizes branching policies directly within the execution graph, allowing the model to learn adaptive decomposition via trial and error; and 3) a robust NPR Engine that refactors memory management and flow control of SGLang to enable stable, large-scale parallel RL training. Across eight reasoning benchmarks, NPR trained on Qwen3-4B achieves performance gains of up to 24.5% and inference speedups up to 4.6x. Unlike prior baselines that often fall back to autoregressive decoding, NPR demonstrates 100% genuine parallel execution, establishing a new standard for self-evolving, efficient, and scalable agentic reasoning.","authors":["Tong Wu","Yang Liu","Jun Bai","Zixia Jia","Shuyi Zhang","Ziyong Lin","Yanting Wang","Song-Chun Zhu","Zilong Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.06000v2","updated":"2025-12-19T02:07:06Z","published":"2025-11-08T13:12:36Z","title":"LLMs Do Not See Age: Assessing Demographic Bias in Automated Systematic Review Synthesis","summary":"Clinical interventions often hinge on age: medications and procedures safe for adults may be harmful to children or ineffective for older adults. However, as language models are increasingly integrated into biomedical evidence synthesis workflows, it remains uncertain whether these systems preserve such crucial demographic distinctions. To address this gap, we evaluate how well state-of-the-art language models retain age-related information when generating abstractive summaries of biomedical studies. We construct DemogSummary, a novel age-stratified dataset of systematic review primary studies, covering child, adult, and older adult populations. We evaluate three prominent summarisation-capable LLMs, Qwen (open-source), Longformer (open-source) and GPT-4.1 Nano (proprietary), using both standard metrics and a newly proposed Demographic Salience Score (DSS), which quantifies age-related entity retention and hallucination. Our results reveal systematic disparities across models and age groups: demographic fidelity is lowest for adult-focused summaries, and under-represented populations are more prone to hallucinations. These findings highlight the limitations of current LLMs in faithful and bias-free summarisation and point to the need for fairness-aware evaluation frameworks and summarisation pipelines in biomedical NLP.","authors":["Favour Yahdii Aghaebe","Tanefa Apekey","Elizabeth Williams","Nafise Sadat Moosavi"],"pdf_url":"","comment":"Accepted at AACL 2025 Version 2 Updated with Final version"},{"id":"http://arxiv.org/abs/2505.14886v2","updated":"2025-12-19T02:04:23Z","published":"2025-05-20T20:17:51Z","title":"Strategic Planning and Rationalizing on Trees Make LLMs Better Debaters","summary":"Winning competitive debates requires sophisticated reasoning and argument skills. There are unique challenges in the competitive debate: (1) The time constraints force debaters to make strategic choices about which points to pursue rather than covering all possible arguments; (2) The persuasiveness of the debate relies on the back-and-forth interaction between arguments, which a single final game status cannot evaluate. To address these challenges, we propose TreeDebater, a novel debate framework that excels in competitive debate. We introduce two tree structures: the Rehearsal Tree and Debate Flow Tree. The Rehearsal Tree anticipates the attack and defenses to evaluate the strength of the claim, while the Debate Flow Tree tracks the debate status to identify the active actions. TreeDebater allocates its time budget among candidate actions and uses the speech time controller and feedback from the simulated audience to revise its statement. The human evaluation on both the stage-level and the debate-level comparison shows that our TreeDebater outperforms the state-of-the-art multi-agent debate system, with a +15.6% improvement in stage-level persuasiveness with DeepSeek and +10% debate-level opinion shift win. Further investigation shows that TreeDebater shows better strategies in limiting time to important debate actions, aligning with the strategies of human debate experts.","authors":["Danqing Wang","Zhuorui Ye","Xinran Zhao","Fei Fang","Lei Li"],"pdf_url":"","comment":"9 main pages"},{"id":"http://arxiv.org/abs/2509.21791v3","updated":"2025-12-19T01:55:45Z","published":"2025-09-26T02:47:11Z","title":"Quantifying the Impact of Structured Output Format on Large Language Models through Causal Inference","summary":"Structured output from large language models (LLMs) has enhanced efficiency in processing generated information and is increasingly adopted in industrial applications. Prior studies have investigated the impact of structured output on LLMs' generation quality, often presenting one-way findings. Some suggest that structured format enhances completeness and factual accuracy, while others argue that it restricts the reasoning capacity of LLMs and leads to reductions in standard evaluation metrics. Potential limitations of these assessments include restricted testing scenarios, weakly controlled comparative settings, and reliance on coarse metrics. In this work, we present a refined analysis using causal inference. Based on one assumed and two guaranteed constraints, we derive five potential causal structures characterizing the influence of structured output on LLMs' generation: (1) collider without m-bias, (2) collider with m-bias, (3) single cause from instruction, (4) single cause from output format, and (5) independence. Across seven public and one developed reasoning tasks, we find that coarse metrics report positive, negative, or neutral effects of structured output on GPT-4o's generation. However, causal inference reveals no causal impact in 43 out of 48 scenarios. In the remaining 5, 3 involve multifaceted causal structures influenced by concrete instructions. Further experiments show that OpenAI-o3 are more resilient to output formats than general-purpose GPT-4o and GPT-4.1, highlighting an unaware advantage of reasoning models.","authors":["Han Yuan","Yue Zhao","Li Zhang","Wuqiong Luo","Zheng Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.22732v2","updated":"2025-12-19T23:16:01Z","published":"2025-10-26T16:03:39Z","title":"WebATLAS: An LLM Agent with Experience-Driven Memory and Action Simulation","summary":"Large Language Model (LLM) web agents often struggle with long-horizon web navigation and web task completion in new websites, producing inefficient action sequences unless fine-tuned on environment-specific data. We show that experience-driven memory, combined with look-ahead action simulation, is sufficient for LLM agents to adapt to unseen web environments by remembering past failures and predicting the consequences of future actions. We introduce WebATLAS (Actor-Critic Task-completion with Look-ahead Action Simulation), a memory-augmented LLM web agent that learns a lightweight internal model of the environment from interaction experience and performs hypothetical action rollouts before acting in the real world. WebATLAS builds a persistent cognitive map via curiosity-driven exploration, stores interaction outcomes as experience-based memory, and evaluates candidate actions in cognitive space using a planner--simulator--critic loop. This enables the agent to reuse past experience, avoid previously unsuccessful behaviors, and generate more efficient plans. We evaluate WebATLAS on the WebArena-Lite benchmark for autonomous web navigation and demonstrate a success rate of 63%, outperforming the previous state-of-the-art at 53.9%. Unlike previous systems, our modular architecture requires no website-specific LLM fine-tuning. Ablation studies confirm that experience-driven memory, look-ahead action simulation, and hierarchical replanning play complementary roles in enabling robust, training-free web agents.","authors":["Jiali Cheng","Anjishnu Kumar","Roshan Lal","Rishi Rajasekaran","Hani Ramezani","Omar Zia Khan","Oleg Rokhlenko","Sunny Chiu-Webster","Gang Hua","Hadi Amiri"],"pdf_url":"","comment":"9 pages, NeurIPS 2025 Workshop on Language Agents and World Models"},{"id":"http://arxiv.org/abs/2512.18119v1","updated":"2025-12-19T22:56:57Z","published":"2025-12-19T22:56:57Z","title":"Distributed Asymmetric Allocation: A Topic Model for Large Imbalanced Corpora in Social Sciences","summary":"Social scientists employ latent Dirichlet allocation (LDA) to find highly specific topics in large corpora, but they often struggle in this task because (1) LDA, in general, takes a significant amount of time to fit on large corpora; (2) unsupervised LDA fragments topics into sub-topics in short documents; (3) semi-supervised LDA fails to identify specific topics defined using seed words. To solve these problems, I have developed a new topic model called distributed asymmetric allocation (DAA) that integrates multiple algorithms for efficiently identifying sentences about important topics in large corpora. I evaluate the ability of DAA to identify politically important topics by fitting it to the transcripts of speeches at the United Nations General Assembly between 1991 and 2017. The results show that DAA can classify sentences significantly more accurately and quickly than LDA thanks to the new algorithms. More generally, the results demonstrate that it is important for social scientists to optimize Dirichlet priors of LDA to perform content analysis accurately.","authors":["Kohei Watanabe"],"pdf_url":"","comment":"34 pages"},{"id":"http://arxiv.org/abs/2510.13901v2","updated":"2025-12-19T22:55:25Z","published":"2025-10-14T19:33:09Z","title":"RAID: Refusal-Aware and Integrated Decoding for Jailbreaking LLMs","summary":"Large language models (LLMs) achieve impressive performance across diverse tasks yet remain vulnerable to jailbreak attacks that bypass safety mechanisms. We present RAID (Refusal-Aware and Integrated Decoding), a framework that systematically probes these weaknesses by crafting adversarial suffixes that induce restricted content while preserving fluency. RAID relaxes discrete tokens into continuous embeddings and optimizes them with a joint objective that (i) encourages restricted responses, (ii) incorporates a refusal-aware regularizer to steer activations away from refusal directions in embedding space, and (iii) applies a coherence term to maintain semantic plausibility and non-redundancy. After optimization, a critic-guided decoding procedure maps embeddings back to tokens by balancing embedding affinity with language-model likelihood. This integration yields suffixes that are both effective in bypassing defenses and natural in form. Experiments on multiple open-source LLMs show that RAID achieves higher attack success rates with fewer queries and lower computational cost than recent white-box and black-box baselines. These findings highlight the importance of embedding-space regularization for understanding and mitigating LLM jailbreak vulnerabilities.","authors":["Tuan T. Nguyen","John Le","Thai T. Vu","Willy Susilo","Heath Cooper"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18115v1","updated":"2025-12-19T22:43:12Z","published":"2025-12-19T22:43:12Z","title":"Layout-Aware Text Editing for Efficient Transformation of Academic PDFs to Markdown","summary":"Academic documents stored in PDF format can be transformed into plain text structured markup languages to enhance accessibility and enable scalable digital library workflows. Markup languages allow for easier updates and customization, making academic content more adaptable and accessible to diverse usage, such as linguistic corpus compilation. Such documents, typically delivered in PDF format, contain complex elements including mathematical formulas, figures, headers, and tables, as well as densely layouted text. Existing end-to-end decoder transformer models can transform screenshots of documents into markup language. However, these models exhibit significant inefficiencies; their token-by-token decoding from scratch wastes a lot of inference steps in regenerating dense text that could be directly copied from PDF files. To solve this problem, we introduce EditTrans, a hybrid editing-generation model whose features allow identifying a queue of to-be-edited text from a PDF before starting to generate markup language. EditTrans contains a lightweight classifier fine-tuned from a Document Layout Analysis model on 162,127 pages of documents from arXiv. In our evaluations, EditTrans reduced the transformation latency up to 44.5% compared to end-to-end decoder transformer models, while maintaining transformation quality. Our code and reproducible dataset production scripts are open-sourced.","authors":["Changxu Duan"],"pdf_url":"","comment":"Accepted ICDAR 2025"},{"id":"http://arxiv.org/abs/2505.14972v2","updated":"2025-12-19T22:14:03Z","published":"2025-05-20T23:20:38Z","title":"Multimodal Cultural Safety: Evaluation Framework and Alignment Strategies","summary":"Large vision-language models (LVLMs) are increasingly deployed in globally distributed applications, such as tourism assistants, yet their ability to produce culturally appropriate responses remains underexplored. Existing multimodal safety benchmarks primarily focus on physical safety and overlook violations rooted in cultural norms, which can result in symbolic harm. To address this gap, we introduce CROSS, a benchmark designed to assess the cultural safety reasoning capabilities of LVLMs. CROSS includes 1,284 multilingual visually grounded queries from 16 countries, three everyday domains, and 14 languages, where cultural norm violations emerge only when images are interpreted in context. We propose CROSS-Eval, an intercultural theory-based framework that measures four key dimensions: cultural awareness, norm education, compliance, and helpfulness. Using this framework, we evaluate 21 leading LVLMs, including mixture-of-experts models and reasoning models. Results reveal significant cultural safety gaps: the best-performing model achieves only 61.79% in awareness and 37.73% in compliance. While some open-source models reach GPT-4o-level performance, they still fall notably short of proprietary models. Our results further show that increasing reasoning capacity improves cultural alignment but does not fully resolve the issue. To improve model performance, we develop two enhancement strategies: supervised fine-tuning with culturally grounded, open-ended data and preference tuning with contrastive response pairs that highlight safe versus unsafe behaviors. These methods substantially improve GPT-4o's cultural awareness (+60.14%) and compliance (+55.2%), while preserving general multimodal capabilities with minimal performance reduction on general multimodal understanding benchmarks.","authors":["Haoyi Qiu","Kung-Hsiang Huang","Ruichen Zheng","Jiao Sun","Nanyun Peng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.14918v2","updated":"2025-12-19T21:50:40Z","published":"2025-05-20T21:12:58Z","title":"Reliable Decision Support with LLMs: A Framework for Evaluating Consistency in Binary Text Classification Applications","summary":"This study introduces a framework for evaluating consistency in large language model (LLM) binary text classification, addressing the lack of established reliability assessment methods. Adapting psychometric principles, we determine sample size requirements, develop metrics for invalid responses, and evaluate intra- and inter-rater reliability. Our case study examines financial news sentiment classification across 14 LLMs (including claude-3-7-sonnet, gpt-4o, deepseek-r1, gemma3, llama3.2, phi4, and command-r-plus), with five replicates per model on 1,350 articles. Models demonstrated high intra-rater consistency, achieving perfect agreement on 90-98% of examples, with minimal differences between expensive and economical models from the same families. When validated against StockNewsAPI labels, models achieved strong performance (accuracy 0.76-0.88), with smaller models like gemma3:1B, llama3.2:3B, and claude-3-5-haiku outperforming larger counterparts. All models performed at chance when predicting actual market movements, indicating task constraints rather than model limitations. Our framework provides systematic guidance for LLM selection, sample size planning, and reliability assessment, enabling organizations to optimize resources for classification tasks.","authors":["Fadel M. Megahed","Ying-Ju Chen","L. Allision Jones-Farmer","Younghwa Lee","Jiawei Brooke Wang","Inez M. Zwetsloot"],"pdf_url":"","comment":"26 pages"}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2512.17667v1","updated":"2025-12-19T15:12:01Z","published":"2025-12-19T15:12:01Z","title":"STAR: Semantic-Traffic Alignment and Retrieval for Zero-Shot HTTPS Website Fingerprinting","summary":"Modern HTTPS mechanisms such as Encrypted Client Hello (ECH) and encrypted DNS improve privacy but remain vulnerable to website fingerprinting (WF) attacks, where adversaries infer visited sites from encrypted traffic patterns. Existing WF methods rely on supervised learning with site-specific labeled traces, which limits scalability and fails to handle previously unseen websites. We address these limitations by reformulating WF as a zero-shot cross-modal retrieval problem and introducing STAR. STAR learns a joint embedding space for encrypted traffic traces and crawl-time logic profiles using a dual-encoder architecture. Trained on 150K automatically collected traffic-logic pairs with contrastive and consistency objectives and structure-aware augmentation, STAR retrieves the most semantically aligned profile for a trace without requiring target-side traffic during training. Experiments on 1,600 unseen websites show that STAR achieves 87.9 percent top-1 accuracy and 0.963 AUC in open-world detection, outperforming supervised and few-shot baselines. Adding an adapter with only four labeled traces per site further boosts top-5 accuracy to 98.8 percent. Our analysis reveals intrinsic semantic-traffic alignment in modern web protocols, identifying semantic leakage as the dominant privacy risk in encrypted HTTPS traffic. We release STAR's datasets and code to support reproducibility and future research.","authors":["Yifei Cheng","Yujia Zhu","Baiyang Li","Xinhao Deng","Yitong Cai","Yaochen Ren","Qingyun Liu"],"pdf_url":"","comment":"Accepted by IEEE INFOCOM 2026. Camera-ready version"},{"id":"http://arxiv.org/abs/2512.17538v1","updated":"2025-12-19T13:01:54Z","published":"2025-12-19T13:01:54Z","title":"Binding Agent ID: Unleashing the Power of AI Agents with accountability and credibility","summary":"Autonomous AI agents lack traceable accountability mechanisms, creating a fundamental dilemma where systems must either operate as ``downgraded tools'' or risk real-world abuse. This vulnerability stems from the limitations of traditional key-based authentication, which guarantees neither the operator's physical identity nor the agent's code integrity. To bridge this gap, we propose BAID (Binding Agent ID), a comprehensive identity infrastructure establishing verifiable user-code binding. BAID integrates three orthogonal mechanisms: local binding via biometric authentication, decentralized on-chain identity management, and a novel zkVM-based Code-Level Authentication protocol. By leveraging recursive proofs to treat the program binary as the identity, this protocol provides cryptographic guarantees for operator identity, agent configuration integrity, and complete execution provenance, thereby effectively preventing unauthorized operation and code substitution. We implement and evaluate a complete prototype system, demonstrating the practical feasibility of blockchain-based identity management and zkVM-based authentication protocol.","authors":["Zibin Lin","Shengli Zhang","Guofu Liao","Dacheng Tao","Taotao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17414v1","updated":"2025-12-19T10:11:32Z","published":"2025-12-19T10:11:32Z","title":"A decomposition approach for large virtual network embedding","summary":"Virtual Network Embedding (VNE) is the core combinatorial problem of Network Slicing, a 5G technology which enables telecommunication operators to propose diverse service-dedicated virtual networks, embedded onto a common substrate network. VNE asks for a minimum-cost mapping of a virtual network on a substrate network, encompassing simultaneous node placement and edge routing decisions. On a benchmark of large virtual networks with realistic topologies we compiled, the state-of-the art heuristics often provide expensive solutions, or even fail to find a solution when resources are sparse. We introduce a new integer linear formulation together with a decomposition scheme based on an automatic partition of the virtual network. This results in a column generation approach whose pricing problems are also VNE problems. This method allows to compute better lower bounds than state-of-the-art methods. Finally, we devise an efficient Price-and-Branch heuristic for large instances.","authors":["Amal Benhamiche","Pierre Fouilhoux","Lucas Létocart","Nancy Perrot","Alexis Schneider"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17381v1","updated":"2025-12-19T09:36:44Z","published":"2025-12-19T09:36:44Z","title":"Timely Information Updating for Mobile Devices Without and With ML Advice","summary":"This paper investigates an information update system in which a mobile device monitors a physical process and sends status updates to an access point (AP). A fundamental trade-off arises between the timeliness of the information maintained at the AP and the update cost incurred at the device. To address this trade-off, we propose an online algorithm that determines when to transmit updates using only available observations. The proposed algorithm asymptotically achieves the optimal competitive ratio against an adversary that can simultaneously manipulate multiple sources of uncertainty, including the operation duration, the information staleness, the update cost, and the availability of update opportunities. Furthermore, by incorporating machine learning (ML) advice of unknown reliability into the design, we develop an ML-augmented algorithm that asymptotically attains the optimal consistency-robustness trade-off, even when the adversary can additionally corrupt the ML advice. The optimal competitive ratio scales linearly with the range of update costs, but is unaffected by other uncertainties. Moreover, an optimal competitive online algorithm exhibits a threshold-like response to the ML advice: it either fully trusts or completely ignores the ML advice, as partially trusting the advice cannot improve the consistency without severely degrading the robustness. Extensive simulations in stochastic settings further validate the theoretical findings in the adversarial environment.","authors":["Yu-Pin Hsu","Yi-Hsuan Tseng"],"pdf_url":"","comment":"23 pages, journal version of arXiv:1901.03137, submitted for possible journal publication"},{"id":"http://arxiv.org/abs/2507.13717v3","updated":"2025-12-19T08:29:30Z","published":"2025-07-18T07:59:19Z","title":"ATRO: A Fast Algorithm for Topology Engineering of Reconfigurable Datacenter Networks","summary":"Reconfigurable data center networks (DCNs) enhance traditional architectures with optical circuit switches (OCSs), enabling dynamic reconfiguration of inter-pod links, i.e., the logical topology. Optimizing this topology is crucial for adapting to traffic dynamics but is challenging due to its combinatorial nature. The complexity increases further when demands can be distributed across multiple paths, requiring joint optimization of topology and routing. We propose Alternating Topology and Routing Optimization (ATRO), a unified framework that supports both one-hop topology optimization (where traffic is routed via direct paths) and multi-hop joint optimization (where routing is also optimized). Although these settings differ in constraints, both are combinatorially hard and challenge solver-based methods. ATRO addresses both cases efficiently: in the one-hop case, it guarantees the global optimum via an accelerated binary search; in the multi-hop case, it alternates between topology and routing updates, with routing steps optionally accelerated by existing traffic engineering (TE) methods. ATRO supports warm-starting and improves solution quality monotonically across iterations. ATRO remains competitive even when paired with solver-free TE methods, forming a fully solver-free optimization pipeline that still outperforms prior approaches in runtime and maximum link utilization across diverse workloads.","authors":["Yingming Mao","Qiaozhu Zhai","Ximeng Liu","Xinchi Han","Fafan li","Shizhen Zhao","Yuzhou Zhou","Zhen Yao","Xia Zhu"],"pdf_url":"","comment":"Accepted to IEEE INFOCOM 2026 (IEEE International Conference on Computer Communications), to be held in Tokyo, Japan"},{"id":"http://arxiv.org/abs/2512.17199v1","updated":"2025-12-19T03:25:26Z","published":"2025-12-19T03:25:26Z","title":"Quantum-enhanced Information Retrieval from Reflective Intelligent Surfaces","summary":"Information retrieval from passive backscatter systems is widely used in digital applications with tight energy budgets, short communication distances, and low data rates. Due to the fundamental limits of classical wireless receivers, the achievable data rate cannot be increased without compromising either energy efficiency or communication range, thereby hindering the broader adoption of this technology. In this work, we present a novel time-resolving quantum receiver combined with a multi-mode probing signal to extract large-alphabet information modulated by a passive reconfigurable intelligent surface (RIS). The adaptive nature of the proposed receiver yields significant quantum advantages over classical receivers without relying on complex or fragile quantum resources such as entanglement. Simulation results show that the proposed technique surpasses the classical standard quantum limit (SQL) for modulation sizes up to M = 2^8, meanwhile halving the probing energy or increasing the communication distance by a factor of 1.41.","authors":["Shiqian Guo","Tingxiang Ji","Jianqing Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.20116v2","updated":"2025-12-19T02:09:53Z","published":"2025-07-27T03:45:07Z","title":"PeerSync: Accelerating Containerized Service Delivery at the Network Edge","summary":"Efficient container image distribution is crucial for enabling machine learning inference at the network edge, where resource limitations and dynamic network conditions create significant challenges. In this paper, we present PeerSync, a decentralized P2P-based system designed to optimize image distribution in edge environments. PeerSync employs a popularity- and network-aware download engine that dynamically adapts to content popularity and real-time network conditions. PeerSync further integrates automated tracker election for rapid peer discovery and dynamic cache management for efficient storage utilization. We implement PeerSync with 8000+ lines of Rust code and test its performance extensively on both large-scale Docker-based emulations and physical edge devices. Experimental results show that PeerSync delivers a remarkable speed increase of 2.72$\\times$, 1.79$\\times$, and 1.28$\\times$ compared to the Baseline solution, Dragonfly, and Kraken, respectively, while significantly reducing cross-network traffic by 90.72% under congested and varying network conditions.","authors":["Yinuo Deng","Hailiang Zhao","Dongjing Wang","Peng Chen","Wenzhuo Qian","Jianwei Yin","Schahram Dustdar","Shuiguang Deng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.22046v2","updated":"2025-12-19T01:58:25Z","published":"2025-11-27T02:59:03Z","title":"AutoRec: Accelerating Loss Recovery for Live Streaming in a Multi-Supplier Market","summary":"Due to the limited permissions for upgrading dualside (i.e., server-side and client-side) loss tolerance schemes from the perspective of CDN vendors in a multi-supplier market, modern large-scale live streaming services are still using the automatic-repeat-request (ARQ) based paradigm for loss recovery, which only requires server-side modifications. In this paper, we first conduct a large-scale measurement study with up to 50 million live streams. We find that loss shows dynamics and live streaming contains frequent on-off mode switching in the wild. We further find that the recovery latency, enlarged by the ubiquitous retransmission loss, is a critical factor affecting live streaming's client-side QoE (e.g., video freezing). We then propose an enhanced recovery mechanism called AutoRec, which can transform the disadvantages of on-off mode switching into an advantage for reducing loss recovery latency without any modifications on the client side. AutoRec allows users to customize overhead tolerance and recovery latency tolerance and adaptively adjusts strategies as the network environment changes to ensure that recovery latency meets user demands whenever possible while keeping overhead under control. We implement AutoRec upon QUIC and evaluate it via testbed and real-world commercial services deployments. The experimental results demonstrate the practicability and profitability of AutoRec.","authors":["Tong Li","Xu Yan","Bo Wu","Cheng Luo","Fuyu Wang","Jiuxiang Zhu","Haoyi Fang","Xinle Du","Ke Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17158v1","updated":"2025-12-19T01:36:26Z","published":"2025-12-19T01:36:26Z","title":"Enhancing AIGC Service Efficiency with Adaptive Multi-Edge Collaboration in A Distributed System","summary":"The Artificial Intelligence Generated Content (AIGC) technique has gained significant traction for producing diverse content. However, existing AIGC services typically operate within a centralized framework, resulting in high response times. To address this issue, we integrate collaborative Mobile Edge Computing (MEC) technology to reduce processing delays for AIGC services. Current collaborative MEC methods primarily support single-server offloading or facilitate interactions among fixed Edge Servers (ESs), limiting flexibility and resource utilization across all ESs to meet the varying computing and networking requirements of AIGC services. We propose AMCoEdge, an adaptive multi-server collaborative MEC approach to enhancing AIGC service efficiency. The AMCoEdge fully utilizes the computing and networking resources across all ESs through adaptive multi-ES selection and dynamic workload allocation, thereby minimizing the offloading make-span of AIGC services. Our design features an online distributed algorithm based on deep reinforcement learning, accompanied by theoretical analyses that confirm an approximate linear time complexity. Simulation results show that our method outperforms state-of-the-art baselines, achieving at least an 11.04% reduction in task offloading make-span and a 44.86% decrease in failure rate. Additionally, we develop a distributed prototype system to implement and evaluate our AMCoEdge method for real AIGC service execution, demonstrating service delays that are 9.23% - 31.98% lower than the three representative methods.","authors":["Changfu Xu","Jianxiong Guo","Jiandian Zeng","Houming Qiu","Tian Wang","Xiaowen Chu","Jiannong Cao"],"pdf_url":"","comment":"16 pages"},{"id":"http://arxiv.org/abs/2509.23516v3","updated":"2025-12-19T23:21:33Z","published":"2025-09-27T22:31:24Z","title":"Network-Optimised Spiking Neural Network for Event-Driven Networking","summary":"Time-critical networking requires low-latency decisions from sparse and bursty telemetry, where fixed-step neural inference waste computation. We introduce Network-Optimised Spiking (NOS), a two-state neuron whose variables correspond to normalised queue occupancy and a recovery resource. NOS combines a saturating excitability nonlinearity for finite buffers, service and damping leaks, graph-local inputs with per-link gates and delays, and differentiable resets compatible with surrogate gradients and neuromorphic deployment. We establish existence and uniqueness of subthreshold equilibria, derive Jacobian-based local stability tests, and obtain a scalar network stability threshold that separates topology from node physics through a Perron-mode spectral condition. A stochastic arrival model aligned with telemetry smoothing links NOS responses to classical queueing behaviour while explaining increased variability near stability margins. Across chain, star, and scale-free graphs, NOS improves early-warning F1 and detection latency over MLP, RNN, GRU, and temporal-GNN baselines under a common residual-based protocol, while providing practical calibration and stability rules suited to resource-constrained networking deployments. Code and Demos: https://mbilal84.github.io/nos-snn-networking/","authors":["Muhammad Bilal"],"pdf_url":"","comment":"56 pages, 16 figures, 9 tables"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2512.17908v1","updated":"2025-12-19T18:59:56Z","published":"2025-12-19T18:59:56Z","title":"Re-Depth Anything: Test-Time Depth Refinement via Self-Supervised Re-lighting","summary":"Monocular depth estimation remains challenging as recent foundation models, such as Depth Anything V2 (DA-V2), struggle with real-world images that are far from the training distribution. We introduce Re-Depth Anything, a test-time self-supervision framework that bridges this domain gap by fusing DA-V2 with the powerful priors of large-scale 2D diffusion models. Our method performs label-free refinement directly on the input image by re-lighting predicted depth maps and augmenting the input. This re-synthesis method replaces classical photometric reconstruction by leveraging shape from shading (SfS) cues in a new, generative context with Score Distillation Sampling (SDS). To prevent optimization collapse, our framework employs a targeted optimization strategy: rather than optimizing depth directly or fine-tuning the full model, we freeze the encoder and only update intermediate embeddings while also fine-tuning the decoder. Across diverse benchmarks, Re-Depth Anything yields substantial gains in depth accuracy and realism over the DA-V2, showcasing new avenues for self-supervision by augmenting geometric reasoning.","authors":["Ananta R. Bhattarai","Helge Rhodin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17899v1","updated":"2025-12-19T18:58:11Z","published":"2025-12-19T18:58:11Z","title":"Distributionally Robust Imitation Learning: Layered Control Architecture for Certifiable Autonomy","summary":"Imitation learning (IL) enables autonomous behavior by learning from expert demonstrations. While more sample-efficient than comparative alternatives like reinforcement learning, IL is sensitive to compounding errors induced by distribution shifts. There are two significant sources of distribution shifts when using IL-based feedback laws on systems: distribution shifts caused by policy error and distribution shifts due to exogenous disturbances and endogenous model errors due to lack of learning. Our previously developed approaches, Taylor Series Imitation Learning (TaSIL) and $\\mathcal{L}_1$ -Distributionally Robust Adaptive Control (\\ellonedrac), address the challenge of distribution shifts in complementary ways. While TaSIL offers robustness against policy error-induced distribution shifts, \\ellonedrac offers robustness against distribution shifts due to aleatoric and epistemic uncertainties. To enable certifiable IL for learned and/or uncertain dynamical systems, we formulate \\textit{Distributionally Robust Imitation Policy (DRIP)} architecture, a Layered Control Architecture (LCA) that integrates TaSIL and~\\ellonedrac. By judiciously designing individual layer-centric input and output requirements, we show how we can guarantee certificates for the entire control pipeline. Our solution paves the path for designing fully certifiable autonomy pipelines, by integrating learning-based components, such as perception, with certifiable model-based decision-making through the proposed LCA approach.","authors":["Aditya Gahlawat","Ahmed Aboudonia","Sandeep Banik","Naira Hovakimyan","Nikolai Matni","Aaron D. Ames","Gioele Zardini","Alberto Speranzon"],"pdf_url":"","comment":"18 pages, 5 figures"},{"id":"http://arxiv.org/abs/2512.17897v1","updated":"2025-12-19T18:57:33Z","published":"2025-12-19T18:57:33Z","title":"RadarGen: Automotive Radar Point Cloud Generation from Cameras","summary":"We present RadarGen, a diffusion model for synthesizing realistic automotive radar point clouds from multi-view camera imagery. RadarGen adapts efficient image-latent diffusion to the radar domain by representing radar measurements in bird's-eye-view form that encodes spatial structure together with radar cross section (RCS) and Doppler attributes. A lightweight recovery step reconstructs point clouds from the generated maps. To better align generation with the visual scene, RadarGen incorporates BEV-aligned depth, semantic, and motion cues extracted from pretrained foundation models, which guide the stochastic generation process toward physically plausible radar patterns. Conditioning on images makes the approach broadly compatible, in principle, with existing visual datasets and simulation frameworks, offering a scalable direction for multimodal generative simulation. Evaluations on large-scale driving data show that RadarGen captures characteristic radar measurement distributions and reduces the gap to perception models trained on real data, marking a step toward unified generative simulation across sensing modalities.","authors":["Tomer Borreda","Fangqiang Ding","Sanja Fidler","Shengyu Huang","Or Litany"],"pdf_url":"","comment":"Project page: https://radargen.github.io/"},{"id":"http://arxiv.org/abs/2507.01939v4","updated":"2025-12-19T18:39:57Z","published":"2025-07-02T17:49:52Z","title":"SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars","summary":"In recent years, large language models (LLMs) have transformed natural language understanding through vast datasets and large-scale parameterization. Inspired by this success, we present SpecCLIP, a foundation model framework that extends LLM-inspired methodologies to stellar spectral analysis. Stellar spectra, akin to structured language, encode rich physical and chemical information about stars. By training foundation models on large-scale spectral datasets, our goal is to learn robust and informative embeddings that support diverse downstream applications. As a proof of concept, SpecCLIP involves pre-training on two spectral types--LAMOST low-resolution and Gaia XP--followed by contrastive alignment using the CLIP (Contrastive Language-Image Pre-training) framework, adapted to associate spectra from different instruments. This alignment is complemented by auxiliary decoders that preserve spectrum-specific information and enable translation (prediction) between spectral types, with the former achieved by maximizing mutual information between embeddings and input spectra. The result is a cross-spectrum framework enabling intrinsic calibration and flexible applications across instruments. We demonstrate that fine-tuning these models on moderate-sized labeled datasets improves adaptability to tasks such as stellar-parameter estimation and chemical-abundance determination. SpecCLIP also enhances the accuracy and precision of parameter estimates benchmarked against external survey data. Additionally, its similarity search and cross-spectrum prediction capabilities offer potential for anomaly detection. Our results suggest that contrastively trained foundation models enriched with spectrum-aware decoders can advance precision stellar spectroscopy. Our code SpecCLIP is publicly available at https://github.com/Xiaosheng-Zhao/SpecCLIP","authors":["Xiaosheng Zhao","Yang Huang","Guirong Xue","Xiao Kong","Jifeng Liu","Xiaoyu Tang","Timothy C. Beers","Yuan-Sen Ting","A-Li Luo"],"pdf_url":"","comment":"29 pages, 8 figures, 6 tables. Accepted for publication in ApJ. Comments welcome"},{"id":"http://arxiv.org/abs/2512.17884v1","updated":"2025-12-19T18:36:24Z","published":"2025-12-19T18:36:24Z","title":"Regularized Random Fourier Features and Finite Element Reconstruction for Operator Learning in Sobolev Space","summary":"Operator learning is a data-driven approximation of mappings between infinite-dimensional function spaces, such as the solution operators of partial differential equations. Kernel-based operator learning can offer accurate, theoretically justified approximations that require less training than standard methods. However, they can become computationally prohibitive for large training sets and can be sensitive to noise. We propose a regularized random Fourier feature (RRFF) approach, coupled with a finite element reconstruction map (RRFF-FEM), for learning operators from noisy data. The method uses random features drawn from multivariate Student's $t$ distributions, together with frequency-weighted Tikhonov regularization that suppresses high-frequency noise. We establish high-probability bounds on the extreme singular values of the associated random feature matrix and show that when the number of features $N$ scales like $m \\log m$ with the number of training samples $m$, the system is well-conditioned, which yields estimation and generalization guarantees. Detailed numerical experiments on benchmark PDE problems, including advection, Burgers', Darcy flow, Helmholtz, Navier-Stokes, and structural mechanics, demonstrate that RRFF and RRFF-FEM are robust to noise and achieve improved performance with reduced training time compared to the unregularized random feature model, while maintaining competitive accuracy relative to kernel and neural operator tests.","authors":["Xinyue Yu","Hayden Schaeffer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17878v1","updated":"2025-12-19T18:31:27Z","published":"2025-12-19T18:31:27Z","title":"Weighted Stochastic Differential Equation to Implement Wasserstein-Fisher-Rao Gradient Flow","summary":"Score-based diffusion models currently constitute the state of the art in continuous generative modeling. These methods are typically formulated via overdamped or underdamped Ornstein--Uhlenbeck-type stochastic differential equations, in which sampling is driven by a combination of deterministic drift and Brownian diffusion, resulting in continuous particle trajectories in the ambient space. While such dynamics enjoy exponential convergence guarantees for strongly log-concave target distributions, it is well known that their mixing rates deteriorate exponentially in the presence of nonconvex or multimodal landscapes, such as double-well potentials. Since many practical generative modeling tasks involve highly non-log-concave target distributions, considerable recent effort has been devoted to developing sampling schemes that improve exploration beyond classical diffusion dynamics.\n  A promising line of work leverages tools from information geometry to augment diffusion-based samplers with controlled mass reweighting mechanisms. This perspective leads naturally to Wasserstein--Fisher--Rao (WFR) geometries, which couple transport in the sample space with vertical (reaction) dynamics on the space of probability measures. In this work, we formulate such reweighting mechanisms through the introduction of explicit correction terms and show how they can be implemented via weighted stochastic differential equations using the Feynman--Kac representation. Our study provides a preliminary but rigorous investigation of WFR-based sampling dynamics, and aims to clarify their geometric and operator-theoretic structure as a foundation for future theoretical and algorithmic developments.","authors":["Herlock Rahimi"],"pdf_url":"","comment":"26 pages, 1 figure"},{"id":"http://arxiv.org/abs/2512.17877v1","updated":"2025-12-19T18:31:07Z","published":"2025-12-19T18:31:07Z","title":"Learning vertical coordinates via automatic differentiation of a dynamical core","summary":"Terrain-following coordinates in atmospheric models often imprint their grid structure onto the solution, particularly over steep topography, where distorted coordinate layers can generate spurious horizontal and vertical motion. Standard formulations, such as hybrid or SLEVE coordinates, mitigate these errors by using analytic decay functions controlled by heuristic scale parameters that are typically tuned by hand and fixed a priori. In this work, we propose a framework to define a parametric vertical coordinate system as a learnable component within a differentiable dynamical core. We develop an end-to-end differentiable numerical solver for the two-dimensional non-hydrostatic Euler equations on an Arakawa C-grid, and introduce a NEUral Vertical Enhancement (NEUVE) terrain-following coordinate based on an integral transformed neural network that guarantees monotonicity. A key feature of our approach is the use of automatic differentiation to compute exact geometric metric terms, thereby eliminating truncation errors associated with finite-difference coordinate derivatives. By coupling simulation errors through the time integration to the parameterization, our formulation finds a grid structure optimized for both the underlying physics and numerics. Using several standard tests, we demonstrate that these learned coordinates reduce the mean squared error by a factor of 1.4 to 2 in non-linear statistical benchmarks, and eliminate spurious vertical velocity striations over steep topography.","authors":["Tim Whittaker","Seth Taylor","Elsa Cardoso-Bihlo","Alejandro Di Luca","Alex Bihlo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.15692v2","updated":"2025-12-19T18:30:30Z","published":"2025-12-17T18:47:31Z","title":"mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs","summary":"Prevailing Vision-Language-Action Models (VLAs) for robotic manipulation are built upon vision-language backbones pretrained on large-scale, but disconnected static web data. As a result, despite improved semantic generalization, the policy must implicitly infer complex physical dynamics and temporal dependencies solely from robot trajectories. This reliance creates an unsustainable data burden, necessitating continuous, large-scale expert data collection to compensate for the lack of innate physical understanding. We contend that while vision-language pretraining effectively captures semantic priors, it remains blind to physical causality. A more effective paradigm leverages video to jointly capture semantics and visual dynamics during pretraining, thereby isolating the remaining task of low-level control. To this end, we introduce mimic-video, a novel Video-Action Model (VAM) that pairs a pretrained Internet-scale video model with a flow matching-based action decoder conditioned on its latent representations. The decoder serves as an Inverse Dynamics Model (IDM), generating low-level robot actions from the latent representation of video-space action plans. Our extensive evaluation shows that our approach achieves state-of-the-art performance on simulated and real-world robotic manipulation tasks, improving sample efficiency by 10x and convergence speed by 2x compared to traditional VLA architectures.","authors":["Jonas Pai","Liam Achenbach","Victoriano Montesinos","Benedek Forrai","Oier Mees","Elvis Nava"],"pdf_url":"","comment":"Revised Introduction, Related Work, and Appendix. Additional minor notational and grammatical fixes"},{"id":"http://arxiv.org/abs/2512.17875v1","updated":"2025-12-19T18:26:58Z","published":"2025-12-19T18:26:58Z","title":"Visually Prompted Benchmarks Are Surprisingly Fragile","summary":"A key challenge in evaluating VLMs is testing models' ability to analyze visual content independently from their textual priors. Recent benchmarks such as BLINK probe visual perception through visual prompting, where questions about visual content are paired with coordinates to which the question refers, with the coordinates explicitly marked in the image itself. While these benchmarks are an important part of VLM evaluation, we find that existing models are surprisingly fragile to seemingly irrelevant details of visual prompting: simply changing a visual marker from red to blue can completely change rankings among models on a leaderboard. By evaluating nine commonly-used open- and closed-source VLMs on two visually prompted tasks, we demonstrate how details in benchmark setup, including visual marker design and dataset size, have a significant influence on model performance and leaderboard rankings. These effects can even be exploited to lift weaker models above stronger ones; for instance, slightly increasing the size of the visual marker results in open-source InternVL3-8B ranking alongside or better than much larger proprietary models like Gemini 2.5 Pro. We further show that low-level inference choices that are often ignored in benchmarking, such as JPEG compression levels in API calls, can also cause model lineup changes. These details have substantially larger impacts on visually prompted benchmarks than on conventional semantic VLM evaluations. To mitigate this instability, we curate existing datasets to create VPBench, a larger visually prompted benchmark with 16 visual marker variants. VPBench and additional analysis tools are released at https://lisadunlap.github.io/vpbench/.","authors":["Haiwen Feng","Long Lian","Lisa Dunlap","Jiahao Shu","XuDong Wang","Renhao Wang","Trevor Darrell","Alane Suhr","Angjoo Kanazawa"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18214v2","updated":"2025-12-19T18:23:00Z","published":"2025-11-22T23:13:04Z","title":"Deep Gaussian Process Proximal Policy Optimization","summary":"Uncertainty estimation for Reinforcement Learning (RL) is a critical component in control tasks where agents must balance safe exploration and efficient learning. While deep neural networks have enabled breakthroughs in RL, they often lack calibrated uncertainty estimates. We introduce Deep Gaussian Process Proximal Policy Optimization (GPPO), a scalable, model-free actor-critic algorithm that leverages Deep Gaussian Processes (DGPs) to approximate both the policy and value function. GPPO maintains competitive performance with respect to Proximal Policy Optimization on standard high-dimensional continuous control benchmarks while providing well-calibrated uncertainty estimates that can inform safer and more effective exploration.","authors":["Matthijs van der Lende","Juan Cardenas-Cartagena"],"pdf_url":"","comment":"Withdrawn by the authors as the manuscript is not yet complete; no updated version is available at this time"},{"id":"http://arxiv.org/abs/2412.15184v2","updated":"2025-12-19T18:17:28Z","published":"2024-12-19T18:55:17Z","title":"Data for Mathematical Copilots: Better Ways of Presenting Proofs for Machine Learning","summary":"The datasets and benchmarks commonly used to train and evaluate the mathematical capabilities of AI-based mathematical copilots (primarily large language models) exhibit several shortcomings and misdirections. These range from a restricted scope of mathematical complexity to limited fidelity in capturing aspects beyond the final, written proof (e.g. motivating the proof, or representing the thought processes leading to a proof). These issues are compounded by a dynamic reminiscent of Goodhart's law: as benchmark performance becomes the primary target for model development, the benchmarks themselves become less reliable indicators of genuine mathematical capability. We systematically explore these limitations and contend that enhancing the capabilities of large language models, or any forthcoming advancements in AI-based mathematical assistants (copilots or ``thought partners''), necessitates a course correction both in the design of mathematical datasets and the evaluation criteria of the models' mathematical ability. In particular, it is necessary for benchmarks to move beyond the existing result-based datasets that map theorem statements directly to proofs, and instead focus on datasets that translate the richer facets of mathematical research practice into data that LLMs can learn from. This includes benchmarks that supervise the proving process and the proof discovery process itself, and we advocate for mathematical dataset developers to consider the concept of \"motivated proof\", introduced by G. Pólya in 1949, which can serve as a blueprint for datasets that offer a better proof learning signal, alleviating some of the mentioned limitations.","authors":["Simon Frieder","Jonas Bayer","Sam Looi","Jacob Loader","Julius Berner","Katherine M. Collins","András Juhász","Fabian Ruehle","Sean Welleck","Gabriel Poesia","Ryan-Rhys Griffiths","Adrian Weller","Anirudh Goyal","Cameron Freer","Thomas Lukasiewicz","Timothy Gowers"],"pdf_url":"","comment":"59 pages"},{"id":"http://arxiv.org/abs/2501.10321v3","updated":"2025-12-19T18:08:16Z","published":"2025-01-17T17:51:22Z","title":"Towards Human-Guided, Data-Centric LLM Co-Pilots","summary":"Machine learning (ML) has the potential to revolutionize various domains, but its adoption is often hindered by the disconnect between the needs of domain experts and translating these needs into robust and valid ML tools. Despite recent advances in LLM-based co-pilots to democratize ML for non-technical domain experts, these systems remain predominantly focused on model-centric aspects while overlooking critical data-centric challenges. This limitation is problematic in complex real-world settings where raw data often contains complex issues, such as missing values, label noise, and domain-specific nuances requiring tailored handling. To address this we introduce CliMB-DC, a human-guided, data-centric framework for LLM co-pilots that combines advanced data-centric tools with LLM-driven reasoning to enable robust, context-aware data processing. At its core, CliMB-DC introduces a novel, multi-agent reasoning system that combines a strategic coordinator for dynamic planning and adaptation with a specialized worker agent for precise execution. Domain expertise is then systematically incorporated to guide the reasoning process using a human-in-the-loop approach. To guide development, we formalize a taxonomy of key data-centric challenges that co-pilots must address. Thereafter, to address the dimensions of the taxonomy, we integrate state-of-the-art data-centric tools into an extensible, open-source architecture, facilitating the addition of new tools from the research community. Empirically, using real-world healthcare datasets we demonstrate CliMB-DC's ability to transform uncurated datasets into ML-ready formats, significantly outperforming existing co-pilot baselines for handling data-centric challenges. CliMB-DC promises to empower domain experts from diverse domains -- healthcare, finance, social sciences and more -- to actively participate in driving real-world impact using ML.","authors":["Evgeny Saveliev","Jiashuo Liu","Nabeel Seedat","Anders Boyd","Mihaela van der Schaar"],"pdf_url":"","comment":"Saveliev, Liu & Seedat contributed equally"},{"id":"http://arxiv.org/abs/2410.06800v2","updated":"2025-12-19T18:07:37Z","published":"2024-10-09T11:54:33Z","title":"Low-Rank Filtering and Smoothing for Sequential Deep Learning","summary":"Learning multiple tasks sequentially requires neural networks to balance retaining knowledge, yet being flexible enough to adapt to new tasks. Regularizing network parameters is a common approach, but it rarely incorporates prior knowledge about task relationships, and limits information flow to future tasks only. We propose a Bayesian framework that treats the network's parameters as the state space of a nonlinear Gaussian model, unlocking two key capabilities: (1) A principled way to encode domain knowledge about task relationships, allowing, e.g., control over which layers should adapt between tasks. (2) A novel application of Bayesian smoothing, allowing task-specific models to also incorporate knowledge from models learned later. This does not require direct access to their data, which is crucial, e.g., for privacy-critical applications. These capabilities rely on efficient filtering and smoothing operations, for which we propose diagonal plus low-rank approximations of the precision matrix in the Laplace approximation (LR-LGF). Empirical results demonstrate the efficiency of LR-LGF and the benefits of the unlocked capabilities.","authors":["Joanna Sliwa","Frank Schneider","Nathanael Bosch","Agustinus Kristiadi","Philipp Hennig"],"pdf_url":"","comment":"Revised version: improved presentation and added experiments"},{"id":"http://arxiv.org/abs/2411.19908v6","updated":"2025-12-19T17:48:29Z","published":"2024-11-29T18:12:50Z","title":"Another look at inference after prediction","summary":"From structural biology to epidemiology, predictions from machine learning (ML) models are increasingly used to complement costly gold-standard data to enable faster, more affordable, and scalable scientific inquiry. In response, prediction-based (PB) inference has emerged to accommodate statistical analysis using a large volume of predictions together with a small amount of gold-standard data. The goals of PB inference are two-fold: (i) to mitigate bias from errors in predictions and (ii) to improve efficiency relative to traditional inference using only the gold-standard data. While early PB inference methods focused on bias, their ability to enhance efficiency remains unclear. We revisit a popular PB inference method and show that a simple modification can be applied to guarantee improvements in efficiency beyond yielding valid inferences when the ML predictions are imperfect. The utility of this approach in leveraging prediction-based outcomes to enhance efficiency is demonstrated through extensive simulation studies and an application to the UK Biobank data. We further contextualize the problem of PB inference through historical literature from economics and statistics to highlight perspectives from classical methods in this contemporary problem.","authors":["Jessica Gronsbell","Jianhui Gao","Yaqi Shi","Zachary R. McCaw","David Cheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.11512v2","updated":"2025-12-19T17:47:28Z","published":"2025-09-15T01:53:30Z","title":"Machine Learning-Driven Predictive Resource Management in Complex Science Workflows","summary":"The collaborative efforts of large communities in science experiments, often comprising thousands of global members, reflect a monumental commitment to exploration and discovery. Recently, advanced and complex data processing has gained increasing importance in science experiments. Data processing workflows typically consist of multiple intricate steps, and the precise specification of resource requirements is crucial for each step to allocate optimal resources for effective processing. Estimating resource requirements in advance is challenging due to a wide range of analysis scenarios, varying skill levels among community members, and the continuously increasing spectrum of computing options. One practical approach to mitigate these challenges involves initially processing a subset of each step to measure precise resource utilization from actual processing profiles before completing the entire step. While this two-staged approach enables processing on optimal resources for most of the workflow, it has drawbacks such as initial inaccuracies leading to potential failures and suboptimal resource usage, along with overhead from waiting for initial processing completion, which is critical for fast-turnaround analyses. In this context, our study introduces a novel pipeline of machine learning models within a comprehensive workflow management system, the Production and Distributed Analysis (PanDA) system. These models employ advanced machine learning techniques to predict key resource requirements, overcoming challenges posed by limited upfront knowledge of characteristics at each step. Accurate forecasts of resource requirements enable informed and proactive decision-making in workflow management, enhancing the efficiency of handling diverse, complex workflows across heterogeneous resources.","authors":["Tasnuva Chowdhury","Tadashi Maeno","Fatih Furkan Akman","Joseph Boudreau","Sankha Dutta","Shengyu Feng","Adolfy Hoisie","Kuan-Chieh Hsu","Raees Khan","Jaehyung Kim","Ozgur O. Kilic","Scott Klasky","Alexei Klimentov","Tatiana Korchuganova","Verena Ingrid Martinez Outschoorn","Paul Nilsson","David K. Park","Norbert Podhorszki","Yihui Ren","John Rembrandt Steele","Frédéric Suter","Sairam Sri Vatsavai","Torre Wenaus","Wei Yang","Yiming Yang","Shinjae Yoo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17820v1","updated":"2025-12-19T17:24:12Z","published":"2025-12-19T17:24:12Z","title":"Exploiting ID-Text Complementarity via Ensembling for Sequential Recommendation","summary":"Modern Sequential Recommendation (SR) models commonly utilize modality features to represent items, motivated in large part by recent advancements in language and vision modeling. To do so, several works completely replace ID embeddings with modality embeddings, claiming that modality embeddings render ID embeddings unnecessary because they can match or even exceed ID embedding performance. On the other hand, many works jointly utilize ID and modality features, but posit that complex fusion strategies, such as multi-stage training and/or intricate alignment architectures, are necessary for this joint utilization. However, underlying both these lines of work is a lack of understanding of the complementarity of ID and modality features. In this work, we address this gap by studying the complementarity of ID- and text-based SR models. We show that these models do learn complementary signals, meaning that either should provide performance gain when used properly alongside the other. Motivated by this, we propose a new SR method that preserves ID-text complementarity through independent model training, then harnesses it through a simple ensembling strategy. Despite this method's simplicity, we show it outperforms several competitive SR baselines, implying that both ID and text features are necessary to achieve state-of-the-art SR performance but complex fusion architectures are not.","authors":["Liam Collins","Bhuvesh Kumar","Clark Mingxuan Ju","Tong Zhao","Donald Loveland","Leonardo Neves","Neil Shah"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.10892v3","updated":"2025-12-19T17:14:07Z","published":"2025-06-12T16:55:35Z","title":"The Diffusion Duality","summary":"Uniform-state discrete diffusion models hold the promise of fast text generation due to their inherent ability to self-correct. However, they are typically outperformed by autoregressive models and masked diffusion models. In this work, we narrow this performance gap by leveraging a key insight: Uniform-state diffusion processes naturally emerge from an underlying Gaussian diffusion. Our method, Duo, transfers powerful techniques from Gaussian diffusion to improve both training and sampling. First, we introduce a curriculum learning strategy guided by the Gaussian process, doubling training speed by reducing variance. Models trained with curriculum learning surpass autoregressive models in zero-shot perplexity on 3 of 7 benchmarks. Second, we present Discrete Consistency Distillation, which adapts consistency distillation from the continuous to the discrete setting. This algorithm unlocks few-step generation in diffusion language models by accelerating sampling by two orders of magnitude. We provide the code, model checkpoints, and video tutorials on the project page: http://s-sahoo.github.io/duo","authors":["Subham Sekhar Sahoo","Justin Deschenaux","Aaron Gokaslan","Guanghan Wang","Justin Chiu","Volodymyr Kuleshov"],"pdf_url":"","comment":"ICML 2025. We provide the code at: https://github.com/s-sahoo/duo [v3] includes improved theory, clearer presentation, and a new future work section"},{"id":"http://arxiv.org/abs/2512.17800v1","updated":"2025-12-19T17:02:58Z","published":"2025-12-19T17:02:58Z","title":"Domain-Aware Quantum Circuit for QML","summary":"Designing parameterized quantum circuits (PQCs) that are expressive, trainable, and robust to hardware noise is a central challenge for quantum machine learning (QML) on noisy intermediate-scale quantum (NISQ) devices. We present a Domain-Aware Quantum Circuit (DAQC) that leverages image priors to guide locality-preserving encoding and entanglement via non-overlapping DCT-style zigzag windows. The design employs interleaved encode-entangle-train cycles, where entanglement is applied among qubits hosting neighboring pixels, aligned to device connectivity. This staged, locality-preserving information flow expands the effective receptive field without deep global mixing, enabling efficient use of limited depth and qubits. The design concentrates representational capacity on short-range correlations, reduces long-range two-qubit operations, and encourages stable optimization, thereby mitigating depth-induced and globally entangled barren-plateau effects. We evaluate DAQC on MNIST, FashionMNIST, and PneumoniaMNIST datasets. On quantum hardware, DAQC achieves performance competitive with strong classical baselines (e.g., ResNet-18/50, DenseNet-121, EfficientNet-B0) and substantially outperforming Quantum Circuit Search (QCS) baselines. To the best of our knowledge, DAQC, which uses a quantum feature extractor with only a linear classical readout (no deep classical backbone), currently achieves the best reported performance on real quantum hardware for QML-based image classification tasks. Code and pretrained models are available at: https://github.com/gurinder-hub/DAQC.","authors":["Gurinder Singh","Thaddeus Pellegrini","Kenneth M. Merz,"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.18057v6","updated":"2025-12-19T16:58:50Z","published":"2025-09-22T17:30:33Z","title":"Reinforced Generation of Combinatorial Structures: Hardness of Approximation","summary":"Can AI based methods help us make advances in complexity theory? We provide evidence towards answering this in the affirmative, using AlphaEvolve (an LLM code mutation agent) to obtain new results in three settings:\n  a) We improve a recent result of Kunisky and Yu to obtain near-optimal upper and (conditional) lower bounds on certification algorithms for MAX-CUT and MAX-Independent Set on random 3- and 4-regular graphs. Our improved lower bounds are obtained by constructing nearly extremal Ramanujan graphs on as many as $163$ vertices, and our upper bounds are obtained via analytical arguments.\n  b) We obtain new inapproximability results for MAX-4-CUT and MAX-3-CUT, proving that it is NP-hard to approximate them within factors of $0.987$ and $0.9649$ respectively, using AlphaEvolve to discover new gadget reductions. Our MAX-4-CUT result improves upon the SOTA of $0.9883$, and our MAX-3-CUT result improves on the current best gadget-based inapproximability result of $0.9853$, but falls short of the SOTA of $16/17$ that relies on a custom PCP (rather than a reduction from ``standard'' Håstad-style PCPs).\n  c) Inapproximability for the metric Traveling Salesman Problem (TSP): We show that it is NP-hard to approximate the minimum cost tour within a factor of $111/110$ using AlphaEvolve to discover a new gadget, thus improving the SOTA of $117/116$. Along the way, we provide new modular soundness and completeness arguments that can be of independent interest.\n  A key technical challenge we faced: verifying a candidate construction produced by AlphaEvolve is costly (sometimes requiring time exponential in the size of the construction). We used AlphaEvolve itself to evolve the verification procedure to be faster (sometimes by $10,000\\times$ for our gadgets). Our results suggest that gadget based proofs would benefit from a pass through AI-based tools to obtain stronger results.","authors":["Ansh Nagda","Prabhakar Raghavan","Abhradeep Thakurta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17788v1","updated":"2025-12-19T16:58:31Z","published":"2025-12-19T16:58:31Z","title":"Calibratable Disambiguation Loss for Multi-Instance Partial-Label Learning","summary":"Multi-instance partial-label learning (MIPL) is a weakly supervised framework that extends the principles of multi-instance learning (MIL) and partial-label learning (PLL) to address the challenges of inexact supervision in both instance and label spaces. However, existing MIPL approaches often suffer from poor calibration, undermining classifier reliability. In this work, we propose a plug-and-play calibratable disambiguation loss (CDL) that simultaneously improves classification accuracy and calibration performance. The loss has two instantiations: the first one calibrates predictions based on probabilities from the candidate label set, while the second one integrates probabilities from both candidate and non-candidate label sets. The proposed CDL can be seamlessly incorporated into existing MIPL and PLL frameworks. We provide a theoretical analysis that establishes the lower bound and regularization properties of CDL, demonstrating its superiority over conventional disambiguation losses. Experimental results on benchmark and real-world datasets confirm that our CDL significantly enhances both classification and calibration performance.","authors":["Wei Tang","Yin-Fang Yang","Weijia Zhang","Min-Ling Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.00645v3","updated":"2025-12-19T16:57:39Z","published":"2024-05-01T17:18:46Z","title":"HGQ: High Granularity Quantization for Real-time Neural Networks on FPGAs","summary":"Neural networks with sub-microsecond inference latency are required by many critical applications. Targeting such applications deployed on FPGAs, we present High Granularity Quantization (HGQ), a quantization-aware training framework that optimizes parameter bit-widths through gradient descent. Unlike conventional methods, HGQ determines the optimal bit-width for each parameter independently, making it suitable for hardware platforms supporting heterogeneous arbitrary precision arithmetic. In our experiments, HGQ shows superior performance compared to existing network compression methods, achieving orders of magnitude reduction in resource consumption and latency while maintaining the accuracy on several benchmark tasks. These improvements enable the deployment of complex models previously infeasible due to resource or latency constraints. HGQ is open-source and is used for developing next-generation trigger systems at the CERN ATLAS and CMS experiments for particle physics, enabling the use of advanced machine learning models for real-time data selection with sub-microsecond latency.","authors":["Chang Sun","Zhiqiang Que","Thea K. Årrestad","Vladimir Loncar","Jennifer Ngadiuba","Wayne Luk","Maria Spiropulu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17774v1","updated":"2025-12-19T16:45:23Z","published":"2025-12-19T16:45:23Z","title":"MedNeXt-v2: Scaling 3D ConvNeXts for Large-Scale Supervised Representation Learning in Medical Image Segmentation","summary":"Large-scale supervised pretraining is rapidly reshaping 3D medical image segmentation. However, existing efforts focus primarily on increasing dataset size and overlook the question of whether the backbone network is an effective representation learner at scale. In this work, we address this gap by revisiting ConvNeXt-based architectures for volumetric segmentation and introducing MedNeXt-v2, a compound-scaled 3D ConvNeXt that leverages improved micro-architecture and data scaling to deliver state-of-the-art performance. First, we show that routinely used backbones in large-scale pretraining pipelines are often suboptimal. Subsequently, we use comprehensive backbone benchmarking prior to scaling and demonstrate that stronger from scratch performance reliably predicts stronger downstream performance after pretraining. Guided by these findings, we incorporate a 3D Global Response Normalization module and use depth, width, and context scaling to improve our architecture for effective representation learning. We pretrain MedNeXt-v2 on 18k CT volumes and demonstrate state-of-the-art performance when fine-tuning across six challenging CT and MR benchmarks (144 structures), showing consistent gains over seven publicly released pretrained models. Beyond improvements, our benchmarking of these models also reveals that stronger backbones yield better results on similar data, representation scaling disproportionately benefits pathological segmentation, and that modality-specific pretraining offers negligible benefit once full finetuning is applied. In conclusion, our results establish MedNeXt-v2 as a strong backbone for large-scale supervised representation learning in 3D Medical Image Segmentation. Our code and pretrained models are made available with the official nnUNet repository at: https://www.github.com/MIC-DKFZ/nnUNet","authors":["Saikat Roy","Yannick Kirchhoff","Constantin Ulrich","Maximillian Rokuss","Tassilo Wald","Fabian Isensee","Klaus Maier-Hein"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17771v1","updated":"2025-12-19T16:43:07Z","published":"2025-12-19T16:43:07Z","title":"Easy Adaptation: An Efficient Task-Specific Knowledge Injection Method for Large Models in Resource-Constrained Environments","summary":"While the enormous parameter scale endows Large Models (LMs) with unparalleled performance, it also limits their adaptability across specific tasks. Parameter-Efficient Fine-Tuning (PEFT) has emerged as a critical approach for effectively adapting LMs to a diverse range of downstream tasks. However, existing PEFT methods face two primary challenges: (1) High resource cost. Although PEFT methods significantly reduce resource demands compared to full fine-tuning, it still requires substantial time and memory, making it impractical in resource-constrained environments. (2) Parameter dependency. PEFT methods heavily rely on updating a subset of parameters associated with LMs to incorporate task-specific knowledge. Yet, due to increasing competition in the LMs landscape, many companies have adopted closed-source policies for their leading models, offering access only via Application Programming Interface (APIs). Whereas, the expense is often cost-prohibitive and difficult to sustain, as the fine-tuning process of LMs is extremely slow. Even if small models perform far worse than LMs in general, they can achieve superior results on particular distributions while requiring only minimal resources. Motivated by this insight, we propose Easy Adaptation (EA), which designs Specific Small Models (SSMs) to complement the underfitted data distribution for LMs. Extensive experiments show that EA matches the performance of PEFT on diverse tasks without accessing LM parameters, and requires only minimal resources.","authors":["Dong Chen","Zhengqing Hu","Shixing Zhao","Yibo Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17762v1","updated":"2025-12-19T16:34:27Z","published":"2025-12-19T16:34:27Z","title":"Can You Hear Me Now? A Benchmark for Long-Range Graph Propagation","summary":"Effectively capturing long-range interactions remains a fundamental yet unresolved challenge in graph neural network (GNN) research, critical for applications across diverse fields of science. To systematically address this, we introduce ECHO (Evaluating Communication over long HOps), a novel benchmark specifically designed to rigorously assess the capabilities of GNNs in handling very long-range graph propagation. ECHO includes three synthetic graph tasks, namely single-source shortest paths, node eccentricity, and graph diameter, each constructed over diverse and structurally challenging topologies intentionally designed to introduce significant information bottlenecks. ECHO also includes two real-world datasets, ECHO-Charge and ECHO-Energy, which define chemically grounded benchmarks for predicting atomic partial charges and molecular total energies, respectively, with reference computations obtained at the density functional theory (DFT) level. Both tasks inherently depend on capturing complex long-range molecular interactions. Our extensive benchmarking of popular GNN architectures reveals clear performance gaps, emphasizing the difficulty of true long-range propagation and highlighting design choices capable of overcoming inherent limitations. ECHO thereby sets a new standard for evaluating long-range information propagation, also providing a compelling example for its need in AI for science.","authors":["Luca Miglior","Matteo Tolloso","Alessio Gravina","Davide Bacciu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17759v1","updated":"2025-12-19T16:32:31Z","published":"2025-12-19T16:32:31Z","title":"Breast Cancer Neoadjuvant Chemotherapy Treatment Response Prediction Using Aligned Longitudinal MRI and Clinical Data","summary":"Aim: This study investigates treatment response prediction to neoadjuvant chemotherapy (NACT) in breast cancer patients, using longitudinal contrast-enhanced magnetic resonance images (CE-MRI) and clinical data. The goal is to develop machine learning (ML) models to predict pathologic complete response (PCR binary classification) and 5-year relapse-free survival status (RFS binary classification). Method: The proposed framework includes tumour segmentation, image registration, feature extraction, and predictive modelling. Using the image registration method, MRI image features can be extracted and compared from the original tumour site at different time points, therefore monitoring the intratumor changes during NACT process. Four feature extractors, including one radiomics and three deep learning-based (MedicalNet, Segformer3D, SAM-Med3D) were implemented and compared. In combination with three feature selection methods and four ML models, predictive models are built and compared. Results: The proposed image registration-based feature extraction consistently improves the predictive models. In the PCR and RFS classification tasks logistic regression model trained on radiomic features performed the best with an AUC of 0.88 and classification accuracy of 0.85 for PCR classification, and AUC of 0.78 and classification accuracy of 0.72 for RFS classification. Conclusions: It is evidenced that the image registration method has significantly improved performance in longitudinal feature learning in predicting PCR and RFS. The radiomics feature extractor is more effective than the pre-trained deep learning feature extractors, with higher performance and better interpretability.","authors":["Rahul Ravi","Ruizhe Li","Tarek Abdelfatah","Stephen Chan","Xin Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14745v2","updated":"2025-12-19T16:32:22Z","published":"2025-11-18T18:45:32Z","title":"Look-Ahead Reasoning on Learning Platforms","summary":"On many learning platforms, the optimization criteria guiding model training reflect the priorities of the designer rather than those of the individuals they affect. Consequently, users may act strategically to obtain more favorable outcomes. While past work has studied strategic user behavior on learning platforms, the focus has largely been on strategic responses to a deployed model, without considering the behavior of other users. In contrast, look-ahead reasoning takes into account that user actions are coupled, and -- at scale -- impact future predictions. Within this framework, we first formalize level-k thinking, a concept from behavioral economics, where users aim to outsmart their peers by looking one step ahead. We show that, while convergence to an equilibrium is accelerated, the equilibrium remains the same, providing no benefit of higher-level reasoning for individuals in the long run. Then, we focus on collective reasoning, where users take coordinated actions by optimizing through their joint impact on the model. By contrasting collective with selfish behavior, we characterize the benefits and limits of coordination; a new notion of alignment between the learner's and the users' utilities emerges as a key concept. Look-ahead reasoning can be seen as a generalization of algorithmic collective action; we thus offer the first results characterizing the utility trade-offs of coordination when contesting algorithmic systems.","authors":["Haiqing Zhu","Tijana Zrnic","Celestine Mendler-Dünner"],"pdf_url":"","comment":"published at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2508.10501v4","updated":"2025-12-19T16:27:34Z","published":"2025-08-14T10:03:47Z","title":"PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning","summary":"Existing tool-augmented agentic systems are limited in the real world by (i) black-box reasoning steps that undermine trust of decision-making and pose safety risks, (ii) poor multimodal integration, which is inherently critical for healthcare tasks, and (iii) rigid and computationally inefficient agentic pipelines. We introduce PASS (Probabilistic Agentic Supernet Sampling), the first multimodal framework to address these challenges in the context of Chest X-Ray (CXR) reasoning. PASS adaptively samples agentic workflows over a multi-tool graph, yielding decision paths annotated with interpretable probabilities. Given the complex CXR reasoning task with multimodal medical data, PASS leverages its learned task-conditioned distribution over the agentic supernet. Thus, it adaptively selects the most suitable tool at each supernet layer, offering probability-annotated trajectories for post-hoc audits and directly enhancing medical AI safety. PASS also continuously compresses salient findings into an evolving personalized memory, while dynamically deciding whether to deepen its reasoning path or invoke an early exit for efficiency. To optimize a Pareto frontier balancing performance and cost, we design a novel three-stage training procedure, including expert knowledge warm-up, contrastive path-ranking, and cost-aware reinforcement learning. To facilitate rigorous evaluation, we introduce CAB-E, a comprehensive benchmark for multi-step, safety-critical, free-form CXR reasoning. Experiments across various benchmarks validate that PASS significantly outperforms strong baselines in multiple metrics (e.g., accuracy, LLM-Judge, semantic similarity, etc.) while balancing computational costs, pushing a new paradigm shift towards interpretable, adaptive, and multimodal medical agentic systems.","authors":["Yushi Feng","Junye Du","Yingying Hong","Qifan Wang","Lequan Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.24830v2","updated":"2025-12-19T16:21:05Z","published":"2025-10-28T16:42:53Z","title":"The Generation Phases of Flow Matching: a Denoising Perspective","summary":"Flow matching has achieved remarkable success, yet the factors influencing the quality of its generation process remain poorly understood. In this work, we adopt a denoising perspective and design a framework to empirically probe the generation process. Laying down the formal connections between flow matching models and denoisers, we provide a common ground to compare their performances on generation and denoising. This enables the design of principled and controlled perturbations to influence sample generation: noise and drift. This leads to new insights on the distinct dynamical phases of the generative process, enabling us to precisely characterize at which stage of the generative process denoisers succeed or fail and why this matters.","authors":["Anne Gagneux","Ségolène Martin","Rémi Gribonval","Mathurin Massias"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.07588v5","updated":"2025-12-19T16:19:39Z","published":"2024-08-14T14:40:00Z","title":"Adjusting Model Size in Continual Gaussian Processes: How Big is Big Enough?","summary":"Many machine learning models require setting a parameter that controls their size before training, e.g. number of neurons in DNNs, or inducing points in GPs. Increasing capacity typically improves performance until all the information from the dataset is captured. After this point, computational cost keeps increasing, without improved performance. This leads to the question \"How big is big enough?\" We investigate this problem for Gaussian processes (single-layer neural networks) in continual learning. Here, data becomes available incrementally, and the final dataset size will therefore not be known before training, preventing the use of heuristics for setting a fixed model size. We develop a method to automatically adjust model size while maintaining near-optimal performance. Our experimental procedure follows the constraint that any hyperparameters must be set without seeing dataset properties, and we show that our method performs well across diverse datasets without the need to adjust its hyperparameter, showing it requires less tuning than others.","authors":["Guiomar Pescador-Barrios","Sarah Filippi","Mark van der Wilk"],"pdf_url":"","comment":"9 pages main, 27 pages total, 13 figures, 9 tables, conference paper, minor correction"},{"id":"http://arxiv.org/abs/2512.17720v1","updated":"2025-12-19T15:54:36Z","published":"2025-12-19T15:54:36Z","title":"Mitigating Forgetting in Low Rank Adaptation","summary":"Parameter-efficient fine-tuning methods, such as Low-Rank Adaptation (LoRA), enable fast specialization of large pre-trained models to different downstream applications. However, this process often leads to catastrophic forgetting of the model's prior domain knowledge. We address this issue with LaLoRA, a weight-space regularization technique that applies a Laplace approximation to Low-Rank Adaptation. Our approach estimates the model's confidence in each parameter and constrains updates in high-curvature directions, preserving prior knowledge while enabling efficient target-domain learning. By applying the Laplace approximation only to the LoRA weights, the method remains lightweight. We evaluate LaLoRA by fine-tuning a Llama model for mathematical reasoning and demonstrate an improved learning-forgetting trade-off, which can be directly controlled via the method's regularization strength. We further explore different loss landscape curvature approximations for estimating parameter confidence, analyze the effect of the data used for the Laplace approximation, and study robustness across hyperparameters.","authors":["Joanna Sliwa","Frank Schneider","Philipp Hennig","Jose Miguel Hernandez-Lobato"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.10290v3","updated":"2025-12-19T15:43:55Z","published":"2025-01-17T16:34:45Z","title":"Pairwise Elimination with Instance-Dependent Guarantees for Bandits with Cost Subsidy","summary":"Multi-armed bandits (MAB) are commonly used in sequential online decision-making when the reward of each decision is an unknown random variable. In practice however, the typical goal of maximizing total reward may be less important than minimizing the total cost of the decisions taken, subject to a reward constraint. For example, we may seek to make decisions that have at least the reward of a reference ``default'' decision, with as low a cost as possible. This problem was recently introduced in the Multi-Armed Bandits with Cost Subsidy (MAB-CS) framework. MAB-CS is broadly applicable to problem domains where a primary metric (cost) is constrained by a secondary metric (reward), and the rewards are unknown. In our work, we address variants of MAB-CS including ones with reward constrained by the reward of a known reference arm or by the subsidized best reward. We introduce the Pairwise-Elimination (PE) algorithm for the known reference arm variant and generalize PE to PE-CS for the subsidized best reward variant. Our instance-dependent analysis of PE and PE-CS reveals that both algorithms have an order-wise logarithmic upper bound on Cost and Quality Regret, making our policies the first with such a guarantee. Moreover, by comparing our upper and lower bound results we establish that PE is order-optimal for all known reference arm problem instances. Finally, experiments are conducted using the MovieLens 25M and Goodreads datasets for both PE and PE-CS revealing the effectiveness of PE and the superior balance between performance and reliability offered by PE-CS compared to baselines from the literature.","authors":["Ishank Juneja","Carlee Joe-Wong","Osman Yağan"],"pdf_url":"","comment":"ICLR 2025 Conference Paper"},{"id":"http://arxiv.org/abs/2409.03735v3","updated":"2025-12-19T15:41:38Z","published":"2024-09-05T17:50:31Z","title":"Privacy Bias in Language Models: A Contextual Integrity-based Auditing Metric","summary":"As large language models (LLMs) are integrated into sociotechnical systems, it is crucial to examine the privacy biases they exhibit. We define privacy bias as the appropriateness value of information flows in responses from LLMs. A deviation between privacy biases and expected values, referred to as privacy bias delta, may indicate privacy violations. As an auditing metric, privacy bias can help (a) model trainers evaluate the ethical and societal impact of LLMs, (b) service providers select context-appropriate LLMs, and (c) policymakers assess the appropriateness of privacy biases in deployed LLMs. We formulate and answer a novel research question: how can we reliably examine privacy biases in LLMs and the factors that influence them? We present a novel approach for assessing privacy biases using a contextual integrity-based methodology to evaluate the responses from various LLMs. Our approach accounts for the sensitivity of responses across prompt variations, which hinders the evaluation of privacy biases. Finally, we investigate how privacy biases are affected by model capacities and optimizations.","authors":["Yan Shvartzshnaider","Vasisht Duddu"],"pdf_url":"","comment":"Privacy Enhancing Technologies Symposium (PETS), 2026"},{"id":"http://arxiv.org/abs/2512.17703v1","updated":"2025-12-19T15:36:27Z","published":"2025-12-19T15:36:27Z","title":"Revisiting the Broken Symmetry Phase of Solid Hydrogen: A Neural Network Variational Monte Carlo Study","summary":"The crystal structure of high-pressure solid hydrogen remains a fundamental open problem. Although the research frontier has mostly shifted toward ultra-high pressure phases above 400 GPa, we show that even the broken symmetry phase observed around 130~GPa requires revisiting due to its intricate coupling of electronic and nuclear degrees of freedom. Here, we develop a first principle quantum Monte Carlo framework based on a deep neural network wave function that treats both electrons and nuclei quantum mechanically within the constant pressure ensemble. Our calculations reveal an unreported ground-state structure candidate for the broken symmetry phase with $Cmcm$ space group symmetry, and we test its stability up to 96 atoms. The predicted structure quantitatively matches the experimental equation of state and X-ray diffraction patterns. Furthermore, our group-theoretical analysis shows that the $Cmcm$ structure is compatible with existing Raman and infrared spectroscopic data. Crucially, static density functional theory calculation reveals the $Cmcm$ structure as a dynamically unstable saddle point on the Born-Oppenheimer potential energy surface, demonstrating that a full quantum many-body treatment of the problem is necessary. These results shed new light on the phase diagram of high-pressure hydrogen and call for further experimental verifications.","authors":["Shengdu Chai","Chen Lin","Xinyang Dong","Yuqiang Li","Wanli Ouyang","Lei Wang","X. C. Xie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.12118v3","updated":"2025-12-19T15:36:27Z","published":"2024-02-19T13:13:16Z","title":"Sparse, Efficient and Explainable Data Attribution with DualXDA","summary":"Data Attribution (DA) is an emerging approach in the field of eXplainable Artificial Intelligence (XAI), aiming to identify influential training datapoints which determine model outputs. It seeks to provide transparency about the model and individual predictions, e.g. for model debugging, identifying data-related causes of suboptimal performance. However, existing DA approaches suffer from prohibitively high computational costs and memory demands when applied to even medium-scale datasets and models, forcing practitioners to resort to approximations that may fail to capture the true inference process of the underlying model. Additionally, current attribution methods exhibit low sparsity, resulting in non-negligible attribution scores across a high number of training examples, hindering the discovery of decisive patterns in the data. In this work, we introduce DualXDA, a framework for sparse, efficient and explainable DA, comprised of two interlinked approaches, Dual Data Attribution (DualDA) and eXplainable Data Attribution (XDA): With DualDA, we propose a novel approach for efficient and effective DA, leveraging Support Vector Machine theory to provide fast and naturally sparse data attributions for AI predictions. In extensive quantitative analyses, we demonstrate that DualDA achieves high attribution quality, excels at solving a series of evaluated downstream tasks, while at the same time improving explanation time by a factor of up to 4,100,000x compared to the original Influence Functions method, and up to 11,000x compared to the method's most efficient approximation from literature to date. We further introduce XDA, a method for enhancing Data Attribution with capabilities from feature attribution methods to explain why training samples are relevant for the prediction of a test sample in terms of impactful features, which we showcase and verify qualitatively in detail.","authors":["Galip Ümit Yolcu","Moritz Weckbecker","Thomas Wiegand","Wojciech Samek","Sebastian Lapuschkin"],"pdf_url":"","comment":"Accepted to Transactions on Machine Learning Research (TMLR), 2025"},{"id":"http://arxiv.org/abs/2511.09801v2","updated":"2025-12-19T15:36:03Z","published":"2025-11-12T23:05:14Z","title":"Generalized infinite dimensional Alpha-Procrustes based geometries","summary":"This work extends the recently introduced Alpha-Procrustes family of Riemannian metrics for symmetric positive definite (SPD) matrices by incorporating generalized versions of the Bures-Wasserstein (GBW), Log-Euclidean, and Wasserstein distances. While the Alpha-Procrustes framework has unified many classical metrics in both finite- and infinite- dimensional settings, it previously lacked the structural components necessary to realize these generalized forms. We introduce a formalism based on unitized Hilbert-Schmidt operators and an extended Mahalanobis norm that allows the construction of robust, infinite-dimensional generalizations of GBW and Log-Hilbert-Schmidt distances. Our approach also incorporates a learnable regularization parameter that enhances geometric stability in high-dimensional comparisons. Preliminary experiments reproducing benchmarks from the literature demonstrate the improved performance of our generalized metrics, particularly in scenarios involving comparisons between datasets of varying dimension and scale. This work lays a theoretical and computational foundation for advancing robust geometric methods in machine learning, statistical inference, and functional data analysis.","authors":["Salvish Goomanee","Andi Han","Pratik Jawanpuria","Bamdev Mishra"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17696v1","updated":"2025-12-19T15:32:24Z","published":"2025-12-19T15:32:24Z","title":"Spatially-informed transformers: Injecting geostatistical covariance biases into self-attention for spatio-temporal forecasting","summary":"The modeling of high-dimensional spatio-temporal processes presents a fundamental dichotomy between the probabilistic rigor of classical geostatistics and the flexible, high-capacity representations of deep learning. While Gaussian processes offer theoretical consistency and exact uncertainty quantification, their prohibitive computational scaling renders them impractical for massive sensor networks. Conversely, modern transformer architectures excel at sequence modeling but inherently lack a geometric inductive bias, treating spatial sensors as permutation-invariant tokens without a native understanding of distance. In this work, we propose a spatially-informed transformer, a hybrid architecture that injects a geostatistical inductive bias directly into the self-attention mechanism via a learnable covariance kernel. By formally decomposing the attention structure into a stationary physical prior and a non-stationary data-driven residual, we impose a soft topological constraint that favors spatially proximal interactions while retaining the capacity to model complex dynamics. We demonstrate the phenomenon of ``Deep Variography'', where the network successfully recovers the true spatial decay parameters of the underlying process end-to-end via backpropagation. Extensive experiments on synthetic Gaussian random fields and real-world traffic benchmarks confirm that our method outperforms state-of-the-art graph neural networks. Furthermore, rigorous statistical validation confirms that the proposed method delivers not only superior predictive accuracy but also well-calibrated probabilistic forecasts, effectively bridging the gap between physics-aware modeling and data-driven learning.","authors":["Yuri Calleo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17689v1","updated":"2025-12-19T15:24:49Z","published":"2025-12-19T15:24:49Z","title":"Imputation Uncertainty in Interpretable Machine Learning Methods","summary":"In real data, missing values occur frequently, which affects the interpretation with interpretable machine learning (IML) methods. Recent work considers bias and shows that model explanations may differ between imputation methods, while ignoring additional imputation uncertainty and its influence on variance and confidence intervals. We therefore compare the effects of different imputation methods on the confidence interval coverage probabilities of the IML methods permutation feature importance, partial dependence plots and Shapley values. We show that single imputation leads to underestimation of variance and that, in most cases, only multiple imputation is close to nominal coverage.","authors":["Pegah Golchian","Marvin N. Wright"],"pdf_url":"","comment":"19 pages, 15 Figures, accepted at conference: IJCAI 2025 Workshop on Explainable Artificial Intelligence (Montreal, Canada)"},{"id":"http://arxiv.org/abs/2512.17688v1","updated":"2025-12-19T15:23:44Z","published":"2025-12-19T15:23:44Z","title":"Convergence Guarantees for Federated SARSA with Local Training and Heterogeneous Agents","summary":"We present a novel theoretical analysis of Federated SARSA (FedSARSA) with linear function approximation and local training. We establish convergence guarantees for FedSARSA in the presence of heterogeneity, both in local transitions and rewards, providing the first sample and communication complexity bounds in this setting. At the core of our analysis is a new, exact multi-step error expansion for single-agent SARSA, which is of independent interest. Our analysis precisely quantifies the impact of heterogeneity, demonstrating the convergence of FedSARSA with multiple local updates. Crucially, we show that FedSARSA achieves linear speed-up with respect to the number of agents, up to higher-order terms due to Markovian sampling. Numerical experiments support our theoretical findings.","authors":["Paul Mangold","Eloïse Berthier","Eric Moulines"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12817v2","updated":"2025-12-19T15:20:17Z","published":"2025-11-16T22:58:22Z","title":"Assessing Automated Fact-Checking for Medical LLM Responses with Knowledge Graphs","summary":"The recent proliferation of large language models (LLMs) holds the potential to revolutionize healthcare, with strong capabilities in diverse medical tasks. Yet, deploying LLMs in high-stakes healthcare settings requires rigorous verification and validation to understand any potential harm. This paper investigates the reliability and viability of using medical knowledge graphs (KGs) for the automated factuality evaluation of LLM-generated responses. To ground this investigation, we introduce FAITH, a framework designed to systematically probe the strengths and limitations of this KG-based approach. FAITH operates without reference answers by decomposing responses into atomic claims, linking them to a medical KG, and scoring them based on evidence paths. Experiments on diverse medical tasks with human subjective evaluations demonstrate that KG-grounded evaluation achieves considerably higher correlations with clinician judgments and can effectively distinguish LLMs with varying capabilities. It is also robust to textual variances. The inherent explainability of its scoring can further help users understand and mitigate the limitations of current LLMs. We conclude that while limitations exist, leveraging KGs is a prominent direction for automated factuality assessment in healthcare.","authors":["Shasha Zhou","Mingyu Huang","Jack Cole","Charles Britton","Ming Yin","Jan Wolber","Ke Li"],"pdf_url":"","comment":"Accepted as a conference paper at AAAI'26"},{"id":"http://arxiv.org/abs/2512.17678v1","updated":"2025-12-19T15:17:34Z","published":"2025-12-19T15:17:34Z","title":"You Only Train Once: Differentiable Subset Selection for Omics Data","summary":"Selecting compact and informative gene subsets from single-cell transcriptomic data is essential for biomarker discovery, improving interpretability, and cost-effective profiling. However, most existing feature selection approaches either operate as multi-stage pipelines or rely on post hoc feature attribution, making selection and prediction weakly coupled. In this work, we present YOTO (you only train once), an end-to-end framework that jointly identifies discrete gene subsets and performs prediction within a single differentiable architecture. In our model, the prediction task directly guides which genes are selected, while the learned subsets, in turn, shape the predictive representation. This closed feedback loop enables the model to iteratively refine both what it selects and how it predicts during training. Unlike existing approaches, YOTO enforces sparsity so that only the selected genes contribute to inference, eliminating the need to train additional downstream classifiers. Through a multi-task learning design, the model learns shared representations across related objectives, allowing partially labeled datasets to inform one another, and discovering gene subsets that generalize across tasks without additional training steps. We evaluate YOTO on two representative single-cell RNA-seq datasets, showing that it consistently outperforms state-of-the-art baselines. These results demonstrate that sparse, end-to-end, multi-task gene subset selection improves predictive performance and yields compact and meaningful gene subsets, advancing biomarker discovery and single-cell analysis.","authors":["Daphné Chopard","Jorge da Silva Gonçalves","Irene Cannistraci","Thomas M. Sutter","Julia E. Vogt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.17702v2","updated":"2025-12-19T15:15:01Z","published":"2025-08-25T06:21:11Z","title":"MolMark: Safeguarding Molecular Structures through Learnable Atom-Level Watermarking","summary":"AI-driven molecular generation is reshaping drug discovery and materials design, yet the lack of protection mechanisms leaves AI-generated molecules vulnerable to unauthorized reuse and provenance ambiguity. Such limitation undermines both scientific reproducibility and intellectual property security. To address this challenge, we propose the first deep learning based watermarking framework for molecules (MolMark), which is exquisitely designed to embed high-fidelity digital signatures into molecules without compromising molecular functionalities. MolMark learns to modulate the chemically meaningful atom-level representations and enforce geometric robustness through SE(3)-invariant features, maintaining robustness under rotation, translation, and reflection. Additionally, MolMark integrates seamlessly with AI-based molecular generative models, enabling watermarking to be treated as a learned transformation with minimal interference to molecular structures. Experiments on benchmark datasets (QM9, GEOM-DRUG) and state-of-the-art molecular generative models (GeoBFN, GeoLDM) demonstrate that MolMark can embed 16-bit watermarks while retaining more than 90% of essential molecular properties, preserving downstream performance, and enabling >95% extraction accuracy under SE(3) transformations. MolMark establishes a principled pathway for unifying molecular generation with verifiable authorship, supporting trustworthy and accountable AI-driven molecular discovery.","authors":["Runwen Hu","Peilin Chen","Keyan Ding","Shiqi Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.10784v5","updated":"2025-12-19T15:14:56Z","published":"2025-02-15T12:28:51Z","title":"Preconditioned Inexact Stochastic ADMM for Deep Model","summary":"The recent advancement of foundation models (FMs) has brought about a paradigm shift, revolutionizing various sectors worldwide. The popular optimizers used to train these models are stochastic gradient descent-based algorithms, which face inherent limitations, such as slow convergence and stringent assumptions for convergence. In particular, data heterogeneity arising from distributed settings poses significant challenges to their theoretical and numerical performance. This paper develops an algorithm, PISA (Preconditioned Inexact Stochastic Alternating Direction Method of Multipliers). Grounded in rigorous theoretical guarantees, the algorithm converges under the sole assumption of Lipschitz continuity of the gradient on a bounded region, thereby removing the need for other conditions commonly imposed by stochastic methods. This capability enables the proposed algorithm to tackle the challenge of data heterogeneity effectively. Moreover, the algorithmic architecture enables scalable parallel computing and supports various preconditions, such as second-order information, second moment, and orthogonalized momentum by Newton-Schulz iterations. Incorporating the latter two preconditions in PISA yields two computationally efficient variants: SISA and NSISA. Comprehensive experimental evaluations for training or fine-tuning diverse deep models, including vision models, large language models, reinforcement learning models, generative adversarial networks, and recurrent neural networks, demonstrate superior numerical performance of SISA and NSISA compared to various state-of-the-art optimizers.","authors":["Shenglong Zhou","Ouya Wang","Ziyan Luo","Yongxu Zhu","Geoffrey Ye Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17671v1","updated":"2025-12-19T15:14:14Z","published":"2025-12-19T15:14:14Z","title":"Polyharmonic Cascade","summary":"This paper presents a deep machine learning architecture, the \"polyharmonic cascade\" -- a sequence of packages of polyharmonic splines, where each layer is rigorously derived from the theory of random functions and the principles of indifference. This makes it possible to approximate nonlinear functions of arbitrary complexity while preserving global smoothness and a probabilistic interpretation. For the polyharmonic cascade, a training method alternative to gradient descent is proposed: instead of directly optimizing the coefficients, one solves a single global linear system on each batch with respect to the function values at fixed \"constellations\" of nodes. This yields synchronized updates of all layers, preserves the probabilistic interpretation of individual layers and theoretical consistency with the original model, and scales well: all computations reduce to 2D matrix operations efficiently executed on a GPU. Fast learning without overfitting on MNIST is demonstrated.","authors":["Yuriy N. Bakhvalov"],"pdf_url":"","comment":"Part 3 of 4 in the \"Polyharmonic Cascade\" cycle. Proposes a non-SGD training method based on global linear solvers. Previous papers: arXiv:2512.12731, arXiv.2512.16718. Source code is available at: https://github.com/xolod7/polyharmonic-cascade"},{"id":"http://arxiv.org/abs/2402.04114v3","updated":"2025-12-19T15:11:58Z","published":"2024-02-06T16:06:59Z","title":"SCAFFLSA: Taming Heterogeneity in Federated Linear Stochastic Approximation and TD Learning","summary":"In this paper, we analyze the sample and communication complexity of the federated linear stochastic approximation (FedLSA) algorithm. We explicitly quantify the effects of local training with agent heterogeneity. We show that the communication complexity of FedLSA scales polynomially with the inverse of the desired accuracy $ε$. To overcome this, we propose SCAFFLSA a new variant of FedLSA that uses control variates to correct for client drift, and establish its sample and communication complexities. We show that for statistically heterogeneous agents, its communication complexity scales logarithmically with the desired accuracy, similar to Scaffnew. An important finding is that, compared to the existing results for Scaffnew, the sample complexity scales with the inverse of the number of agents, a property referred to as linear speed-up. Achieving this linear speed-up requires completely new theoretical arguments. We apply the proposed method to federated temporal difference learning with linear function approximation and analyze the corresponding complexity improvements.","authors":["Paul Mangold","Sergey Samsonov","Safwan Labbi","Ilya Levin","Reda Alami","Alexey Naumov","Eric Moulines"],"pdf_url":"","comment":"now with linear speed-up!"},{"id":"http://arxiv.org/abs/2512.17661v1","updated":"2025-12-19T15:04:24Z","published":"2025-12-19T15:04:24Z","title":"Vidarc: Embodied Video Diffusion Model for Closed-loop Control","summary":"Robotic arm manipulation in data-scarce settings is a highly challenging task due to the complex embodiment dynamics and diverse contexts. Recent video-based approaches have shown great promise in capturing and transferring the temporal and physical interactions by pre-training on Internet-scale video data. However, such methods are often not optimized for the embodiment-specific closed-loop control, typically suffering from high latency and insufficient grounding. In this paper, we present Vidarc (Video Diffusion for Action Reasoning and Closed-loop Control), a novel autoregressive embodied video diffusion approach augmented by a masked inverse dynamics model. By grounding video predictions with action-relevant masks and incorporating real-time feedback through cached autoregressive generation, Vidarc achieves fast, accurate closed-loop control. Pre-trained on one million cross-embodiment episodes, Vidarc surpasses state-of-the-art baselines, achieving at least a 15% higher success rate in real-world deployment and a 91% reduction in latency. We also highlight its robust generalization and error correction capabilities across previously unseen robotic platforms.","authors":["Yao Feng","Chendong Xiang","Xinyi Mao","Hengkai Tan","Zuyue Zhang","Shuhe Huang","Kaiwen Zheng","Haitian Liu","Hang Su","Jun Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17660v1","updated":"2025-12-19T15:03:00Z","published":"2025-12-19T15:03:00Z","title":"Fraud detection in credit card transactions using Quantum-Assisted Restricted Boltzmann Machines","summary":"Use cases for emerging quantum computing platforms become economically relevant as the efficiency of processing and availability of quantum computers increase. We assess the performance of Restricted Boltzmann Machines (RBM) assisted by quantum computing, running on real quantum hardware and simulators, using a real dataset containing 145 million transactions provided by Stone, a leading Brazilian fintech, for credit card fraud detection. The results suggest that the quantum-assisted RBM method is able to achieve superior performance in most figures of merit in comparison to classical approaches, even using current noisy quantum annealers. Our study paves the way for implementing quantum-assisted RBMs for general fault detection in financial systems.","authors":["João Marcos Cavalcanti de Albuquerque Neto","Gustavo Castro do Amaral","Guilherme Penello Temporão"],"pdf_url":"","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2512.17659v1","updated":"2025-12-19T14:59:27Z","published":"2025-12-19T14:59:27Z","title":"Generative Multi-Objective Bayesian Optimization with Scalable Batch Evaluations for Sample-Efficient De Novo Molecular Design","summary":"Designing molecules that must satisfy multiple, often conflicting objectives is a central challenge in molecular discovery. The enormous size of chemical space and the cost of high-fidelity simulations have driven the development of machine learning-guided strategies for accelerating design with limited data. Among these, Bayesian optimization (BO) offers a principled framework for sample-efficient search, while generative models provide a mechanism to propose novel, diverse candidates beyond fixed libraries. However, existing methods that couple the two often rely on continuous latent spaces, which introduces both architectural entanglement and scalability challenges. This work introduces an alternative, modular \"generate-then-optimize\" framework for de novo multi-objective molecular design/discovery. At each iteration, a generative model is used to construct a large, diverse pool of candidate molecules, after which a novel acquisition function, qPMHI (multi-point Probability of Maximum Hypervolume Improvement), is used to optimally select a batch of candidates most likely to induce the largest Pareto front expansion. The key insight is that qPMHI decomposes additively, enabling exact, scalable batch selection via only simple ranking of probabilities that can be easily estimated with Monte Carlo sampling. We benchmark the framework against state-of-the-art latent-space and discrete molecular optimization methods, demonstrating significant improvements across synthetic benchmarks and application-driven tasks. Specifically, in a case study related to sustainable energy storage, we show that our approach quickly uncovers novel, diverse, and high-performing organic (quinone-based) cathode materials for aqueous redox flow battery applications.","authors":["Madhav R. Muthyala","Farshud Sorourifar","Tianhong Tan","You Peng","Joel A. Paulson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17654v1","updated":"2025-12-19T14:52:04Z","published":"2025-12-19T14:52:04Z","title":"Estimating Spatially Resolved Radiation Fields Using Neural Networks","summary":"We present an in-depth analysis on how to build and train neural networks to estimate the spatial distribution of scattered radiation fields for radiation protection dosimetry in medical radiation fields, such as those found in Interventional Radiology and Cardiology. Therefore, we present three different synthetically generated datasets with increasing complexity for training, using a Monte-Carlo Simulation application based on Geant4. On those datasets, we evaluate convolutional and fully connected architectures of neural networks to demonstrate which design decisions work well for reconstructing the fluence and spectra distributions over the spatial domain of such radiation fields. All used datasets as well as our training pipeline are published as open source in separate repositories.","authors":["Felix Lehner","Pasquale Lombardo","Susana Castillo","Oliver Hupe","Marcus Magnor"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.01389v2","updated":"2025-12-19T14:49:41Z","published":"2024-12-02T11:22:19Z","title":"Refined Analysis of Federated Averaging and Federated Richardson-Romberg","summary":"In this paper, we present a novel analysis of \\FedAvg with constant step size, relying on the Markov property of the underlying process. We demonstrate that the global iterates of the algorithm converge to a stationary distribution and analyze its resulting bias and variance relative to the problem's solution. We provide a first-order bias expansion in both homogeneous and heterogeneous settings. Interestingly, this bias decomposes into two distinct components: one that depends solely on stochastic gradient noise and another on client heterogeneity. Finally, we introduce a new algorithm based on the Richardson-Romberg extrapolation technique to mitigate this bias.","authors":["Paul Mangold","Alain Durmus","Aymeric Dieuleveut","Sergey Samsonov","Eric Moulines"],"pdf_url":"","comment":"37 pages"},{"id":"http://arxiv.org/abs/2509.21647v2","updated":"2025-12-19T14:43:46Z","published":"2025-09-25T22:05:20Z","title":"Automated Machine Learning Pipeline: Large Language Models-Assisted Automated Dataset Generation for Training Machine-Learned Interatomic Potentials","summary":"Machine learning interatomic potentials (MLIPs) have become powerful tools to extend molecular simulations beyond the limits of quantum methods, offering near-quantum accuracy at much lower computational cost. Yet, developing reliable MLIPs remains difficult because it requires generating high-quality datasets, preprocessing atomic structures, and carefully training and validating models. In this work, we introduce an Automated Machine Learning Pipeline (AMLP) that unifies the entire workflow from dataset creation to model validation. AMLP employs large-language-model agents to assist with electronic-structure code selection, input preparation, and output conversion, while its analysis suite (AMLP-Analysis), based on ASE supports a range of molecular simulations. The pipeline is built on the MACE architecture and validated on acridine polymorphs, where, with a straightforward fine-tuning of a foundation model, mean absolute errors of ~1.7 meV/atom in energies and ~7.0 meV/Å in forces are achieved. The fitted MLIP reproduces DFT geometries with sub-Å accuracy and demonstrates stability during molecular dynamics simulations in the microcanonical and canonical ensembles.","authors":["Adam Lahouari","Jutta Rogal","Mark E. Tuckerman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17636v1","updated":"2025-12-19T14:37:07Z","published":"2025-12-19T14:37:07Z","title":"Trust-Region Adaptive Policy Optimization","summary":"Post-training methods, especially Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), play an important role in improving large language models' (LLMs) complex reasoning abilities. However, the dominant two-stage pipeline (SFT then RL) suffers from a key inconsistency: SFT enforces rigid imitation that suppresses exploration and induces forgetting, limiting RL's potential for improvements. We address this inefficiency with TRAPO (\\textbf{T}rust-\\textbf{R}egion \\textbf{A}daptive \\textbf{P}olicy \\textbf{O}ptimization), a hybrid framework that interleaves SFT and RL within each training instance by optimizing SFT loss on expert prefixes and RL loss on the model's own completions, unifying external supervision and self-exploration. To stabilize training, we introduce Trust-Region SFT (TrSFT), which minimizes forward KL divergence inside a trust region but attenuates optimization outside, effectively shifting toward reverse KL and yielding stable, mode-seeking updates favorable for RL. An adaptive prefix-selection mechanism further allocates expert guidance based on measured utility. Experiments on five mathematical reasoning benchmarks show that TRAPO consistently surpasses standard SFT, RL, and SFT-then-RL pipelines, as well as recent state-of-the-art approaches, establishing a strong new paradigm for reasoning-enhanced LLMs.","authors":["Mingyu Su","Jian Guan","Yuxian Gu","Minlie Huang","Hongning Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17630v1","updated":"2025-12-19T14:33:14Z","published":"2025-12-19T14:33:14Z","title":"Confidence-Credibility Aware Weighted Ensembles of Small LLMs Outperform Large LLMs in Emotion Detection","summary":"This paper introduces a confidence-weighted, credibility-aware ensemble framework for text-based emotion detection, inspired by Condorcet's Jury Theorem (CJT). Unlike conventional ensembles that often rely on homogeneous architectures, our approach combines architecturally diverse small transformer-based large language models (sLLMs) - BERT, RoBERTa, DistilBERT, DeBERTa, and ELECTRA, each fully fine-tuned for emotion classification. To preserve error diversity, we minimize parameter convergence while taking advantage of the unique biases of each model. A dual-weighted voting mechanism integrates both global credibility (validation F1 score) and local confidence (instance-level probability) to dynamically weight model contributions. Experiments on the DAIR-AI dataset demonstrate that our credibility-confidence ensemble achieves a macro F1 score of 93.5 percent, surpassing state-of-the-art benchmarks and significantly outperforming large-scale LLMs, including Falcon, Mistral, Qwen, and Phi, even after task-specific Low-Rank Adaptation (LoRA). With only 595M parameters in total, our small LLMs ensemble proves more parameter-efficient and robust than models up to 7B parameters, establishing that carefully designed ensembles of small, fine-tuned models can outperform much larger LLMs in specialized natural language processing (NLP) tasks such as emotion detection.","authors":["Menna Elgabry","Ali Hamdi"],"pdf_url":"","comment":"Accepted at IRICT 2025"},{"id":"http://arxiv.org/abs/2512.17629v1","updated":"2025-12-19T14:33:02Z","published":"2025-12-19T14:33:02Z","title":"SCOPE: Sequential Causal Optimization of Process Interventions","summary":"Prescriptive Process Monitoring (PresPM) recommends interventions during business processes to optimize key performance indicators (KPIs). In realistic settings, interventions are rarely isolated: organizations need to align sequences of interventions to jointly steer the outcome of a case. Existing PresPM approaches fall short in this respect. Many focus on a single intervention decision, while others treat multiple interventions independently, ignoring how they interact over time. Methods that do address these dependencies depend either on simulation or data augmentation to approximate the process to train a Reinforcement Learning (RL) agent, which can create a reality gap and introduce bias. We introduce SCOPE, a PresPM approach that learns aligned sequential intervention recommendations. SCOPE employs backward induction to estimate the effect of each candidate intervention action, propagating its impact from the final decision point back to the first. By leveraging causal learners, our method can utilize observational data directly, unlike methods that require constructing process approximations for reinforcement learning. Experiments on both an existing synthetic dataset and a new semi-synthetic dataset show that SCOPE consistently outperforms state-of-the-art PresPM techniques in optimizing the KPI. The novel semi-synthetic setup, based on a real-life event log, is provided as a reusable benchmark for future work on sequential PresPM.","authors":["Jakob De Moor","Hans Weytjens","Johannes De Smedt","Jochen De Weerdt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.06658v3","updated":"2025-12-19T14:26:04Z","published":"2025-02-10T16:48:48Z","title":"Generating Samples to Probe Trained Models","summary":"There is a growing need for investigating how machine learning models operate. With this work, we aim to understand trained machine learning models by questioning their data preferences. We propose a mathematical framework that allows us to probe trained models and identify their preferred samples in various scenarios including prediction-risky, parameter-sensitive, or model-contrastive samples. To showcase our framework, we pose these queries to a range of models trained on a range of classification and regression tasks, and receive answers in the form of generated data.","authors":["Eren Mehmet Kıral","Nurşen Aydın","Ş. İlker Birbil"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17607v1","updated":"2025-12-19T14:12:17Z","published":"2025-12-19T14:12:17Z","title":"More Consistent Accuracy PINN via Alternating Easy-Hard Training","summary":"Physics-informed neural networks (PINNs) have recently emerged as a prominent paradigm for solving partial differential equations (PDEs), yet their training strategies remain underexplored. While hard prioritization methods inspired by finite element methods are widely adopted, recent research suggests that easy prioritization can also be effective. Nevertheless, we find that both approaches exhibit notable trade-offs and inconsistent performance across PDE types. To address this issue, we develop a hybrid strategy that combines the strengths of hard and easy prioritization through an alternating training algorithm. On PDEs with steep gradients, nonlinearity, and high dimensionality, the proposed method achieves consistently high accuracy, with relative L2 errors mostly in the range of O(10^-5) to O(10^-6), significantly surpassing baseline methods. Moreover, it offers greater reliability across diverse problems, whereas compared approaches often suffer from variable accuracy depending on the PDE. This work provides new insights into designing hybrid training strategies to enhance the performance and robustness of PINNs.","authors":["Zhaoqian Gao","Min Yanga"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17598v1","updated":"2025-12-19T14:05:20Z","published":"2025-12-19T14:05:20Z","title":"A Systems-Theoretic View on the Convergence of Algorithms under Disturbances","summary":"Algorithms increasingly operate within complex physical, social, and engineering systems where they are exposed to disturbances, noise, and interconnections with other dynamical systems. This article extends known convergence guarantees of an algorithm operating in isolation (i.e., without disturbances) and systematically derives stability bounds and convergence rates in the presence of such disturbances. By leveraging converse Lyapunov theorems, we derive key inequalities that quantify the impact of disturbances. We further demonstrate how our result can be utilized to assess the effects of disturbances on algorithmic performance in a wide variety of applications, including communication constraints in distributed learning, sensitivity in machine learning generalization, and intentional noise injection for privacy. This underpins the role of our result as a unifying tool for algorithm analysis in the presence of noise, disturbances, and interconnections with other dynamical systems.","authors":["Guner Dilsad Er","Sebastian Trimpe","Michael Muehlebach"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17594v1","updated":"2025-12-19T14:02:37Z","published":"2025-12-19T14:02:37Z","title":"MAD-OOD: A Deep Learning Cluster-Driven Framework for an Out-of-Distribution Malware Detection and Classification","summary":"Out of distribution (OOD) detection remains a critical challenge in malware classification due to the substantial intra family variability introduced by polymorphic and metamorphic malware variants. Most existing deep learning based malware detectors rely on closed world assumptions and fail to adequately model this intra class variation, resulting in degraded performance when confronted with previously unseen malware families. This paper presents MADOOD, a novel two stage, cluster driven deep learning framework for robust OOD malware detection and classification. In the first stage, malware family embeddings are modeled using class conditional spherical decision boundaries derived from Gaussian Discriminant Analysis (GDA), enabling statistically grounded separation of indistribution and OOD samples without requiring OOD data during training. Z score based distance analysis across multiple class centroids is employed to reliably identify anomalous samples in the latent space. In the second stage, a deep neural network integrates cluster based predictions, refined embeddings, and supervised classifier outputs to enhance final classification accuracy. Extensive evaluations on benchmark malware datasets comprising 25 known families and multiple novel OOD variants demonstrate that MADOOD significantly outperforms state of the art OOD detection methods, achieving an AUC of up to 0.911 on unseen malware families. The proposed framework provides a scalable, interpretable, and statistically principled solution for real world malware detection and anomaly identification in evolving cybersecurity environments.","authors":["Tosin Ige","Christopher Kiekintveld","Aritran Piplai","Asif Rahman","Olukunle Kolade","Sasidhar Kunapuli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17593v1","updated":"2025-12-19T14:01:50Z","published":"2025-12-19T14:01:50Z","title":"A Unified Representation of Neural Networks Architectures","summary":"In this paper we consider the limiting case of neural networks (NNs) architectures when the number of neurons in each hidden layer and the number of hidden layers tend to infinity thus forming a continuum, and we derive approximation errors as a function of the number of neurons and/or hidden layers. Firstly, we consider the case of neural networks with a single hidden layer and we derive an integral infinite width neural representation that generalizes existing continuous neural networks (CNNs) representations. Then we extend this to deep residual CNNs that have a finite number of integral hidden layers and residual connections. Secondly, we revisit the relation between neural ODEs and deep residual NNs and we formalize approximation errors via discretization techniques. Then, we merge these two approaches into a unified homogeneous representation of NNs as a Distributed Parameter neural Network (DiPaNet) and we show that most of the existing finite and infinite-dimensional NNs architectures are related via homogeneization/discretization with the DiPaNet representation. Our approach is purely deterministic and applies to general, uniformly continuous matrix weight functions. Differences and similarities with neural fields are discussed along with further possible generalizations and applications of the DiPaNet framework.","authors":["Christophe Prieur","Mircea Lazar","Bogdan Robu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17592v1","updated":"2025-12-19T13:59:46Z","published":"2025-12-19T13:59:46Z","title":"Sharing Knowledge without Sharing Data: Stitches can improve ensembles of disjointly trained models","summary":"Deep learning has been shown to be very capable at performing many real-world tasks. However, this performance is often dependent on the presence of large and varied datasets. In some settings, like in the medical domain, data is often fragmented across parties, and cannot be readily shared. While federated learning addresses this situation, it is a solution that requires synchronicity of parties training a single model together, exchanging information about model weights. We investigate how asynchronous collaboration, where only already trained models are shared (e.g. as part of a publication), affects performance, and propose to use stitching as a method for combining models.\n  Through taking a multi-objective perspective, where performance on each parties' data is viewed independently, we find that training solely on a single parties' data results in similar performance when merging with another parties' data, when considering performance on that single parties' data, while performance on other parties' data is notably worse. Moreover, while an ensemble of such individually trained networks generalizes better, performance on each parties' own dataset suffers. We find that combining intermediate representations in individually trained models with a well placed pair of stitching layers allows this performance to recover to a competitive degree while maintaining improved generalization, showing that asynchronous collaboration can yield competitive results.","authors":["Arthur Guijt","Dirk Thierens","Ellen Kerkhof","Jan Wiersma","Tanja Alderliesten","Peter A. N. Bosman"],"pdf_url":"","comment":"35 pages, 11 figures"},{"id":"http://arxiv.org/abs/2412.12667v2","updated":"2025-12-19T13:54:51Z","published":"2024-12-17T08:36:47Z","title":"Embedding-Driven Data Distillation for 360-Degree IQA With Residual-Aware Refinement","summary":"This article identifies and addresses a fundamental bottleneck in data-driven 360-degree image quality assessment (IQA): the lack of intelligent, sample-level data selection. Hence, we propose a novel framework that introduces a critical refinement step between patches sampling and model training. The core of our contribution is an embedding similarity-based selection algorithm that distills an initial, potentially redundant set of patches into a compact, maximally informative subset. This is formulated as a regularized optimization problem that preserves intrinsic perceptual relationships in a low-dimensional space, using residual analysis to explicitly filter out irrelevant or redundant samples. Extensive experiments on three benchmark datasets (CVIQ, OIQA, MVAQD) demonstrate that our selection enables a baseline model to match or exceed the performance of using all sampled data while keeping only 40-50% of patches. Particularly, we demonstrate the universal applicability of our approach by integrating it with several state-of-the-art IQA models, incleasy to deploy. Most significantly, its value as a generic,uding CNN- and transformer-based architectures, consistently enabling them to maintain or improve performance with 20-40\\% reduced computational load. This work establishes that adaptive, post-sampling data refinement is a powerful and widely applicable strategy for achieving efficient and robust 360-degree IQA.","authors":["Abderrezzaq Sendjasni","Seif-Eddine Benkabou","Mohamed-Chaker Larabi"],"pdf_url":"","comment":"Submitted to IEEE Transactions on Image Processing"},{"id":"http://arxiv.org/abs/2512.17586v1","updated":"2025-12-19T13:52:19Z","published":"2025-12-19T13:52:19Z","title":"Learning Safe Autonomous Driving Policies Using Predictive Safety Representations","summary":"Safe reinforcement learning (SafeRL) is a prominent paradigm for autonomous driving, where agents are required to optimize performance under strict safety requirements. This dual objective creates a fundamental tension, as overly conservative policies limit driving efficiency while aggressive exploration risks safety violations. The Safety Representations for Safer Policy Learning (SRPL) framework addresses this challenge by equipping agents with a predictive model of future constraint violations and has shown promise in controlled environments. This paper investigates whether SRPL extends to real-world autonomous driving scenarios. Systematic experiments on the Waymo Open Motion Dataset (WOMD) and NuPlan demonstrate that SRPL can improve the reward-safety tradeoff, achieving statistically significant improvements in success rate (effect sizes r = 0.65-0.86) and cost reduction (effect sizes r = 0.70-0.83), with p < 0.05 for observed improvements. However, its effectiveness depends on the underlying policy optimizer and the dataset distribution. The results further show that predictive safety representations play a critical role in improving robustness to observation noise. Additionally, in zero-shot cross-dataset evaluation, SRPL-augmented agents demonstrate improved generalization compared to non-SRPL methods. These findings collectively demonstrate the potential of predictive safety representations to strengthen SafeRL for autonomous driving.","authors":["Mahesh Keswani","Raunak Bhattacharyya"],"pdf_url":"","comment":"8 pages, 4 figures. Submitted to ICRA 2026"},{"id":"http://arxiv.org/abs/2512.17585v1","updated":"2025-12-19T13:52:11Z","published":"2025-12-19T13:52:11Z","title":"SkinGenBench: Generative Model and Preprocessing Effects for Synthetic Dermoscopic Augmentation in Melanoma Diagnosis","summary":"This work introduces SkinGenBench, a systematic biomedical imaging benchmark that investigates how preprocessing complexity interacts with generative model choice for synthetic dermoscopic image augmentation and downstream melanoma diagnosis. Using a curated dataset of 14,116 dermoscopic images from HAM10000 and MILK10K across five lesion classes, we evaluate the two representative generative paradigms: StyleGAN2-ADA and Denoising Diffusion Probabilistic Models (DDPMs) under basic geometric augmentation and advanced artifact removal pipelines. Synthetic melanoma images are assessed using established perceptual and distributional metrics (FID, KID, IS), feature space analysis, and their impact on diagnostic performance across five downstream classifiers. Experimental results demonstrate that generative architecture choice has a stronger influence on both image fidelity and diagnostic utility than preprocessing complexity. StyleGAN2-ADA consistently produced synthetic images more closely aligned with real data distributions, achieving the lowest FID (~65.5) and KID (~0.05), while diffusion models generated higher variance samples at the cost of reduces perceptual fidelity and class anchoring. Advanced artifact removal yielded only marginal improvements in generative metrics and provided limited downstream diagnostic gains, suggesting possible suppression of clinically relevant texture cues. In contrast, synthetic data augmentation substantially improved melanoma detection with 8-15% absolute gains in melanoma F1-score, and ViT-B/16 achieving F1~0.88 and ROC-AUC~0.98, representing an improvement of approximately 14% over non-augmented baselines. Our code can be found at https://github.com/adarsh-crafts/SkinGenBench","authors":["N. A. Adarsh Pritam","Jeba Shiney O","Sanyam Jain"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.15215v2","updated":"2025-12-19T13:45:03Z","published":"2025-05-21T07:44:39Z","title":"Clustering and Pruning in Causal Data Fusion","summary":"Data fusion, the process of combining observational and experimental data, can enable the identification of causal effects that would otherwise remain non-identifiable. Although identification algorithms have been developed for specific scenarios, do-calculus remains the only general-purpose tool for causal data fusion, particularly when variables are present in some data sources but not others. However, approaches based on do-calculus may encounter computational challenges as the number of variables increases and the causal graph grows in complexity. Consequently, there exists a need to reduce the size of such models while preserving the essential features. For this purpose, we propose pruning (removing unnecessary variables) and clustering (combining variables) as preprocessing operations for causal data fusion. We generalize earlier results on a single data source and derive conditions for applying pruning and clustering in the case of multiple data sources. We give sufficient conditions for inferring the identifiability or non-identifiability of a causal effect in a larger graph based on a smaller graph and show how to obtain the corresponding identifying functional for identifiable causal effects. Examples from epidemiology and social science demonstrate the use of the results.","authors":["Otto Tabell","Santtu Tikka","Juha Karvanen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17577v1","updated":"2025-12-19T13:44:23Z","published":"2025-12-19T13:44:23Z","title":"Machine Learning for Static and Single-Event Dynamic Complex Network Analysis","summary":"The primary objective of this thesis is to develop novel algorithmic approaches for Graph Representation Learning of static and single-event dynamic networks. In such a direction, we focus on the family of Latent Space Models, and more specifically on the Latent Distance Model which naturally conveys important network characteristics such as homophily, transitivity, and the balance theory. Furthermore, this thesis aims to create structural-aware network representations, which lead to hierarchical expressions of network structure, community characterization, the identification of extreme profiles in networks, and impact dynamics quantification in temporal networks. Crucially, the methods presented are designed to define unified learning processes, eliminating the need for heuristics and multi-stage processes like post-processing steps. Our aim is to delve into a journey towards unified network embeddings that are both comprehensive and powerful, capable of characterizing network structures and adeptly handling the diverse tasks that graph analysis offers.","authors":["Nikolaos Nakis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17574v1","updated":"2025-12-19T13:40:13Z","published":"2025-12-19T13:40:13Z","title":"Enabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing","summary":"Multimodal large language models (MLLMs) extend LLMs with visual understanding through a three-stage pipeline: multimodal preprocessing, vision encoding, and LLM inference. While these stages enhance capability, they introduce significant system bottlenecks. First, multimodal preprocessing-especially video decoding-often dominates Time-to-First-Token (TTFT). Most systems rely on CPU-based decoding, which severely limits throughput, while existing GPU-based approaches prioritize throughput-oriented parallelism and fail to meet the latency-sensitive requirements of MLLM inference. Second, the vision encoder is a standalone, compute-intensive stage that produces visual embeddings and cannot be co-batched with LLM prefill or decoding. This heterogeneity forces inter-stage blocking and increases token-generation latency. Even when deployed on separate GPUs, these stages underutilize available compute and memory resources, reducing overall utilization and constraining system throughput.\n  To address these challenges, we present FlashCodec and UnifiedServe, two complementary designs that jointly optimize the end-to-end MLLM pipeline. FlashCodec accelerates the multimodal preprocessing stage through collaborative multi-GPU video decoding, reducing decoding latency while preserving high throughput. UnifiedServe optimizes the vision-to-text and inference stages using a logically decoupled their execution to eliminate inter-stage blocking, yet physically sharing GPU resources to maximize GPU system utilization. By carefully orchestrating execution across stages and minimizing interference, UnifiedServe Together, our proposed framework forms an end-to-end optimized stack that can serve up to 3.0$\\times$ more requests or enforce 1.5$\\times$ tighter SLOs, while achieving up to 4.4$\\times$ higher throughput compared to state-of-the-art systems.","authors":["Lingxiao Zhao","Haoran Zhou","Yuezhi Che","Dazhao Cheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17570v1","updated":"2025-12-19T13:36:31Z","published":"2025-12-19T13:36:31Z","title":"GreedySnake: Accelerating SSD-Offloaded LLM Training with Efficient Scheduling and Optimizer Step Overlapping","summary":"SSD-offloaded training offers a practical and promising approach to making LLM training cost-effective. Building on gradient accumulation with micro-batches, this paper introduces GreedySnake, a new SSD-offloaded training system that employs vertical scheduling, which executes all microbatches of a layer before proceeding to the next. Compared to existing systems that use horizontal scheduling (i.e., executing micro-batches sequentially), GreedySnake achieves higher training throughput with smaller batch sizes, bringing the system much closer to the ideal scenario predicted by the roofline model. To further mitigate the I/O bottleneck, GreedySnake overlaps part of the optimization step with the forward pass of the next iteration. Experimental results on A100 GPUs show that GreedySnake achieves saturated training throughput improvements over ZeRO-Infinity: 1.96x on 1 GPU and 1.93x on 4 GPUs for GPT-65B, and 2.53x on 1 GPU for GPT-175B. The code is open-sourced at https://github.com/npz7yyk/GreedySnake","authors":["Yikang Yue","Yishu Yin","Xuehai Qian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17569v1","updated":"2025-12-19T13:35:32Z","published":"2025-12-19T13:35:32Z","title":"Bayesian Optimisation: Which Constraints Matter?","summary":"Bayesian optimisation has proven to be a powerful tool for expensive global black-box optimisation problems. In this paper, we propose new Bayesian optimisation variants of the popular Knowledge Gradient acquisition functions for problems with \\emph{decoupled} black-box constraints, in which subsets of the objective and constraint functions may be evaluated independently. In particular, our methods aim to take into account that often only a handful of the constraints may be binding at the optimum, and hence we should evaluate only relevant constraints when trying to optimise a function. We empirically benchmark these methods against existing methods and demonstrate their superiority over the state-of-the-art.","authors":["Xietao Wang Lin","Juan Ungredda","Max Butler","James Town","Alma Rahat","Hemant Singh","Juergen Branke"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17562v1","updated":"2025-12-19T13:32:19Z","published":"2025-12-19T13:32:19Z","title":"When De-noising Hurts: A Systematic Study of Speech Enhancement Effects on Modern Medical ASR Systems","summary":"Speech enhancement methods are commonly believed to improve the performance of automatic speech recognition (ASR) in noisy environments. However, the effectiveness of these techniques cannot be taken for granted in the case of modern large-scale ASR models trained on diverse, noisy data. We present a systematic evaluation of MetricGAN-plus-voicebank denoising on four state-of-the-art ASR systems: OpenAI Whisper, NVIDIA Parakeet, Google Gemini Flash 2.0, Parrotlet-a using 500 medical speech recordings under nine noise conditions. ASR performance is measured using semantic WER (semWER), a normalized word error rate (WER) metric accounting for domain-specific normalizations. Our results reveal a counterintuitive finding: speech enhancement preprocessing degrades ASR performance across all noise conditions and models. Original noisy audio achieves lower semWER than enhanced audio in all 40 tested configurations (4 models x 10 conditions), with degradations ranging from 1.1% to 46.6% absolute semWER increase. These findings suggest that modern ASR models possess sufficient internal noise robustness and that traditional speech enhancement may remove acoustic features critical for ASR. For practitioners deploying medical scribe systems in noisy clinical environments, our results indicate that preprocessing audio with noise reduction techniques might not just be computationally wasteful but also be potentially harmful to the transcription accuracy.","authors":["Sujal Chondhekar","Vasanth Murukuri","Rushabh Vasani","Sanika Goyal","Rajshree Badami","Anushree Rana","Sanjana SN","Karthik Pandia","Sulabh Katiyar","Neha Jagadeesh","Sankalp Gulati"],"pdf_url":"","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2512.16715v2","updated":"2025-12-19T13:06:55Z","published":"2025-12-18T16:18:06Z","title":"Towards Reproducibility in Predictive Process Mining: SPICE -- A Deep Learning Library","summary":"In recent years, Predictive Process Mining (PPM) techniques based on artificial neural networks have evolved as a method for monitoring the future behavior of unfolding business processes and predicting Key Performance Indicators (KPIs). However, many PPM approaches often lack reproducibility, transparency in decision making, usability for incorporating novel datasets and benchmarking, making comparisons among different implementations very difficult. In this paper, we propose SPICE, a Python framework that reimplements three popular, existing baseline deep-learning-based methods for PPM in PyTorch, while designing a common base framework with rigorous configurability to enable reproducible and robust comparison of past and future modelling approaches. We compare SPICE to original reported metrics and with fair metrics on 11 datasets.","authors":["Oliver Stritzel","Nick Hühnerbein","Simon Rauch","Itzel Zarate","Lukas Fleischmann","Moike Buck","Attila Lischka","Christian Frey"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17534v1","updated":"2025-12-19T12:58:06Z","published":"2025-12-19T12:58:06Z","title":"HydroGym: A Reinforcement Learning Platform for Fluid Dynamics","summary":"Modeling and controlling fluid flows is critical for several fields of science and engineering, including transportation, energy, and medicine. Effective flow control can lead to, e.g., lift increase, drag reduction, mixing enhancement, and noise reduction. However, controlling a fluid faces several significant challenges, including high-dimensional, nonlinear, and multiscale interactions in space and time. Reinforcement learning (RL) has recently shown great success in complex domains, such as robotics and protein folding, but its application to flow control is hindered by a lack of standardized benchmark platforms and the computational demands of fluid simulations. To address these challenges, we introduce HydroGym, a solver-independent RL platform for flow control research. HydroGym integrates sophisticated flow control benchmarks, scalable runtime infrastructure, and state-of-the-art RL algorithms. Our platform includes 42 validated environments spanning from canonical laminar flows to complex three-dimensional turbulent scenarios, validated over a wide range of Reynolds numbers. We provide non-differentiable solvers for traditional RL and differentiable solvers that dramatically improve sample efficiency through gradient-enhanced optimization. Comprehensive evaluation reveals that RL agents consistently discover robust control principles across configurations, such as boundary layer manipulation, acoustic feedback disruption, and wake reorganization. Transfer learning studies demonstrate that controllers learned at one Reynolds number or geometry adapt efficiently to new conditions, requiring approximately 50% fewer training episodes. The HydroGym platform is highly extensible and scalable, providing a framework for researchers in fluid dynamics, machine learning, and control to add environments, surrogate models, and control algorithms to advance science and technology.","authors":["Christian Lagemann","Sajeda Mokbel","Miro Gondrum","Mario Rüttgers","Jared Callaham","Ludger Paehler","Samuel Ahnert","Nicholas Zolman","Kai Lagemann","Nikolaus Adams","Matthias Meinke","Wolfgang Schröder","Jean-Christophe Loiseau","Esther Lagemann","Steven L. Brunton"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12346v2","updated":"2025-12-19T12:55:37Z","published":"2025-11-15T20:25:59Z","title":"CLAReSNet: When Convolution Meets Latent Attention for Hyperspectral Image Classification","summary":"Hyperspectral image (HSI) classification faces critical challenges, including high spectral dimensionality, complex spectral-spatial correlations, and limited training samples with severe class imbalance. While CNNs excel at local feature extraction and transformers capture long-range dependencies, their isolated application yields suboptimal results due to quadratic complexity and insufficient inductive biases. We propose CLAReSNet (Convolutional Latent Attention Residual Spectral Network), a hybrid architecture that integrates multi-scale convolutional extraction with transformer-style attention via an adaptive latent bottleneck. The model employs a multi-scale convolutional stem with deep residual blocks and an enhanced Convolutional Block Attention Module for hierarchical spatial features, followed by spectral encoder layers combining bidirectional RNNs (LSTM/GRU) with Multi-Scale Spectral Latent Attention (MSLA). MSLA reduces complexity from $\\mathcal{O}(T^2D)$ to $\\mathcal{O}(T\\log(T)D)$ by adaptive latent token allocation (8-64 tokens) that scales logarithmically with the sequence length. Hierarchical cross-attention fusion dynamically aggregates multi-level representations for robust classification. Experiments conducted on the Indian Pines and Salinas datasets show state-of-the-art performance, achieving overall accuracies of 99.71% and 99.96%, significantly surpassing HybridSN, SSRN, and SpectralFormer. The learned embeddings exhibit superior inter-class separability and compact intra-class clustering, validating CLAReSNet's effectiveness under severe class imbalance.","authors":["Asmit Bandyopadhyay","Anindita Das Bhattacharjee","Rakesh Das"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17531v1","updated":"2025-12-19T12:54:03Z","published":"2025-12-19T12:54:03Z","title":"NetworkFF: Unified Layer Optimization in Forward-Only Neural Networks","summary":"The Forward-Forward algorithm eliminates backpropagation's memory constraints and biological implausibility through dual forward passes with positive and negative data. However, conventional implementations suffer from critical inter-layer isolation, where layers optimize goodness functions independently without leveraging collective learning dynamics. This isolation constrains representational coordination and limits convergence efficiency in deeper architectures. This paper introduces Collaborative Forward-Forward (CFF) learning, extending the original algorithm through inter-layer cooperation mechanisms that preserve forward-only computation while enabling global context integration. Our framework implements two collaborative paradigms: Fixed CFF (F-CFF) with constant inter-layer coupling and Adaptive CFF (A-CFF) with learnable collaboration parameters that evolve during training. The collaborative goodness function incorporates weighted contributions from all layers, enabling coordinated feature learning while maintaining memory efficiency and biological plausibility. Comprehensive evaluation on MNIST and Fashion-MNIST demonstrates significant performance improvements over baseline Forward-Forward implementations. These findings establish inter-layer collaboration as a fundamental enhancement to Forward-Forward learning, with immediate applicability to neuromorphic computing architectures and energy-constrained AI systems.","authors":["Salar Beigzad"],"pdf_url":"","comment":"Conference paper, IEEE, 2025"},{"id":"http://arxiv.org/abs/2512.17527v1","updated":"2025-12-19T12:51:31Z","published":"2025-12-19T12:51:31Z","title":"SafeBench-Seq: A Homology-Clustered, CPU-Only Baseline for Protein Hazard Screening with Physicochemical/Composition Features and Cluster-Aware Confidence Intervals","summary":"Foundation models for protein design raise concrete biosecurity risks, yet the community lacks a simple, reproducible baseline for sequence-level hazard screening that is explicitly evaluated under homology control and runs on commodity CPUs. We introduce SafeBench-Seq, a metadata-only, reproducible benchmark and baseline classifier built entirely from public data (SafeProtein hazards and UniProt benigns) and interpretable features (global physicochemical descriptors and amino-acid composition). To approximate \"never-before-seen\" threats, we homology-cluster the combined dataset at <=40% identity and perform cluster-level holdouts (no cluster overlap between train/test). We report discrimination (AUROC/AUPRC) and screening-operating points (TPR@1% FPR; FPR@95% TPR) with 95% bootstrap confidence intervals (n=200), and we provide calibrated probabilities via CalibratedClassifierCV (isotonic for Logistic Regression / Random Forest; Platt sigmoid for Linear SVM). We quantify probability quality using Brier score, Expected Calibration Error (ECE; 15 bins), and reliability diagrams. Shortcut susceptibility is probed via composition-preserving residue shuffles and length-/composition-only ablations. Empirically, random splits substantially overestimate robustness relative to homology-clustered evaluation; calibrated linear models exhibit comparatively good calibration, while tree ensembles retain slightly higher Brier/ECE. SafeBench-Seq is CPU-only, reproducible, and releases metadata only (accessions, cluster IDs, split labels), enabling rigorous evaluation without distributing hazardous sequences.","authors":["Muhammad Haris Khan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.13161v2","updated":"2025-12-19T12:40:33Z","published":"2024-10-17T02:30:44Z","title":"Non-Perturbative Trivializing Flows for Lattice Gauge Theories","summary":"Continuous normalizing flows are known to be highly expressive and flexible, which allows for easier incorporation of large symmetries and makes them a powerful computational tool for lattice field theories. Building on previous work, we present a general continuous normalizing flow architecture for matrix Lie groups that is equivariant under group transformations. We apply this to lattice gauge theories in two dimensions as a proof of principle and demonstrate competitive performance, showing its potential as a tool for future lattice computations.","authors":["Mathis Gerdes","Pim de Haan","Roberto Bondesan","Miranda C. N. Cheng"],"pdf_url":"","comment":"7+7 pages, 5 figures, 4 tables; expanded published version, added 2 appendices with computational cost analysis and numerical evaluations (added 1 table and 2 figures)"},{"id":"http://arxiv.org/abs/2512.17517v1","updated":"2025-12-19T12:35:57Z","published":"2025-12-19T12:35:57Z","title":"PathBench-MIL: A Comprehensive AutoML and Benchmarking Framework for Multiple Instance Learning in Histopathology","summary":"We introduce PathBench-MIL, an open-source AutoML and benchmarking framework for multiple instance learning (MIL) in histopathology. The system automates end-to-end MIL pipeline construction, including preprocessing, feature extraction, and MIL-aggregation, and provides reproducible benchmarking of dozens of MIL models and feature extractors. PathBench-MIL integrates visualization tooling, a unified configuration system, and modular extensibility, enabling rapid experimentation and standardization across datasets and tasks. PathBench-MIL is publicly available at https://github.com/Sbrussee/PathBench-MIL","authors":["Siemen Brussee","Pieter A. Valkema","Jurre A. J. Weijer","Thom Doeleman","Anne M. R. Schrader","Jesper Kers"],"pdf_url":"","comment":"14 Pages, 3 Figures, 2 Appendices"},{"id":"http://arxiv.org/abs/2512.17515v1","updated":"2025-12-19T12:32:57Z","published":"2025-12-19T12:32:57Z","title":"Resource-efficient medical image classification for edge devices","summary":"Medical image classification is a critical task in healthcare, enabling accurate and timely diagnosis. However, deploying deep learning models on resource-constrained edge devices presents significant challenges due to computational and memory limitations. This research investigates a resource-efficient approach to medical image classification by employing model quantization techniques. Quantization reduces the precision of model parameters and activations, significantly lowering computational overhead and memory requirements without sacrificing classification accuracy. The study focuses on the optimization of quantization-aware training (QAT) and post-training quantization (PTQ) methods tailored for edge devices, analyzing their impact on model performance across medical imaging datasets. Experimental results demonstrate that quantized models achieve substantial reductions in model size and inference latency, enabling real-time processing on edge hardware while maintaining clinically acceptable diagnostic accuracy. This work provides a practical pathway for deploying AI-driven medical diagnostics in remote and resource-limited settings, enhancing the accessibility and scalability of healthcare technologies.","authors":["Mahsa Lavaei","Zahra Abadi","Salar Beigzad","Alireza Maleki"],"pdf_url":"","comment":"Conference paper published in ICAMIDA 2025 (IEEE)"},{"id":"http://arxiv.org/abs/2504.12392v2","updated":"2025-12-19T12:20:38Z","published":"2025-04-16T18:01:05Z","title":"A Survey on Archetypal Analysis","summary":"Archetypal analysis (AA) was originally proposed in 1994 by Adele Cutler and Leo Breiman as a computational procedure for extracting distinct aspects, so-called archetypes, from observations, with each observational record approximated as a mixture (i.e., convex combination) of these archetypes. AA thereby provides straightforward, interpretable, and explainable representations for feature extraction and dimensionality reduction, facilitating the understanding of the structure of high-dimensional data and enabling wide applications across the sciences. However, AA also faces challenges, particularly as the associated optimization problem is non-convex. This is the first survey that provides researchers and data mining practitioners with an overview of the methodologies and opportunities that AA offers, surveying the many applications of AA across disparate fields of science, as well as best practices for modeling data with AA and its limitations. The survey concludes by explaining crucial future research directions concerning AA.","authors":["Aleix Alcacer","Irene Epifanio","Sebastian Mair","Morten Mørup"],"pdf_url":"","comment":"27 pages, 14 figures, under review"},{"id":"http://arxiv.org/abs/2410.18686v2","updated":"2025-12-19T12:12:39Z","published":"2024-10-24T12:32:19Z","title":"Hierarchical Multimodal LLMs with Semantic Space Alignment for Enhanced Time Series Classification","summary":"Time series classification plays a fundamental role in a wide range of real-world applications. Recently, large language models (LLMs) have demonstrated strong generalization and reasoning capacities, but directly applying them to time series classification remains non-trivial due to the representation gap between numerical sequences and linguistic semantics. In this paper, we propose HiTime, a hierarchical LLM-based framework for multimodal time series classification that bridges structured temporal representations with semantic reasoning in a generative paradigm. Specifically, we design a hierarchical sequence feature encoding module composed of a data-specific encoder and a task-specific encoder to extract complementary temporal features. To mitigate the embedding gap between time series representations and textual semantics, we further introduce a semantic space alignment module that jointly performs coarse-grained global modeling and fine-grained cross-modal correspondence. Building upon the above representations, we employ a parameter-efficient supervised fine-tuning strategy to activate the generative classification capability of the algined LLMs, thereby transforming conventional discriminative time series classification into a generative task. Extensive experiments on multiple benchmarks demonstrate that the proposed framework consistently outperforms state-of-the-art baselines. The code is publicly available at https://github.com/Xiaoyu-Tao/HiTime.","authors":["Xiaoyu Tao","Tingyue Pan","Mingyue Cheng","Yucong Luo","Qi Liu","Enhong Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17488v1","updated":"2025-12-19T11:59:41Z","published":"2025-12-19T11:59:41Z","title":"TwinSegNet: A Digital Twin-Enabled Federated Learning Framework for Brain Tumor Analysis","summary":"Brain tumor segmentation is critical in diagnosis and treatment planning for the disease. Yet, current deep learning methods rely on centralized data collection, which raises privacy concerns and limits generalization across diverse institutions. In this paper, we propose TwinSegNet, which is a privacy-preserving federated learning framework that integrates a hybrid ViT-UNet model with personalized digital twins for accurate and real-time brain tumor segmentation. Our architecture combines convolutional encoders with Vision Transformer bottlenecks to capture local and global context. Each institution fine-tunes the global model of private data to form its digital twin. Evaluated on nine heterogeneous MRI datasets, including BraTS 2019-2021 and custom tumor collections, TwinSegNet achieves high Dice scores (up to 0.90%) and sensitivity/specificity exceeding 90%, demonstrating robustness across non-independent and identically distributed (IID) client distributions. Comparative results against centralized models such as TumorVisNet highlight TwinSegNet's effectiveness in preserving privacy without sacrificing performance. Our approach enables scalable, personalized segmentation for multi-institutional clinical settings while adhering to strict data confidentiality requirements.","authors":["Almustapha A. Wakili","Adamu Hussaini","Abubakar A. Musa","Woosub Jung","Wei Yu"],"pdf_url":"","comment":"IEEE Virtual Conference on Communications. 4-6 November 2025"},{"id":"http://arxiv.org/abs/2507.17860v3","updated":"2025-12-19T11:48:41Z","published":"2025-07-23T18:33:27Z","title":"Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis","summary":"Recent advances in deep learning and on-device inference could transform routine screening for skin cancers. Along with the anticipated benefits of this technology, potential dangers arise from unforeseen and inherent biases. A significant obstacle is building evaluation datasets that accurately reflect key demographics, including sex, age, and race, as well as other underrepresented groups. To address this, we train a state-of-the-art generative model to generate synthetic data in a controllable manner to assess the fairness of publicly available skin cancer classifiers. To evaluate whether synthetic images can be used as a fairness testing dataset, we prepare a real-image dataset (MILK10K) as a benchmark and compare the True Positive Rate result of three models (DeepGuide, MelaNet, and SkinLesionDensnet). As a result, the classification tendencies observed in each model when tested on real and generated images showed similar patterns across different attribute data sets. We confirm that highly realistic synthetic images facilitate model fairness verification.","authors":["Ko Watanabe","Stanislav Frolov","Aya Hassan","David Dembinsky","Adriano Lucieri","Andreas Dengel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17477v1","updated":"2025-12-19T11:44:12Z","published":"2025-12-19T11:44:12Z","title":"Deep Learning-Based Surrogate Creep Modelling in Inconel 625: A High-Temperature Alloy Study","summary":"Time-dependent deformation, particularly creep, in high-temperature alloys such as Inconel 625 is a key factor in the long-term reliability of components used in aerospace and energy systems. Although Inconel 625 shows excellent creep resistance, finite-element creep simulations in tools such as ANSYS remain computationally expensive, often requiring tens of minutes for a single 10,000-hour run. This work proposes deep learning based surrogate models to provide fast and accurate replacements for such simulations. Creep strain data was generated in ANSYS using the Norton law under uniaxial stresses of 50 to 150 MPa and temperatures of 700 to 1000 $^\\circ$C, and this temporal dataset was used to train two architectures: a BiLSTM Variational Autoencoder for uncertainty-aware and generative predictions, and a BiLSTM Transformer hybrid that employs self-attention to capture long-range temporal behavior. Both models act as surrogate predictors, with the BiLSTM-VAE offering probabilistic output and the BiLSTM-Transformer delivering high deterministic accuracy. Performance is evaluated using RMSE, MAE, and $R^2$. Results show that the BiLSTM-VAE provides stable and reliable creep strain forecasts, while the BiLSTM-Transformer achieves strong accuracy across the full time range. Latency tests indicate substantial speedup: while each ANSYS simulation requires 30 to 40 minutes for a given stress-temperature condition, the surrogate models produce predictions within seconds. The proposed framework enables rapid creep assessment for design optimization and structural health monitoring, and provides a scalable solution for high-temperature alloy applications.","authors":["Shubham Das","Kaushal Singhania","Amit Sadhu","Suprabhat Das","Arghya Nandi"],"pdf_url":"","comment":"Presented in 10th International Congress on Computational Mechanics and Simulation (ICCMS) 2025, IIT Bhubaneswar"},{"id":"http://arxiv.org/abs/2512.17473v1","updated":"2025-12-19T11:40:06Z","published":"2025-12-19T11:40:06Z","title":"Alternating Direction Method of Multipliers for Nonlinear Matrix Decompositions","summary":"We present an algorithm based on the alternating direction method of multipliers (ADMM) for solving nonlinear matrix decompositions (NMD). Given an input matrix $X \\in \\mathbb{R}^{m \\times n}$ and a factorization rank $r \\ll \\min(m, n)$, NMD seeks matrices $W \\in \\mathbb{R}^{m \\times r}$ and $H \\in \\mathbb{R}^{r \\times n}$ such that $X \\approx f(WH)$, where $f$ is an element-wise nonlinear function. We evaluate our method on several representative nonlinear models: the rectified linear unit activation $f(x) = \\max(0, x)$, suitable for nonnegative sparse data approximation, the component-wise square $f(x) = x^2$, applicable to probabilistic circuit representation, and the MinMax transform $f(x) = \\min(b, \\max(a, x))$, relevant for recommender systems. The proposed framework flexibly supports diverse loss functions, including least squares, $\\ell_1$ norm, and the Kullback-Leibler divergence, and can be readily extended to other nonlinearities and metrics. We illustrate the applicability, efficiency, and adaptability of the approach on real-world datasets, highlighting its potential for a broad range of applications.","authors":["Atharva Awari","Nicolas Gillis","Arnaud Vandaele"],"pdf_url":"","comment":"14 pages, 6 figures. Code available from https://gitlab.com/Atharva05/admm-for-nmd"},{"id":"http://arxiv.org/abs/2512.17470v1","updated":"2025-12-19T11:33:30Z","published":"2025-12-19T11:33:30Z","title":"Translating the Rashomon Effect to Sequential Decision-Making Tasks","summary":"The Rashomon effect describes the phenomenon where multiple models trained on the same data produce identical predictions while differing in which features they rely on internally. This effect has been studied extensively in classification tasks, but not in sequential decision-making, where an agent learns a policy to achieve an objective by taking actions in an environment. In this paper, we translate the Rashomon effect to sequential decision-making. We define it as multiple policies that exhibit identical behavior, visiting the same states and selecting the same actions, while differing in their internal structure, such as feature attributions. Verifying identical behavior in sequential decision-making differs from classification. In classification, predictions can be directly compared to ground-truth labels. In sequential decision-making with stochastic transitions, the same policy may succeed or fail on any single trajectory due to randomness. We address this using formal verification methods that construct and compare the complete probabilistic behavior of each policy in the environment. Our experiments demonstrate that the Rashomon effect exists in sequential decision-making. We further show that ensembles constructed from the Rashomon set exhibit greater robustness to distribution shifts than individual policies. Additionally, permissive policies derived from the Rashomon set reduce computational requirements for verification while maintaining optimal performance.","authors":["Dennis Gross","Jørn Eirik Betten","Helge Spieker"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17466v1","updated":"2025-12-19T11:29:56Z","published":"2025-12-19T11:29:56Z","title":"Linear Attention for Joint Power Optimization and User-Centric Clustering in Cell-Free Networks","summary":"Optimal AP clustering and power allocation are critical in user-centric cell-free massive MIMO systems. Existing deep learning models lack flexibility to handle dynamic network configurations. Furthermore, many approaches overlook pilot contamination and suffer from high computational complexity. In this paper, we propose a lightweight transformer model that overcomes these limitations by jointly predicting AP clusters and powers solely from spatial coordinates of user devices and AP. Our model is architecture-agnostic to users load, handles both clustering and power allocation without channel estimation overhead, and eliminates pilot contamination by assigning users to AP within a pilot reuse constraint. We also incorporate a customized linear attention mechanism to capture user-AP interactions efficiently and enable linear scalability with respect to the number of users. Numerical results confirm the model's effectiveness in maximizing the minimum spectral efficiency and providing near-optimal performance while ensuring adaptability and scalability in dynamic scenarios.","authors":["Irched Chafaa","Giacomo Bacci","Luca Sanguinetti"],"pdf_url":"","comment":"Submitted"},{"id":"http://arxiv.org/abs/2512.17462v1","updated":"2025-12-19T11:25:18Z","published":"2025-12-19T11:25:18Z","title":"Behavioural Effects of Agentic Messaging: A Case Study on a Financial Service Application","summary":"Marketing and product personalisation provide a prominent and visible use-case for the application of Information Retrieval methods across several business domains. Recently, agentic approaches to these problems have been gaining traction. This work evaluates the behavioural and retention effects of agentic personalisation on a financial service application's customer communication system during a 2025 national tax filing period. Through a two month-long randomised controlled trial, we compare an agentic messaging approach against a business-as-usual (BAU) rule-based campaign system, focusing on two primary outcomes: unsubscribe behaviour and conversion timing. Empirical results show that agent-led messaging reduced unsubscribe events by 21\\% ($\\pm 0.01$) relative to BAU and increased early filing behaviour in the weeks preceding the national deadline. These findings demonstrate how adaptive, user-level decision-making systems can modulate engagement intensity whilst improving long-term retention indicators.","authors":["Olivier Jeunen","Schaun Wheeler"],"pdf_url":"","comment":"To appear in the 48th European Conference on Information Retrieval (ECIR '26) Industry Track"},{"id":"http://arxiv.org/abs/2512.17460v1","updated":"2025-12-19T11:21:12Z","published":"2025-12-19T11:21:12Z","title":"When Data Quality Issues Collide: A Large-Scale Empirical Study of Co-Occurring Data Quality Issues in Software Defect Prediction","summary":"Software Defect Prediction (SDP) models are central to proactive software quality assurance, yet their effectiveness is often constrained by the quality of available datasets. Prior research has typically examined single issues such as class imbalance or feature irrelevance in isolation, overlooking that real-world data problems frequently co-occur and interact. This study presents, to our knowledge, the first large-scale empirical analysis in SDP that simultaneously examines five co-occurring data quality issues (class imbalance, class overlap, irrelevant features, attribute noise, and outliers) across 374 datasets and five classifiers. We employ Explainable Boosting Machines together with stratified interaction analysis to quantify both direct and conditional effects under default hyperparameter settings, reflecting practical baseline usage.\n  Our results show that co-occurrence is nearly universal: even the least frequent issue (attribute noise) appears alongside others in more than 93% of datasets. Irrelevant features and imbalance are nearly ubiquitous, while class overlap is the most consistently harmful issue. We identify stable tipping points around 0.20 for class overlap, 0.65-0.70 for imbalance, and 0.94 for irrelevance, beyond which most models begin to degrade. We also uncover counterintuitive patterns, such as outliers improving performance when irrelevant features are low, underscoring the importance of context-aware evaluation. Finally, we expose a performance-robustness trade-off: no single learner dominates under all conditions.\n  By jointly analyzing prevalence, co-occurrence, thresholds, and conditional effects, our study directly addresses a persistent gap in SDP research. Hence, moving beyond isolated analyses to provide a holistic, data-aware understanding of how quality issues shape model performance in real-world settings.","authors":["Emmanuel Charleson Dapaah","Jens Grabowski"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.11529v2","updated":"2025-12-19T11:20:16Z","published":"2025-12-12T12:59:38Z","title":"xGR: Efficient Generative Recommendation Serving at Scale","summary":"Recommendation system delivers substantial economic benefits by providing personalized predictions. Generative recommendation (GR) integrates LLMs to enhance the understanding of long user-item sequences. Despite employing attention-based architectures, GR's workload differs markedly from that of LLM serving. GR typically processes long prompt while producing short, fixed-length outputs, yet the computational cost of each decode phase is especially high due to the large beam width. In addition, since the beam search involves a vast item space, the sorting overhead becomes particularly time-consuming. We propose xGR, a GR-oriented serving system that meets strict low-latency requirements under highconcurrency scenarios. First, xGR unifies the processing of prefill and decode phases through staged computation and separated KV cache. Second, xGR enables early sorting termination and mask-based item filtering with data structure reuse. Third, xGR reconstructs the overall pipeline to exploit multilevel overlap and multi-stream parallelism. Our experiments with real-world recommendation service datasets demonstrate that xGR achieves at least 3.49x throughput compared to the state-of-the-art baseline under strict latency constraints.","authors":["Qingxiao Sun","Tongxuan Liu","Shen Zhang","Siyu Wu","Peijun Yang","Haotian Liang","Menxin Li","Xiaolong Ma","Zhiwei Liang","Ziyi Ren","Minchao Zhang","Xinyu Liu","Ke Zhang","Depei Qian","Hailong Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.02342v2","updated":"2025-12-19T11:15:38Z","published":"2025-12-02T02:24:32Z","title":"Safeguarded Stochastic Polyak Step Sizes for Non-smooth Optimization: Robust Performance Without Small (Sub)Gradients","summary":"The stochastic Polyak step size (SPS) has proven to be a promising choice for stochastic gradient descent (SGD), delivering competitive performance relative to state-of-the-art methods on smooth convex and non-convex optimization problems, including deep neural network training. However, extensions of this approach to non-smooth settings remain in their early stages, often relying on interpolation assumptions or requiring knowledge of the optimal solution. In this work, we propose a novel SPS variant, Safeguarded SPS (SPS$_{safe}$), for the stochastic subgradient method, and provide rigorous convergence guarantees for non-smooth convex optimization with no need for strong assumptions. We further incorporate momentum into the update rule, yielding equally tight theoretical results. On non-smooth convex benchmarks, our experiments are consistent with the theoretical predictions on how the safeguard affects the convergence neighborhood. On deep neural networks the proposed step size achieves competitive performance to existing adaptive baselines and exhibits stable behavior across a wide range of problem settings. Moreover, in these experiments, the gradient norms under our step size do not collapse to (near) zero, indicating robustness to vanishing gradients.","authors":["Dimitris Oikonomou","Nicolas Loizou"],"pdf_url":"","comment":"28 pages, 15 figures"},{"id":"http://arxiv.org/abs/2512.17453v1","updated":"2025-12-19T11:12:20Z","published":"2025-12-19T11:12:20Z","title":"A lightweight Spatial-Temporal Graph Neural Network for Long-term Time Series Forecasting","summary":"We propose Lite-STGNN, a lightweight spatial-temporal graph neural network for long-term multivariate forecasting that integrates decomposition-based temporal modeling with learnable sparse graph structure. The temporal module applies trend-seasonal decomposition, while the spatial module performs message passing with low-rank Top-$K$ adjacency learning and conservative horizon-wise gating, enabling spatial corrections that enhance a strong linear baseline. Lite-STGNN achieves state-of-the-art accuracy on four benchmark datasets for horizons up to 720 steps, while being parameter-efficient and substantially faster to train than transformer-based methods. Ablation studies show that the spatial module yields 4.6% improvement over the temporal baseline, Top-$K$ enhances locality by 3.3%, and learned adjacency matrices reveal domain-specific interaction dynamics. Lite-STGNN thus offers a compact, interpretable, and efficient framework for long-term multivariate time series forecasting.","authors":["Henok Tenaw Moges","Deshendran Moodley"],"pdf_url":"","comment":"9 pages, 5 figures, 2 tables. Accepted for presentation at the 18th International Conference on Agents and Artificial Intelligence (ICAART 2026), Marbella, Spain"},{"id":"http://arxiv.org/abs/2512.17452v1","updated":"2025-12-19T11:08:58Z","published":"2025-12-19T11:08:58Z","title":"Learning What to Write: Write-Gated KV for Efficient Long-Context Inference","summary":"Long-context LLM inference is bottlenecked by the quadratic attention complexity and linear KV cache growth. Prior approaches mitigate this via post-hoc selection or eviction but overlook the root inefficiency: indiscriminate writing to persistent memory. In this paper, we formalize KV cache management as a causal system of three primitives: KV Admission, Selection, and Eviction. We instantiate KV Admission via Write-Gated KV, a lightweight mechanism that learns to predict token utility before it enters the cache. By filtering out low-utility states early to maintain a compact global cache alongside a sliding local cache, Write-Gated KV reduces memory usage by 46-57% and delivers 3.03-3.45$\\times$ prefill and 1.89-2.56$\\times$ decode speedups on Llama model with negligible accuracy loss, all while remaining compatible with FlashAttention and paged-KV systems. These results demonstrate that learning what to write, is a principled and practical recipe for efficient long-context inference. Code is available at https://github.com/EMCLab-Sinica/WG-KV .","authors":["Yen-Chieh Huang","Rui Fang","Ming-Syan Chen","Pi-Cheng Hsiu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17450v1","updated":"2025-12-19T11:06:46Z","published":"2025-12-19T11:06:46Z","title":"MULTIAQUA: A multimodal maritime dataset and robust training strategies for multimodal semantic segmentation","summary":"Unmanned surface vehicles can encounter a number of varied visual circumstances during operation, some of which can be very difficult to interpret. While most cases can be solved only using color camera images, some weather and lighting conditions require additional information. To expand the available maritime data, we present a novel multimodal maritime dataset MULTIAQUA (Multimodal Aquatic Dataset). Our dataset contains synchronized, calibrated and annotated data captured by sensors of different modalities, such as RGB, thermal, IR, LIDAR, etc. The dataset is aimed at developing supervised methods that can extract useful information from these modalities in order to provide a high quality of scene interpretation regardless of potentially poor visibility conditions. To illustrate the benefits of the proposed dataset, we evaluate several multimodal methods on our difficult nighttime test set. We present training approaches that enable multimodal methods to be trained in a more robust way, thus enabling them to retain reliable performance even in near-complete darkness. Our approach allows for training a robust deep neural network only using daytime images, thus significantly simplifying data acquisition, annotation, and the training process.","authors":["Jon Muhovič","Janez Perš"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17444v1","updated":"2025-12-19T10:56:34Z","published":"2025-12-19T10:56:34Z","title":"Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning","summary":"Electricity systems are key to transforming today's society into a carbon-free economy. Long-term electricity market mechanisms, including auctions, support schemes, and other policy instruments, are critical in shaping the electricity generation mix. In light of the need for more advanced tools to support policymakers and other stakeholders in designing, testing, and evaluating long-term markets, this work presents a multi-agent reinforcement learning model capable of capturing the key features of decarbonizing energy systems. Profit-maximizing generation companies make investment decisions in the wholesale electricity market, responding to system needs, competitive dynamics, and policy signals. The model employs independent proximal policy optimization, which was selected for suitability to the decentralized and competitive environment. Nevertheless, given the inherent challenges of independent learning in multi-agent settings, an extensive hyperparameter search ensures that decentralized training yields market outcomes consistent with competitive behavior. The model is applied to a stylized version of the Italian electricity system and tested under varying levels of competition, market designs, and policy scenarios. Results highlight the critical role of market design for decarbonizing the electricity sector and avoiding price volatility. The proposed framework allows assessing long-term electricity markets in which multiple policy and market mechanisms interact simultaneously, with market participants responding and adapting to decarbonization pathways.","authors":["Javier Gonzalez-Ruiz","Carlos Rodriguez-Pardo","Iacopo Savelli","Alice Di Bella","Massimo Tavoni"],"pdf_url":"","comment":"Accepted to Energy and AI. Code available in https://github.com/jjgonzalez2491/MARLEY_V1"},{"id":"http://arxiv.org/abs/2512.15675v3","updated":"2025-12-19T10:55:54Z","published":"2025-12-17T18:28:04Z","title":"Stylized Synthetic Augmentation further improves Corruption Robustness","summary":"This paper proposes a training data augmentation pipeline that combines synthetic image data with neural style transfer in order to address the vulnerability of deep vision models to common corruptions. We show that although applying style transfer on synthetic images degrades their quality with respect to the common Frechet Inception Distance (FID) metric, these images are surprisingly beneficial for model training. We conduct a systematic empirical analysis of the effects of both augmentations and their key hyperparameters on the performance of image classifiers. Our results demonstrate that stylization and synthetic data complement each other well and can be combined with popular rule-based data augmentation techniques such as TrivialAugment, while not working with others. Our method achieves state-of-the-art corruption robustness on several small-scale image classification benchmarks, reaching 93.54%, 74.9% and 50.86% robust accuracy on CIFAR-10-C, CIFAR-100-C and TinyImageNet-C, respectively","authors":["Georg Siedel","Rojan Regmi","Abhirami Anand","Weijia Shao","Silvia Vock","Andrey Morozov"],"pdf_url":"","comment":"Accepted at VISAPP 2026 conference"},{"id":"http://arxiv.org/abs/2508.20717v2","updated":"2025-12-19T10:45:33Z","published":"2025-08-28T12:37:25Z","title":"Unified Acoustic Representations for Screening Neurological and Respiratory Pathologies from Voice","summary":"Voice-based health assessment offers unprecedented opportunities for scalable, non-invasive disease screening, yet existing approaches typically focus on single conditions and fail to leverage the rich, multi-faceted information embedded in speech. We present MARVEL (Multi-task Acoustic Representations for Voice-based Health Analysis), a privacy-conscious multitask learning framework that simultaneously detects nine distinct neurological, respiratory, and voice disorders using only derived acoustic features, eliminating the need for raw audio transmission. Our dual-branch architecture employs specialized encoders with task-specific heads sharing a common acoustic backbone, enabling effective cross-condition knowledge transfer. Evaluated on the large-scale Bridge2AI-Voice v2.0 dataset, MARVEL achieves an overall AUROC of 0.78, with exceptional performance on neurological disorders (AUROC = 0.89), particularly for Alzheimer's disease/mild cognitive impairment (AUROC = 0.97). Our framework consistently outperforms single-modal baselines by 5-19% and surpasses state-of-the-art self-supervised models on 7 of 9 tasks, while correlation analysis reveals that the learned representations exhibit meaningful similarities with established acoustic features, indicating that the model's internal representations are consistent with clinically recognized acoustic patterns. By demonstrating that a single unified model can effectively screen for diverse conditions, this work establishes a foundation for deployable voice-based diagnostics in resource-constrained and remote healthcare settings.","authors":["Ran Piao","Yuan Lu","Hareld Kemps","Tong Xia","Aaqib Saeed"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17426v1","updated":"2025-12-19T10:23:38Z","published":"2025-12-19T10:23:38Z","title":"Perfect reconstruction of sparse signals using nonconvexity control and one-step RSB message passing","summary":"We consider sparse signal reconstruction via minimization of the smoothly clipped absolute deviation (SCAD) penalty, and develop one-step replica-symmetry-breaking (1RSB) extensions of approximate message passing (AMP), termed 1RSB-AMP. Starting from the 1RSB formulation of belief propagation, we derive explicit update rules of 1RSB-AMP together with the corresponding state evolution (1RSB-SE) equations. A detailed comparison shows that 1RSB-AMP and 1RSB-SE agree remarkably well at the macroscopic level, even in parameter regions where replica-symmetric (RS) AMP, termed RS-AMP, diverges and where the 1RSB description itself is not expected to be thermodynamically exact. Fixed-point analysis of 1RSB-SE reveals a phase diagram consisting of success, failure, and diverging phases, as in the RS case. However, the diverging-region boundary now depends on the Parisi parameter due to the 1RSB ansatz, and we propose a new criterion -- minimizing the size of the diverging region -- rather than the conventional zero-complexity condition, to determine its value. Combining this criterion with the nonconvexity-control (NCC) protocol proposed in a previous RS study improves the algorithmic limit of perfect reconstruction compared with RS-AMP. Numerical solutions of 1RSB-SE and experiments with 1RSB-AMP confirm that this improved limit is achieved in practice, though the gain is modest and remains slightly inferior to the Bayes-optimal threshold. We also report the behavior of thermodynamic quantities -- overlaps, free entropy, complexity, and the non-self-averaging susceptibility -- that characterize the 1RSB phase in this problem.","authors":["Xiaosi Gu","Ayaka Sakata","Tomoyuki Obuchi"],"pdf_url":"","comment":"49 pages, 10 figures"},{"id":"http://arxiv.org/abs/2506.22376v4","updated":"2025-12-19T10:17:53Z","published":"2025-06-27T16:44:11Z","title":"OptScale: Probabilistic Optimality for Inference-time Scaling","summary":"Inference-time scaling has emerged as a powerful technique for enhancing the reasoning performance of Large Language Models (LLMs). However, existing approaches often rely on heuristic strategies for parallel sampling, lacking a principled foundation. To address this gap, we propose a probabilistic framework that formalizes the optimality of inference-time scaling under the assumption that parallel samples are independently and identically distributed (i.i.d.), and where the Best-of-$N$ selection strategy follows a probability distribution that can be estimated. Within this framework, we derive a theoretical lower bound on the required number of samples to achieve a target performance level, providing the first principled guidance for compute-efficient scaling. Leveraging this insight, we develop \\textsc{OptScale}, a practical algorithm that dynamically determines the optimal number of sampled responses. \\textsc{OptScale} employs a language model-based predictor to estimate probabilistic prior parameters, enabling the decision of the minimal number of samples needed that satisfy predefined performance thresholds and confidence levels. Extensive experiments on representative reasoning benchmarks (including MATH-500, GSM8K, AIME, and AMC) demonstrate that \\textsc{OptScale} significantly reduces sampling overhead while remaining better or on par with state-of-the-art reasoning performance. Our work offers both a theoretical foundation and a practical solution for principled inference-time scaling, addressing a critical gap in the efficient deployment of LLMs for complex reasoning.","authors":["Youkang Wang","Jian Wang","Rubing Chen","Xiao-Yong Wei"],"pdf_url":"","comment":"Accepted by AAAI-2026"},{"id":"http://arxiv.org/abs/2512.17419v1","updated":"2025-12-19T10:16:51Z","published":"2025-12-19T10:16:51Z","title":"SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories","summary":"Benchmarks like SWE-bench have standardized the evaluation of Large Language Models (LLMs) on repository-level software engineering tasks. However, these efforts remain limited by manual curation, static datasets, and a focus on Python-based bug fixes. We introduce SWE-Bench++, an automated framework that generates repository-level coding tasks from open-source GitHub projects. Unlike synthetic approaches, our pipeline harvests live pull requests to cover both bug fixes and feature requests across 11 languages. SWE-Bench++ turns GitHub pull requests (PRs) into reproducible, execution-based tasks via four stages: programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance. A final hint-guided trajectory synthesis step converts instances that strong models fail on into training trajectories. Our initial benchmark consists of 11,133 instances from 3,971 repositories across 11 languages. On a subset of 1,782 instances of this benchmark, today's strongest models perform as follows: claude-sonnet-4.5 achieves 36.20% pass@10, gpt-5-2025-08-07 34.57%, gemini/gemini-2.5-pro 24.92%, and gpt-4o 16.89%. We further demonstrate the utility of our dataset by showing that fine-tuning on SWE-Bench++ instances yields measurable improvements on the SWE-bench Multilingual benchmark. SWE-Bench++ provides a scalable, multilingual benchmark for evaluating and improving repository-level code generation.","authors":["Lilin Wang","Lucas Ramalho","Alan Celestino","Phuc Anthony Pham","Yu Liu","Umang Kumar Sinha","Andres Portillo","Onassis Osunwa","Gabriel Maduekwe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.04469v3","updated":"2025-12-19T10:05:59Z","published":"2025-11-06T15:44:07Z","title":"Towards Causal Market Simulators","summary":"Market generators using deep generative models have shown promise for synthetic financial data generation, but existing approaches lack causal reasoning capabilities essential for counterfactual analysis and risk assessment. We propose a Time-series Neural Causal Model VAE (TNCM-VAE) that combines variational autoencoders with structural causal models to generate counterfactual financial time series while preserving both temporal dependencies and causal relationships. Our approach enforces causal constraints through directed acyclic graphs in the decoder architecture and employs the causal Wasserstein distance for training. We validate our method on synthetic autoregressive models inspired by the Ornstein-Uhlenbeck process, demonstrating superior performance in counterfactual probability estimation with L1 distances as low as 0.03-0.10 compared to ground truth. The model enables financial stress testing, scenario analysis, and enhanced backtesting by generating plausible counterfactual market trajectories that respect underlying causal mechanisms.","authors":["Dennis Thumm","Luis Ontaneda Mijares"],"pdf_url":"","comment":"ICAIF 2025 Workshop on Rethinking Financial Time-Series"},{"id":"http://arxiv.org/abs/2512.17409v1","updated":"2025-12-19T10:01:52Z","published":"2025-12-19T10:01:52Z","title":"meval: A Statistical Toolbox for Fine-Grained Model Performance Analysis","summary":"Analyzing machine learning model performance stratified by patient and recording properties is becoming the accepted norm and often yields crucial insights about important model failure modes. Performing such analyses in a statistically rigorous manner is non-trivial, however. Appropriate performance metrics must be selected that allow for valid comparisons between groups of different sample sizes and base rates; metric uncertainty must be determined and multiple comparisons be corrected for, in order to assess whether any observed differences may be purely due to chance; and in the case of intersectional analyses, mechanisms must be implemented to find the most `interesting' subgroups within combinatorially many subgroup combinations. We here present a statistical toolbox that addresses these challenges and enables practitioners to easily yet rigorously assess their models for potential subgroup performance disparities. While broadly applicable, the toolbox is specifically designed for medical imaging applications. The analyses provided by the toolbox are illustrated in two case studies, one in skin lesion malignancy classification on the ISIC2020 dataset and one in chest X-ray-based disease classification on the MIMIC-CXR dataset.","authors":["Dishantkumar Sutariya","Eike Petersen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17398v1","updated":"2025-12-19T09:50:23Z","published":"2025-12-19T09:50:23Z","title":"DeepShare: Sharing ReLU Across Channels and Layers for Efficient Private Inference","summary":"Private Inference (PI) uses cryptographic primitives to perform privacy preserving machine learning. In this setting, the owner of the network runs inference on the data of the client without learning anything about the data and without revealing any information about the model. It has been observed that a major computational bottleneck of PI is the calculation of the gate (i.e., ReLU), so a considerable amount of effort have been devoted to reducing the number of ReLUs in a given network.\n  We focus on the DReLU, which is the non-linear step function of the ReLU and show that one DReLU can serve many ReLU operations. We suggest a new activation module where the DReLU operation is only performed on a subset of the channels (Prototype channels), while the rest of the channels (replicate channels) replicates the DReLU of each of their neurons from the corresponding neurons in one of the prototype channels. We then extend this idea to work across different layers.\n  We show that this formulation can drastically reduce the number of DReLU operations in resnet type network. Furthermore, our theoretical analysis shows that this new formulation can solve an extended version of the XOR problem, using just one non-linearity and two neurons, something that traditional formulations and some PI specific methods cannot achieve. We achieve new SOTA results on several classification setups, and achieve SOTA results on image segmentation.","authors":["Yonathan Bornfeld","Shai Avidan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.18242v3","updated":"2025-12-19T09:49:50Z","published":"2025-07-24T09:30:37Z","title":"Boosting Revisited: Benchmarking and Advancing LP-Based Ensemble Methods","summary":"Despite their theoretical appeal, totally corrective boosting methods based on linear programming have received limited empirical attention. In this paper, we conduct the first large-scale experimental study of six LP-based boosting formulations, including two novel methods, NM-Boost and QRLP-Boost, across 20 diverse datasets. We evaluate the use of both heuristic and optimal base learners within these formulations, and analyze not only accuracy, but also ensemble sparsity, margin distribution, anytime performance, and hyperparameter sensitivity. We show that totally corrective methods can outperform or match state-of-the-art heuristics like XGBoost and LightGBM when using shallow trees, while producing significantly sparser ensembles. We further show that these methods can thin pre-trained ensembles without sacrificing performance, and we highlight both the strengths and limitations of using optimal decision trees in this context.","authors":["Fabian Akkerman","Julien Ferry","Christian Artigues","Emmanuel Hebrard","Thibaut Vidal"],"pdf_url":"","comment":"Published in Transactions on Machine Learning Research (2025), see: https://openreview.net/forum?id=lscC4PZUE4"},{"id":"http://arxiv.org/abs/2505.17720v2","updated":"2025-12-19T09:48:05Z","published":"2025-05-23T10:37:12Z","title":"PEAR: Equal Area Weather Forecasting on the Sphere","summary":"Artificial intelligence is rapidly reshaping the natural sciences, with weather forecasting emerging as a flagship AI4Science application where machine learning models can now rival and even surpass traditional numerical simulations. Following the success of the landmark models Pangu Weather and Graphcast, outperforming traditional numerical methods for global medium-range forecasting, many novel data-driven methods have emerged. A common limitation shared by many of these models is their reliance on an equiangular discretization of the sphere which suffers from a much finer grid at the poles than around the equator. In contrast, in the Hierarchical Equal Area iso-Latitude Pixelization (HEALPix) of the sphere, each pixel covers the same surface area, removing unphysical biases. Motivated by a growing support for this grid in meteorology and climate sciences, we propose to perform weather forecasting with deep learning models which natively operate on the HEALPix grid. To this end, we introduce Pangu Equal ARea (PEAR), a transformer-based weather forecasting model which operates directly on HEALPix-features and outperforms the corresponding model on an equiangular grid without any computational overhead.","authors":["Hampus Linander","Christoffer Petersson","Daniel Persson","Jan E. Gerken"],"pdf_url":"","comment":"Published in the AI for Science workshop (NeurIPS 2025), 8 pages, 4 figures; 6 pages supplementary material"},{"id":"http://arxiv.org/abs/2510.23117v3","updated":"2025-12-19T09:46:41Z","published":"2025-10-27T08:38:17Z","title":"Seeing Structural Failure Before it Happens: An Image-Based Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction","summary":"Physics Informed Neural Networks (PINNs) are gaining attention for their ability to embed physical laws into deep learning models, which is particularly useful in structural engineering tasks with limited data. This paper aims to explore the use of PINNs to predict the weight of small scale spaghetti bridges, a task relevant to understanding load limits and potential failure modes in simplified structural models. Our proposed framework incorporates physics-based constraints to the prediction model for improved performance. In addition to standard PINNs, we introduce a novel architecture named Physics Informed Kolmogorov Arnold Network (PIKAN), which blends universal function approximation theory with physical insights. The structural parameters provided as input to the model are collected either manually or through computer vision methods. Our dataset includes 15 real bridges, augmented to 100 samples, and our best model achieves an $R^2$ score of 0.9603 and a mean absolute error (MAE) of 10.50 units. From applied perspective, we also provide a web based interface for parameter entry and prediction. These results show that PINNs can offer reliable estimates of structural weight, even with limited data, and may help inform early stage failure analysis in lightweight bridge designs.\n  The complete data and code are available at https://github.com/OmerJauhar/PINNS-For-Spaghetti-Bridges.","authors":["Omer Jauhar Khan","Sudais Khan","Hafeez Anwar","Shahzeb Khan","Shams Ul Arifeen"],"pdf_url":"","comment":"14 pages, 21 figures. Preprint"},{"id":"http://arxiv.org/abs/2502.03480v2","updated":"2025-12-19T09:44:32Z","published":"2025-01-27T23:02:05Z","title":"Foundation for unbiased cross-validation of spatio-temporal models for species distribution modeling","summary":"Evaluating the predictive performance of species distribution models (SDMs) under realistic deployment scenarios requires careful handling of spatial and temporal dependencies in the data. Cross-validation (CV) is the standard approach for model evaluation, but its design strongly influences the validity of performance estimates. When SDMs are intended for spatial or temporal transfer, random CV can lead to overoptimistic results due to spatial autocorrelation (SAC) among neighboring observations.\n  We benchmark four machine learning algorithms (GBM, XGBoost, LightGBM, Random Forest) on two real-world presence-absence datasets, a temperate plant and an anadromous fish, using multiple CV designs: random, spatial, spatio-temporal, environmental, and forward-chaining. Two training data usage strategies (LAST FOLD and RETRAIN) are evaluated, with hyperparameter tuning performed within each CV scheme. Model performance is assessed on independent out-of-time test sets using AUC, MAE, and correlation metrics.\n  Random CV overestimates AUC by up to 0.16 and produces MAE values up to 80 percent higher than spatially blocked alternatives. Blocking at the empirical SAC range substantially reduces this bias. Training strategy affects evaluation outcomes: LAST FOLD yields smaller validation-test discrepancies under strong SAC, while RETRAIN achieves higher test AUC when SAC is weaker. Boosted ensemble models consistently perform best under spatially structured CV designs. We recommend a robust SDM workflow based on SAC-aware blocking, blocked hyperparameter tuning, and external temporal validation to improve reliability under spatial and temporal shifts.","authors":["Diana Koldasbayeva","Alexey Zaytsev"],"pdf_url":"","comment":"Accepted manuscript. Published in Ecological Informatics (2025)"},{"id":"http://arxiv.org/abs/2512.17381v1","updated":"2025-12-19T09:36:44Z","published":"2025-12-19T09:36:44Z","title":"Timely Information Updating for Mobile Devices Without and With ML Advice","summary":"This paper investigates an information update system in which a mobile device monitors a physical process and sends status updates to an access point (AP). A fundamental trade-off arises between the timeliness of the information maintained at the AP and the update cost incurred at the device. To address this trade-off, we propose an online algorithm that determines when to transmit updates using only available observations. The proposed algorithm asymptotically achieves the optimal competitive ratio against an adversary that can simultaneously manipulate multiple sources of uncertainty, including the operation duration, the information staleness, the update cost, and the availability of update opportunities. Furthermore, by incorporating machine learning (ML) advice of unknown reliability into the design, we develop an ML-augmented algorithm that asymptotically attains the optimal consistency-robustness trade-off, even when the adversary can additionally corrupt the ML advice. The optimal competitive ratio scales linearly with the range of update costs, but is unaffected by other uncertainties. Moreover, an optimal competitive online algorithm exhibits a threshold-like response to the ML advice: it either fully trusts or completely ignores the ML advice, as partially trusting the advice cannot improve the consistency without severely degrading the robustness. Extensive simulations in stochastic settings further validate the theoretical findings in the adversarial environment.","authors":["Yu-Pin Hsu","Yi-Hsuan Tseng"],"pdf_url":"","comment":"23 pages, journal version of arXiv:1901.03137, submitted for possible journal publication"},{"id":"http://arxiv.org/abs/2508.19011v3","updated":"2025-12-19T09:33:52Z","published":"2025-08-26T13:14:53Z","title":"STDiff: A State Transition Diffusion Framework for Time Series Imputation in Industrial Systems","summary":"Incomplete sensor data is a major obstacle in industrial time-series analytics. In wastewater treatment plants (WWTPs), key sensors show long, irregular gaps caused by fouling, maintenance, and outages. We introduce STDiff and STDiff-W, diffusion-based imputers that cast gap filling as state-space simulation under partial observability, where targets, controls, and exogenous signals may all be intermittently missing. STDiff learns a one-step transition model conditioned on observed values and masks, while STDiff-W extends this with a context encoder that jointly inpaints contiguous blocks, combining long-range consistency with short-term detail. On two WWTP datasets (one with synthetic block gaps from Agtrup and another with natural outages from Avedøre), STDiff-W achieves state-of-the-art accuracy compared with strong neural baselines such as SAITS, BRITS, and CSDI. Beyond point-error metrics, its reconstructions preserve realistic dynamics including oscillations, spikes, and regime shifts, and they achieve top or tied-top downstream one-step forecasting performance compared with strong neural baselines, indicating that preserving dynamics does not come at the expense of predictive utility. Ablation studies that drop, shuffle, or add noise to control or exogenous inputs consistently degrade NH4 and PO4 performance, with the largest deterioration observed when exogenous signals are removed, showing that the model captures meaningful dependencies. We conclude with practical guidance for deployment: evaluate performance beyond MAE using task-oriented and visual checks, include exogenous drivers, and balance computational cost against robustness to structured outages.","authors":["Gary Simethy","Daniel Ortiz-Arroyo","Petar Durdevic"],"pdf_url":"","comment":"Peer-reviewed and published in Expert Systems with Applications, Volume 302 (2026). This version reflects the published article"},{"id":"http://arxiv.org/abs/2410.22674v2","updated":"2025-12-19T09:23:30Z","published":"2024-10-30T03:52:21Z","title":"Dynamic PET Image Prediction Using a Network Combining Reversible and Irreversible Modules","summary":"Dynamic positron emission tomography (PET) images can reveal the distribution of tracers in the organism and the dynamic processes involved in biochemical reactions, and it is widely used in clinical practice. Despite the high effectiveness of dynamic PET imaging in studying the kinetics and metabolic processes of radiotracers. Pro-longed scan times can cause discomfort for both patients and medical personnel. This study proposes a dynamic frame prediction method for dynamic PET imaging, reduc-ing dynamic PET scanning time by applying a multi-module deep learning framework composed of reversible and irreversible modules. The network can predict kinetic parameter images based on the early frames of dynamic PET images, and then generate complete dynamic PET images. In validation experiments with simulated data, our network demonstrated good predictive performance for kinetic parameters and was able to reconstruct high-quality dynamic PET images. Additionally, in clinical data experiments, the network exhibited good generalization performance and attached that the proposed method has promising clinical application prospects.","authors":["Jie Sun","Junyan Zhang","Qian Xia","Chuanfu Sun","Yumei Chen","Yunjie Yang","Huafeng Liu","Wentao Zhu","Qiegen Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.12783v2","updated":"2025-12-19T09:22:54Z","published":"2025-12-14T17:48:13Z","title":"Credit Risk Estimation with Non-Financial Features: Evidence from a Synthetic Istanbul Dataset","summary":"Financial exclusion constrains entrepreneurship, increases income volatility, and widens wealth gaps. Underbanked consumers in Istanbul often have no bureau file because their earnings and payments flow through informal channels. To study how such borrowers can be evaluated we create a synthetic dataset of one hundred thousand Istanbul residents that reproduces first quarter 2025 TÜİK census marginals and telecom usage patterns. Retrieval augmented generation feeds these public statistics into the OpenAI o3 model, which synthesises realistic yet private records. Each profile contains seven socio demographic variables and nine alternative attributes that describe phone specifications, online shopping rhythm, subscription spend, car ownership, monthly rent, and a credit card flag. To test the impact of the alternative financial data CatBoost, LightGBM, and XGBoost are each trained in two versions. Demo models use only the socio demographic variables; Full models include both socio demographic and alternative attributes. Across five fold stratified validation the alternative block raises area under the curve by about one point three percentage and lifts balanced \\(F_{1}\\) from roughly 0.84 to 0.95, a fourteen percent gain. We contribute an open Istanbul 2025 Q1 synthetic dataset, a fully reproducible modeling pipeline, and empirical evidence that a concise set of behavioural attributes can approach bureau level discrimination power while serving borrowers who lack formal credit records. These findings give lenders and regulators a transparent blueprint for extending fair and safe credit access to the underbanked.","authors":["Atalay Denknalbant","Emre Sezdi","Zeki Furkan Kutlu","Polat Goktas"],"pdf_url":"","comment":"Substantial experimental errors were discovered that affect the validity of the results. Then, we want to withdraw the paper"},{"id":"http://arxiv.org/abs/2512.17375v1","updated":"2025-12-19T09:22:11Z","published":"2025-12-19T09:22:11Z","title":"AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens","summary":"Reward models and LLM-as-a-Judge systems are central to modern post-training pipelines such as RLHF, DPO, and RLAIF, where they provide scalar feedback and binary decisions that guide model selection and RL-based fine-tuning. We show that these judge systems exhibit a recurring vulnerability: short sequences of low-perplexity control tokens can flip many binary evaluations from correct ``No'' judgments to incorrect ``Yes'' judgments by steering the last-layer logit gap. These control tokens are patterns that a policy model could plausibly generate during post-training, and thus represent realistic reward-hacking risks rather than worst-case adversarial strings. Our method, AdvJudge-Zero, uses the model's next-token distribution and beam-search exploration to discover diverse control-token sequences from scratch, and our analysis shows that the induced hidden-state perturbations concentrate in a low-rank ``soft mode'' that is anti-aligned with the judge's refusal direction. Empirically, these tokens cause very high false positive rates when large open-weight and specialized judge models score incorrect answers on math and reasoning benchmarks. Finally, we show that LoRA-based adversarial training on small sets of control-token-augmented examples can markedly reduce these false positives while preserving evaluation quality.","authors":["Tung-Ling Li","Yuhao Wu","Hongliang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17367v1","updated":"2025-12-19T09:08:27Z","published":"2025-12-19T09:08:27Z","title":"Adversarially Robust Detection of Harmful Online Content: A Computational Design Science Approach","summary":"Social media platforms are plagued by harmful content such as hate speech, misinformation, and extremist rhetoric. Machine learning (ML) models are widely adopted to detect such content; however, they remain highly vulnerable to adversarial attacks, wherein malicious users subtly modify text to evade detection. Enhancing adversarial robustness is therefore essential, requiring detectors that can defend against diverse attacks (generalizability) while maintaining high overall accuracy. However, simultaneously achieving both optimal generalizability and accuracy is challenging. Following the computational design science paradigm, this study takes a sequential approach that first proposes a novel framework (Large Language Model-based Sample Generation and Aggregation, LLM-SGA) by identifying the key invariances of textual adversarial attacks and leveraging them to ensure that a detector instantiated within the framework has strong generalizability. Second, we instantiate our detector (Adversarially Robust Harmful Online Content Detector, ARHOCD) with three novel design components to improve detection accuracy: (1) an ensemble of multiple base detectors that exploits their complementary strengths; (2) a novel weight assignment method that dynamically adjusts weights based on each sample's predictability and each base detector's capability, with weights initialized using domain knowledge and updated via Bayesian inference; and (3) a novel adversarial training strategy that iteratively optimizes both the base detectors and the weight assignor. We addressed several limitations of existing adversarial robustness enhancement research and empirically evaluated ARHOCD across three datasets spanning hate speech, rumor, and extremist content. Results show that ARHOCD offers strong generalizability and improves detection accuracy under adversarial conditions.","authors":["Yidong Chai","Yi Liu","Mohammadreza Ebrahimi","Weifeng Li","Balaji Padmanabhan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.14386v2","updated":"2025-12-19T09:00:50Z","published":"2025-10-16T07:37:59Z","title":"ASecond-Order SpikingSSM for Wearables","summary":"Spiking neural networks have garnered increasing attention due to their energy efficiency, multiplication-free computation, and sparse event-based processing. In parallel, state space models have emerged as scalable alternatives to transformers for long-range sequence modelling by avoiding quadratic dependence on sequence length. We propose SHaRe-SSM (Spiking Harmonic Resonate-and-Fire State Space Model), a second-order spiking SSM for classification and regression on ultra-long sequences. SHaRe-SSM outperforms transformers and first-order SSMs on average while eliminating matrix multiplications, making it highly suitable for resource-constrained applications. To ensure fast computation over tens of thousands of time steps, we leverage a parallel scan formulation of the underlying dynamical system. Furthermore, we introduce a kernel-based spiking regressor, which enables the accurate modelling of dependencies in sequences of up to 50k steps. Our results demonstrate that SHaRe-SSM achieves superior long-range modelling capability with energy efficiency (52.1x less than ANN-based second order SSM), positioning it as a strong candidate for resource-constrained devices such as wearables","authors":["Kartikay Agrawal","Abhijeet Vikram","Vedant Sharma","Vaishnavi Nagabhushana","Ayon Borthakur"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17352v1","updated":"2025-12-19T08:48:36Z","published":"2025-12-19T08:48:36Z","title":"Adaptive Graph Pruning with Sudden-Events Evaluation for Traffic Prediction using Online Semi-Decentralized ST-GNNs","summary":"Spatio-Temporal Graph Neural Networks (ST-GNNs) are well-suited for processing high-frequency data streams from geographically distributed sensors in smart mobility systems. However, their deployment at the edge across distributed compute nodes (cloudlets) createssubstantial communication overhead due to repeated transmission of overlapping node features between neighbouring cloudlets. To address this, we propose an adaptive pruning algorithm that dynamically filters redundant neighbour features while preserving the most informative spatial context for prediction. The algorithm adjusts pruning rates based on recent model performance, allowing each cloudlet to focus on regions experiencing traffic changes without compromising accuracy. Additionally, we introduce the Sudden Event Prediction Accuracy (SEPA), a novel event-focused metric designed to measure responsiveness to traffic slowdowns and recoveries, which are often missed by standard error metrics. We evaluate our approach in an online semi-decentralized setting with traditional FL, server-free FL, and Gossip Learning on two large-scale traffic datasets, PeMS-BAY and PeMSD7-M, across short-, mid-, and long-term prediction horizons. Experiments show that, in contrast to standard metrics, SEPA exposes the true value of spatial connectivity in predicting dynamic and irregular traffic. Our adaptive pruning algorithm maintains prediction accuracy while significantly lowering communication cost in all online semi-decentralized settings, demonstrating that communication can be reduced without compromising responsiveness to critical traffic events.","authors":["Ivan Kralj","Lodovico Giaretta","Gordan Ježić","Ivana Podnar Žarko","Šarūnas Girdzijauskas"],"pdf_url":"","comment":"19 pages, 6 figures, 5 tables, journal"},{"id":"http://arxiv.org/abs/2512.17341v1","updated":"2025-12-19T08:34:05Z","published":"2025-12-19T08:34:05Z","title":"Sharp Structure-Agnostic Lower Bounds for General Functional Estimation","summary":"The design of efficient nonparametric estimators has long been a central problem in statistics, machine learning, and decision making. Classical optimal procedures often rely on strong structural assumptions, which can be misspecified in practice and complicate deployment. This limitation has sparked growing interest in structure-agnostic approaches -- methods that debias black-box nuisance estimates without imposing structural priors. Understanding the fundamental limits of these methods is therefore crucial. This paper provides a systematic investigation of the optimal error rates achievable by structure-agnostic estimators. We first show that, for estimating the average treatment effect (ATE), a central parameter in causal inference, doubly robust learning attains optimal structure-agnostic error rates. We then extend our analysis to a general class of functionals that depend on unknown nuisance functions and establish the structure-agnostic optimality of debiased/double machine learning (DML). We distinguish two regimes -- one where double robustness is attainable and one where it is not -- leading to different optimal rates for first-order debiasing, and show that DML is optimal in both regimes. Finally, we instantiate our general lower bounds by deriving explicit optimal rates that recover existing results and extend to additional estimands of interest. Our results provide theoretical validation for widely used first-order debiasing methods and guidance for practitioners seeking optimal approaches in the absence of structural assumptions. This paper generalizes and subsumes the ATE lower bound established in \\citet{jin2024structure} by the same authors.","authors":["Jikai Jin","Vasilis Syrgkanis"],"pdf_url":"","comment":"95 pages; generalize and subsume partial results of arXiv:2402.14264 by the same authors"},{"id":"http://arxiv.org/abs/2512.17340v1","updated":"2025-12-19T08:33:48Z","published":"2025-12-19T08:33:48Z","title":"Penalized Fair Regression for Multiple Groups in Chronic Kidney Disease","summary":"Fair regression methods have the potential to mitigate societal bias concerns in health care, but there has been little work on penalized fair regression when multiple groups experience such bias. We propose a general regression framework that addresses this gap with unfairness penalties for multiple groups. Our approach is demonstrated for binary outcomes with true positive rate disparity penalties. It can be efficiently implemented through reduction to a cost-sensitive classification problem. We additionally introduce novel score functions for automatically selecting penalty weights. Our penalized fair regression methods are empirically studied in simulations, where they achieve a fairness-accuracy frontier beyond that of existing comparison methods. Finally, we apply these methods to a national multi-site primary care study of chronic kidney disease to develop a fair classifier for end-stage renal disease. There we find substantial improvements in fairness for multiple race and ethnicity groups who experience societal bias in the health care system without any appreciable loss in overall fit.","authors":["Carter H. Nakamoto","Lucia Lushi Chen","Agata Foryciarz","Sherri Rose"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.11575v2","updated":"2025-12-19T08:22:55Z","published":"2025-12-12T14:03:40Z","title":"In-Context Learning for Seismic Data Processing","summary":"Seismic processing transforms raw data into subsurface images essential for geophysical applications. Traditional methods face challenges, such as noisy data, and manual parameter tuning, among others. Recently deep learning approaches have proposed alternative solutions to some of these problems. However, important challenges of existing deep learning approaches are spatially inconsistent results across neighboring seismic gathers and lack of user-control. We address these limitations by introducing ContextSeisNet, an in-context learning model, to seismic demultiple processing. Our approach conditions predictions on a support set of spatially related example pairs: neighboring common-depth point gathers from the same seismic line and their corresponding labels. This allows the model to learn task-specific processing behavior at inference time by observing how similar gathers should be processed, without any retraining. This method provides both flexibility through user-defined examples and improved lateral consistency across seismic lines. On synthetic data, ContextSeisNet outperforms a U-Net baseline quantitatively and demonstrates enhanced spatial coherence between neighboring gathers. On field data, our model achieves superior lateral consistency compared to both traditional Radon demultiple and the U-Net baseline. Relative to the U-Net, ContextSeisNet also delivers improved near-offset performance and more complete multiple removal. Notably, ContextSeisNet achieves comparable field data performance despite being trained on 90% less data, demonstrating substantial data efficiency. These results establish ContextSeisNet as a practical approach for spatially consistent seismic demultiple with potential applicability to other seismic processing tasks.","authors":["Fabian Fuchs","Mario Ruben Fernandez","Norman Ettrich","Janis Keuper"],"pdf_url":"","comment":"Source code available under https://codeberg.org/fuchsfa/in-context-learning-seismic. In submission to Geophysics"},{"id":"http://arxiv.org/abs/2503.19041v4","updated":"2025-12-19T08:17:42Z","published":"2025-03-24T18:11:42Z","title":"LookAhead Tuning: Safer Language Models via Partial Answer Previews","summary":"Fine-tuning enables large language models (LLMs) to adapt to specific domains, but often compromises their previously established safety alignment. To mitigate the degradation of model safety during fine-tuning, we introduce LookAhead Tuning, a lightweight and effective data-driven approach that preserves safety during fine-tuning. The method introduces two simple strategies that modify training data by previewing partial answer prefixes, thereby minimizing perturbations to the model's initial token distributions and maintaining its built-in safety mechanisms. Comprehensive experiments demonstrate that LookAhead Tuning effectively maintains model safety without sacrificing robust performance on downstream tasks. Our findings position LookAhead Tuning as a reliable and efficient solution for the safe and effective adaptation of LLMs.","authors":["Kangwei Liu","Mengru Wang","Yujie Luo","Lin Yuan","Mengshu Sun","Lei Liang","Zhiqiang Zhang","Jun Zhou","Bryan Hooi","Shumin Deng"],"pdf_url":"","comment":"WSDM 2026 short"},{"id":"http://arxiv.org/abs/2512.12218v2","updated":"2025-12-19T08:16:24Z","published":"2025-12-13T07:04:42Z","title":"Journey Before Destination: On the importance of Visual Faithfulness in Slow Thinking","summary":"Reasoning-augmented vision language models (VLMs) generate explicit chains of thought that promise greater capability and transparency but also introduce new failure modes: models may reach correct answers via visually unfaithful intermediate steps, or reason faithfully yet fail on the final prediction. Standard evaluations that only measure final-answer accuracy cannot distinguish these behaviors. We introduce the visual faithfulness of reasoning chains as a distinct evaluation dimension, focusing on whether the perception steps of a reasoning chain are grounded in the image. We propose a training- and reference-free framework that decomposes chains into perception versus reasoning steps and uses off-the-shelf VLM judges for step-level faithfulness, additionally verifying this approach through a human meta-evaluation. Building on this metric, we present a lightweight self-reflection procedure that detects and locally regenerates unfaithful perception steps without any training. Across multiple reasoning-trained VLMs and perception-heavy benchmarks, our method reduces Unfaithful Perception Rate while preserving final-answer accuracy, improving the reliability of multimodal reasoning.","authors":["Rheeya Uppaal","Phu Mon Htut","Min Bai","Nikolaos Pappas","Zheng Qi","Sandesh Swamy"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2512.17325v1","updated":"2025-12-19T08:14:21Z","published":"2025-12-19T08:14:21Z","title":"Task Schema and Binding: A Double Dissociation Study of In-Context Learning","summary":"We provide causal mechanistic validation that in-context learning (ICL) decomposes into two separable mechanisms: Task Schema (abstract task type recognition) and Binding (specific input-output associations). Through activation patching experiments across 9 models from 7 Transformer families plus Mamba (370M-13B parameters), we establish three key findings:\n  1. Double dissociation: Task Schema transfers at 100% via late MLP patching; Binding transfers at 62% via residual stream patching -- proving separable mechanisms\n  2. Prior-Schema trade-off: Schema reliance inversely correlates with prior knowledge (Spearman rho = -0.596, p < 0.001, N=28 task-model pairs)\n  3. Architecture generality: The mechanism operates across all tested architectures including the non-Transformer Mamba\n  These findings offer a mechanistic account of the ICL puzzle that contrasts with prior views treating ICL as a monolithic mechanism (whether retrieval-based, gradient descent-like, or purely Bayesian). By establishing that Schema and Binding are neurally dissociable -- not merely behavioral modes -- we provide causal evidence for dual-process theories of ICL. Models rely on Task Schema when prior knowledge is absent, but prior knowledge interferes through attentional mis-routing (72.7% recency bias) rather than direct output competition (0%). This explains why arbitrary mappings succeed (zero prior leads to full Schema reliance) while factual overrides fail -- and reveals that the true bottleneck is attentional, not output-level. Practical implications: Understanding these dual mechanisms enables more efficient prompt engineering -- reliable schema transfer reduces required demonstrations for novel tasks, while prior-aware design can mitigate the 38% binding failure rate in high-prior scenarios, improving ICL system reliability in production deployments.","authors":["Chaeha Kim"],"pdf_url":"","comment":"20pages, 2figures"},{"id":"http://arxiv.org/abs/2512.17316v1","updated":"2025-12-19T07:59:36Z","published":"2025-12-19T07:59:36Z","title":"Explanation Beyond Intuition: A Testable Criterion for Inherent Explainability","summary":"Inherent explainability is the gold standard in Explainable Artificial Intelligence (XAI). However, there is not a consistent definition or test to demonstrate inherent explainability. Work to date either characterises explainability through metrics, or appeals to intuition - \"we know it when we see it\". We propose a globally applicable criterion for inherent explainability. The criterion uses graph theory for representing and decomposing models for structure-local explanation, and recomposing them into global explanations. We form the structure-local explanations as annotations, a verifiable hypothesis-evidence structure that allows for a range of explanatory methods to be used. This criterion matches existing intuitions on inherent explainability, and provides justifications why a large regression model may not be explainable but a sparse neural network could be. We differentiate explainable -- a model that allows for explanation -- and \\textit{explained} -- one that has a verified explanation. Finally, we provide a full explanation of PREDICT -- a Cox proportional hazards model of cardiovascular disease risk, which is in active clinical use in New Zealand. It follows that PREDICT is inherently explainable. This work provides structure to formalise other work on explainability, and allows regulators a flexible but rigorous test that can be used in compliance frameworks.","authors":["Michael Merry","Pat Riddle","Jim Warren"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17299v1","updated":"2025-12-19T07:27:30Z","published":"2025-12-19T07:27:30Z","title":"M2RU: Memristive Minion Recurrent Unit for Continual Learning at the Edge","summary":"Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.","authors":["Abdullah M. Zyarah","Dhireesha Kudithipudi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.13478v4","updated":"2025-12-19T07:21:39Z","published":"2025-12-15T16:14:32Z","title":"Non-Resolution Reasoning (NRR): A Computational Framework for Contextual Identity and Ambiguity Preservation","summary":"Current artificial intelligence systems, despite remarkable capabilities in text generation and pattern recognition, exhibit a fundamental architectural limitation: they resolve ambiguity prematurely. This premature semantic collapse -- the tendency to collapse multiple valid interpretations into a single output -- stems from classical identity assumptions embedded in standard neural architectures. We propose Non-Resolution Reasoning (NRR), a computational framework that treats ambiguity retention as a valid reasoning mode rather than a defect to be eliminated. NRR introduces three core principles: (1) Non-Identity ($A \\neq A$) -- the same symbol refers to different entities across contexts; (2) Approximate Identity ($A \\approx A$) -- entities share partial structural overlap without being identical; and (3) Non-Resolution -- conflicting interpretations can coexist without forced convergence. We formalize these principles through three architectural components: Multi-Vector Embeddings for context-dependent representation, Non-Collapsing Attention for parallel interpretation retention, and Contextual Identity Tracking (CIT) for maintaining $A \\neq A$ across inference. We demonstrate NRR's advantages through case studies in paradox handling, creative generation, and context-dependent reasoning. Crucially, we provide a minimal empirical validation on a synthetic context-shift task where an NRR-lite model achieves 90.9% out-of-distribution accuracy compared to 9.1% for standard architectures, demonstrating that ambiguity preservation enables structural generalization. NRR challenges the assumption that meaning must collapse to be useful, offering a foundation for AI systems capable of sophisticated ambiguity handling and creative reasoning. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.","authors":["Kei Saito"],"pdf_url":"","comment":"16 pages, 1 figure. Updated version with corrected references and aligned acknowledgments"},{"id":"http://arxiv.org/abs/2510.16882v2","updated":"2025-12-19T07:13:05Z","published":"2025-10-19T15:32:01Z","title":"Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning","summary":"Supervised fine-tuning (SFT) is a commonly used technique to adapt large language models (LLMs) to downstream tasks. In practice, SFT on a full dataset is computationally expensive and sometimes suffers from overfitting or bias amplification. This facilitates the rise of data curation in SFT, which prioritizes the most valuable data to optimze. This work studies the online batch selection family that dynamically scores and filters samples during the training process. However, existing popular methods often (i) rely merely on the utility of data to select a subset while neglecting other crucial factors like diversity, (ii) rely on external resources such as reference models or validation sets, and (iii) incur extra training time over full-dataset training. To address these limitations, this work develops \\textbf{UDS (Utility-Diversity Sampling)}, a framework for efficient online batch selection in SFT. UDS leverages the nuclear norm of the logits matrix to capture both data utility and intra-sample diversity, while estimating inter-sample diversity through efficient low-dimensional embedding comparisons with a lightweight memory buffer of historical samples. Such a design eliminates the need for external resources and unnecessary backpropagation, securing computational efficiency. Experiments on multiple benchmarks demonstrate that UDS consistently outperforms state-of-the-art online batch selection methods under varying data budgets, and significantly reduces training time compared to full-dataset fine-tuning. Code is available at https://github.com/gfyddha/UDS.","authors":["Heming Zou","Yixiu Mao","Yun Qu","Qi Wang","Xiangyang Ji"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17281v1","updated":"2025-12-19T06:56:24Z","published":"2025-12-19T06:56:24Z","title":"LibriVAD: A Scalable Open Dataset with Deep Learning Benchmarks for Voice Activity Detection","summary":"Robust Voice Activity Detection (VAD) remains a challenging task, especially under noisy, diverse, and unseen acoustic conditions. Beyond algorithmic development, a key limitation in advancing VAD research is the lack of large-scale, systematically controlled, and publicly available datasets. To address this, we introduce LibriVAD - a scalable open-source dataset derived from LibriSpeech and augmented with diverse real-world and synthetic noise sources. LibriVAD enables systematic control over speech-to-noise ratio, silence-to-speech ratio (SSR), and noise diversity, and is released in three sizes (15 GB, 150 GB, and 1.5 TB) with two variants (LibriVAD-NonConcat and LibriVAD-Concat) to support different experimental setups. We benchmark multiple feature-model combinations, including waveform, Mel-Frequency Cepstral Coefficients (MFCC), and Gammatone filter bank cepstral coefficients, and introduce the Vision Transformer (ViT) architecture for VAD. Our experiments show that ViT with MFCC features consistently outperforms established VAD models such as boosted deep neural network and convolutional long short-term memory deep neural network across seen, unseen, and out-of-distribution (OOD) conditions, including evaluation on the real-world VOiCES dataset. We further analyze the impact of dataset size and SSR on model generalization, experimentally showing that scaling up dataset size and balancing SSR noticeably and consistently enhance VAD performance under OOD conditions. All datasets, trained models, and code are publicly released to foster reproducibility and accelerate progress in VAD research.","authors":["Ioannis Stylianou","Achintya kr. Sarkar","Nauman Dawalatabad","James Glass","Zheng-Hua Tan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.00040v2","updated":"2025-12-19T06:56:17Z","published":"2025-10-28T01:33:43Z","title":"Semi-Supervised Preference Optimization with Limited Feedback","summary":"The field of preference optimization has made outstanding contributions to the alignment of language models with human preferences. Despite these advancements, recent methods still rely heavily on substantial paired (labeled) feedback data, leading to substantial resource expenditures. To address these challenges, we study the problem of Semi-Supervised Preference Optimization (SSPO) in which the idea is to learn from both a small number of pairwise preference labels and a large pool of unpaired samples simultaneously. Our key theoretical contribution proves the existence of an optimal reward threshold capable of separating winning and losing responses with high probability, which enables a principled pseudo-labeling of unpaired data. By leveraging these pseudo-labels, SSPO effectively distills latent preferences from large-scale unpaired data, thus maintaining human alignment while drastically reducing acquisition costs. Extensive experiments across datasets validate this remarkable data efficiency; for instance, SSPO trained with Mistral-7B-Instruct on just 1% of UltraFeedback consistently surpasses strong baselines trained on 10% of UltraFeedback.","authors":["Seonggyun Lee","Sungjun Lim","Seojin Park","Soeun Cheon","Kyungwoo Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.15877v4","updated":"2025-12-19T06:49:59Z","published":"2024-05-24T18:40:20Z","title":"Basis Selection: Low-Rank Decomposition of Pretrained Large Language Models for Target Applications","summary":"Large language models (LLMs) significantly enhance the performance of various applications, but they are computationally intensive and energy-demanding. This makes it challenging to deploy them on devices with limited resources, such as personal computers and mobile/wearable devices, and results in substantial inference costs in resource-rich environments like cloud servers. To extend the use of LLMs, we introduce a low-rank decomposition approach to effectively compress these models, tailored to the requirements of specific applications. We observe that LLMs pretrained on general datasets contain many redundant components not needed for particular applications. Our method focuses on identifying and removing these redundant parts, retaining only the necessary elements for the target applications. Specifically, we represent the weight matrices of LLMs as a linear combination of base components. We then prune the irrelevant bases and enhance the model with new bases beneficial for specific applications. Deep compression results on the Llama 2-7b and -13B models, conducted on target applications including mathematical reasoning and code generation, show that our method significantly reduces model size while maintaining comparable accuracy to state-of-the-art low-rank compression techniques.","authors":["Yang Li","Daniel Agyei Asante","Changsheng Zhao","Ernie Chang","Yangyang Shi","Vikas Chandra"],"pdf_url":"","comment":"Transactions on Machine Learning Research (TMLR), 2025"},{"id":"http://arxiv.org/abs/2512.17277v1","updated":"2025-12-19T06:49:55Z","published":"2025-12-19T06:49:55Z","title":"Warmer for Less: A Cost-Efficient Strategy for Cold-Start Recommendations at Pinterest","summary":"Pinterest is a leading visual discovery platform where recommender systems (RecSys) are key to delivering relevant, engaging, and fresh content to our users. In this paper, we study the problem of improving RecSys model predictions for cold-start (CS) items, which appear infrequently in the training data. Although this problem is well-studied in academia, few studies have addressed its root causes effectively at the scale of a platform like Pinterest. By investigating live traffic data, we identified several challenges of the CS problem and developed a corresponding solution for each: First, industrial-scale RecSys models must operate under tight computational constraints. Since CS items are a minority, any related improvements must be highly cost-efficient. To address this, our solutions were designed to be lightweight, collectively increasing the total parameters by only 5%. Second, CS items are represented only by non-historical (e.g., content or attribute) features, which models often treat as less important. To elevate their significance, we introduce a residual connection for the non-historical features. Third, CS items tend to receive lower prediction scores compared to non-CS items, reducing their likelihood of being surfaced. We mitigate this by incorporating a score regularization term into the model. Fourth, the labels associated with CS items are sparse, making it difficult for the model to learn from them. We apply the manifold mixup technique to address this data sparsity. Implemented together, our methods increased fresh content engagement at Pinterest by 10% without negatively impacting overall engagement and cost, and have been deployed to serve over 570 million users on Pinterest.","authors":["Saeed Ebrahimi","Weijie Jiang","Jaewon Yang","Olafur Gudmundsson","Yucheng Tu","Huizhong Duan"],"pdf_url":"","comment":"Submitted to the WWW'26"},{"id":"http://arxiv.org/abs/2511.11571v2","updated":"2025-12-19T06:48:56Z","published":"2025-11-14T18:59:59Z","title":"Optimizing Mixture of Block Attention","summary":"Mixture of Block Attention (MoBA) (Lu et al., 2025) is a promising building block for efficiently processing long contexts in LLMs by enabling queries to sparsely attend to a small subset of key-value blocks, drastically reducing computational cost. However, the design principles governing MoBA's performance are poorly understood, and it lacks an efficient GPU implementation, hindering its practical adoption. In this paper, we first develop a statistical model to analyze MoBA's underlying mechanics. Our model reveals that performance critically depends on the router's ability to accurately distinguish relevant from irrelevant blocks based on query-key affinities. We derive a signal-to-noise ratio that formally connects architectural parameters to this retrieval accuracy. Guided by our analysis, we identify two key pathways for improvement: using smaller block sizes and applying a short convolution on keys to cluster relevant signals, which enhances routing accuracy. While theoretically better, small block sizes are inefficient on GPUs. To bridge this gap, we introduce FlashMoBA, a hardware-aware CUDA kernel that enables efficient MoBA execution even with the small block sizes our theory recommends. We validate our insights by training LLMs from scratch, showing that our improved MoBA models match the performance of dense attention baselines. FlashMoBA achieves up to 14.7x speedup over FlashAttention-2 for small blocks, making our theoretically-grounded improvements practical. Code is available at: https://github.com/mit-han-lab/flash-moba.","authors":["Guangxuan Xiao","Junxian Guo","Kasra Mazaheri","Song Han"],"pdf_url":"","comment":"The first two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2512.17276v1","updated":"2025-12-19T06:48:54Z","published":"2025-12-19T06:48:54Z","title":"Alzheimer's Disease Brain Network Mining","summary":"Machine learning approaches for Alzheimer's disease (AD) diagnosis face a fundamental challenges. Clinical assessments are expensive and invasive, leaving ground truth labels available for only a fraction of neuroimaging datasets. We introduce Multi view Adaptive Transport Clustering for Heterogeneous Alzheimer's Disease (MATCH-AD), a semi supervised framework that integrates deep representation learning, graph-based label propagation, and optimal transport theory to address this limitation. The framework leverages manifold structure in neuroimaging data to propagate diagnostic information from limited labeled samples to larger unlabeled populations, while using Wasserstein distances to quantify disease progression between cognitive states. Evaluated on nearly five thousand subjects from the National Alzheimer's Coordinating Center, encompassing structural MRI measurements from hundreds of brain regions, cerebrospinal fluid biomarkers, and clinical variables MATCHAD achieves near-perfect diagnostic accuracy despite ground truth labels for less than one-third of subjects. The framework substantially outperforms all baseline methods, achieving kappa indicating almost perfect agreement compared to weak agreement for the best baseline, a qualitative transformation in diagnostic reliability. Performance remains clinically useful even under severe label scarcity, and we provide theoretical convergence guarantees with proven bounds on label propagation error and transport stability. These results demonstrate that principled semi-supervised learning can unlock the diagnostic potential of the vast repositories of partially annotated neuroimaging data accumulating worldwide, substantially reducing annotation burden while maintaining accuracy suitable for clinical deployment.","authors":["Alireza Moayedikia","Sara Fin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17273v1","updated":"2025-12-19T06:42:16Z","published":"2025-12-19T06:42:16Z","title":"MINPO: Memory-Informed Neural Pseudo-Operator to Resolve Nonlocal Spatiotemporal Dynamics","summary":"Many physical systems exhibit nonlocal spatiotemporal behaviors described by integro-differential equations (IDEs). Classical methods for solving IDEs require repeatedly evaluating convolution integrals, whose cost increases quickly with kernel complexity and dimensionality. Existing neural solvers can accelerate selected instances of these computations, yet they do not generalize across diverse nonlocal structures. In this work, we introduce the Memory-Informed Neural Pseudo-Operator (MINPO), a unified framework for modeling nonlocal dynamics arising from long-range spatial interactions and/or long-term temporal memory. MINPO, employing either Kolmogorov-Arnold Networks (KANs) or multilayer perceptron networks (MLPs) as encoders, learns the nonlocal operator and its inverse directly through neural representations, and then explicitly reconstruct the unknown solution fields. The learning is guarded by a lightweight nonlocal consistency loss term to enforce coherence between the learned operator and reconstructed solution. The MINPO formulation allows to naturally capture and efficiently resolve nonlocal spatiotemporal dependencies governed by a wide spectrum of IDEs and their subsets, including fractional PDEs. We evaluate the efficacy of MINPO in comparison with classical techniques and state-of-the-art neural-based strategies based on MLPs, such as A-PINN and fPINN, along with their newly-developed KAN variants, A-PIKAN and fPIKAN, designed to facilitate a fair comparison. Our study offers compelling evidence of the accuracy of MINPO and demonstrates its robustness in handling (i) diverse kernel types, (ii) different kernel dimensionalities, and (iii) the substantial computational demands arising from repeated evaluations of kernel integrals. MINPO, thus, generalizes beyond problem-specific formulations, providing a unified framework for systems governed by nonlocal operators.","authors":["Farinaz Mostajeran","Aruzhan Tleubek","Salah A Faroughi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17270v1","updated":"2025-12-19T06:37:44Z","published":"2025-12-19T06:37:44Z","title":"Understanding Generalization in Role-Playing Models via Information Theory","summary":"Role-playing models (RPMs) are widely used in real-world applications but underperform when deployed in the wild. This degradation can be attributed to distribution shifts, including user, character, and dialogue compositional shifts. Existing methods like LLM-as-a-judge fall short in providing a fine-grained diagnosis of how these shifts affect RPM generalization, and thus there lack formal frameworks to characterize RPM generalization behaviors. To bridge these gaps, we introduce an information-theoretic metric, named reasoning-based effective mutual information difference (R-EMID), to measure RPM performance degradation in an interpretable way. We also derive an upper bound on R-EMID to predict the worst-case generalization performance of RPMs and theoretically reveal how various shifts contribute to the RPM performance degradation. Moreover, we propose a co-evolving reinforcement learning framework to adaptively model the connection among user, character, and dialogue context and thus enhance the estimation of dialogue response generation probability, which is critical for calculating R-EMID. Finally, we evaluate the generalization performance of various RPMs using R-EMID, finding that user shift poses the highest risk among all shifts and reinforcement learning is the most effective approach for enhancing RPM generalization.","authors":["Yongqi Li","Hao Lang","Fei Huang","Tieyun Qian","Yongbin Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17265v1","updated":"2025-12-19T06:29:51Z","published":"2025-12-19T06:29:51Z","title":"A Theoretical Analysis of State Similarity Between Markov Decision Processes","summary":"The bisimulation metric (BSM) is a powerful tool for analyzing state similarities within a Markov decision process (MDP), revealing that states closer in BSM have more similar optimal value functions. While BSM has been successfully utilized in reinforcement learning (RL) for tasks like state representation learning and policy exploration, its application to state similarity between multiple MDPs remains challenging. Prior work has attempted to extend BSM to pairs of MDPs, but a lack of well-established mathematical properties has limited further theoretical analysis between MDPs. In this work, we formally establish a generalized bisimulation metric (GBSM) for measuring state similarity between arbitrary pairs of MDPs, which is rigorously proven with three fundamental metric properties, i.e., GBSM symmetry, inter-MDP triangle inequality, and a distance bound on identical spaces. Leveraging these properties, we theoretically analyze policy transfer, state aggregation, and sampling-based estimation across MDPs, obtaining explicit bounds that are strictly tighter than existing ones derived from the standard BSM. Additionally, GBSM provides a closed-form sample complexity for estimation, improving upon existing asymptotic results based on BSM. Numerical results validate our theoretical findings and demonstrate the effectiveness of GBSM in multi-MDP scenarios.","authors":["Zhenyu Tao","Wei Xu","Xiaohu You"],"pdf_url":"","comment":"Submitted to an IEEE Transactions. arXiv admin note: substantial text overlap with arXiv:2509.18714"},{"id":"http://arxiv.org/abs/2512.17262v1","updated":"2025-12-19T06:25:05Z","published":"2025-12-19T06:25:05Z","title":"SHARP-QoS: Sparsely-gated Hierarchical Adaptive Routing for joint Prediction of QoS","summary":"Dependable service-oriented computing relies on multiple Quality of Service (QoS) parameters that are essential to assess service optimality. However, real-world QoS data are extremely sparse, noisy, and shaped by hierarchical dependencies arising from QoS interactions, and geographical and network-level factors, making accurate QoS prediction challenging. Existing methods often predict each QoS parameter separately, requiring multiple similar models, which increases computational cost and leads to poor generalization. Although recent joint QoS prediction studies have explored shared architectures, they suffer from negative transfer due to loss-scaling caused by inconsistent numerical ranges across QoS parameters and further struggle with inadequate representation learning, resulting in degraded accuracy. This paper presents an unified strategy for joint QoS prediction, called SHARP-QoS, that addresses these issues using three components. First, we introduce a dual mechanism to extract the hierarchical features from both QoS and contextual structures via hyperbolic convolution formulated in the Poincaré ball. Second, we propose an adaptive feature-sharing mechanism that allows feature exchange across informative QoS and contextual signals. A gated feature fusion module is employed to support dynamic feature selection among structural and shared representations. Third, we design an EMA-based loss balancing strategy that allows stable joint optimization, thereby mitigating the negative transfer. Evaluations on three datasets with two, three, and four QoS parameters demonstrate that SHARP-QoS outperforms both single- and multi-task baselines. Extensive study shows that our model effectively addresses major challenges, including sparsity, robustness to outliers, and cold-start, while maintaining moderate computational overhead, underscoring its capability for reliable joint QoS prediction.","authors":["Suraj Kumar","Arvind Kumar","Soumi Chattopadhyay"],"pdf_url":"","comment":"12 pages, 4 figures, 10 tables"},{"id":"http://arxiv.org/abs/2510.01384v3","updated":"2025-12-19T06:19:54Z","published":"2025-10-01T19:15:25Z","title":"Fine-Tuning Masked Diffusion for Provable Self-Correction","summary":"A natural desideratum for generative models is self-correction--detecting and revising low-quality tokens at inference. While Masked Diffusion Models (MDMs) have emerged as a promising approach for generative modeling in discrete spaces, their capacity for self-correction remains poorly understood. Prior attempts to incorporate self-correction into MDMs either require overhauling MDM architectures/training or rely on imprecise proxies for token quality, limiting their applicability. Motivated by this, we introduce PRISM--Plug-in Remasking for Inference-time Self-correction of Masked Diffusions--a lightweight, model-agnostic approach that applies to any pretrained MDM. Theoretically, PRISM defines a self-correction loss that provably learns per-token quality scores, without RL or a verifier. These quality scores are computed in the same forward pass with MDM and used to detect low-quality tokens. Empirically, PRISM advances MDM inference across domains and scales: Sudoku; unconditional text (170M); and code with LLaDA (8B).","authors":["Jaeyeon Kim","Seunggeun Kim","Taekyun Lee","David Z. Pan","Hyeji Kim","Sham Kakade","Sitan Chen"],"pdf_url":"","comment":"Authorship statement: Jaeyeon Kim and Seunggeun Kim contributed equally, and Taekyun Lee is also a co first author"},{"id":"http://arxiv.org/abs/2512.17259v1","updated":"2025-12-19T06:12:43Z","published":"2025-12-19T06:12:43Z","title":"Verifiability-First Agents: Provable Observability and Lightweight Audit Agents for Controlling Autonomous LLM Systems","summary":"As LLM-based agents grow more autonomous and multi-modal, ensuring they remain controllable, auditable, and faithful to deployer intent becomes critical. Prior benchmarks measured the propensity for misaligned behavior and showed that agent personalities and tool access significantly influence misalignment. Building on these insights, we propose a Verifiability-First architecture that (1) integrates run-time attestations of agent actions using cryptographic and symbolic methods, (2) embeds lightweight Audit Agents that continuously verify intent versus behavior using constrained reasoning, and (3) enforces challenge-response attestation protocols for high-risk operations. We introduce OPERA (Observability, Provable Execution, Red-team, Attestation), a benchmark suite and evaluation protocol designed to measure (i) detectability of misalignment, (ii) time to detection under stealthy strategies, and (iii) resilience of verifiability mechanisms to adversarial prompt and persona injection. Our approach shifts the evaluation focus from how likely misalignment is to how quickly and reliably misalignment can be detected and remediated.","authors":["Abhivansh Gupta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.06699v2","updated":"2025-12-19T06:10:50Z","published":"2025-12-07T07:25:08Z","title":"Predictive Modeling of I/O Performance for Machine Learning Training Pipelines: A Data-Driven Approach to Storage Optimization","summary":"Modern machine learning training is increasingly bottlenecked by data I/O rather than compute. GPUs often sit idle at below 50% utilization waiting for data. This paper presents a machine learning approach to predict I/O performance and recommend optimal storage configurations for ML training pipelines. We collected 141 observations through systematic benchmarking across different storage backends (NVMe SSD, network-attached storage, in-memory filesystems), data formats, and access patterns, covering both low-level I/O operations and full training pipelines. After evaluating seven regression models and three classification approaches, XGBoost achieved the best performance with R-squared of 0.991, predicting I/O throughput within 11.8% error on average. Feature importance analysis revealed that throughput metrics and batch size are the primary performance drivers. This data-driven approach can reduce configuration time from days of trial-and-error to minutes of predictive recommendation. The methodology is reproducible and extensible to other resource management problems in ML systems. Code and data are available at https://github.com/knkarthik01/gpu_storage_ml_project","authors":["Karthik Prabhakar","Durgamadhab Mishra"],"pdf_url":"","comment":"20 pages, 10 figures"},{"id":"http://arxiv.org/abs/2509.25977v2","updated":"2025-12-19T06:08:01Z","published":"2025-09-30T09:09:33Z","title":"Data-Free Continual Learning of Server Models in Model-Heterogeneous Cloud-Device Collaboration","summary":"The rise of cloud-device collaborative computing has enabled intelligent services to be delivered across distributed edge devices while leveraging centralized cloud resources. In this paradigm, federated learning (FL) has become a key enabler for privacy-preserving model training without transferring raw data from edge devices to the cloud. However, with the continuous emergence of new data and increasing model diversity, traditional federated learning faces significant challenges, including inherent issues of data heterogeneity, model heterogeneity and catastrophic forgetting, along with new challenge of knowledge misalignment. In this study, we introduce FedDCL, a novel framework designed to enable data-free continual learning of the server model in a model-heterogeneous federated setting. We leverage pre-trained diffusion models to extract lightweight class-specific prototypes, which confer a threefold data-free advantage, enabling: (1) generation of synthetic data for the current task to augment training and counteract non-IID data distributions; (2) exemplar-free generative replay for retaining knowledge from previous tasks; and (3) data-free dynamic knowledge transfer from heterogeneous devices to the cloud server.Experimental results on various datasets demonstrate the effectiveness of FedDCL, showcasing its potential to enhance the generalizability and practical applicability of federated cloud-device collaboration in dynamic settings.","authors":["Xiao Zhang","Zengzhe Chen","Yuan Yuan","Yifei Zou","Fuzhen Zhuang","Wenyu Jiao","Yuke Wang","Dongxiao Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17257v1","updated":"2025-12-19T06:07:41Z","published":"2025-12-19T06:07:41Z","title":"Electric Vehicle Charging Load Forecasting: An Experimental Comparison of Machine Learning Methods","summary":"With the growing popularity of electric vehicles as a means of addressing climate change, concerns have emerged regarding their impact on electric grid management. As a result, predicting EV charging demand has become a timely and important research problem. While substantial research has addressed energy load forecasting in transportation, relatively few studies systematically compare multiple forecasting methods across different temporal horizons and spatial aggregation levels in diverse urban settings. This work investigates the effectiveness of five time series forecasting models, ranging from traditional statistical approaches to machine learning and deep learning methods. Forecasting performance is evaluated for short-, mid-, and long-term horizons (on the order of minutes, hours, and days, respectively), and across spatial scales ranging from individual charging stations to regional and city-level aggregations. The analysis is conducted on four publicly available real-world datasets, with results reported independently for each dataset. To the best of our knowledge, this is the first work to systematically evaluate EV charging demand forecasting across such a wide range of temporal horizons and spatial aggregation levels using multiple real-world datasets.","authors":["Iason Kyriakopoulos","Yannis Theodoridis"],"pdf_url":"","comment":"18 pages, 2 figures, 5 tables"},{"id":"http://arxiv.org/abs/2512.17254v1","updated":"2025-12-19T05:52:35Z","published":"2025-12-19T05:52:35Z","title":"Practical Framework for Privacy-Preserving and Byzantine-robust Federated Learning","summary":"Federated Learning (FL) allows multiple clients to collaboratively train a model without sharing their private data. However, FL is vulnerable to Byzantine attacks, where adversaries manipulate client models to compromise the federated model, and privacy inference attacks, where adversaries exploit client models to infer private data. Existing defenses against both backdoor and privacy inference attacks introduce significant computational and communication overhead, creating a gap between theory and practice. To address this, we propose ABBR, a practical framework for Byzantine-robust and privacy-preserving FL. We are the first to utilize dimensionality reduction to speed up the private computation of complex filtering rules in privacy-preserving FL. Additionally, we analyze the accuracy loss of vector-wise filtering in low-dimensional space and introduce an adaptive tuning strategy to minimize the impact of malicious models that bypass filtering on the global model. We implement ABBR with state-of-the-art Byzantine-robust aggregation rules and evaluate it on public datasets, showing that it runs significantly faster, has minimal communication overhead, and maintains nearly the same Byzantine-resilience as the baselines.","authors":["Baolei Zhang","Minghong Fang","Zhuqing Liu","Biao Yi","Peizhao Zhou","Yuan Wang","Tong Li","Zheli Liu"],"pdf_url":"","comment":"Accepted for publication in IEEE Transactions on Information Forensics and Security"},{"id":"http://arxiv.org/abs/2512.17251v1","updated":"2025-12-19T05:36:23Z","published":"2025-12-19T05:36:23Z","title":"AlignDP: Hybrid Differential Privacy with Rarity-Aware Protection for LLMs","summary":"Large language models are exposed to risks of extraction, distillation, and unauthorized fine-tuning. Existing defenses use watermarking or monitoring, but these act after leakage. We design AlignDP, a hybrid privacy lock that blocks knowledge transfer at the data interface. The key idea is to separate rare and non-rare fields. Rare fields are shielded by PAC indistinguishability, giving effective zero-epsilon local DP. Non-rare fields are privatized with RAPPOR, giving unbiased frequency estimates under local DP. A global aggregator enforces composition and budget. This two-tier design hides rare events and adds controlled noise to frequent events. We prove limits of PAC extension to global aggregation, give bounds for RAPPOR estimates, and analyze utility trade-off. A toy simulation confirms feasibility: rare categories remain hidden, frequent categories are recovered with small error.","authors":["Madhava Gaikwad"],"pdf_url":"","comment":"39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: LOCK-LLM Work-shop, NeurIPS 2025"},{"id":"http://arxiv.org/abs/2512.17245v1","updated":"2025-12-19T05:22:54Z","published":"2025-12-19T05:22:54Z","title":"Machine Learning Assisted Parameter Tuning on Wavelet Transform Amorphous Radial Distribution Function","summary":"Understanding atomic structures is crucial, yet amorphous materials remain challenging due to their irregular and non-periodic nature. The wavelet-transform radial distribution function (WT-RDF) offers a physics-based framework for analyzing amorphous structures, reliably predicting the first and second RDF peaks and overall curve trends in both binary Ge 0.25 Se 0.75 and ternary Ag x(Ge 0.25 Se 0.75)100-x (x=5,10,15,20,25) systems. Despite these strengths, WT-RDF shows limitations in amplitude accuracy, which affects quantitative analyses such as coordination numbers. This study addresses the issue by optimizing WT-RDF parameters using a machine learning approach, producing the enhanced WT-RDF+ framework. WT-RDF+ improves the precision of peak predictions and outperforms benchmark ML models, including RBF and LSTM, even when trained on only 25 percent of the binary dataset. These results demonstrate that WT-RDF+ is a robust and reliable model for structural characterization of amorphous materials, particularly Ge-Se systems, and support the efficient design and development of phase-change thin films for next-generation electronic devices and components.","authors":["Deriyan Senjaya","Stephen Ekaputra Limantoro"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2401.15502v3","updated":"2025-12-19T05:07:43Z","published":"2024-01-27T21:07:11Z","title":"Differentially private Bayesian tests","summary":"Differential privacy has emerged as an significant cornerstone in the realm of scientific hypothesis testing utilizing confidential data. In reporting scientific discoveries, Bayesian tests are widely adopted since they effectively circumnavigate the key criticisms of P-values, namely, lack of interpretability and inability to quantify evidence in support of the competing hypotheses. We present a novel differentially private Bayesian hypotheses testing framework that arise naturally under a principled data generative mechanism, inherently maintaining the interpretability of the resulting inferences. Furthermore, by focusing on differentially private Bayes factors based on widely used test statistics, we circumvent the need to model the complete data generative mechanism and ensure substantial computational benefits. We also provide a set of sufficient conditions to establish results on Bayes factor consistency under the proposed framework. The utility of the devised technology is showcased via several numerical experiments.","authors":["Abhisek Chakraborty","Saptati Datta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.07540v2","updated":"2025-12-19T04:16:55Z","published":"2025-12-08T13:21:44Z","title":"Minimum Bayes Risk Decoding for Error Span Detection in Reference-Free Automatic Machine Translation Evaluation","summary":"Error Span Detection (ESD) extends automatic machine translation (MT) evaluation by localizing translation errors and labeling their severity. Current generative ESD methods typically use Maximum a Posteriori (MAP) decoding, assuming that the model-estimated probabilities are perfectly correlated with similarity to the human annotation, but we often observe higher likelihood assigned to an incorrect annotation than to the human one. We instead apply Minimum Bayes Risk (MBR) decoding to generative ESD. We use a sentence- or span-level similarity function for MBR decoding, which selects candidate hypotheses based on their approximate similarity to the human annotation. Experimental results on the WMT24 Metrics Shared Task show that MBR decoding significantly improves span-level performance and generally matches or outperforms MAP at the system and sentence levels. To reduce the computational cost of MBR decoding, we further distill its decisions into a model decoded via greedy search, removing the inference-time latency bottleneck.","authors":["Boxuan Lyu","Haiyue Song","Hidetaka Kamigaito","Chenchen Ding","Hideki Tanaka","Masao Utiyama","Kotaro Funakoshi","Manabu Okumura"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.00277v4","updated":"2025-12-19T04:07:05Z","published":"2025-02-01T02:24:31Z","title":"Regularized Langevin Dynamics for Combinatorial Optimization","summary":"This work proposes a simple yet effective sampling framework for combinatorial optimization (CO). Our method builds on discrete Langevin dynamics (LD), an efficient gradient-guided generative paradigm. However, we observe that directly applying LD often leads to limited exploration. To overcome this limitation, we propose the Regularized Langevin Dynamics (RLD), which enforces an expected distance between the sampled and current solutions, effectively avoiding local minima. We develop two CO solvers on top of RLD, one based on simulated annealing (SA), and the other one based on neural network (NN). Empirical results on three classic CO problems demonstrate that both of our methods can achieve comparable or better performance against the previous state-of-the-art (SOTA) SA- and NN-based solvers. In particular, our SA algorithm reduces the runtime of the previous SOTA SA method by up to 80\\%, while achieving equal or superior performance. In summary, RLD offers a promising framework for enhancing both traditional heuristics and NN models to solve CO problems. Our code is available at https://github.com/Shengyu-Feng/RLD4CO.","authors":["Shengyu Feng","Yiming Yang"],"pdf_url":"","comment":"ICML 2025"},{"id":"http://arxiv.org/abs/2511.23083v4","updated":"2025-12-19T03:50:56Z","published":"2025-11-28T11:14:15Z","title":"Spectral Concentration at the Edge of Stability: Information Geometry of Kernel Associative Memory","summary":"High-capacity kernel Hopfield networks exhibit a \\textit{Ridge of Optimization} characterized by extreme stability. While previously linked to \\textit{Spectral Concentration}, its origin remains elusive. Here, we analyze the network dynamics on a statistical manifold, revealing that the Ridge corresponds to the Edge of Stability, a critical boundary where the Fisher Information Matrix becomes singular. We demonstrate that the apparent Euclidean force antagonism is a manifestation of \\textit{Dual Equilibrium} in the Riemannian space. This unifies learning dynamics and capacity via the Minimum Description Length principle, offering a geometric theory of self-organized criticality.","authors":["Akira Tamamori"],"pdf_url":"","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2512.17213v1","updated":"2025-12-19T03:50:42Z","published":"2025-12-19T03:50:42Z","title":"CheXPO-v2: Preference Optimization for Chest X-ray VLMs with Knowledge Graph Consistency","summary":"Medical Vision-Language Models (VLMs) are prone to hallucinations, compromising clinical reliability. While reinforcement learning methods like Group Relative Policy Optimization (GRPO) offer a low-cost alignment solution, their reliance on sparse, outcome-based rewards inadvertently encourages models to \"overthink\" -- generating verbose, convoluted, and unverifiable Chain-of-Thought reasoning to justify answers. This focus on outcomes obscures factual errors and poses significant safety risks. To address this, we propose CheXPO-v2, a novel alignment framework that shifts from outcome to process supervision. Our core innovation is a Knowledge Graph Consistency Reward mechanism driven by Entity-Relation Matching. By explicitly parsing reasoning steps into structured \"Disease, Relation, Anatomy\" triplets, we provide fine-grained supervision that penalizes incoherent logic and hallucinations at the atomic level. Integrating this with a hard-example mining strategy, our approach significantly outperforms GRPO and state-of-the-art models on benchmarks like MIMIC-CXR-VQA. Crucially, CheXPO-v2 achieves new state-of-the-art accuracy using only 5k samples, demonstrating exceptional data efficiency while producing clinically sound and verifiable reasoning. The project source code is publicly available at: https://github.com/ecoxial2007/CheX-Phi4MM.","authors":["Xiao Liang","Yuxuan An","Di Wang","Jiawei Hu","Zhicheng Jiao","Bin Jing","Quan Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17209v1","updated":"2025-12-19T03:42:47Z","published":"2025-12-19T03:42:47Z","title":"Do Foundational Audio Encoders Understand Music Structure?","summary":"In music information retrieval (MIR) research, the use of pretrained foundational audio encoders (FAEs) has recently become a trend. FAEs pretrained on large amounts of music and audio data have been shown to improve performance on MIR tasks such as music tagging and automatic music transcription. However, their use for music structure analysis (MSA) remains underexplored. Although many open-source FAE models are available, only a small subset has been examined for MSA, and the impact of factors such as learning methods, training data, and model context length on MSA performance remains unclear. In this study, we conduct comprehensive experiments on 11 types of FAEs to investigate how these factors affect MSA performance. Our results demonstrate that FAEs using selfsupervised learning with masked language modeling on music data are particularly effective for MSA. These findings pave the way for future research in MSA.","authors":["Keisuke Toyama","Zhi Zhong","Akira Takahashi","Shusuke Takahashi","Yuki Mitsufuji"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.09496v2","updated":"2025-12-19T03:39:47Z","published":"2025-02-13T17:03:03Z","title":"On Agnostic PAC Learning in the Small Error Regime","summary":"Binary classification in the classic PAC model exhibits a curious phenomenon: Empirical Risk Minimization (ERM) learners are suboptimal in the realizable case yet optimal in the agnostic case. Roughly speaking, this owes itself to the fact that non-realizable distributions $\\mathcal{D}$ are simply more difficult to learn than realizable distributions -- even when one discounts a learner's error by $\\mathrm{err}(h^*_{\\mathcal{D}})$, the error of the best hypothesis in $\\mathcal{H}$ for $\\mathcal{D}$. Thus, optimal agnostic learners are permitted to incur excess error on (easier-to-learn) distributions $\\mathcal{D}$ for which $τ= \\mathrm{err}(h^*_{\\mathcal{D}})$ is small.\n  Recent work of Hanneke, Larsen, and Zhivotovskiy (FOCS `24) addresses this shortcoming by including $τ$ itself as a parameter in the agnostic error term. In this more fine-grained model, they demonstrate tightness of the error lower bound $τ+ Ω\\left(\\sqrt{\\frac{τ(d + \\log(1 / δ))}{m}} + \\frac{d + \\log(1 / δ)}{m} \\right)$ in a regime where $τ> d/m$, and leave open the question of whether there may be a higher lower bound when $τ\\approx d/m$, with $d$ denoting $\\mathrm{VC}(\\mathcal{H})$. In this work, we resolve this question by exhibiting a learner which achieves error $c \\cdot τ+ O \\left(\\sqrt{\\frac{τ(d + \\log(1 / δ))}{m}} + \\frac{d + \\log(1 / δ)}{m} \\right)$ for a constant $c \\leq 2.1$, thus matching the lower bound when $τ\\approx d/m$. Further, our learner is computationally efficient and is based upon careful aggregations of ERM classifiers, making progress on two other questions of Hanneke, Larsen, and Zhivotovskiy (FOCS `24). We leave open the interesting question of whether our approach can be refined to lower the constant from 2.1 to 1, which would completely settle the complexity of agnostic learning.","authors":["Julian Asilis","Mikael Møller Høgsgaard","Grigoris Velegkas"],"pdf_url":"","comment":"36 pages, NeurIPS 2025"},{"id":"http://arxiv.org/abs/2512.17203v1","updated":"2025-12-19T03:29:23Z","published":"2025-12-19T03:29:23Z","title":"Learning solution operator of dynamical systems with diffusion maps kernel ridge regression","summary":"Many scientific and engineering systems exhibit complex nonlinear dynamics that are difficult to predict accurately over long time horizons. Although data-driven models have shown promise, their performance often deteriorates when the geometric structures governing long-term behavior are unknown or poorly represented. We demonstrate that a simple kernel ridge regression (KRR) framework, when combined with a dynamics-aware validation strategy, provides a strong baseline for long-term prediction of complex dynamical systems. By employing a data-driven kernel derived from diffusion maps, the proposed Diffusion Maps Kernel Ridge Regression (DM-KRR) method implicitly adapts to the intrinsic geometry of the system's invariant set, without requiring explicit manifold reconstruction or attractor modeling, procedures that often limit predictive performance. Across a broad range of systems, including smooth manifolds, chaotic attractors, and high-dimensional spatiotemporal flows, DM-KRR consistently outperforms state-of-the-art random feature, neural-network and operator-learning methods in both accuracy and data efficiency. These findings underscore that long-term predictive skill depends not only on model expressiveness, but critically on respecting the geometric constraints encoded in the data through dynamically consistent model selection. Together, simplicity, geometry awareness, and strong empirical performance point to a promising path for reliable and efficient learning of complex dynamical systems.","authors":["Jiwoo Song","Daning Huang","John Harlim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.19009v3","updated":"2025-12-19T03:29:08Z","published":"2025-08-26T13:14:29Z","title":"Dual-Distilled Heterogeneous Federated Learning with Adaptive Margins for Trainable Global Prototypes","summary":"Heterogeneous Federated Learning (HFL) has gained significant attention for its capacity to handle both model and data heterogeneity across clients. Prototype-based HFL methods emerge as a promising solution to address statistical and model heterogeneity as well as privacy challenges, paving the way for new advancements in HFL research. This method focuses on sharing class-representative prototypes among heterogeneous clients. However, aggregating these prototypes via standard weighted averaging often yields sub-optimal global knowledge. Specifically, the averaging approach induces a shrinking of the aggregated prototypes' decision margins, thereby degrading model performance in scenarios with model heterogeneity and non-IID data distributions. The propose FedProtoKD in a Heterogeneous Federated Learning setting, utilizing an enhanced dual-knowledge distillation mechanism to enhance system performance by leveraging clients' logits and prototype feature representations. The proposed framework aims to resolve the prototype margin-shrinking problem using a contrastive learning-based trainable server prototype by leveraging a class-wise adaptive prototype margin. Furthermore, the framework assess the importance of public samples using the closeness of the sample's prototype to its class representative prototypes, which enhances learning performance. FedProtoKD improved test accuracy by an average of 1.13% and up to 34.13% across various settings, significantly outperforming existing state-of-the-art HFL methods.","authors":["Fatema Siddika","Md Anwar Hossen","Wensheng Zhang","Anuj Sharma","Juan Pablo Muñoz","Ali Jannesari"],"pdf_url":"","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2512.17198v1","updated":"2025-12-19T03:25:05Z","published":"2025-12-19T03:25:05Z","title":"BumpNet: A Sparse Neural Network Framework for Learning PDE Solutions","summary":"We introduce BumpNet, a sparse neural network framework for PDE numerical solution and operator learning. BumpNet is based on meshless basis function expansion, in a similar fashion to radial-basis function (RBF) networks. Unlike RBF networks, the basis functions in BumpNet are constructed from ordinary sigmoid activation functions. This enables the efficient use of modern training techniques optimized for such networks. All parameters of the basis functions, including shape, location, and amplitude, are fully trainable. Model parsimony and h-adaptivity are effectively achieved through dynamically pruning basis functions during training. BumpNet is a general framework that can be combined with existing neural architectures for learning PDE solutions: here, we propose Bump-PINNs (BumpNet with physics-informed neural networks) for solving general PDEs; Bump-EDNN (BumpNet with evolutionary deep neural networks) to solve time-evolution PDEs; and Bump-DeepONet (BumpNet with deep operator networks) for PDE operator learning. Bump-PINNs are trained using the same collocation-based approach used by PINNs, Bump-EDNN uses a BumpNet only in the spatial domain and uses EDNNs to advance the solution in time, while Bump-DeepONets employ a BumpNet regression network as the trunk network of a DeepONet. Extensive numerical experiments demonstrate the efficiency and accuracy of the proposed architecture.","authors":["Shao-Ting Chiu","Ioannis G. Kevrekidis","Ulisses Braga-Neto"],"pdf_url":"","comment":null}],"Operating Systems":[{"id":"http://arxiv.org/abs/2512.16238v2","updated":"2025-12-19T09:05:37Z","published":"2025-12-18T06:33:24Z","title":"Trustworthy and Controllable Professional Knowledge Utilization in Large Language Models with TEE-GPU Execution","summary":"Future improvements in large language model (LLM) services increasingly hinge on access to high-value professional knowledge rather than more generic web data. However, the data providers of this knowledge face a skewed tradeoff between income and risk: they receive little share of downstream value yet retain copyright and privacy liability, making them reluctant to contribute their assets to LLM services. Existing techniques do not offer a trustworthy and controllable way to use professional knowledge, because they keep providers in the dark and combine knowledge parameters with the underlying LLM backbone.\n  In this paper, we present PKUS, the Professional Knowledge Utilization System, which treats professional knowledge as a first-class, separable artifact. PKUS keeps the backbone model on GPUs and encodes each provider's contribution as a compact adapter that executes only inside an attested Trusted Execution Environment (TEE). A hardware-rooted lifecycle protocol, adapter pruning, multi-provider aggregation, and split-execution scheduling together make this design practical at serving time. On SST-2, MNLI, and SQuAD with GPT-2 Large and Llama-3.2-1B, PKUS preserves model utility, matching the accuracy and F1 of full fine-tuning and plain LoRA, while achieving the lowest per-request latency with 8.1-11.9x speedup over CPU-only TEE inference and naive CPU-GPU co-execution.","authors":["Yifeng Cai","Zhida An","Yuhan Meng","Houqian Liu","Pengli Wang","Hanwen Lei","Yao Guo","Ding Li"],"pdf_url":"","comment":null}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2512.17834v1","updated":"2025-12-19T17:43:21Z","published":"2025-12-19T17:43:21Z","title":"A 14ns-Latency 9Gb/s 0.44mm$^2$ 62pJ/b Short-Blocklength LDPC Decoder ASIC in 22FDX","summary":"Ultra-reliable low latency communication (URLLC) is a key part of 5G wireless systems. Achieving low latency necessitates codes with short blocklengths for which polar codes with successive cancellation list (SCL) decoding typically outperform message-passing (MP)-based decoding of low-density parity-check (LDPC) codes. However, SCL decoders are known to exhibit high latency and poor area efficiency. In this paper, we propose a new short-blocklength multi-rate binary LDPC code that outperforms the 5G-LDPC code for the same blocklength and is suitable for URLLC applications using fully parallel MP. To demonstrate our code's efficacy, we present a 0.44mm$^2$ GlobalFoundries 22FDX LDPC decoder ASIC which supports three rates and achieves the lowest-in-class decoding latency of 14ns while reaching an information throughput of 9Gb/s at 62pJ/b energy efficiency for a rate-1/2 code with 128-bit blocklength.","authors":["Darja Nonaca","Jérémy Guichemerre","Reinhard Wiesmayr","Nihat Engin Tunali","Christoph Studer"],"pdf_url":"","comment":"Presented at the 2025 IEEE European Solid-State Electronics Research Conference (ESSERC)"},{"id":"http://arxiv.org/abs/2512.17814v1","updated":"2025-12-19T17:19:08Z","published":"2025-12-19T17:19:08Z","title":"LLM-based Behaviour Driven Development for Hardware Design","summary":"Test and verification are essential activities in hardware and system design, but their complexity grows significantly with increasing system sizes. While Behavior Driven Development (BDD) has proven effective in software engineering, it is not yet well established in hardware design, and its practical use remains limited. One contributing factor is the manual effort required to derive precise behavioral scenarios from textual specifications.\n  Recent advances in Large Language Models (LLMs) offer new opportunities to automate this step. In this paper, we investigate the use of LLM-based techniques to support BDD in the context of hardware design.","authors":["Rolf Drechsler","Qian Liu"],"pdf_url":"","comment":"7 pages, keynote given at 2nd International Symposium on Artificial Intelligence and Internet of Things (AIIoT-25), December 22-24th, 2025"},{"id":"http://arxiv.org/abs/2512.12068v2","updated":"2025-12-19T15:19:22Z","published":"2025-12-12T22:30:31Z","title":"TreeVQA: A Tree-Structured Execution Framework for Shot Reduction in Variational Quantum Algorithms","summary":"Variational Quantum Algorithms (VQAs) are promising for near- and intermediate-term quantum computing, but their execution cost is substantial. Each task requires many iterations and numerous circuits per iteration, and real-world applications often involve multiple tasks, scaling with the precision needed to explore the application's energy landscape. This demands an enormous number of execution shots, making practical use prohibitively expensive. We observe that VQA costs can be significantly reduced by exploiting execution similarities across an application's tasks. Based on this insight, we propose TreeVQA, a tree-based execution framework that begins by executing tasks jointly and progressively branches only as their quantum executions diverge. Implemented as a VQA wrapper, TreeVQA integrates with typical VQA applications. Evaluations on scientific and combinatorial benchmarks show shot count reductions of $25.9\\times$ on average and over $100\\times$ for large-scale problems at the same target accuracy. The benefits grow further with increasing problem size and precision requirements.","authors":["Yuewen Hou","Dhanvi Bharadwaj","Gokul Subramanian Ravi"],"pdf_url":"","comment":"To appear at 31st ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS 2026)"},{"id":"http://arxiv.org/abs/2512.17589v1","updated":"2025-12-19T13:57:25Z","published":"2025-12-19T13:57:25Z","title":"Torrent: A Distributed DMA for Efficient and Flexible Point-to-Multipoint Data Movement","summary":"The growing disparity between computational power and on-chip communication bandwidth is a critical bottleneck in modern Systems-on-Chip (SoCs), especially for data-parallel workloads like AI. Efficient point-to-multipoint (P2MP) data movement, such as multicast, is essential for high performance. However, native multicast support is lacking in standard interconnect protocols. Existing P2MP solutions, such as multicast-capable Network-on-Chip (NoC), impose additional overhead to the network hardware and require modifications to the interconnect protocol, compromising scalability and compatibility.\n  This paper introduces Torrent, a novel distributed DMA architecture that enables efficient P2MP data transfers without modifying NoC hardware and interconnect protocol. Torrent conducts P2MP data transfers by forming logical chains over the NoC, where the data traverses through targeted destinations resembling a linked list. This Chainwrite mechanism preserves the P2P nature of every data transfer while enabling flexible data transfers to an unlimited number of destinations. To optimize the performance and energy consumption of Chainwrite, two scheduling algorithms are developed to determine the optimal chain order based on NoC topology.\n  Our RTL and FPGA prototype evaluations using both synthetic and real workloads demonstrate significant advantages in performance, flexibility, and scalability over network-layer multicast. Compared to the unicast baseline, Torrent achieves up to a 7.88x speedup. ASIC synthesis on 16nm technology confirms the architecture's minimal footprint in area (1.2%) and power (2.3%). Thanks to the Chainwrite, Torrent delivers scalable P2MP data transfers with a small cycle overhead of 82CC and area overhead of 207um2 per destination.","authors":["Yunhao Deng","Fanchen Kong","Xiaoling Yi","Ryan Antonio","Marian Verhelst"],"pdf_url":"","comment":"7 pages, 11 figures, Proceeded by the 2026 Design, Automation and Test in Europe Conference (DATE 26)"},{"id":"http://arxiv.org/abs/2512.12284v2","updated":"2025-12-19T08:02:44Z","published":"2025-12-13T11:02:04Z","title":"V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval","summary":"Streaming video large language models (LLMs) are increasingly used for real-time multimodal tasks such as video captioning, question answering, conversational agents, and augmented reality. However, these models face fundamental memory and computational challenges because their key-value (KV) caches grow substantially with continuous streaming video input. This process requires an iterative prefill stage, which is a unique feature of streaming video LLMs. Due to its iterative prefill stage, it suffers from significant limitations, including extensive computation, substantial data transfer, and degradation in accuracy. Crucially, this issue is exacerbated for edge deployment, which is the primary target for these models.\n  In this work, we propose V-Rex, the first software-hardware co-designed accelerator that comprehensively addresses both algorithmic and hardware bottlenecks in streaming video LLM inference. At its core, V-Rex introduces ReSV, a training-free dynamic KV cache retrieval algorithm. ReSV exploits temporal and spatial similarity-based token clustering to reduce excessive KV cache memory across video frames. To fully realize these algorithmic benefits, V-Rex offers a compact, low-latency hardware accelerator with a dynamic KV cache retrieval engine (DRE), featuring bit-level and early-exit based computing units. V-Rex achieves unprecedented real-time of 3.9-8.3 FPS and energy-efficient streaming video LLM inference on edge deployment with negligible accuracy loss. While DRE only accounts for 2.2% power and 2.0% area, the system delivers 1.9-19.7x speedup and 3.1-18.5x energy efficiency improvements over AGX Orin GPU. This work is the first to comprehensively tackle KV cache retrieval across algorithms and hardware, enabling real-time streaming video LLM inference on resource-constrained edge devices.","authors":["Donghyuk Kim","Sejeong Yang","Wonjin Shin","Joo-Young Kim"],"pdf_url":"","comment":"14 pages, 20 figures, conference"},{"id":"http://arxiv.org/abs/2405.15877v4","updated":"2025-12-19T06:49:59Z","published":"2024-05-24T18:40:20Z","title":"Basis Selection: Low-Rank Decomposition of Pretrained Large Language Models for Target Applications","summary":"Large language models (LLMs) significantly enhance the performance of various applications, but they are computationally intensive and energy-demanding. This makes it challenging to deploy them on devices with limited resources, such as personal computers and mobile/wearable devices, and results in substantial inference costs in resource-rich environments like cloud servers. To extend the use of LLMs, we introduce a low-rank decomposition approach to effectively compress these models, tailored to the requirements of specific applications. We observe that LLMs pretrained on general datasets contain many redundant components not needed for particular applications. Our method focuses on identifying and removing these redundant parts, retaining only the necessary elements for the target applications. Specifically, we represent the weight matrices of LLMs as a linear combination of base components. We then prune the irrelevant bases and enhance the model with new bases beneficial for specific applications. Deep compression results on the Llama 2-7b and -13B models, conducted on target applications including mathematical reasoning and code generation, show that our method significantly reduces model size while maintaining comparable accuracy to state-of-the-art low-rank compression techniques.","authors":["Yang Li","Daniel Agyei Asante","Changsheng Zhao","Ernie Chang","Yangyang Shi","Vikas Chandra"],"pdf_url":"","comment":"Transactions on Machine Learning Research (TMLR), 2025"},{"id":"http://arxiv.org/abs/2412.09299v3","updated":"2025-12-19T02:47:08Z","published":"2024-12-12T14:16:50Z","title":"Q-Fly: An Optical Interconnect for Modular Quantum Computers","summary":"Much like classical supercomputers, scaling up quantum computers requires an optical interconnect. However, signal attenuation leads to irreversible qubit loss, making quantum interconnect design guidelines and metrics different from conventional computing. Inspired by the classical Dragonfly topology, we propose a multi-group structure where the group switch routes photons emitted by computational end nodes to the group's shared pool of Bell state analyzers (which conduct the entanglement swapping that creates end-to-end entanglement) or across a low-diameter path to another group. We present a full-stack analysis of system performance, a combination of distributed and centralized protocols, and a resource scheduler that plans qubit placement and communications for large-scale, fault-tolerant systems. We implement a prototype three-node switched interconnect to justify hardware-side scalability and to expose low-level architectural challenges. We create two-hop entanglement with fidelities of 0.6-0.76. Our design emphasizes reducing network hops and optical components to simplify system stabilization while flexibly adjusting optical path lengths. Based on evaluated loss and infidelity budgets, we find that moderate-radix switches enable systems meeting expected near-term needs, and large systems are feasible. Our design is expected to be effective for a variety of quantum computing technologies, including ion traps and neutral atoms.","authors":["Daisuke Sakuma","Tomoki Tsuno","Hikaru Shimizu","Yuki Kurosawa","Monet Tokuyama Friedrich","Kentaro Teramoto","Amin Taherkhani","Andrew Todd","Yosuke Ueno","Michal Hajdušek","Rikizo Ikuta","Rodney Van Meter","Toshihiko Sasaki","Shota Nagayama"],"pdf_url":"","comment":"16 pages, 12 figures, 5 tables"},{"id":"http://arxiv.org/abs/2512.18134v1","updated":"2025-12-19T23:34:56Z","published":"2025-12-19T23:34:56Z","title":"Optimal Software Pipelining and Warp Specialization for Tensor Core GPUs","summary":"GPU architectures have continued to grow in complexity, with recent incarnations introducing increasingly powerful fixed-function units for matrix multiplication and data movement to accompany highly parallel general-purpose cores. To fully leverage these machines, software must use sophisticated schedules that maximally utilize all hardware resources. Since realizing such schedules is complex, both programmers and compilers routinely employ program transformations, such as software pipelining (SWP) and warp specialization (WS), to do so in practice. However, determining how best to use SWP and WS in combination is a challenging problem that is currently handled through a mix of brittle compilation heuristics and fallible human intuition, with little insight into the space of solutions. To remedy this situation, we introduce a novel formulation of SWP and WS as a joint optimization problem that can be solved holistically by off-the-shelf constraint solvers. We reify our approach in Twill, the first system that automatically derives optimal SWP and WS schedules for a large class of iterative programs. Twill is heuristic-free, easily extensible to new GPU architectures, and guaranteed to produce optimal schedules. We show that Twill can rediscover, and thereby prove optimal, the SWP and WS schedules manually developed by experts for Flash Attention on both the NVIDIA Hopper and Blackwell GPU architectures.","authors":["Rupanshu Soi","Rohan Yadav","Fredrik Kjolstad","Alex Aiken","Maryam Mehri Dehnavi","Michael Garland","Michael Bauer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18132v1","updated":"2025-12-19T23:31:16Z","published":"2025-12-19T23:31:16Z","title":"PermuteV: A Performant Side-channel-Resistant RISC-V Core Securing Edge AI Inference","summary":"Edge AI inference is becoming prevalent thanks to the emergence of small yet high-performance microprocessors. This shift from cloud to edge processing brings several benefits in terms of energy savings, improved latency, and increased privacy. On the downside, bringing computation to the edge makes them more vulnerable to physical side-channel attacks (SCA), which aim to extract the confidentiality of neural network models, e.g., architecture and weight. To address this growing threat, we propose PermuteV, a performant side-channel resistant RISC-V core designed to secure neural network inference. PermuteV employs a hardware-accelerated defense mechanism that randomly permutes the execution order of loop iterations, thereby obfuscating the electromagnetic (EM) signature associated with sensitive operations. We implement PermuteV on FPGA and perform evaluations in terms of side-channel security, hardware area, and runtime overhead. The experimental results demonstrate that PermuteV can effectively defend against EM SCA with minimal area and runtime overhead.","authors":["Nuntipat Narkthong","Xiaolin Xu"],"pdf_url":"","comment":null}],"Software Engineering":[{"id":"http://arxiv.org/abs/2510.22815v2","updated":"2025-12-19T17:54:40Z","published":"2025-10-26T20:02:49Z","title":"On the Freshness of Pinned Dependencies in Maven","summary":"Library dependencies in software ecosystems play a crucial role in the development of software. As newer releases of these libraries are published, developers may opt to pin their dependencies to a particular version. While pinning may have benefits in ensuring reproducible builds and avoiding breaking changes, it bears larger risks in using outdated dependencies that may contain bugs and security vulnerabilities. To understand the frequency and consequences of dependency pinning, we first define the concepts of stale and fresh pins, which are distinguished based on how outdated the dependency is relative to the release date of the project. We conduct an empirical study to show that over 60% of consumers of popular Maven libraries contain stale pins to their dependencies, with some outdated versions over a year old. These pinned versions often miss out on security fixes; we find that 10% of all dependency upgrades in our dataset to the latest minor or patch version would reduce security vulnerabilities.\n  We prototype an approach called Pin-Freshener that can encourage developers to freshen their pins by leveraging the insight that crowdsourced tests of peer projects can provide additional signal for the safety of an upgrade. Running Pin-Freshener on dependency upgrades shows that just 1-5 additional test suites can provide 35-100% more coverage of a dependency, compared to that of a single consumer test suite. Our evaluation on real-world pins to the top 500 popular libraries in Maven shows that Pin-Freshener can provide an additional signal of at least 5 passing crowdsourced test suites to over 3,000 consumers to safely perform an upgrade that reduces security vulnerabilities. Pin-Freshener can provide practical confidence to developers by offering additional signal beyond their own test suites, representing an improvement over current practices.","authors":["Vasudev Vikram","Yuvraj Agarwal","Rohan Padhye"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15817v4","updated":"2025-12-19T17:21:22Z","published":"2025-11-19T19:18:28Z","title":"A Causal Perspective on Measuring, Explaining and Mitigating Smells in LLM-Generated Code","summary":"Recent advances in large language models (LLMs) have accelerated their adoption in software engineering contexts. However, concerns persist about the structural quality of the code they produce. In particular, LLMs often replicate poor coding practices, introducing code smells (i.e., patterns that hinder readability, maintainability, or design integrity). Although prior research has examined the detection or repair of smells, we still lack a clear understanding of how and when these issues emerge in generated code.\n  This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code. We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality. Using PSC as an instrument for causal analysis, we identify how generation strategy, model size, model architecture and prompt formulation shape the structural properties of generated code. Our findings show that prompt design and architectural choices play a decisive role in smell propensity and motivate practical mitigation strategies that reduce its occurrence. A user study further demonstrates that PSC helps developers interpret model behavior and assess code quality, providing evidence that smell propensity signals can support human judgement. Taken together, our work lays the groundwork for integrating quality-aware assessments into the evaluation and deployment of LLMs for code.","authors":["Alejandro Velasco","Daniel Rodriguez-Cardenas","Dipin Khati","David N. Palacio","Luftar Rahman Alif","Denys Poshyvanyk"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17814v1","updated":"2025-12-19T17:19:08Z","published":"2025-12-19T17:19:08Z","title":"LLM-based Behaviour Driven Development for Hardware Design","summary":"Test and verification are essential activities in hardware and system design, but their complexity grows significantly with increasing system sizes. While Behavior Driven Development (BDD) has proven effective in software engineering, it is not yet well established in hardware design, and its practical use remains limited. One contributing factor is the manual effort required to derive precise behavioral scenarios from textual specifications.\n  Recent advances in Large Language Models (LLMs) offer new opportunities to automate this step. In this paper, we investigate the use of LLM-based techniques to support BDD in the context of hardware design.","authors":["Rolf Drechsler","Qian Liu"],"pdf_url":"","comment":"7 pages, keynote given at 2nd International Symposium on Artificial Intelligence and Internet of Things (AIIoT-25), December 22-24th, 2025"},{"id":"http://arxiv.org/abs/2512.17710v1","updated":"2025-12-19T15:42:22Z","published":"2025-12-19T15:42:22Z","title":"A Practical Solution to Systematically Monitor Inconsistencies in SBOM-based Vulnerability Scanners","summary":"Software Bill of Materials (SBOM) provides new opportunities for automated vulnerability identification in software products. While the industry is adopting SBOM-based Vulnerability Scanning (SVS) to identify vulnerabilities, we increasingly observe inconsistencies and unexpected behavior, that result in false negatives and silent failures. In this work, we present the background necessary to understand the underlying complexity of SVS and introduce SVS-TEST, a method and tool to analyze the capability, maturity, and failure conditions of SVS-tools in real-world scenarios. We showcase the utility of SVS-TEST in a case study evaluating seven real-world SVS-tools using 16 precisely crafted SBOMs and their respective ground truth. Our results unveil significant differences in the reliability and error handling of SVS-tools; multiple SVS-tools silently fail on valid input SBOMs, creating a false sense of security. We conclude our work by highlighting implications for researchers and practitioners, including how organizations and developers of SVS-tools can utilize SVS-TEST to monitor SVS capability and maturity. All results and research artifacts are made publicly available and all findings were disclosed to the SVS-tool developers ahead of time.","authors":["Martin Rosso","Muhammad Asad Jahangir Jaffar","Alessandro Brighente","Mauro Conti"],"pdf_url":"","comment":"to be published in the proceedings of The 41st ACM/SIGAPP Symposium on Applied Computing (SAC '26)"},{"id":"http://arxiv.org/abs/2507.22659v2","updated":"2025-12-19T15:41:06Z","published":"2025-07-30T13:17:16Z","title":"A Systematic Literature Review on Detecting Software Vulnerabilities with Large Language Models","summary":"The increasing adoption of Large Language Models (LLMs) in software engineering has sparked interest in their use for software vulnerability detection. However, the rapid development of this field has resulted in a fragmented research landscape, with diverse studies that are difficult to compare due to differences in, e.g., system designs and dataset usage. This fragmentation makes it difficult to obtain a clear overview of the state-of-the-art or compare and categorize studies meaningfully. In this work, we present a comprehensive systematic literature review (SLR) of LLM-based software vulnerability detection. We analyze 263 studies published between January 2020 and November 2025, categorizing them by task formulation, input representation, system architecture, and techniques. Further, we analyze the datasets used, including their characteristics, vulnerability coverage, and diversity. We present a fine-grained taxonomy of vulnerability detection approaches, identify key limitations, and outline actionable future research opportunities. By providing a structured overview of the field, this review improves transparency and serves as a practical guide for researchers and practitioners aiming to conduct more comparable and reproducible research. We publicly release all artifacts and maintain a living repository of LLM-based software vulnerability detection studies at https://github.com/hs-esslingen-it-security/Awesome-LLM4SVD.","authors":["Sabrina Kaniewski","Fabian Schmidt","Markus Enzweiler","Michael Menth","Tobias Heer"],"pdf_url":"","comment":"43 pages + 20 pages references, 7 tables, 13 figures"},{"id":"http://arxiv.org/abs/2506.11023v2","updated":"2025-12-19T15:34:46Z","published":"2025-05-20T08:15:16Z","title":"OntoGSN: An Ontology-Based Framework for Semantic Management and Extension of Assurance Cases","summary":"Assurance cases (ACs) are a common artifact for building and maintaining confidence in system properties such as safety or robustness. Constructing an AC can be challenging, although existing tools provide support in static, document-centric applications and methods for dynamic contexts (e.g., autonomous driving) are emerging. Unfortunately, managing ACs remains a challenge, since maintaining the embedded knowledge in the face of changes requires substantial effort, in the process deterring developers - or worse, producing poorly managed cases that instill false confidence. To address this, we present OntoGSN: an ontology and supporting middleware for managing ACs in the Goal Structuring Notation (GSN) standard. OntoGSN offers a knowledge representation and a queryable graph that can be automatically populated, evaluated, and updated. Our contributions include: a 1:1 formalization of the GSN Community Standard v3 in an OWL ontology with SWRL rules; a helper ontology and parser for integration with a widely used AC tool; a repository and documentation of design decisions for OntoGSN maintenance; a SPARQL query library with automation patterns; and a prototypical interface. The ontology strictly adheres to the standard's text and has been evaluated according to FAIR principles, the OOPS framework, competency questions, and community feedback. The development of other middleware elements is guided by the community needs and subject to ongoing evaluations. To demonstrate the utility of our contributions, we illustrate dynamic AC management in an example involving assurance of adversarial robustness in large language models.","authors":["Tomas Bueno Momcilovic","Barbara Gallina","Ingmar Kessler","Jule Hendricks","Dian Balta"],"pdf_url":"","comment":"Submitted to the ESWC 2026 Resources track"},{"id":"http://arxiv.org/abs/2512.17540v1","updated":"2025-12-19T13:02:22Z","published":"2025-12-19T13:02:22Z","title":"SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review","summary":"Automating code review with Large Language Models (LLMs) shows immense promise, yet practical adoption is hampered by their lack of reliability, context-awareness, and control. To address this, we propose Specification-Grounded Code Review (SGCR), a framework that grounds LLMs in human-authored specifications to produce trustworthy and relevant feedback. SGCR features a novel dual-pathway architecture: an explicit path ensures deterministic compliance with predefined rules derived from these specifications, while an implicit path heuristically discovers and verifies issues beyond those rules. Deployed in a live industrial environment at HiThink Research, SGCR's suggestions achieved a 42% developer adoption rate-a 90.9% relative improvement over a baseline LLM (22%). Our work demonstrates that specification-grounding is a powerful paradigm for bridging the gap between the generative power of LLMs and the rigorous reliability demands of software engineering.","authors":["Kai Wang","Bingcheng Mao","Shuai Jia","Yujie Ding","Dongming Han","Tianyi Ma","Bin Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17517v1","updated":"2025-12-19T12:35:57Z","published":"2025-12-19T12:35:57Z","title":"PathBench-MIL: A Comprehensive AutoML and Benchmarking Framework for Multiple Instance Learning in Histopathology","summary":"We introduce PathBench-MIL, an open-source AutoML and benchmarking framework for multiple instance learning (MIL) in histopathology. The system automates end-to-end MIL pipeline construction, including preprocessing, feature extraction, and MIL-aggregation, and provides reproducible benchmarking of dozens of MIL models and feature extractors. PathBench-MIL integrates visualization tooling, a unified configuration system, and modular extensibility, enabling rapid experimentation and standardization across datasets and tasks. PathBench-MIL is publicly available at https://github.com/Sbrussee/PathBench-MIL","authors":["Siemen Brussee","Pieter A. Valkema","Jurre A. J. Weijer","Thom Doeleman","Anne M. R. Schrader","Jesper Kers"],"pdf_url":"","comment":"14 Pages, 3 Figures, 2 Appendices"},{"id":"http://arxiv.org/abs/2508.12436v2","updated":"2025-12-19T12:24:06Z","published":"2025-08-17T17:09:16Z","title":"Feature Request Analysis and Processing: Tasks, Techniques, and Trends","summary":"Feature requests are proposed by users to request new features or enhancements of existing features of software products, which represent users' wishes and demands. Satisfying users' demands can benefit the product from both competitiveness and user satisfaction. Feature requests have seen a rise in interest in the past few years and the amount of research has been growing. However, the diversity in the research topics suggests the need for their collective analysis to identify the challenges and opportunities so as to promote new advances in the future. In this work, following a defined process and a search protocol, we provide a systematic overview of the research area by searching and categorizing relevant studies. We select and analyze 131 primary studies using descriptive statistics and qualitative analysis methods. We classify the studies into different topics and group them from the perspective of requirements engineering activities. We investigate open tools as well as datasets for future research. In addition, we identify several key challenges and opportunities, such as: (1) ensuring the quality of feature requests, (2) improving their specification and validation, and (3) developing high-quality benchmarks for large language model-driven tasks.","authors":["Feifei Niu","Chuanyi Li","Haosheng Zuo","Jionghan Wu","Xin Xia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17500v1","updated":"2025-12-19T12:09:29Z","published":"2025-12-19T12:09:29Z","title":"Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem","summary":"The NFT ecosystem represents an interconnected, decentralized environment that encompasses the creation, distribution, and trading of Non-Fungible Tokens (NFTs), where key actors, such as marketplaces, sellers, and buyers, utilize smart contracts to facilitate secure, transparent, and trustless transactions. Scam tokens are deliberately created to mislead users and facilitate financial exploitation, posing significant risks in the NFT ecosystem. Prior work has explored the NFT ecosystem from various perspectives, including security challenges, actor behaviors, and risks from scams and wash trading, leaving a gap in understanding the semantics and interactions of smart contracts during transactions, and how the risks associated with scam tokens manifest in relation to the semantics and interactions of contracts. To bridge this gap, we conducted a large-scale empirical study on smart contract semantics and interactions in the NFT ecosystem, using a curated dataset of nearly 100 million transactions across 20 million blocks on Ethereum. We observe a limited semantic diversity among smart contracts in the NFT ecosystem, dominated by proxy, token, and DeFi contracts. Marketplace and proxy registry contracts are the most frequently involved in smart contract interactions during transactions, engaging with a broad spectrum of contracts in the ecosystem. Token contracts exhibit bytecode-level diversity, whereas scam tokens exhibit bytecode convergence. Certain interaction patterns between smart contracts are common to both risky and non-risky transactions, while others are predominantly associated with risky transactions. Based on our findings, we provide recommendations to mitigate risks in the blockchain ecosystem, and outline future research directions.","authors":["Yujing Chen","Xuanming Liu","Zhiyuan Wan","Zuobin Wang","David Lo","Difan Xie","Xiaohu Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.26538v2","updated":"2025-12-19T11:30:54Z","published":"2025-10-30T14:27:51Z","title":"Empirical and Sustainability Aspects of Software Engineering Research in the Era of Large Language Models: A Reflection","summary":"Software Engineering (SE) research involving the use of Large Language Models (LLMs) has introduced several new challenges related to rigour in benchmarking, contamination, replicability, and sustainability. In this paper, we invite the research community to reflect on how these challenges are addressed in SE. Our results provide a structured overview of current LLM-based SE research at ICSE, highlighting both encouraging practices and persistent shortcomings. We conclude with recommendations to strengthen benchmarking rigour, improve replicability, and address the financial and environmental costs of LLM-based SE.","authors":["David Williams","Max Hort","Maria Kechagia","Aldeida Aleti","Justyna Petke","Federica Sarro"],"pdf_url":"","comment":"5 pages, Camera Ready Accepted at ICSE-NIER 2026"},{"id":"http://arxiv.org/abs/2512.17460v1","updated":"2025-12-19T11:21:12Z","published":"2025-12-19T11:21:12Z","title":"When Data Quality Issues Collide: A Large-Scale Empirical Study of Co-Occurring Data Quality Issues in Software Defect Prediction","summary":"Software Defect Prediction (SDP) models are central to proactive software quality assurance, yet their effectiveness is often constrained by the quality of available datasets. Prior research has typically examined single issues such as class imbalance or feature irrelevance in isolation, overlooking that real-world data problems frequently co-occur and interact. This study presents, to our knowledge, the first large-scale empirical analysis in SDP that simultaneously examines five co-occurring data quality issues (class imbalance, class overlap, irrelevant features, attribute noise, and outliers) across 374 datasets and five classifiers. We employ Explainable Boosting Machines together with stratified interaction analysis to quantify both direct and conditional effects under default hyperparameter settings, reflecting practical baseline usage.\n  Our results show that co-occurrence is nearly universal: even the least frequent issue (attribute noise) appears alongside others in more than 93% of datasets. Irrelevant features and imbalance are nearly ubiquitous, while class overlap is the most consistently harmful issue. We identify stable tipping points around 0.20 for class overlap, 0.65-0.70 for imbalance, and 0.94 for irrelevance, beyond which most models begin to degrade. We also uncover counterintuitive patterns, such as outliers improving performance when irrelevant features are low, underscoring the importance of context-aware evaluation. Finally, we expose a performance-robustness trade-off: no single learner dominates under all conditions.\n  By jointly analyzing prevalence, co-occurrence, thresholds, and conditional effects, our study directly addresses a persistent gap in SDP research. Hence, moving beyond isolated analyses to provide a holistic, data-aware understanding of how quality issues shape model performance in real-world settings.","authors":["Emmanuel Charleson Dapaah","Jens Grabowski"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17455v1","updated":"2025-12-19T11:17:05Z","published":"2025-12-19T11:17:05Z","title":"An Investigation on How AI-Generated Responses Affect SoftwareEngineering Surveys","summary":"Survey research is a fundamental empirical method in software engineering, enabling the systematic collection of data on professional practices, perceptions, and experiences. However, recent advances in large language models (LLMs) have introduced new risks to survey integrity, as participants can use generative tools to fabricate or manipulate their responses. This study explores how LLMs are being misused in software engineering surveys and investigates the methodological implications of such behavior for data authenticity, validity, and research integrity. We collected data from two survey deployments conducted in 2025 through the Prolific platform and analyzed the content of participants' answers to identify irregular or falsified responses. A subset of responses suspected of being AI generated was examined through qualitative pattern inspection, narrative characterization, and automated detection using the Scribbr AI Detector. The analysis revealed recurring structural patterns in 49 survey responses indicating synthetic authorship, including repetitive sequencing, uniform phrasing, and superficial personalization. These false narratives mimicked coherent reasoning while concealing fabricated content, undermining construct, internal, and external validity. Our study identifies data authenticity as an emerging dimension of validity in software engineering surveys. We emphasize that reliable evidence now requires combining automated and interpretive verification procedures, transparent reporting, and community standards to detect and prevent AI generated responses, thereby protecting the credibility of surveys in software engineering.","authors":["Ronnie de Souza Santos","Italo Santos","Maria Teresa Baldassarre","Cleyton Magalhaes","Mairieli Wessel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17419v1","updated":"2025-12-19T10:16:51Z","published":"2025-12-19T10:16:51Z","title":"SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories","summary":"Benchmarks like SWE-bench have standardized the evaluation of Large Language Models (LLMs) on repository-level software engineering tasks. However, these efforts remain limited by manual curation, static datasets, and a focus on Python-based bug fixes. We introduce SWE-Bench++, an automated framework that generates repository-level coding tasks from open-source GitHub projects. Unlike synthetic approaches, our pipeline harvests live pull requests to cover both bug fixes and feature requests across 11 languages. SWE-Bench++ turns GitHub pull requests (PRs) into reproducible, execution-based tasks via four stages: programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance. A final hint-guided trajectory synthesis step converts instances that strong models fail on into training trajectories. Our initial benchmark consists of 11,133 instances from 3,971 repositories across 11 languages. On a subset of 1,782 instances of this benchmark, today's strongest models perform as follows: claude-sonnet-4.5 achieves 36.20% pass@10, gpt-5-2025-08-07 34.57%, gemini/gemini-2.5-pro 24.92%, and gpt-4o 16.89%. We further demonstrate the utility of our dataset by showing that fine-tuning on SWE-Bench++ instances yields measurable improvements on the SWE-bench Multilingual benchmark. SWE-Bench++ provides a scalable, multilingual benchmark for evaluating and improving repository-level code generation.","authors":["Lilin Wang","Lucas Ramalho","Alan Celestino","Phuc Anthony Pham","Yu Liu","Umang Kumar Sinha","Andres Portillo","Onassis Osunwa","Gabriel Maduekwe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.17287v3","updated":"2025-12-19T10:00:40Z","published":"2025-04-24T06:28:18Z","title":"RBCTest: Leveraging LLMs to Mine and Verify Oracles of API Response Bodies for RESTful API Testing","summary":"In API testing, deriving logical constraints on API response bodies to be used as oracles is crucial for generating test cases and performing automated testing of RESTful APIs. However, existing approaches are restricted to dynamic analysis, in which oracles are extracted via the execution of APIs as part of the system under test. In this paper, we propose a complementary LLM-based static approach in which constraints for API response bodies are mined from API specifications. We leverage large language models (LLMs) to comprehend API specifications, mine constraints for response bodies, and generate test cases. To reduce LLM hallucination, we apply an Observation-Confirmation (OC) scheme that uses initial prompts to contextualize constraints, allowing subsequent prompts to more accurately confirm their presence. Our empirical results show that RBCTest with OC prompting achieves high precision in constraint mining, with averages ranging from 85.1% to 93.6%. It also performs well in generating test cases from mined constraints, with precision ranging from 86.4% to 91.7%. We further use test cases generated by RBCTest to detect 46 mismatches between API specifications and actual response data across 19 real-world APIs. Four of these mismatches were reported in developers' forums.","authors":["Hieu Huynh","Tri Le","Tu Nguyen","Viet Nguyen","Vu Nguyen","Tien N. Nguyen"],"pdf_url":"","comment":"The paper is accepted to ICSE 2026"},{"id":"http://arxiv.org/abs/2512.17387v1","updated":"2025-12-19T09:43:20Z","published":"2025-12-19T09:43:20Z","title":"CIFE: Code Instruction-Following Evaluation","summary":"Large Language Models (LLMs) are increasingly applied to real-world code generation, where functional correctness alone is insufficient for reliable deployment, developers also expect adherence to explicit requirements for robustness, formatting, and security. Existing benchmarks primarily assess correctness through test-case execution, offering limited insight into how reliably models follow such constraints. We introduce a benchmark of 1,000 Python tasks, each paired with an average of 7 developer-specified constraints spanning 13 categories. Constraints are curated through a four-stage human-LLM pipeline to ensure they are atomic, relevant, and objective. We evaluate 14 open- and closed-source models using complementary adherence metrics and propose the C2A Score, a composite measure that jointly captures correctness and constraint compliance. Results reveal a substantial gap between partial and strict satisfaction, while strong models achieve over 90% partial adherence, strict adherence remains between 39-66%. These findings highlight that trustworthy code generation requires not only correctness but also consistent adherence to developer intent.","authors":["Sravani Gunnu","Shanmukha Guttula","Hima Patel"],"pdf_url":"","comment":"20 pages, 22 figures, 2 tables"},{"id":"http://arxiv.org/abs/2512.17371v1","updated":"2025-12-19T09:13:51Z","published":"2025-12-19T09:13:51Z","title":"GraphCue for SDN Configuration Code Synthesis","summary":"We present GraphCue, a topology-grounded retrieval and agent-in-the-loop framework for automated SDN configuration. Each case is abstracted into a JSON graph and embedded using a lightweight three-layer GCN trained with contrastive learning. The nearest validated reference is injected into a structured prompt that constrains code generation, while a verifier closes the loop by executing the candidate configuration and feeding failures back to the agent. On 628 validation cases, GraphCue achieves an 88.2 percent pass rate within 20 iterations and completes 95 percent of verification loops within 9 seconds. Ablation studies without retrieval or structured prompting perform substantially worse, indicating that topology-aware retrieval and constraint-based conditioning are key drivers of performance.","authors":["Haomin Qi","Fengfei Yu","Chengbo Huang"],"pdf_url":"","comment":"2 pages, 2 figures"},{"id":"http://arxiv.org/abs/2512.16529v2","updated":"2025-12-19T09:09:13Z","published":"2025-12-18T13:37:50Z","title":"ParamExplorer: A framework for exploring parameters in generative art","summary":"Generative art systems often involve high-dimensional and complex parameter spaces in which aesthetically compelling outputs occupy only small, fragmented regions. Because of this combinatorial explosion, artists typically rely on extensive manual trial-and-error, leaving many potentially interesting configurations undiscovered. In this work we make two contributions. First, we introduce ParamExplorer, an interactive and modular framework inspired by reinforcement learning that helps the exploration of parameter spaces in generative art algorithms, guided by human-in-the-loop or even automated feedback. The framework also integrates seamlessly with existing p5js projects. Second, within this framework we implement and evaluate several exploration strategies, referred to as agents.","authors":["Julien Gachadoat","Guillaume Lagarde"],"pdf_url":"","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2512.17363v1","updated":"2025-12-19T09:02:58Z","published":"2025-12-19T09:02:58Z","title":"What You Trust Is Insecure: Demystifying How Developers (Mis)Use Trusted Execution Environments in Practice","summary":"Trusted Execution Environments (TEEs), such as Intel SGX and ARM TrustZone, provide isolated regions of CPU and memory for secure computation and are increasingly used to protect sensitive data and code across diverse application domains. However, little is known about how developers actually use TEEs in practice. This paper presents the first large-scale empirical study of real-world TEE applications. We collected and analyzed 241 open-source projects from GitHub that utilize the two most widely-adopted TEEs, Intel SGX and ARM TrustZone. By combining manual inspection with customized static analysis scripts, we examined their adoption contexts, usage patterns, and development practices across three phases. First, we categorized the projects into 8 application domains and identified trends in TEE adoption over time. We found that the dominant use case is IoT device security (30%), which contrasts sharply with prior academic focus on blockchain and cryptographic systems (7%), while AI model protection (12%) is rapidly emerging as a growing domain. Second, we analyzed how TEEs are integrated into software and observed that 32.4% of the projects reimplement cryptographic functionalities instead of using official SDK APIs, suggesting that current SDKs may have limited usability and portability to meet developers' practical needs. Third, we examined security practices through manual inspection and found that 25.3% (61 of 241) of the projects exhibit insecure coding behaviors when using TEEs, such as hardcoded secrets and missing input validation, which undermine their intended security guarantees. Our findings have important implications for improving the usability of TEE SDKs and supporting developers in trusted software development.","authors":["Yuqing Niu","Jieke Shi","Ruidong Han","Ye Liu","Chengyan Ma","Yunbo Lyu","David Lo"],"pdf_url":"","comment":"Accepted by the 33rd IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER 2026), 13 Pages"},{"id":"http://arxiv.org/abs/2512.17334v1","updated":"2025-12-19T08:25:54Z","published":"2025-12-19T08:25:54Z","title":"Bridging Natural Language and Formal Specification--Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs","summary":"Automating the translation of natural language (NL) software requirements into formal specifications remains a critical challenge in scaling formal verification practices to industrial settings, particularly in safety-critical domains. Existing approaches, both rule-based and learning-based, face significant limitations. While large language models (LLMs) like GPT-4o demonstrate proficiency in semantic extraction, they still encounter difficulties in addressing the complexity, ambiguity, and logical depth of real-world industrial requirements. In this paper, we propose Req2LTL, a modular framework that bridges NL and Linear Temporal Logic (LTL) through a hierarchical intermediate representation called OnionL. Req2LTL leverages LLMs for semantic decomposition and combines them with deterministic rule-based synthesis to ensure both syntactic validity and semantic fidelity. Our comprehensive evaluation demonstrates that Req2LTL achieves 88.4% semantic accuracy and 100% syntactic correctness on real-world aerospace requirements, significantly outperforming existing methods.","authors":["Zhi Ma","Cheng Wen","Zhexin Su","Xiao Liang","Cong Tian","Shengchao Qin","Mengfei Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16070v2","updated":"2025-12-19T08:24:20Z","published":"2025-12-18T01:35:30Z","title":"LLM4Perf: Large Language Models Are Effective Samplers for Multi-Objective Performance Modeling","summary":"The performance of modern software systems is critically dependent on their complex configuration options. Building accurate performance models to navigate this vast space requires effective sampling strategies, yet existing methods often struggle with multi-objective optimization and cannot leverage semantic information from documentation. The recent success of Large Language Models (LLMs) motivates the central question of this work: Can LLMs serve as effective samplers for multi-objective performance modeling? To explore this, we present a comprehensive empirical study investigating the capabilities and characteristics of LLM-driven sampling. We design and implement LLM4Perf, a feedback-based framework, and use it to systematically evaluate the LLM-guided sampling process across four highly configurable, real-world systems. Our study reveals that the LLM-guided approach outperforms traditional baselines in most cases. Quantitatively, LLM4Perf achieves the best performance in nearly 68.8% (77 out of 112) of all evaluation scenarios, demonstrating its superior effectiveness. We find this effectiveness stems from the LLM's dual capabilities of configuration space pruning and feedback-driven strategy refinement. The effectiveness of this pruning is further validated by the fact that it also improves the performance of the baseline methods in nearly 91.5% (410 out of 448) of cases. Furthermore, we show how the LLM choices for each component and hyperparameters within LLM4Perf affect its effectiveness. Overall, this paper provides strong evidence for the effectiveness of LLMs in performance engineering and offers concrete insights into the mechanisms that drive their success.","authors":["Xin Wang","Zhenhao Li","Zishuo Ding"],"pdf_url":"","comment":"ICSE 2026"},{"id":"http://arxiv.org/abs/2512.14806v3","updated":"2025-12-19T07:14:17Z","published":"2025-12-16T18:51:23Z","title":"Let the Barbarians In: How AI Can Accelerate Systems Performance Research","summary":"Artificial Intelligence (AI) is beginning to transform the research process by automating the discovery of new solutions. This shift depends on the availability of reliable verifiers, which AI-driven approaches require to validate candidate solutions. Research focused on improving systems performance is especially well-suited to this paradigm because system performance problems naturally admit such verifiers: candidates can be implemented in real systems or simulators and evaluated against predefined workloads. We term this iterative cycle of generation, evaluation, and refinement AI-Driven Research for Systems (ADRS). Using several open-source ADRS instances (i.e., OpenEvolve, GEPA, and ShinkaEvolve), we demonstrate across ten case studies (e.g., multi-region cloud scheduling, mixture-of-experts load balancing, LLM-based SQL, transaction scheduling) that ADRS-generated solutions can match or even outperform human state-of-the-art designs. Based on these findings, we outline best practices (e.g., level of prompt specification, amount of feedback, robust evaluation) for effectively using ADRS, and we discuss future research directions and their implications. Although we do not yet have a universal recipe for applying ADRS across all of systems research, we hope our preliminary findings, together with the challenges we identify, offer meaningful guidance for future work as researcher effort shifts increasingly toward problem formulation and strategic oversight.\n  Note: This paper is an extension of our prior work [14]. It adds extensive evaluation across multiple ADRS frameworks and provides deeper analysis and insights into best practices.","authors":["Audrey Cheng","Shu Liu","Melissa Pan","Zhifei Li","Shubham Agarwal","Mert Cemri","Bowen Wang","Alexander Krentsel","Tian Xia","Jongseok Park","Shuo Yang","Jeff Chen","Lakshya Agrawal","Ashwin Naren","Shulu Li","Ruiying Ma","Aditya Desai","Jiarong Xing","Koushik Sen","Matei Zaharia","Ion Stoica"],"pdf_url":"","comment":"arXiv admin note: substantial text overlap with arXiv:2510.06189"},{"id":"http://arxiv.org/abs/2512.17280v1","updated":"2025-12-19T06:55:44Z","published":"2025-12-19T06:55:44Z","title":"Sensor Management System (SMS): Open-source software for FAIR sensor metadata management in Earth system sciences","summary":"Deriving reliable conclusions and insights from environmental observational data urgently requires the enrichment with consistent and comprehensive metadata, including time-resolved context such as changing deployments, configurations, and maintenance actions. We have therefore developed the Sensor Management System (SMS), which provides a user-friendly and feature-rich platform for modeling even the most complex sensor systems and managing all sensor-related information across their life cycle. Each entity is described via well-defined terms like Devices, Platforms and Configurations, as well as Sites that are further enhanced with attributes for, e.g., instrument manufacturers, contact information or measured quantities and complemented by a continuous history of system-related actions. By further linking the SMS to sub-sequent systems and services like PID-registration or controlled vocabularies and establishing a community of end-users, the SMS provides the central element of a digital ecosystem, that fosters a more consistent, sustainable and FAIR provision of sensor-related metadata.","authors":["Christof Lorenza","Nils Brinckmann","Jan Bumberger","Marc Hanisch","Tobias Kuhnert","Ulrich Loup","Rubankumar Moorthy","Florian Obsersteiner","David Schäfer","Thomas Schnicke"],"pdf_url":"","comment":"Submitted to SoftwareX"},{"id":"http://arxiv.org/abs/2405.04994v2","updated":"2025-12-19T01:26:30Z","published":"2024-05-08T11:58:55Z","title":"SPVR: syntax-to-prompt vulnerability repair based on large language models","summary":"Purpose: In the field of vulnerability repair, previous research has leveraged pretrained models and LLM-based prompt engineering, among which LLM-based approaches show better generalizability and achieve the best performance. However, the LLM-based approaches generally regard vulnerability repair as a sequence-to-sequence task, and do not explicitly capture the syntax patterns for different vulnerability types, leading to limited accuracy. We aim to create a method that ensures the specificity of prompts targeting vulnerable code while also leveraging the generative capabilities of Large Language Models. Methods: We propose SPVR (Syntax-to-Prompt Vulnerability Repair), a novel framework that collects information from syntax trees, and generates corresponding prompts. Our method consists of three steps: rule design, prompt generation, and patch generation. In the rule design step, our method parses code patches and designs rules to extract relevant contextual information. These rules aid in identifying vulnerability-related issues. In the prompt generation step, our method extracts information from vulnerable code with pre-defined rules, automatically converting them into prompts. We also incorporate the description of CWE (Common Weakness Enumeration) as known information into the prompts. Finally, in the patch generation step, this prompt will serve as input to any conversational LLM to obtain code patches. Results: Extensive experiments validate that our method achieves excellent results in assisting LLMs to fix vulnerabilities accurately. We utilize multiple Large Language Models to validate the effectiveness of our work, repairing 143 of 547 vulnerable code using ChatGPT-4. We conducted a comparison of our approach against several existing vulnerability repair approaches (including fine-tuning-based and prompt-based), across multiple metrics.","authors":["Ruoke Wang","Zongjie Li","Cuiyun Gao","Chaozheng Wang","Yang Xiao","Xuan Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.20196v2","updated":"2025-12-19T00:21:29Z","published":"2025-04-28T18:59:28Z","title":"Understanding and supporting how developers prompt for LLM-powered code editing in practice","summary":"Large Language Models (LLMs) are rapidly transforming software engineering, with coding assistants embedded in an IDE becoming increasingly prevalent. While research has focused on improving the tools and understanding developer perceptions, a critical gap exists in understanding how developers actually use these tools in their daily workflows, and, crucially, where they struggle. This paper addresses part of this gap through a multi-phased investigation of developer interactions with an LLM-powered code editing feature, Transform Code, in an IDE widely used at Google. First, we analyze telemetry logs of the feature usage, revealing that frequent re-prompting can be an indicator of developer struggles with using Transform Code. Second, we conduct a qualitative analysis of unsatisfactory requests, identifying five key categories of information often missing from developer prompts. Finally, based on these findings, we propose and evaluate a tool, AutoPrompter, for automatically improving prompts by inferring missing information from the surrounding code context, leading to a 27% improvement in edit correctness on our test set.","authors":["Daye Nam","Ahmed Omran","Ambar Murillo","Saksham Thakur","Abner Araujo","Marcel Blistein","Alexander Frömmgen","Vincent Hellendoorn","Satish Chandra"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18131v1","updated":"2025-12-19T23:29:05Z","published":"2025-12-19T23:29:05Z","title":"Holistic Evaluation of State-of-the-Art LLMs for Code Generation","summary":"This study presents a comprehensive empirical evaluation of six state-of-the-art large language models (LLMs) for code generation, including both general-purpose and code-specialized models. Using a dataset of 944 real-world LeetCode problems across five programming languages, we assess model performance using rigorous metrics: compile-time errors, runtime errors, functional failures, and algorithmic suboptimalities. The results reveal significant performance variations, with DeepSeek-R1 and GPT-4.1 consistently outperform others in terms of correctness, efficiency, and robustness. Through detailed case studies, we identify common failure scenarios such as syntax errors, logical flaws, and suboptimal algorithms, highlighting the critical role of prompt engineering and human oversight in improving results. Based on these findings, we provide actionable recommendations for developers and practitioners, emphasizing that successful LLM deployment depends on careful model selection, effective prompt design, and context-aware usage to ensure reliable code generation in real-world software development tasks.","authors":["Le Zhang","Suresh Kothari"],"pdf_url":"","comment":"13 pages, 9 figures, 6 tables"},{"id":"http://arxiv.org/abs/2512.18102v1","updated":"2025-12-19T22:15:53Z","published":"2025-12-19T22:15:53Z","title":"From Coverage to Causes: Data-Centric Fuzzing for JavaScript Engines","summary":"Context: Exhaustive fuzzing of modern JavaScript engines is infeasible due to the vast number of program states and execution paths. Coverage-guided fuzzers waste effort on low-risk inputs, often ignoring vulnerability-triggering ones that do not increase coverage. Existing heuristics proposed to mitigate this require expert effort, are brittle, and hard to adapt.\n  Objective: We propose a data-centric, LLM-boosted alternative that learns from historical vulnerabilities to automatically identify minimal static (code) and dynamic (runtime) features for detecting high-risk inputs.\n  Method: Guided by historical V8 bugs, iterative prompting generated 115 static and 49 dynamic features, with the latter requiring only five trace flags, minimizing instrumentation cost. After feature selection, 41 features remained to train an XGBoost model to predict high-risk inputs during fuzzing.\n  Results: Combining static and dynamic features yields over 85% precision and under 1% false alarms. Only 25% of these features are needed for comparable performance, showing that most of the search space is irrelevant.\n  Conclusion: This work introduces feature-guided fuzzing, an automated data-driven approach that replaces coverage with data-directed inference, guiding fuzzers toward high-risk states for faster, targeted, and reproducible vulnerability discovery. To support open science, all scripts and data are available at https://github.com/KKGanguly/DataCentricFuzzJS .","authors":["Kishan Kumar Ganguly","Tim Menzies"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18088v1","updated":"2025-12-19T21:47:31Z","published":"2025-12-19T21:47:31Z","title":"Detecting Flaky Tests in Quantum Software: A Dynamic Approach","summary":"Flaky tests, tests that pass or fail nondeterministically without changes to code or environment, pose a serious threat to software reliability. While classical software engineering has developed a rich body of dynamic and static techniques to study flakiness, corresponding evidence for quantum software remains limited. Prior work relies primarily on static analysis or small sets of manually reported incidents, leaving open questions about the prevalence, characteristics, and detectability of flaky tests.\n  This paper presents the first large-scale dynamic characterization of flaky tests in quantum software. We executed the Qiskit Terra test suite 10,000 times across 23 releases in controlled environments. For each release, we measured test-outcome variability, identified flaky tests, estimated empirical failure probabilities, analyzed recurrence across versions, and used Wilson confidence intervals to quantify rerun budgets for reliable detection. We further mapped flaky tests to Terra subcomponents to assess component-level susceptibility.\n  Across 27,026 test cases, we identified 290 distinct flaky tests. Although overall flakiness rates were low (0-0.4%), flakiness was highly episodic: nearly two-thirds of flaky tests appeared in only one release, while a small subset recurred intermittently or persistently. Many flaky tests failed with very small empirical probabilities ($\\hat{p} \\approx 10^{-4}$), implying that tens of thousands of executions may be required for confident detection. Flakiness was unevenly distributed across subcomponents, with 'transpiler' and 'quantum_info' accounting for the largest share.\n  These results show that quantum test flakiness is rare but difficult to detect under typical continuous integration budgets. To support future research, we release a public dataset of per-test execution outcomes.","authors":["Dongchan Kim","Hamidreza Khoramrokh","Lei Zhang","Andriy Miranskyy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18080v1","updated":"2025-12-19T21:37:15Z","published":"2025-12-19T21:37:15Z","title":"From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems","summary":"Agentic AI systems capable of generating full-stack web applications from natural language prompts (\"prompt- to-app\") represent a significant shift in software development. However, evaluating these systems remains challenging, as visual polish, functional correctness, and user trust are often misaligned. As a result, it is unclear how existing prompt-to-app tools compare under realistic, human-centered evaluation criteria. In this paper, we introduce a human-centered benchmark for evaluating prompt-to-app systems and conduct a large-scale comparative study of three widely used platforms: Replit, Bolt, and Firebase Studio. Using a diverse set of 96 prompts spanning common web application tasks, we generate 288 unique application artifacts. We evaluate these systems through a large-scale human-rater study involving 205 participants and 1,071 quality-filtered pairwise comparisons, assessing task-based ease of use, visual appeal, perceived completeness, and user trust. Our results show that these systems are not interchangeable: Firebase Studio consistently outperforms competing platforms across all human-evaluated dimensions, achieving the highest win rates for ease of use, trust, visual appeal, and visual appropriateness. Bolt performs competitively on visual appeal but trails Firebase on usability and trust, while Replit underperforms relative to both across most metrics. These findings highlight a persistent gap between visual polish and functional reliability in prompt-to-app systems and demonstrate the necessity of interactive, task-based evaluation. We release our benchmark framework, prompt set, and generated artifacts to support reproducible evaluation and future research in agentic application generation.","authors":["Marcos Ortiz","Justin Hill","Collin Overbay","Ingrida Semenec","Frederic Sauve-Hoover","Jim Schwoebel","Joel Shor"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18020v1","updated":"2025-12-19T19:24:56Z","published":"2025-12-19T19:24:56Z","title":"Specification and Detection of LLM Code Smells","summary":"Large Language Models (LLMs) have gained massive popularity in recent years and are increasingly integrated into software systems for diverse purposes. However, poorly integrating them in source code may undermine software system quality. Yet, to our knowledge, there is no formal catalog of code smells specific to coding practices for LLM inference. In this paper, we introduce the concept of LLM code smells and formalize five recurrent problematic coding practices related to LLM inference in software systems, based on relevant literature. We extend the detection tool SpecDetect4AI to cover the newly defined LLM code smells and use it to validate their prevalence in a dataset of 200 open-source LLM systems. Our results show that LLM code smells affect 60.50% of the analyzed systems, with a detection precision of 86.06%.","authors":["Brahim Mahmoudi","Zacharie Chenail-Larcher","Naouel Moha","Quentin Stievenert","Florent Avellaneda"],"pdf_url":"","comment":"Accepted paper at ICSE NIER 2026 : https://conf.researchr.org/track/icse-2026/icse-2026-nier"},{"id":"http://arxiv.org/abs/2512.19758v1","updated":"2025-12-19T17:03:50Z","published":"2025-12-19T17:03:50Z","title":"Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models","summary":"In the domain of software security testing, Directed Grey-Box Fuzzing (DGF) has garnered widespread attention for its efficient target localization and excellent detection performance. However, existing approaches measure only the physical distance between seed execution paths and target locations, overlooking logical relationships among code segments. This omission can yield redundant or misleading guidance in complex binaries, weakening DGF's real-world effectiveness. To address this, we introduce \\textbf{attention distance}, a novel metric that leverages a large language model's contextual analysis to compute attention scores between code elements and reveal their intrinsic connections. Under the same AFLGo configuration -- without altering any fuzzing components other than the distance metric -- replacing physical distances with attention distances across 38 real vulnerability reproduction experiments delivers a \\textbf{3.43$\\times$} average increase in testing efficiency over the traditional method. Compared to state-of-the-art directed fuzzers DAFL and WindRanger, our approach achieves \\textbf{2.89$\\times$} and \\textbf{7.13$\\times$} improvements, respectively. To further validate the generalizability of attention distance, we integrate it into DAFL and WindRanger, where it also consistently enhances their original performance. All related code and datasets are publicly available at https://github.com/TheBinKing/Attention\\_Distance.git.","authors":["Wang Bin","Ao Yang","Kedan Li","Aofan Liu","Hui Li","Guibo Luo","Weixiang Huang","Yan Zhuang"],"pdf_url":"","comment":"Accepted to ICSE 2026 Research Track"}],"Performance":[{"id":"http://arxiv.org/abs/2512.17855v1","updated":"2025-12-19T17:57:18Z","published":"2025-12-19T17:57:18Z","title":"On General Linearly Implicit Quantized State System Methods","summary":"This work proposes a methodology to develop new numerical integration algorithms for ordinary differential equations based on state quantization, generalizing the notions of Linearly Implicit Quantized State Systems (LIQSS) methods. Using this idea, two novel sub-families of algorithms are designed that improve the performance of current LIQSS methods while preserving their properties regarding stability, global error bound and efficient event handling capabilities. The features of the new algorithms are studied in two application examples where the advantages over classic numerical integration algorithms is also analyzed.","authors":["Mariana Bergonzi","Joaquín Fernández","Ernesto Kofman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17570v1","updated":"2025-12-19T13:36:31Z","published":"2025-12-19T13:36:31Z","title":"GreedySnake: Accelerating SSD-Offloaded LLM Training with Efficient Scheduling and Optimizer Step Overlapping","summary":"SSD-offloaded training offers a practical and promising approach to making LLM training cost-effective. Building on gradient accumulation with micro-batches, this paper introduces GreedySnake, a new SSD-offloaded training system that employs vertical scheduling, which executes all microbatches of a layer before proceeding to the next. Compared to existing systems that use horizontal scheduling (i.e., executing micro-batches sequentially), GreedySnake achieves higher training throughput with smaller batch sizes, bringing the system much closer to the ideal scenario predicted by the roofline model. To further mitigate the I/O bottleneck, GreedySnake overlaps part of the optimization step with the forward pass of the next iteration. Experimental results on A100 GPUs show that GreedySnake achieves saturated training throughput improvements over ZeRO-Infinity: 1.96x on 1 GPU and 1.93x on 4 GPUs for GPT-65B, and 2.53x on 1 GPU for GPT-175B. The code is open-sourced at https://github.com/npz7yyk/GreedySnake","authors":["Yikang Yue","Yishu Yin","Xuehai Qian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.06699v2","updated":"2025-12-19T06:10:50Z","published":"2025-12-07T07:25:08Z","title":"Predictive Modeling of I/O Performance for Machine Learning Training Pipelines: A Data-Driven Approach to Storage Optimization","summary":"Modern machine learning training is increasingly bottlenecked by data I/O rather than compute. GPUs often sit idle at below 50% utilization waiting for data. This paper presents a machine learning approach to predict I/O performance and recommend optimal storage configurations for ML training pipelines. We collected 141 observations through systematic benchmarking across different storage backends (NVMe SSD, network-attached storage, in-memory filesystems), data formats, and access patterns, covering both low-level I/O operations and full training pipelines. After evaluating seven regression models and three classification approaches, XGBoost achieved the best performance with R-squared of 0.991, predicting I/O throughput within 11.8% error on average. Feature importance analysis revealed that throughput metrics and batch size are the primary performance drivers. This data-driven approach can reduce configuration time from days of trial-and-error to minutes of predictive recommendation. The methodology is reproducible and extensible to other resource management problems in ML systems. Code and data are available at https://github.com/knkarthik01/gpu_storage_ml_project","authors":["Karthik Prabhakar","Durgamadhab Mishra"],"pdf_url":"","comment":"20 pages, 10 figures"}],"Programming Languages":[{"id":"http://arxiv.org/abs/2512.17616v1","updated":"2025-12-19T14:19:13Z","published":"2025-12-19T14:19:13Z","title":"Multi-Language Benchmark Generation via L-Systems","summary":"L-systems are a mathematical formalism proposed by biologist Aristid Lindenmayer with the aim of simulating organic structures such as trees, snowflakes, flowers, and other branching phenomena. They are implemented as a formal language that defines how patterns can be iteratively rewritten. This paper describes how such a formalism can be used to create artificial programs written in programming languages such as C, C++, Julia and Go. These programs, being large and complex, can be used to test the performance of compilers, operating systems, and computer architectures. This paper demonstrates the usefulness of these benchmarks through multiple case studies. These case studies include a comparison between clang and gcc; a comparison between C, C++, Julia and Go; a study of the historical evolution of gcc in terms of code quality; a look into the effects of profile guided optimizations in gcc; an analysis of the asymptotic behavior of the different phases of clang's compilation pipeline; and a comparison between the many data structures available in the Gnome Library (GLib). These case studies demonstrate the benefits of the L-System approach to create benchmarks, when compared with fuzzers such as CSmith, which were designed to uncover bugs in compilers, rather than evaluating their performance.","authors":["Vinícius Francisco da Silva","Heitor Leite","Fernando Magno Quintão Pereira"],"pdf_url":"","comment":"29 pages, 19 figures, 1 table and 46 references"},{"id":"http://arxiv.org/abs/2512.18134v1","updated":"2025-12-19T23:34:56Z","published":"2025-12-19T23:34:56Z","title":"Optimal Software Pipelining and Warp Specialization for Tensor Core GPUs","summary":"GPU architectures have continued to grow in complexity, with recent incarnations introducing increasingly powerful fixed-function units for matrix multiplication and data movement to accompany highly parallel general-purpose cores. To fully leverage these machines, software must use sophisticated schedules that maximally utilize all hardware resources. Since realizing such schedules is complex, both programmers and compilers routinely employ program transformations, such as software pipelining (SWP) and warp specialization (WS), to do so in practice. However, determining how best to use SWP and WS in combination is a challenging problem that is currently handled through a mix of brittle compilation heuristics and fallible human intuition, with little insight into the space of solutions. To remedy this situation, we introduce a novel formulation of SWP and WS as a joint optimization problem that can be solved holistically by off-the-shelf constraint solvers. We reify our approach in Twill, the first system that automatically derives optimal SWP and WS schedules for a large class of iterative programs. Twill is heuristic-free, easily extensible to new GPU architectures, and guaranteed to produce optimal schedules. We show that Twill can rediscover, and thereby prove optimal, the SWP and WS schedules manually developed by experts for Flash Attention on both the NVIDIA Hopper and Blackwell GPU architectures.","authors":["Rupanshu Soi","Rohan Yadav","Fredrik Kjolstad","Alex Aiken","Maryam Mehri Dehnavi","Michael Garland","Michael Bauer"],"pdf_url":"","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2512.17908v1","updated":"2025-12-19T18:59:56Z","published":"2025-12-19T18:59:56Z","title":"Re-Depth Anything: Test-Time Depth Refinement via Self-Supervised Re-lighting","summary":"Monocular depth estimation remains challenging as recent foundation models, such as Depth Anything V2 (DA-V2), struggle with real-world images that are far from the training distribution. We introduce Re-Depth Anything, a test-time self-supervision framework that bridges this domain gap by fusing DA-V2 with the powerful priors of large-scale 2D diffusion models. Our method performs label-free refinement directly on the input image by re-lighting predicted depth maps and augmenting the input. This re-synthesis method replaces classical photometric reconstruction by leveraging shape from shading (SfS) cues in a new, generative context with Score Distillation Sampling (SDS). To prevent optimization collapse, our framework employs a targeted optimization strategy: rather than optimizing depth directly or fine-tuning the full model, we freeze the encoder and only update intermediate embeddings while also fine-tuning the decoder. Across diverse benchmarks, Re-Depth Anything yields substantial gains in depth accuracy and realism over the DA-V2, showcasing new avenues for self-supervision by augmenting geometric reasoning.","authors":["Ananta R. Bhattarai","Helge Rhodin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17902v1","updated":"2025-12-19T18:59:16Z","published":"2025-12-19T18:59:16Z","title":"Adversarial Robustness of Vision in Open Foundation Models","summary":"With the increase in deep learning, it becomes increasingly difficult to understand the model in which AI systems can identify objects. Thus, an adversary could aim to modify an image by adding unseen elements, which will confuse the AI in its recognition of an entity. This paper thus investigates the adversarial robustness of LLaVA-1.5-13B and Meta's Llama 3.2 Vision-8B-2. These are tested for untargeted PGD (Projected Gradient Descent) against the visual input modality, and empirically evaluated on the Visual Question Answering (VQA) v2 dataset subset. The results of these adversarial attacks are then quantified using the standard VQA accuracy metric. This evaluation is then compared with the accuracy degradation (accuracy drop) of LLaVA and Llama 3.2 Vision. A key finding is that Llama 3.2 Vision, despite a lower baseline accuracy in this setup, exhibited a smaller drop in performance under attack compared to LLaVA, particularly at higher perturbation levels. Overall, the findings confirm that the vision modality represents a viable attack vector for degrading the performance of contemporary open-weight VLMs, including Meta's Llama 3.2 Vision. Furthermore, they highlight that adversarial robustness does not necessarily correlate directly with standard benchmark performance and may be influenced by underlying architectural and training factors.","authors":["Jonathon Fox","William J Buchanan","Pavlos Papadopoulos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17901v1","updated":"2025-12-19T18:59:11Z","published":"2025-12-19T18:59:11Z","title":"When Reasoning Meets Its Laws","summary":"Despite the superior performance of Large Reasoning Models (LRMs), their reasoning behaviors are often counterintuitive, leading to suboptimal reasoning capabilities. To theoretically formalize the desired reasoning behaviors, this paper presents the Laws of Reasoning (LoRe), a unified framework that characterizes intrinsic reasoning patterns in LRMs. We first propose compute law with the hypothesis that the reasoning compute should scale linearly with question complexity. Beyond compute, we extend LoRe with a supplementary accuracy law. Since the question complexity is difficult to quantify in practice, we examine these hypotheses by two properties of the laws, monotonicity and compositionality. We therefore introduce LoRe-Bench, a benchmark that systematically measures these two tractable properties for large reasoning models. Evaluation shows that most reasoning models exhibit reasonable monotonicity but lack compositionality. In response, we develop an effective finetuning approach that enforces compute-law compositionality. Extensive empirical studies demonstrate that better compliance with compute laws yields consistently improved reasoning performance on multiple benchmarks, and uncovers synergistic effects across properties and laws. Project page: https://lore-project.github.io/","authors":["Junyu Zhang","Yifan Sun","Tianang Leng","Jingyan Shen","Liu Ziyin","Paul Pu Liang","Huan Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17898v1","updated":"2025-12-19T18:57:53Z","published":"2025-12-19T18:57:53Z","title":"Humanlike AI Design Increases Anthropomorphism but Yields Divergent Outcomes on Engagement and Trust Globally","summary":"Over a billion users across the globe interact with AI systems engineered with increasing sophistication to mimic human traits. This shift has triggered urgent debate regarding Anthropomorphism, the attribution of human characteristics to synthetic agents, and its potential to induce misplaced trust or emotional dependency. However, the causal link between more humanlike AI design and subsequent effects on engagement and trust has not been tested in realistic human-AI interactions with a global user pool. Prevailing safety frameworks continue to rely on theoretical assumptions derived from Western populations, overlooking the global diversity of AI users. Here, we address these gaps through two large-scale cross-national experiments (N=3,500) across 10 diverse nations, involving real-time and open-ended interactions with an AI system. We find that when evaluating an AI's human-likeness, users focus less on the kind of theoretical aspects often cited in policy (e.g., sentience or consciousness), but rather applied, interactional cues like conversation flow or understanding the user's perspective. We also experimentally demonstrate that humanlike design levers can causally increase anthropomorphism among users; however, we do not find that humanlike design universally increases behavioral measures for user engagement and trust, as previous theoretical work suggests. Instead, part of the connection between human-likeness and behavioral outcomes is fractured by culture: specific design choices that foster self-reported trust in AI-systems in some populations (e.g., Brazil) may trigger the opposite result in others (e.g., Japan). Our findings challenge prevailing narratives of inherent risk in humanlike AI design. Instead, we identify a nuanced, culturally mediated landscape of human-AI interaction, which demands that we move beyond a one-size-fits-all approach in AI governance.","authors":["Robin Schimmelpfennig","Mark Díaz","Vinodkumar Prabhakaran","Aida Davani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17897v1","updated":"2025-12-19T18:57:33Z","published":"2025-12-19T18:57:33Z","title":"RadarGen: Automotive Radar Point Cloud Generation from Cameras","summary":"We present RadarGen, a diffusion model for synthesizing realistic automotive radar point clouds from multi-view camera imagery. RadarGen adapts efficient image-latent diffusion to the radar domain by representing radar measurements in bird's-eye-view form that encodes spatial structure together with radar cross section (RCS) and Doppler attributes. A lightweight recovery step reconstructs point clouds from the generated maps. To better align generation with the visual scene, RadarGen incorporates BEV-aligned depth, semantic, and motion cues extracted from pretrained foundation models, which guide the stochastic generation process toward physically plausible radar patterns. Conditioning on images makes the approach broadly compatible, in principle, with existing visual datasets and simulation frameworks, offering a scalable direction for multimodal generative simulation. Evaluations on large-scale driving data show that RadarGen captures characteristic radar measurement distributions and reduces the gap to perception models trained on real data, marking a step toward unified generative simulation across sensing modalities.","authors":["Tomer Borreda","Fangqiang Ding","Sanja Fidler","Shengyu Huang","Or Litany"],"pdf_url":"","comment":"Project page: https://radargen.github.io/"},{"id":"http://arxiv.org/abs/2512.17893v1","updated":"2025-12-19T18:49:33Z","published":"2025-12-19T18:49:33Z","title":"Exploring the Effect of Basis Rotation on NQS Performance","summary":"Neural Quantum States (NQS) use neural networks to represent wavefunctions of quantum many-body systems, but their performance depends on the choice of basis, yet the underlying mechanism remains poorly understood. We use a fully solvable one-dimensional Ising model to show that local basis rotations leave the loss landscape unchanged while relocating the exact wavefunction in parameter space, effectively increasing its geometric distance from typical initializations. By sweeping a rotation angle, we compute quantum Fisher information and Fubini-Study distances to quantify how the rotated wavefunction moves within the loss landscape. Shallow architectures (with focus on Restricted Boltzmann Machines (RBMs)) trained with quantum natural gradient are more likely to fall into saddle-point regions depending on the rotation angle: they achieve low energy error but fail to reproduce correct coefficient distributions. In the ferromagnetic case, near-degenerate eigenstates create high-curvature barriers that trap optimization at intermediate fidelities. We introduce a framework based on an analytically solvable rotated Ising model to investigate how relocating the target wavefunction within a fixed loss landscape exposes information-geometric barriers,such as saddle points and high-curvature regions,that hinder shallow NQS optimization, underscoring the need for landscape-aware model design in variational training.","authors":["Sven Benjamin Kožić","Vinko Zlatić","Fabio Franchini","Salvatore Marco Giampaolo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.01939v4","updated":"2025-12-19T18:39:57Z","published":"2025-07-02T17:49:52Z","title":"SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars","summary":"In recent years, large language models (LLMs) have transformed natural language understanding through vast datasets and large-scale parameterization. Inspired by this success, we present SpecCLIP, a foundation model framework that extends LLM-inspired methodologies to stellar spectral analysis. Stellar spectra, akin to structured language, encode rich physical and chemical information about stars. By training foundation models on large-scale spectral datasets, our goal is to learn robust and informative embeddings that support diverse downstream applications. As a proof of concept, SpecCLIP involves pre-training on two spectral types--LAMOST low-resolution and Gaia XP--followed by contrastive alignment using the CLIP (Contrastive Language-Image Pre-training) framework, adapted to associate spectra from different instruments. This alignment is complemented by auxiliary decoders that preserve spectrum-specific information and enable translation (prediction) between spectral types, with the former achieved by maximizing mutual information between embeddings and input spectra. The result is a cross-spectrum framework enabling intrinsic calibration and flexible applications across instruments. We demonstrate that fine-tuning these models on moderate-sized labeled datasets improves adaptability to tasks such as stellar-parameter estimation and chemical-abundance determination. SpecCLIP also enhances the accuracy and precision of parameter estimates benchmarked against external survey data. Additionally, its similarity search and cross-spectrum prediction capabilities offer potential for anomaly detection. Our results suggest that contrastively trained foundation models enriched with spectrum-aware decoders can advance precision stellar spectroscopy. Our code SpecCLIP is publicly available at https://github.com/Xiaosheng-Zhao/SpecCLIP","authors":["Xiaosheng Zhao","Yang Huang","Guirong Xue","Xiao Kong","Jifeng Liu","Xiaoyu Tang","Timothy C. Beers","Yuan-Sen Ting","A-Li Luo"],"pdf_url":"","comment":"29 pages, 8 figures, 6 tables. Accepted for publication in ApJ. Comments welcome"},{"id":"http://arxiv.org/abs/2512.17878v1","updated":"2025-12-19T18:31:27Z","published":"2025-12-19T18:31:27Z","title":"Weighted Stochastic Differential Equation to Implement Wasserstein-Fisher-Rao Gradient Flow","summary":"Score-based diffusion models currently constitute the state of the art in continuous generative modeling. These methods are typically formulated via overdamped or underdamped Ornstein--Uhlenbeck-type stochastic differential equations, in which sampling is driven by a combination of deterministic drift and Brownian diffusion, resulting in continuous particle trajectories in the ambient space. While such dynamics enjoy exponential convergence guarantees for strongly log-concave target distributions, it is well known that their mixing rates deteriorate exponentially in the presence of nonconvex or multimodal landscapes, such as double-well potentials. Since many practical generative modeling tasks involve highly non-log-concave target distributions, considerable recent effort has been devoted to developing sampling schemes that improve exploration beyond classical diffusion dynamics.\n  A promising line of work leverages tools from information geometry to augment diffusion-based samplers with controlled mass reweighting mechanisms. This perspective leads naturally to Wasserstein--Fisher--Rao (WFR) geometries, which couple transport in the sample space with vertical (reaction) dynamics on the space of probability measures. In this work, we formulate such reweighting mechanisms through the introduction of explicit correction terms and show how they can be implemented via weighted stochastic differential equations using the Feynman--Kac representation. Our study provides a preliminary but rigorous investigation of WFR-based sampling dynamics, and aims to clarify their geometric and operator-theoretic structure as a foundation for future theoretical and algorithmic developments.","authors":["Herlock Rahimi"],"pdf_url":"","comment":"26 pages, 1 figure"},{"id":"http://arxiv.org/abs/2512.15692v2","updated":"2025-12-19T18:30:30Z","published":"2025-12-17T18:47:31Z","title":"mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs","summary":"Prevailing Vision-Language-Action Models (VLAs) for robotic manipulation are built upon vision-language backbones pretrained on large-scale, but disconnected static web data. As a result, despite improved semantic generalization, the policy must implicitly infer complex physical dynamics and temporal dependencies solely from robot trajectories. This reliance creates an unsustainable data burden, necessitating continuous, large-scale expert data collection to compensate for the lack of innate physical understanding. We contend that while vision-language pretraining effectively captures semantic priors, it remains blind to physical causality. A more effective paradigm leverages video to jointly capture semantics and visual dynamics during pretraining, thereby isolating the remaining task of low-level control. To this end, we introduce mimic-video, a novel Video-Action Model (VAM) that pairs a pretrained Internet-scale video model with a flow matching-based action decoder conditioned on its latent representations. The decoder serves as an Inverse Dynamics Model (IDM), generating low-level robot actions from the latent representation of video-space action plans. Our extensive evaluation shows that our approach achieves state-of-the-art performance on simulated and real-world robotic manipulation tasks, improving sample efficiency by 10x and convergence speed by 2x compared to traditional VLA architectures.","authors":["Jonas Pai","Liam Achenbach","Victoriano Montesinos","Benedek Forrai","Oier Mees","Elvis Nava"],"pdf_url":"","comment":"Revised Introduction, Related Work, and Appendix. Additional minor notational and grammatical fixes"},{"id":"http://arxiv.org/abs/2511.12712v2","updated":"2025-12-19T18:24:09Z","published":"2025-11-16T17:52:32Z","title":"Adaptive Focus Memory for Language Models","summary":"Large language models (LLMs) are increasingly deployed in multi-turn dialogue settings, yet their behavior remains bottlenecked by naive history management strategies. Replaying the full conversation at every turn is simple but costly, while recency-based truncation or static summarization often causes early, high-impact user constraints to drift out of effective context. As a result, models may retain text without reliably applying it when it matters.\n  We present Adaptive Focus Memory (AFM), a lightweight context management system that dynamically assigns each past message one of three fidelity levels: Full, Compressed, or Placeholder, based on semantic relevance, temporal decay, and importance classification. AFM packs messages chronologically under a fixed token budget, preserving critical constraints at high fidelity while allowing low-importance context to degrade gracefully.\n  We evaluate AFM on two multi-turn dialogue benchmarks designed to stress long-horizon constraint preservation: a safety-critical travel scenario involving a user with a severe peanut allergy, and a policy-critical tax compliance scenario involving an illegal evasion request. Under strict grading that requires both explicit constraint recall and appropriately conditioned generation, AFM succeeds in 83.3 percent of allergy runs where all baseline strategies fail, and preserves correct refusal behavior on the tax benchmark.\n  These results demonstrate that effective dialogue memory requires more than retaining prior text. Selectively allocating fidelity across past messages enables reliable constraint preservation under bounded context growth, without modifying model weights or introducing external retrieval infrastructure. We release an open-source implementation of AFM compatible with OpenAI-style chat APIs to support reproducible research and practical deployment.","authors":["Christopher Cruz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17864v1","updated":"2025-12-19T18:11:15Z","published":"2025-12-19T18:11:15Z","title":"Interpretable Plant Leaf Disease Detection Using Attention-Enhanced CNN","summary":"Plant diseases pose a significant threat to global food security, necessitating accurate and interpretable disease detection methods. This study introduces an interpretable attention-guided Convolutional Neural Network (CNN), CBAM-VGG16, for plant leaf disease detection. By integrating Convolution Block Attention Module (CBAM) at each convolutional stage, the model enhances feature extraction and disease localization. Trained on five diverse plant disease datasets, our approach outperforms recent techniques, achieving high accuracy (up to 98.87%) and demonstrating robust generalization. Here, we show the effectiveness of our method through comprehensive evaluation and interpretability analysis using CBAM attention maps, Grad-CAM, Grad-CAM++, and Layer-wise Relevance Propagation (LRP). This study advances the application of explainable AI in agricultural diagnostics, offering a transparent and reliable system for smart farming. The code of our proposed work is available at https://github.com/BS0111/PlantAttentionCBAM.","authors":["Balram Singh","Ram Prakash Sharma","Somnath Dey"],"pdf_url":"","comment":"27 pages, 12 figures"},{"id":"http://arxiv.org/abs/2512.17853v1","updated":"2025-12-19T17:55:48Z","published":"2025-12-19T17:55:48Z","title":"AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning","summary":"Generalist robot learning remains constrained by data: large-scale, diverse, and high-quality interaction data are expensive to collect in the real world. While simulation has become a promising way for scaling up data collection, the related tasks, including simulation task design, task-aware scene generation, expert demonstration synthesis, and sim-to-real transfer, still demand substantial human effort. We present AnyTask, an automated framework that pairs massively parallel GPU simulation with foundation models to design diverse manipulation tasks and synthesize robot data. We introduce three AnyTask agents for generating expert demonstrations aiming to solve as many tasks as possible: 1) ViPR, a novel task and motion planning agent with VLM-in-the-loop Parallel Refinement; 2) ViPR-Eureka, a reinforcement learning agent with generated dense rewards and LLM-guided contact sampling; 3) ViPR-RL, a hybrid planning and learning approach that jointly produces high-quality demonstrations with only sparse rewards. We train behavior cloning policies on generated data, validate them in simulation, and deploy them directly on real robot hardware. The policies generalize to novel object poses, achieving 44% average success across a suite of real-world pick-and-place, drawer opening, contact-rich pushing, and long-horizon manipulation tasks. Our project website is at https://anytask.rai-inst.com .","authors":["Ran Gong","Xiaohan Zhang","Jinghuan Shang","Maria Vittoria Minniti","Jigarkumar Patel","Valerio Pepe","Riedana Yan","Ahmet Gundogdu","Ivan Kapelyukh","Ali Abbas","Xiaoqiang Yan","Harsh Patel","Laura Herlant","Karl Schmeckpeper"],"pdf_url":"","comment":"28 pages, 25 figures. The first four authors contributed equally"},{"id":"http://arxiv.org/abs/2512.17851v1","updated":"2025-12-19T17:52:43Z","published":"2025-12-19T17:52:43Z","title":"InfSplign: Inference-Time Spatial Alignment of Text-to-Image Diffusion Models","summary":"Text-to-image (T2I) diffusion models generate high-quality images but often fail to capture the spatial relations specified in text prompts. This limitation can be traced to two factors: lack of fine-grained spatial supervision in training data and inability of text embeddings to encode spatial semantics. We introduce InfSplign, a training-free inference-time method that improves spatial alignment by adjusting the noise through a compound loss in every denoising step. Proposed loss leverages different levels of cross-attention maps extracted from the backbone decoder to enforce accurate object placement and a balanced object presence during sampling. The method is lightweight, plug-and-play, and compatible with any diffusion backbone. Our comprehensive evaluations on VISOR and T2I-CompBench show that InfSplign establishes a new state-of-the-art (to the best of our knowledge), achieving substantial performance gains over the strongest existing inference-time baselines and even outperforming the fine-tuning-based methods. Codebase is available at GitHub.","authors":["Sarah Rastegar","Violeta Chatalbasheva","Sieger Falkena","Anuj Singh","Yanbo Wang","Tejas Gokhale","Hamid Palangi","Hadi Jamali-Rad"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17850v1","updated":"2025-12-19T17:50:05Z","published":"2025-12-19T17:50:05Z","title":"Integrating Computational Methods and AI into Qualitative Studies of Aging and Later Life","summary":"This chapter demonstrates how computational social science (CSS) tools are extending and expanding research on aging. The depth and context from traditionally qualitative methods such as participant observation, in-depth interviews, and historical documents are increasingly employed alongside scalable data management, computational text analysis, and open-science practices. Machine learning (ML) and natural language processing (NLP), provide resources to aggregate and systematically index large volumes of qualitative data, identify patterns, and maintain clear links to in-depth accounts. Drawing on case studies of projects that examine later life--including examples with original data from the DISCERN study (a team-based ethnography of life with dementia) and secondary analyses of the American Voices Project (nationally representative interview)--the chapter highlights both uses and challenges of bringing CSS tools into more meaningful dialogue with qualitative aging research. The chapter argues such work has potential for (1) streamlining and augmenting existing workflows, (2) scaling up samples and projects, and (3) generating multi-method approaches to address important questions in new ways, before turning to practices useful for individuals and teams seeking to understand current possibilities or refine their workflow processes. The chapter concludes that current developments are not without peril, but offer potential for new insights into aging and the life course by broadening--rather than replacing--the methodological foundations of qualitative research.","authors":["Corey M. Abramson"],"pdf_url":"","comment":"CITE: Abramson, Corey M. (Forthcoming 2026). \"Integrating Computational Methods and AI into Qualitative Studies of Aging and Later Life.\" In Handbook of the Sociology of Aging, 2nd ed., edited by Markus H. Schafer, Dawn C. Carr, Jacqueline L. Angel, and Richard A. Settersten Jr"},{"id":"http://arxiv.org/abs/2512.17846v1","updated":"2025-12-19T17:49:13Z","published":"2025-12-19T17:49:13Z","title":"Planning as Descent: Goal-Conditioned Latent Trajectory Synthesis in Learned Energy Landscapes","summary":"We present Planning as Descent (PaD), a framework for offline goal-conditioned reinforcement learning that grounds trajectory synthesis in verification. Instead of learning a policy or explicit planner, PaD learns a goal-conditioned energy function over entire latent trajectories, assigning low energy to feasible, goal-consistent futures. Planning is realized as gradient-based refinement in this energy landscape, using identical computation during training and inference to reduce train-test mismatch common in decoupled modeling pipelines.\n  PaD is trained via self-supervised hindsight goal relabeling, shaping the energy landscape around the planning dynamics. At inference, multiple trajectory candidates are refined under different temporal hypotheses, and low-energy plans balancing feasibility and efficiency are selected.\n  We evaluate PaD on OGBench cube manipulation tasks. When trained on narrow expert demonstrations, PaD achieves state-of-the-art 95\\% success, strongly outperforming prior methods that peak at 68\\%. Remarkably, training on noisy, suboptimal data further improves success and plan efficiency, highlighting the benefits of verification-driven planning. Our results suggest learning to evaluate and refine trajectories provides a robust alternative to direct policy learning for offline, reward-free planning.","authors":["Carlos Vélez García","Miguel Cazorla","Jorge Pomares"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17843v1","updated":"2025-12-19T17:47:53Z","published":"2025-12-19T17:47:53Z","title":"ShareChat: A Dataset of Chatbot Conversations in the Wild","summary":"While Large Language Models (LLMs) have evolved into distinct platforms with unique interface designs and capabilities, existing public datasets treat models as generic text generators, stripping away the interface context that actively shapes user interaction. To address this limitation, we present ShareChat, a large-scale, cross-platform corpus comprising 142,808 conversations and over 660,000 turns collected from publicly shared URLs across five major platforms: ChatGPT, Claude, Gemini, Perplexity, and Grok. ShareChat distinguishes itself by preserving native platform affordances often lost in standard logs, including reasoning traces, source links, and code artifacts, while spanning 101 languages over the period from April 2023 to October 2025. Furthermore, ShareChat offers substantially longer context windows and greater interaction depth than prior datasets. We demonstrate the dataset's multifaceted utility through three representative analyses: (1) analyzing conversation completeness to measure user intent satisfaction; (2) evaluating source citation behaviors in content generation; and (3) conducting temporal analysis to track evolving usage patterns. This work provides the community with a vital and timely resource for understanding authentic user-LLM chatbot interactions in the wild.","authors":["Yueru Yan","Tuc Nguyen","Bo Su","Melissa Lieffers","Thai Le"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.11512v2","updated":"2025-12-19T17:47:28Z","published":"2025-09-15T01:53:30Z","title":"Machine Learning-Driven Predictive Resource Management in Complex Science Workflows","summary":"The collaborative efforts of large communities in science experiments, often comprising thousands of global members, reflect a monumental commitment to exploration and discovery. Recently, advanced and complex data processing has gained increasing importance in science experiments. Data processing workflows typically consist of multiple intricate steps, and the precise specification of resource requirements is crucial for each step to allocate optimal resources for effective processing. Estimating resource requirements in advance is challenging due to a wide range of analysis scenarios, varying skill levels among community members, and the continuously increasing spectrum of computing options. One practical approach to mitigate these challenges involves initially processing a subset of each step to measure precise resource utilization from actual processing profiles before completing the entire step. While this two-staged approach enables processing on optimal resources for most of the workflow, it has drawbacks such as initial inaccuracies leading to potential failures and suboptimal resource usage, along with overhead from waiting for initial processing completion, which is critical for fast-turnaround analyses. In this context, our study introduces a novel pipeline of machine learning models within a comprehensive workflow management system, the Production and Distributed Analysis (PanDA) system. These models employ advanced machine learning techniques to predict key resource requirements, overcoming challenges posed by limited upfront knowledge of characteristics at each step. Accurate forecasts of resource requirements enable informed and proactive decision-making in workflow management, enhancing the efficiency of handling diverse, complex workflows across heterogeneous resources.","authors":["Tasnuva Chowdhury","Tadashi Maeno","Fatih Furkan Akman","Joseph Boudreau","Sankha Dutta","Shengyu Feng","Adolfy Hoisie","Kuan-Chieh Hsu","Raees Khan","Jaehyung Kim","Ozgur O. Kilic","Scott Klasky","Alexei Klimentov","Tatiana Korchuganova","Verena Ingrid Martinez Outschoorn","Paul Nilsson","David K. Park","Norbert Podhorszki","Yihui Ren","John Rembrandt Steele","Frédéric Suter","Sairam Sri Vatsavai","Torre Wenaus","Wei Yang","Yiming Yang","Shinjae Yoo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.22219v3","updated":"2025-12-19T17:35:31Z","published":"2025-07-29T20:35:35Z","title":"RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation","summary":"Preference-learning methods for machine translation (MT), such as Direct Preference Optimization (DPO), have shown strong gains but typically rely on large, carefully curated preference triplets and often struggle to generalize beyond their tuning domains. We propose Reinforcement Learning from Teacher-Model Refinement (RLfR), which replaces static triplets with on-policy, actor-conditioned refinements produced by a frozen teacher. At each step, the actor samples candidate translations, the teacher performs a minimal local edit of each draft, and the actor is reinforced to close the gap using a composite reward that combines scaled negative edit distance for lexical and structural fidelity with COMET for semantic adequacy. This formulation yields a stable, model-aware learning signal without requiring explicit preference datasets. Experiments on FLORES-200 (English to German, Spanish, Chinese, Korean, and Japanese) show that RLfR consistently outperforms strong MT-SFT, DPO, and fixed-reference RL baselines, improving semantic quality and entity preservation, and also achieves superior performance under LLM-based judge evaluations.","authors":["Dongyub Jude Lee","Zhenyi Ye","Pengcheng He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17814v1","updated":"2025-12-19T17:19:08Z","published":"2025-12-19T17:19:08Z","title":"LLM-based Behaviour Driven Development for Hardware Design","summary":"Test and verification are essential activities in hardware and system design, but their complexity grows significantly with increasing system sizes. While Behavior Driven Development (BDD) has proven effective in software engineering, it is not yet well established in hardware design, and its practical use remains limited. One contributing factor is the manual effort required to derive precise behavioral scenarios from textual specifications.\n  Recent advances in Large Language Models (LLMs) offer new opportunities to automate this step. In this paper, we investigate the use of LLM-based techniques to support BDD in the context of hardware design.","authors":["Rolf Drechsler","Qian Liu"],"pdf_url":"","comment":"7 pages, keynote given at 2nd International Symposium on Artificial Intelligence and Internet of Things (AIIoT-25), December 22-24th, 2025"},{"id":"http://arxiv.org/abs/2506.10892v3","updated":"2025-12-19T17:14:07Z","published":"2025-06-12T16:55:35Z","title":"The Diffusion Duality","summary":"Uniform-state discrete diffusion models hold the promise of fast text generation due to their inherent ability to self-correct. However, they are typically outperformed by autoregressive models and masked diffusion models. In this work, we narrow this performance gap by leveraging a key insight: Uniform-state diffusion processes naturally emerge from an underlying Gaussian diffusion. Our method, Duo, transfers powerful techniques from Gaussian diffusion to improve both training and sampling. First, we introduce a curriculum learning strategy guided by the Gaussian process, doubling training speed by reducing variance. Models trained with curriculum learning surpass autoregressive models in zero-shot perplexity on 3 of 7 benchmarks. Second, we present Discrete Consistency Distillation, which adapts consistency distillation from the continuous to the discrete setting. This algorithm unlocks few-step generation in diffusion language models by accelerating sampling by two orders of magnitude. We provide the code, model checkpoints, and video tutorials on the project page: http://s-sahoo.github.io/duo","authors":["Subham Sekhar Sahoo","Justin Deschenaux","Aaron Gokaslan","Guanghan Wang","Justin Chiu","Volodymyr Kuleshov"],"pdf_url":"","comment":"ICML 2025. We provide the code at: https://github.com/s-sahoo/duo [v3] includes improved theory, clearer presentation, and a new future work section"},{"id":"http://arxiv.org/abs/2512.17795v1","updated":"2025-12-19T17:01:03Z","published":"2025-12-19T17:01:03Z","title":"Intelligent Knowledge Mining Framework: Bridging AI Analysis and Trustworthy Preservation","summary":"The unprecedented proliferation of digital data presents significant challenges in access, integration, and value creation across all data-intensive sectors. Valuable information is frequently encapsulated within disparate systems, unstructured documents, and heterogeneous formats, creating silos that impede efficient utilization and collaborative decision-making. This paper introduces the Intelligent Knowledge Mining Framework (IKMF), a comprehensive conceptual model designed to bridge the critical gap between dynamic AI-driven analysis and trustworthy long-term preservation. The framework proposes a dual-stream architecture: a horizontal Mining Process that systematically transforms raw data into semantically rich, machine-actionable knowledge, and a parallel Trustworthy Archiving Stream that ensures the integrity, provenance, and computational reproducibility of these assets. By defining a blueprint for this symbiotic relationship, the paper provides a foundational model for transforming static repositories into living ecosystems that facilitate the flow of actionable intelligence from producers to consumers. This paper outlines the motivation, problem statement, and key research questions guiding the research and development of the framework, presents the underlying scientific methodology, and details its conceptual design and modeling.","authors":["Binh Vu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.18057v6","updated":"2025-12-19T16:58:50Z","published":"2025-09-22T17:30:33Z","title":"Reinforced Generation of Combinatorial Structures: Hardness of Approximation","summary":"Can AI based methods help us make advances in complexity theory? We provide evidence towards answering this in the affirmative, using AlphaEvolve (an LLM code mutation agent) to obtain new results in three settings:\n  a) We improve a recent result of Kunisky and Yu to obtain near-optimal upper and (conditional) lower bounds on certification algorithms for MAX-CUT and MAX-Independent Set on random 3- and 4-regular graphs. Our improved lower bounds are obtained by constructing nearly extremal Ramanujan graphs on as many as $163$ vertices, and our upper bounds are obtained via analytical arguments.\n  b) We obtain new inapproximability results for MAX-4-CUT and MAX-3-CUT, proving that it is NP-hard to approximate them within factors of $0.987$ and $0.9649$ respectively, using AlphaEvolve to discover new gadget reductions. Our MAX-4-CUT result improves upon the SOTA of $0.9883$, and our MAX-3-CUT result improves on the current best gadget-based inapproximability result of $0.9853$, but falls short of the SOTA of $16/17$ that relies on a custom PCP (rather than a reduction from ``standard'' Håstad-style PCPs).\n  c) Inapproximability for the metric Traveling Salesman Problem (TSP): We show that it is NP-hard to approximate the minimum cost tour within a factor of $111/110$ using AlphaEvolve to discover a new gadget, thus improving the SOTA of $117/116$. Along the way, we provide new modular soundness and completeness arguments that can be of independent interest.\n  A key technical challenge we faced: verifying a candidate construction produced by AlphaEvolve is costly (sometimes requiring time exponential in the size of the construction). We used AlphaEvolve itself to evolve the verification procedure to be faster (sometimes by $10,000\\times$ for our gadgets). Our results suggest that gadget based proofs would benefit from a pass through AI-based tools to obtain stronger results.","authors":["Ansh Nagda","Prabhakar Raghavan","Abhradeep Thakurta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17774v1","updated":"2025-12-19T16:45:23Z","published":"2025-12-19T16:45:23Z","title":"MedNeXt-v2: Scaling 3D ConvNeXts for Large-Scale Supervised Representation Learning in Medical Image Segmentation","summary":"Large-scale supervised pretraining is rapidly reshaping 3D medical image segmentation. However, existing efforts focus primarily on increasing dataset size and overlook the question of whether the backbone network is an effective representation learner at scale. In this work, we address this gap by revisiting ConvNeXt-based architectures for volumetric segmentation and introducing MedNeXt-v2, a compound-scaled 3D ConvNeXt that leverages improved micro-architecture and data scaling to deliver state-of-the-art performance. First, we show that routinely used backbones in large-scale pretraining pipelines are often suboptimal. Subsequently, we use comprehensive backbone benchmarking prior to scaling and demonstrate that stronger from scratch performance reliably predicts stronger downstream performance after pretraining. Guided by these findings, we incorporate a 3D Global Response Normalization module and use depth, width, and context scaling to improve our architecture for effective representation learning. We pretrain MedNeXt-v2 on 18k CT volumes and demonstrate state-of-the-art performance when fine-tuning across six challenging CT and MR benchmarks (144 structures), showing consistent gains over seven publicly released pretrained models. Beyond improvements, our benchmarking of these models also reveals that stronger backbones yield better results on similar data, representation scaling disproportionately benefits pathological segmentation, and that modality-specific pretraining offers negligible benefit once full finetuning is applied. In conclusion, our results establish MedNeXt-v2 as a strong backbone for large-scale supervised representation learning in 3D Medical Image Segmentation. Our code and pretrained models are made available with the official nnUNet repository at: https://www.github.com/MIC-DKFZ/nnUNet","authors":["Saikat Roy","Yannick Kirchhoff","Constantin Ulrich","Maximillian Rokuss","Tassilo Wald","Fabian Isensee","Klaus Maier-Hein"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17773v1","updated":"2025-12-19T16:44:32Z","published":"2025-12-19T16:44:32Z","title":"Pix2NPHM: Learning to Regress NPHM Reconstructions From a Single Image","summary":"Neural Parametric Head Models (NPHMs) are a recent advancement over mesh-based 3d morphable models (3DMMs) to facilitate high-fidelity geometric detail. However, fitting NPHMs to visual inputs is notoriously challenging due to the expressive nature of their underlying latent space. To this end, we propose Pix2NPHM, a vision transformer (ViT) network that directly regresses NPHM parameters, given a single image as input. Compared to existing approaches, the neural parametric space allows our method to reconstruct more recognizable facial geometry and accurate facial expressions. For broad generalization, we exploit domain-specific ViTs as backbones, which are pretrained on geometric prediction tasks. We train Pix2NPHM on a mixture of 3D data, including a total of over 100K NPHM registrations that enable direct supervision in SDF space, and large-scale 2D video datasets, for which normal estimates serve as pseudo ground truth geometry. Pix2NPHM not only allows for 3D reconstructions at interactive frame rates, it is also possible to improve geometric fidelity by a subsequent inference-time optimization against estimated surface normals and canonical point maps. As a result, we achieve unprecedented face reconstruction quality that can run at scale on in-the-wild data.","authors":["Simon Giebenhain","Tobias Kirschstein","Liam Schoneveld","Davide Davoli","Zhe Chen","Matthias Nießner"],"pdf_url":"","comment":"Project website: https://simongiebenhain.github.io/Pix2NPHM/ , Video: https://www.youtube.com/watch?v=MgpEJC5p1Ts"},{"id":"http://arxiv.org/abs/2512.17771v1","updated":"2025-12-19T16:43:07Z","published":"2025-12-19T16:43:07Z","title":"Easy Adaptation: An Efficient Task-Specific Knowledge Injection Method for Large Models in Resource-Constrained Environments","summary":"While the enormous parameter scale endows Large Models (LMs) with unparalleled performance, it also limits their adaptability across specific tasks. Parameter-Efficient Fine-Tuning (PEFT) has emerged as a critical approach for effectively adapting LMs to a diverse range of downstream tasks. However, existing PEFT methods face two primary challenges: (1) High resource cost. Although PEFT methods significantly reduce resource demands compared to full fine-tuning, it still requires substantial time and memory, making it impractical in resource-constrained environments. (2) Parameter dependency. PEFT methods heavily rely on updating a subset of parameters associated with LMs to incorporate task-specific knowledge. Yet, due to increasing competition in the LMs landscape, many companies have adopted closed-source policies for their leading models, offering access only via Application Programming Interface (APIs). Whereas, the expense is often cost-prohibitive and difficult to sustain, as the fine-tuning process of LMs is extremely slow. Even if small models perform far worse than LMs in general, they can achieve superior results on particular distributions while requiring only minimal resources. Motivated by this insight, we propose Easy Adaptation (EA), which designs Specific Small Models (SSMs) to complement the underfitted data distribution for LMs. Extensive experiments show that EA matches the performance of PEFT on diverse tasks without accessing LM parameters, and requires only minimal resources.","authors":["Dong Chen","Zhengqing Hu","Shixing Zhao","Yibo Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17769v1","updated":"2025-12-19T16:41:16Z","published":"2025-12-19T16:41:16Z","title":"Bangla MedER: Multi-BERT Ensemble Approach for the Recognition of Bangla Medical Entity","summary":"Medical Entity Recognition (MedER) is an essential NLP task for extracting meaningful entities from the medical corpus. Nowadays, MedER-based research outcomes can remarkably contribute to the development of automated systems in the medical sector, ultimately enhancing patient care and outcomes. While extensive research has been conducted on MedER in English, low-resource languages like Bangla remain underexplored. Our work aims to bridge this gap. For Bangla medical entity recognition, this study first examined a number of transformer models, including BERT, DistilBERT, ELECTRA, and RoBERTa. We also propose a novel Multi-BERT Ensemble approach that outperformed all baseline models with the highest accuracy of 89.58%. Notably, it provides an 11.80% accuracy improvement over the single-layer BERT model, demonstrating its effectiveness for this task. A major challenge in MedER for low-resource languages is the lack of annotated datasets. To address this issue, we developed a high-quality dataset tailored for the Bangla MedER task. The dataset was used to evaluate the effectiveness of our model through multiple performance metrics, demonstrating its robustness and applicability. Our findings highlight the potential of Multi-BERT Ensemble models in improving MedER for Bangla and set the foundation for further advancements in low-resource medical NLP.","authors":["Tanjim Taharat Aurpa","Farzana Akter","Md. Mehedi Hasan","Shakil Ahmed","Shifat Ara Rafiq","Fatema Khan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.00496v2","updated":"2025-12-19T16:38:02Z","published":"2025-08-30T13:37:28Z","title":"ResearchQA: Evaluating Scholarly Question Answering at Scale Across 75 Fields with Survey-Mined Questions and Rubrics","summary":"Evaluating long-form responses to research queries heavily relies on expert annotators, restricting attention to areas like AI where researchers can conveniently enlist colleagues. Yet, research expertise is abundant: survey articles consolidate knowledge spread across the literature. We introduce ResearchQA, a resource for evaluating LLM systems by distilling survey articles from 75 research fields into 21K queries and 160K rubric items. Queries and rubrics are jointly derived from survey sections, where rubric items list query-specific answer evaluation criteria, i.e., citing papers, making explanations, and describing limitations. 31 Ph.D. annotators in 8 fields judge that 90% of queries reflect Ph.D. information needs and 87% of rubric items warrant emphasis of a sentence or longer. We leverage ResearchQA to evaluate 18 systems in 7.6K head-to-heads. No parametric or retrieval-augmented system we evaluate exceeds 70% on covering rubric items, and the highest-ranking system shows 75% coverage. Error analysis reveals that the highest-ranking system fully addresses less than 11% of citation rubric items, 48% of limitation items, and 49% of comparison items. We release our data to facilitate more comprehensive multi-field evaluations.","authors":["Li S. Yifei","Allen Chang","Chaitanya Malaviya","Mark Yatskar"],"pdf_url":"","comment":"12 pages main, 40 pages total, 15 figures"},{"id":"http://arxiv.org/abs/2506.09147v4","updated":"2025-12-19T16:35:50Z","published":"2025-06-10T18:01:42Z","title":"LLM-as-a-qualitative-judge: automating error analysis in natural language generation","summary":"Prompting large language models (LLMs) to evaluate generated text, known as LLM-as-a-judge, has become a standard evaluation approach in natural language generation (NLG), but is primarily used as a quantitative tool, i.e. with numerical scores as main outputs. In this work, we propose LLM-as-a-qualitative-judge, an LLM-based evaluation approach with the main output being a structured report of common issue types in the NLG system outputs. Our approach is targeted at providing developers with meaningful insights on what improvements can be done to a given NLG system and consists of two main steps, namely open-ended per-instance issue analysis and clustering of the discovered issues using an intuitive cumulative algorithm. We also introduce a strategy for evaluating the proposed approach, coupled with ~300 annotations of issues in instances from 12 NLG datasets. Our results show that instance-specific issues output by LLM-as-a-qualitative-judge match those annotated by humans in 2/3 cases, and that LLM-as-a-qualitative-judge is capable of producing error type reports resembling the reports composed by human annotators. We also demonstrate in a case study how the use of LLM-as-a-qualitative-judge can substantially improve NLG systems performance. Our code and data are publicly available at https://github.com/tunde-ajayi/llm-as-a-qualitative-judge.","authors":["Nadezhda Chirkova","Tunde Oluwaseyi Ajayi","Seth Aycock","Zain Muhammad Mujahid","Vladana Perlić","Ekaterina Borisova","Markarit Vartampetian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17756v1","updated":"2025-12-19T16:28:57Z","published":"2025-12-19T16:28:57Z","title":"AncientBench: Towards Comprehensive Evaluation on Excavated and Transmitted Chinese Corpora","summary":"Comprehension of ancient texts plays an important role in archaeology and understanding of Chinese history and civilization. The rapid development of large language models needs benchmarks that can evaluate their comprehension of ancient characters. Existing Chinese benchmarks are mostly targeted at modern Chinese and transmitted documents in ancient Chinese, but the part of excavated documents in ancient Chinese is not covered. To meet this need, we propose the AncientBench, which aims to evaluate the comprehension of ancient characters, especially in the scenario of excavated documents. The AncientBench is divided into four dimensions, which correspond to the four competencies of ancient character comprehension: glyph comprehension, pronunciation comprehension, meaning comprehension, and contextual comprehension. The benchmark also contains ten tasks, including radical, phonetic radical, homophone, cloze, translation, and more, providing a comprehensive framework for evaluation. We convened archaeological researchers to conduct experimental evaluations, proposed an ancient model as baseline, and conducted extensive experiments on the currently best-performing large language models. The experimental results reveal the great potential of large language models in ancient textual scenarios as well as the gap with humans. Our research aims to promote the development and application of large language models in the field of archaeology and ancient Chinese language.","authors":["Zhihan Zhou","Daqian Shi","Rui Song","Lida Shi","Xiaolei Diao","Hao Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10501v4","updated":"2025-12-19T16:27:34Z","published":"2025-08-14T10:03:47Z","title":"PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning","summary":"Existing tool-augmented agentic systems are limited in the real world by (i) black-box reasoning steps that undermine trust of decision-making and pose safety risks, (ii) poor multimodal integration, which is inherently critical for healthcare tasks, and (iii) rigid and computationally inefficient agentic pipelines. We introduce PASS (Probabilistic Agentic Supernet Sampling), the first multimodal framework to address these challenges in the context of Chest X-Ray (CXR) reasoning. PASS adaptively samples agentic workflows over a multi-tool graph, yielding decision paths annotated with interpretable probabilities. Given the complex CXR reasoning task with multimodal medical data, PASS leverages its learned task-conditioned distribution over the agentic supernet. Thus, it adaptively selects the most suitable tool at each supernet layer, offering probability-annotated trajectories for post-hoc audits and directly enhancing medical AI safety. PASS also continuously compresses salient findings into an evolving personalized memory, while dynamically deciding whether to deepen its reasoning path or invoke an early exit for efficiency. To optimize a Pareto frontier balancing performance and cost, we design a novel three-stage training procedure, including expert knowledge warm-up, contrastive path-ranking, and cost-aware reinforcement learning. To facilitate rigorous evaluation, we introduce CAB-E, a comprehensive benchmark for multi-step, safety-critical, free-form CXR reasoning. Experiments across various benchmarks validate that PASS significantly outperforms strong baselines in multiple metrics (e.g., accuracy, LLM-Judge, semantic similarity, etc.) while balancing computational costs, pushing a new paradigm shift towards interpretable, adaptive, and multimodal medical agentic systems.","authors":["Yushi Feng","Junye Du","Yingying Hong","Qifan Wang","Lequan Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.24830v2","updated":"2025-12-19T16:21:05Z","published":"2025-10-28T16:42:53Z","title":"The Generation Phases of Flow Matching: a Denoising Perspective","summary":"Flow matching has achieved remarkable success, yet the factors influencing the quality of its generation process remain poorly understood. In this work, we adopt a denoising perspective and design a framework to empirically probe the generation process. Laying down the formal connections between flow matching models and denoisers, we provide a common ground to compare their performances on generation and denoising. This enables the design of principled and controlled perturbations to influence sample generation: noise and drift. This leads to new insights on the distinct dynamical phases of the generative process, enabling us to precisely characterize at which stage of the generative process denoisers succeed or fail and why this matters.","authors":["Anne Gagneux","Ségolène Martin","Rémi Gribonval","Mathurin Massias"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.12508v4","updated":"2025-12-19T16:18:03Z","published":"2025-09-15T23:19:36Z","title":"Fun-ASR Technical Report","summary":"In recent years, automatic speech recognition (ASR) has witnessed transformative advancements driven by three complementary paradigms: data scaling, model size scaling, and deep integration with large language models (LLMs). However, LLMs are prone to hallucination, which can significantly degrade user experience in real-world ASR applications. In this paper, we present Fun-ASR, a large-scale, LLM-based ASR system that synergistically combines massive data, large model capacity, LLM integration, and reinforcement learning to achieve state-of-the-art performance across diverse and complex speech recognition scenarios. Moreover, Fun-ASR is specifically optimized for practical deployment, with enhancements in streaming capability, noise robustness, code-switching, hotword customization, and satisfying other real-world application requirements. Experimental results show that while most LLM-based ASR systems achieve strong performance on open-source benchmarks, they often underperform on real industry evaluation sets. Thanks to production-oriented optimizations, Fun-ASR achieves state-of-the-art performance on real application datasets, demonstrating its effectiveness and robustness in practical settings. The code and models are accessible at https://github.com/FunAudioLLM/Fun-ASR .","authors":["Keyu An","Yanni Chen","Zhigao Chen","Chong Deng","Zhihao Du","Changfeng Gao","Zhifu Gao","Bo Gong","Xiangang Li","Yabin Li","Ying Liu","Xiang Lv","Yunjie Ji","Yiheng Jiang","Bin Ma","Haoneng Luo","Chongjia Ni","Zexu Pan","Yiping Peng","Zhendong Peng","Peiyao Wang","Hao Wang","Haoxu Wang","Wen Wang","Wupeng Wang","Yuzhong Wu","Biao Tian","Zhentao Tan","Nan Yang","Bin Yuan","Jieping Ye","Jixing Yu","Qinglin Zhang","Kun Zou","Han Zhao","Shengkui Zhao","Jingren Zhou","Yanqiao Zhu"],"pdf_url":"","comment":"Authors are listed in alphabetical order. Work in progress"},{"id":"http://arxiv.org/abs/2508.21052v2","updated":"2025-12-19T16:10:13Z","published":"2025-08-28T17:55:14Z","title":"FakeParts: a New Family of AI-Generated DeepFakes","summary":"We introduce FakeParts, a new class of deepfakes characterized by subtle, localized manipulations to specific spatial regions or temporal segments of otherwise authentic videos. Unlike fully synthetic content, these partial manipulations - ranging from altered facial expressions to object substitutions and background modifications - blend seamlessly with real elements, making them particularly deceptive and difficult to detect. To address the critical gap in detection, we present FakePartsBench, the first large-scale benchmark specifically designed to capture the full spectrum of partial deepfakes. Comprising over 81K (including 44K FakeParts) videos with pixel- and frame-level manipulation annotations, our dataset enables comprehensive evaluation of detection methods. Our user studies demonstrate that FakeParts reduces human detection accuracy by up to 26% compared to traditional deepfakes, with similar performance degradation observed in state-of-the-art detection models. This work identifies an urgent vulnerability in current detectors and provides the necessary resources to develop methods robust to partial manipulations.","authors":["Ziyi Liu","Firas Gabetni","Awais Hussain Sani","Xi Wang","Soobash Daiboo","Gaetan Brison","Gianni Franchi","Vicky Kalogeiton"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17733v1","updated":"2025-12-19T16:09:29Z","published":"2025-12-19T16:09:29Z","title":"Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure","summary":"Beyond user-item modeling, item-to-item relationships are increasingly used to enhance recommendation. However, common methods largely rely on co-occurrence, making them prone to item popularity bias and user attributes, which degrades embedding quality and performance. Meanwhile, although diversity is acknowledged as a key aspect of recommendation quality, existing research offers limited attention to it, with a notable lack of causal perspectives and theoretical grounding. To address these challenges, we propose Cadence: Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure - a plug-and-play framework built upon LightGCN as the backbone, primarily designed to enhance recommendation diversity while preserving accuracy. First, we compute the Unbiased Asymmetric Co-purchase Relationship (UACR) between items - excluding item popularity and user attributes - to construct a deconfounded directed item graph, with an aggregation mechanism to refine embeddings. Second, we leverage UACR to identify diverse categories of items that exhibit strong causal relevance to a user's interacted items but have not yet been engaged with. We then simulate their behavior under high-exposure scenarios, thereby significantly enhancing recommendation diversity while preserving relevance. Extensive experiments on real-world datasets demonstrate that our method consistently outperforms state-of-the-art diversity models in both diversity and accuracy, and further validates its effectiveness, transferability, and efficiency over baselines.","authors":["Jingmao Zhang","Zhiting Zhao","Yunqi Lin","Jianghong Ma","Tianjun Wei","Haijun Zhang","Xiaofeng Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17722v1","updated":"2025-12-19T15:56:12Z","published":"2025-12-19T15:56:12Z","title":"Digital and Web Forensics Model Cards, V1","summary":"This paper introduces a standardized model card framework specifically designed for digital and web forensics. Building upon established model card methodologies and recent work on abstract models for digital forensic analysis, this paper presents a web based framework that generates model cards specifically designed to represent knowledge in the forensic domain. The framework includes controlled vocabularies for classification, reasoning types, bias identification, and error categorization, along with a web-based generator tool to facilitate adoption. The paper describes the model card structure, presents the controlled vocabularies, and introduces the beta version of the generator tool, inviting community feedback to refine this emerging standard. Ultimately, the systemic risk is that that the anti fraud and digital and web forensics processes are controlled by the mobs.","authors":["Paola Di Maio"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.03735v3","updated":"2025-12-19T15:41:38Z","published":"2024-09-05T17:50:31Z","title":"Privacy Bias in Language Models: A Contextual Integrity-based Auditing Metric","summary":"As large language models (LLMs) are integrated into sociotechnical systems, it is crucial to examine the privacy biases they exhibit. We define privacy bias as the appropriateness value of information flows in responses from LLMs. A deviation between privacy biases and expected values, referred to as privacy bias delta, may indicate privacy violations. As an auditing metric, privacy bias can help (a) model trainers evaluate the ethical and societal impact of LLMs, (b) service providers select context-appropriate LLMs, and (c) policymakers assess the appropriateness of privacy biases in deployed LLMs. We formulate and answer a novel research question: how can we reliably examine privacy biases in LLMs and the factors that influence them? We present a novel approach for assessing privacy biases using a contextual integrity-based methodology to evaluate the responses from various LLMs. Our approach accounts for the sensitivity of responses across prompt variations, which hinders the evaluation of privacy biases. Finally, we investigate how privacy biases are affected by model capacities and optimizations.","authors":["Yan Shvartzshnaider","Vasisht Duddu"],"pdf_url":"","comment":"Privacy Enhancing Technologies Symposium (PETS), 2026"},{"id":"http://arxiv.org/abs/2507.22659v2","updated":"2025-12-19T15:41:06Z","published":"2025-07-30T13:17:16Z","title":"A Systematic Literature Review on Detecting Software Vulnerabilities with Large Language Models","summary":"The increasing adoption of Large Language Models (LLMs) in software engineering has sparked interest in their use for software vulnerability detection. However, the rapid development of this field has resulted in a fragmented research landscape, with diverse studies that are difficult to compare due to differences in, e.g., system designs and dataset usage. This fragmentation makes it difficult to obtain a clear overview of the state-of-the-art or compare and categorize studies meaningfully. In this work, we present a comprehensive systematic literature review (SLR) of LLM-based software vulnerability detection. We analyze 263 studies published between January 2020 and November 2025, categorizing them by task formulation, input representation, system architecture, and techniques. Further, we analyze the datasets used, including their characteristics, vulnerability coverage, and diversity. We present a fine-grained taxonomy of vulnerability detection approaches, identify key limitations, and outline actionable future research opportunities. By providing a structured overview of the field, this review improves transparency and serves as a practical guide for researchers and practitioners aiming to conduct more comparable and reproducible research. We publicly release all artifacts and maintain a living repository of LLM-based software vulnerability detection studies at https://github.com/hs-esslingen-it-security/Awesome-LLM4SVD.","authors":["Sabrina Kaniewski","Fabian Schmidt","Markus Enzweiler","Michael Menth","Tobias Heer"],"pdf_url":"","comment":"43 pages + 20 pages references, 7 tables, 13 figures"},{"id":"http://arxiv.org/abs/2402.12118v3","updated":"2025-12-19T15:36:27Z","published":"2024-02-19T13:13:16Z","title":"Sparse, Efficient and Explainable Data Attribution with DualXDA","summary":"Data Attribution (DA) is an emerging approach in the field of eXplainable Artificial Intelligence (XAI), aiming to identify influential training datapoints which determine model outputs. It seeks to provide transparency about the model and individual predictions, e.g. for model debugging, identifying data-related causes of suboptimal performance. However, existing DA approaches suffer from prohibitively high computational costs and memory demands when applied to even medium-scale datasets and models, forcing practitioners to resort to approximations that may fail to capture the true inference process of the underlying model. Additionally, current attribution methods exhibit low sparsity, resulting in non-negligible attribution scores across a high number of training examples, hindering the discovery of decisive patterns in the data. In this work, we introduce DualXDA, a framework for sparse, efficient and explainable DA, comprised of two interlinked approaches, Dual Data Attribution (DualDA) and eXplainable Data Attribution (XDA): With DualDA, we propose a novel approach for efficient and effective DA, leveraging Support Vector Machine theory to provide fast and naturally sparse data attributions for AI predictions. In extensive quantitative analyses, we demonstrate that DualDA achieves high attribution quality, excels at solving a series of evaluated downstream tasks, while at the same time improving explanation time by a factor of up to 4,100,000x compared to the original Influence Functions method, and up to 11,000x compared to the method's most efficient approximation from literature to date. We further introduce XDA, a method for enhancing Data Attribution with capabilities from feature attribution methods to explain why training samples are relevant for the prediction of a test sample in terms of impactful features, which we showcase and verify qualitatively in detail.","authors":["Galip Ümit Yolcu","Moritz Weckbecker","Thomas Wiegand","Wojciech Samek","Sebastian Lapuschkin"],"pdf_url":"","comment":"Accepted to Transactions on Machine Learning Research (TMLR), 2025"},{"id":"http://arxiv.org/abs/2506.11023v2","updated":"2025-12-19T15:34:46Z","published":"2025-05-20T08:15:16Z","title":"OntoGSN: An Ontology-Based Framework for Semantic Management and Extension of Assurance Cases","summary":"Assurance cases (ACs) are a common artifact for building and maintaining confidence in system properties such as safety or robustness. Constructing an AC can be challenging, although existing tools provide support in static, document-centric applications and methods for dynamic contexts (e.g., autonomous driving) are emerging. Unfortunately, managing ACs remains a challenge, since maintaining the embedded knowledge in the face of changes requires substantial effort, in the process deterring developers - or worse, producing poorly managed cases that instill false confidence. To address this, we present OntoGSN: an ontology and supporting middleware for managing ACs in the Goal Structuring Notation (GSN) standard. OntoGSN offers a knowledge representation and a queryable graph that can be automatically populated, evaluated, and updated. Our contributions include: a 1:1 formalization of the GSN Community Standard v3 in an OWL ontology with SWRL rules; a helper ontology and parser for integration with a widely used AC tool; a repository and documentation of design decisions for OntoGSN maintenance; a SPARQL query library with automation patterns; and a prototypical interface. The ontology strictly adheres to the standard's text and has been evaluated according to FAIR principles, the OOPS framework, competency questions, and community feedback. The development of other middleware elements is guided by the community needs and subject to ongoing evaluations. To demonstrate the utility of our contributions, we illustrate dynamic AC management in an example involving assurance of adversarial robustness in large language models.","authors":["Tomas Bueno Momcilovic","Barbara Gallina","Ingmar Kessler","Jule Hendricks","Dian Balta"],"pdf_url":"","comment":"Submitted to the ESWC 2026 Resources track"},{"id":"http://arxiv.org/abs/2512.17678v1","updated":"2025-12-19T15:17:34Z","published":"2025-12-19T15:17:34Z","title":"You Only Train Once: Differentiable Subset Selection for Omics Data","summary":"Selecting compact and informative gene subsets from single-cell transcriptomic data is essential for biomarker discovery, improving interpretability, and cost-effective profiling. However, most existing feature selection approaches either operate as multi-stage pipelines or rely on post hoc feature attribution, making selection and prediction weakly coupled. In this work, we present YOTO (you only train once), an end-to-end framework that jointly identifies discrete gene subsets and performs prediction within a single differentiable architecture. In our model, the prediction task directly guides which genes are selected, while the learned subsets, in turn, shape the predictive representation. This closed feedback loop enables the model to iteratively refine both what it selects and how it predicts during training. Unlike existing approaches, YOTO enforces sparsity so that only the selected genes contribute to inference, eliminating the need to train additional downstream classifiers. Through a multi-task learning design, the model learns shared representations across related objectives, allowing partially labeled datasets to inform one another, and discovering gene subsets that generalize across tasks without additional training steps. We evaluate YOTO on two representative single-cell RNA-seq datasets, showing that it consistently outperforms state-of-the-art baselines. These results demonstrate that sparse, end-to-end, multi-task gene subset selection improves predictive performance and yields compact and meaningful gene subsets, advancing biomarker discovery and single-cell analysis.","authors":["Daphné Chopard","Jorge da Silva Gonçalves","Irene Cannistraci","Thomas M. Sutter","Julia E. Vogt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17675v1","updated":"2025-12-19T15:17:12Z","published":"2025-12-19T15:17:12Z","title":"An Empirical Study of Sampling Hyperparameters in Diffusion-Based Super-Resolution","summary":"Diffusion models have shown strong potential for solving inverse problems such as single-image super-resolution, where a high-resolution image is recovered from a low-resolution observation using a pretrained unconditional prior. Conditioning methods, including Diffusion Posterior Sampling (DPS) and Manifold Constrained Gradient (MCG), can substantially improve reconstruction quality, but they introduce additional hyperparameters that require careful tuning. In this work, we conduct an empirical ablation study on FFHQ super-resolution to identify the dominant factors affecting performance when applying conditioning to pretrained diffusion models, and show that the conditioning step size has a significantly greater impact than the diffusion step count, with step sizes in the range of [2.0, 3.0] yielding the best overall performance in our experiments.","authors":["Yudhistira Arief Wibowo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17673v1","updated":"2025-12-19T15:15:58Z","published":"2025-12-19T15:15:58Z","title":"Learning Spatio-Temporal Feature Representations for Video-Based Gaze Estimation","summary":"Video-based gaze estimation methods aim to capture the inherently temporal dynamics of human eye gaze from multiple image frames. However, since models must capture both spatial and temporal relationships, performance is limited by the feature representations within a frame but also between multiple frames. We propose the Spatio-Temporal Gaze Network (ST-Gaze), a model that combines a CNN backbone with dedicated channel attention and self-attention modules to fuse eye and face features optimally. The fused features are then treated as a spatial sequence, allowing for the capture of an intra-frame context, which is then propagated through time to model inter-frame dynamics. We evaluated our method on the EVE dataset and show that ST-Gaze achieves state-of-the-art performance both with and without person-specific adaptation. Additionally, our ablation study provides further insights into the model performance, showing that preserving and modelling intra-frame spatial context with our spatio-temporal recurrence is fundamentally superior to premature spatial pooling. As such, our results pave the way towards more robust video-based gaze estimation using commonly available cameras.","authors":["Alexandre Personnic","Mihai Bâce"],"pdf_url":"","comment":"12 pages, 5 figures, the code repository is available at https://gitlab.kuleuven.be/u0172623/ST-Gaze"},{"id":"http://arxiv.org/abs/2512.17667v1","updated":"2025-12-19T15:12:01Z","published":"2025-12-19T15:12:01Z","title":"STAR: Semantic-Traffic Alignment and Retrieval for Zero-Shot HTTPS Website Fingerprinting","summary":"Modern HTTPS mechanisms such as Encrypted Client Hello (ECH) and encrypted DNS improve privacy but remain vulnerable to website fingerprinting (WF) attacks, where adversaries infer visited sites from encrypted traffic patterns. Existing WF methods rely on supervised learning with site-specific labeled traces, which limits scalability and fails to handle previously unseen websites. We address these limitations by reformulating WF as a zero-shot cross-modal retrieval problem and introducing STAR. STAR learns a joint embedding space for encrypted traffic traces and crawl-time logic profiles using a dual-encoder architecture. Trained on 150K automatically collected traffic-logic pairs with contrastive and consistency objectives and structure-aware augmentation, STAR retrieves the most semantically aligned profile for a trace without requiring target-side traffic during training. Experiments on 1,600 unseen websites show that STAR achieves 87.9 percent top-1 accuracy and 0.963 AUC in open-world detection, outperforming supervised and few-shot baselines. Adding an adapter with only four labeled traces per site further boosts top-5 accuracy to 98.8 percent. Our analysis reveals intrinsic semantic-traffic alignment in modern web protocols, identifying semantic leakage as the dominant privacy risk in encrypted HTTPS traffic. We release STAR's datasets and code to support reproducibility and future research.","authors":["Yifei Cheng","Yujia Zhu","Baiyang Li","Xinhao Deng","Yitong Cai","Yaochen Ren","Qingyun Liu"],"pdf_url":"","comment":"Accepted by IEEE INFOCOM 2026. Camera-ready version"},{"id":"http://arxiv.org/abs/2512.17637v1","updated":"2025-12-19T14:39:03Z","published":"2025-12-19T14:39:03Z","title":"About Time: Model-free Reinforcement Learning with Timed Reward Machines","summary":"Reward specification plays a central role in reinforcement learning (RL), guiding the agent's behavior. To express non-Markovian rewards, formalisms such as reward machines have been introduced to capture dependencies on histories. However, traditional reward machines lack the ability to model precise timing constraints, limiting their use in time-sensitive applications. In this paper, we propose timed reward machines (TRMs), which are an extension of reward machines that incorporate timing constraints into the reward structure. TRMs enable more expressive specifications with tunable reward logic, for example, imposing costs for delays and granting rewards for timely actions. We study model-free RL frameworks (i.e., tabular Q-learning) for learning optimal policies with TRMs under digital and real-time semantics. Our algorithms integrate the TRM into learning via abstractions of timed automata, and employ counterfactual-imagining heuristics that exploit the structure of the TRM to improve the search. Experimentally, we demonstrate that our algorithm learns policies that achieve high rewards while satisfying the timing constraints specified by the TRM on popular RL benchmarks. Moreover, we conduct comparative studies of performance under different TRM semantics, along with ablations that highlight the benefits of counterfactual-imagining.","authors":["Anirban Majumdar","Ritam Raha","Rajarshi Roy","David Parker","Marta Kwiatkowska"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.17330v2","updated":"2025-12-19T14:39:03Z","published":"2025-10-20T09:23:29Z","title":"CharDiff-LP: A Diffusion Model with Character-Level Guidance for License Plate Image Restoration","summary":"License plate image restoration is important not only as a preprocessing step for license plate recognition but also for enhancing evidential value, improving visual clarity, and enabling broader reuse of license plate images. We propose a novel diffusion-based framework with character-level guidance, CharDiff-LP, which effectively restores and recognizes severely degraded license plate images captured under realistic conditions. CharDiff-LP leverages fine-grained character-level priors extracted through external segmentation and Optical Character Recognition (OCR) modules tailored for low-quality license plate images. For precise and focused guidance, CharDiff-LP incorporates a novel Character-guided Attention through Region-wise Masking (CHARM) module, which ensures that each character's guidance is restricted to its own region, thereby avoiding interference with other regions. In experiments, CharDiff-LP significantly outperformed baseline restoration models in both restoration quality and recognition accuracy, achieving a 28.3% relative reduction in character error rate (CER) on the Roboflow-LP dataset compared with the best-performing baseline.","authors":["Kihyun Na","Gyuhwan Park","Injung Kim"],"pdf_url":"","comment":"15 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2512.17636v1","updated":"2025-12-19T14:37:07Z","published":"2025-12-19T14:37:07Z","title":"Trust-Region Adaptive Policy Optimization","summary":"Post-training methods, especially Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), play an important role in improving large language models' (LLMs) complex reasoning abilities. However, the dominant two-stage pipeline (SFT then RL) suffers from a key inconsistency: SFT enforces rigid imitation that suppresses exploration and induces forgetting, limiting RL's potential for improvements. We address this inefficiency with TRAPO (\\textbf{T}rust-\\textbf{R}egion \\textbf{A}daptive \\textbf{P}olicy \\textbf{O}ptimization), a hybrid framework that interleaves SFT and RL within each training instance by optimizing SFT loss on expert prefixes and RL loss on the model's own completions, unifying external supervision and self-exploration. To stabilize training, we introduce Trust-Region SFT (TrSFT), which minimizes forward KL divergence inside a trust region but attenuates optimization outside, effectively shifting toward reverse KL and yielding stable, mode-seeking updates favorable for RL. An adaptive prefix-selection mechanism further allocates expert guidance based on measured utility. Experiments on five mathematical reasoning benchmarks show that TRAPO consistently surpasses standard SFT, RL, and SFT-then-RL pipelines, as well as recent state-of-the-art approaches, establishing a strong new paradigm for reasoning-enhanced LLMs.","authors":["Mingyu Su","Jian Guan","Yuxian Gu","Minlie Huang","Hongning Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17629v1","updated":"2025-12-19T14:33:02Z","published":"2025-12-19T14:33:02Z","title":"SCOPE: Sequential Causal Optimization of Process Interventions","summary":"Prescriptive Process Monitoring (PresPM) recommends interventions during business processes to optimize key performance indicators (KPIs). In realistic settings, interventions are rarely isolated: organizations need to align sequences of interventions to jointly steer the outcome of a case. Existing PresPM approaches fall short in this respect. Many focus on a single intervention decision, while others treat multiple interventions independently, ignoring how they interact over time. Methods that do address these dependencies depend either on simulation or data augmentation to approximate the process to train a Reinforcement Learning (RL) agent, which can create a reality gap and introduce bias. We introduce SCOPE, a PresPM approach that learns aligned sequential intervention recommendations. SCOPE employs backward induction to estimate the effect of each candidate intervention action, propagating its impact from the final decision point back to the first. By leveraging causal learners, our method can utilize observational data directly, unlike methods that require constructing process approximations for reinforcement learning. Experiments on both an existing synthetic dataset and a new semi-synthetic dataset show that SCOPE consistently outperforms state-of-the-art PresPM techniques in optimizing the KPI. The novel semi-synthetic setup, based on a real-life event log, is provided as a reusable benchmark for future work on sequential PresPM.","authors":["Jakob De Moor","Hans Weytjens","Johannes De Smedt","Jochen De Weerdt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21417v2","updated":"2025-12-19T14:32:02Z","published":"2025-11-26T14:08:28Z","title":"New Hybrid Heuristics for Pseudo-Boolean Propagation","summary":"In pseudo-boolean solving the currently most successful unit propagation strategy is a hybrid mode combining the watched literal scheme with the counting method. This short paper introduces new heuristics for this hybrid decision, which are able to drastically outperform the current method in the RoundingSAT solver.","authors":["Mia Müßig","Jan Johannsen"],"pdf_url":"","comment":"5 pages, 3 figures, added different cut-off for old hybrid"},{"id":"http://arxiv.org/abs/2507.06261v6","updated":"2025-12-19T14:25:46Z","published":"2025-07-07T17:36:04Z","title":"Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities","summary":"In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that excels at multimodal understanding and it is now able to process up to 3 hours of video content. Its unique combination of long context, multimodal and reasoning capabilities can be combined to unlock new agentic workflows. Gemini 2.5 Flash provides excellent reasoning abilities at a fraction of the compute and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high performance at low latency and cost. Taken together, the Gemini 2.X model generation spans the full Pareto frontier of model capability vs cost, allowing users to explore the boundaries of what is possible with complex agentic problem solving.","authors":["Gheorghe Comanici","Eric Bieber","Mike Schaekermann","Ice Pasupat","Noveen Sachdeva","Inderjit Dhillon","Marcel Blistein","Ori Ram","Dan Zhang","Evan Rosen","Luke Marris","Sam Petulla","Colin Gaffney","Asaf Aharoni","Nathan Lintz","Tiago Cardal Pais","Henrik Jacobsson","Idan Szpektor","Nan-Jiang Jiang","Krishna Haridasan","Ahmed Omran","Nikunj Saunshi","Dara Bahri","Gaurav Mishra","Eric Chu","Toby Boyd","Brad Hekman","Aaron Parisi","Chaoyi Zhang","Kornraphop Kawintiranon","Tania Bedrax-Weiss","Oliver Wang","Ya Xu","Ollie Purkiss","Uri Mendlovic","Ilaï Deutel","Nam Nguyen","Adam Langley","Flip Korn","Lucia Rossazza","Alexandre Ramé","Sagar Waghmare","Helen Miller","Nathan Byrd","Ashrith Sheshan","Raia Hadsell","Sangnie Bhardwaj","Pawel Janus","Tero Rissa","Dan Horgan","Alvin Abdagic","Lior Belenki","James Allingham","Anima Singh","Theo Guidroz","Srivatsan Srinivasan","Herman Schmit","Kristen Chiafullo","Andre Elisseeff","Nilpa Jha","Prateek Kolhar","Leonard Berrada","Frank Ding","Xiance Si","Shrestha Basu Mallick","Franz Och","Sofia Erell","Eric Ni","Tejasi Latkar","Sherry Yang","Petar Sirkovic","Ziqiang Feng","Robert Leland","Rachel Hornung","Gang Wu","Charles Blundell","Hamidreza Alvari","Po-Sen Huang","Cathy Yip","Sanja Deur","Li Liu","Gabriela Surita","Pablo Duque","Dima Damen","Johnson Jia","Arthur Guez","Markus Mircea","Animesh Sinha","Alberto Magni","Paweł Stradomski","Tal Marian","Vlado Galić","Wenhu Chen","Hisham Husain","Achintya Singhal","Dominik Grewe","François-Xavier Aubet","Shuang Song","Lorenzo Blanco","Leland Rechis","Lewis Ho","Rich Munoz","Kelvin Zheng","Jessica Hamrick","Kevin Mather","Hagai Taitelbaum","Eliza Rutherford","Yun Lei","Kuangyuan Chen","Anand Shukla","Erica Moreira","Eric Doi","Berivan Isik","Nir Shabat","Dominika Rogozińska","Kashyap Kolipaka","Jason Chang","Eugen Vušak","Srinivasan Venkatachary","Shadi Noghabi","Tarun Bharti","Younghoon Jun","Aleksandr Zaks","Simon Green","Jeshwanth Challagundla","William Wong","Muqthar Mohammad","Dean Hirsch","Yong Cheng","Iftekhar Naim","Lev Proleev","Damien Vincent","Aayush Singh","Maxim Krikun","Dilip Krishnan","Zoubin Ghahramani","Aviel Atias","Rajeev Aggarwal","Christo Kirov","Dimitrios Vytiniotis","Christy Koh","Alexandra Chronopoulou","Pawan Dogra","Vlad-Doru Ion","Gladys Tyen","Jason Lee","Felix Weissenberger","Trevor Strohman","Ashwin Balakrishna","Jack Rae","Marko Velic","Raoul de Liedekerke","Oded Elyada","Wentao Yuan","Canoee Liu","Lior Shani","Sergey Kishchenko","Bea Alessio","Yandong Li","Richard Song","Sam Kwei","Orion Jankowski","Aneesh Pappu","Youhei Namiki","Yenai Ma","Nilesh Tripuraneni","Colin Cherry","Marissa Ikonomidis","Yu-Cheng Ling","Colin Ji","Beka Westberg","Auriel Wright","Da Yu","David Parkinson","Swaroop Ramaswamy","Jerome Connor","Soheil Hassas Yeganeh","Snchit Grover","George Kenwright","Lubo Litchev","Chris Apps","Alex Tomala","Felix Halim","Alex Castro-Ros","Zefei Li","Anudhyan Boral","Pauline Sho","Michal Yarom","Eric Malmi","David Klinghoffer","Rebecca Lin","Alan Ansell","Pradeep Kumar S","Shubin Zhao","Siqi Zuo","Adam Santoro","Heng-Tze Cheng","Solomon Demmessie","Yuchi Liu","Nicole Brichtova","Allie Culp","Nathaniel Braun","Dan Graur","Will Ng","Nikhil Mehta","Aaron Phillips","Patrik Sundberg","Varun Godbole","Fangyu Liu","Yash Katariya","David Rim","Mojtaba Seyedhosseini","Sean Ammirati","Jonas Valfridsson","Mahan Malihi","Timothy Knight","Andeep Toor","Thomas Lampe","Abe Ittycheriah","Lewis Chiang","Chak Yeung","Alexandre Fréchette","Jinmeng Rao","Huisheng Wang","Himanshu Srivastava","Richard Zhang","Rocky Rhodes","Ariel Brand","Dean Weesner","Ilya Figotin","Felix Gimeno","Rachana Fellinger","Pierre Marcenac","José Leal","Eyal Marcus","Victor Cotruta","Rodrigo Cabrera","Sheryl Luo","Dan Garrette","Vera Axelrod","Sorin Baltateanu","David Barker","Dongkai Chen","Horia Toma","Ben Ingram","Jason Riesa","Chinmay Kulkarni","Yujing Zhang","Hongbin Liu","Chao Wang","Martin Polacek","Will Wu","Kai Hui","Adrian N Reyes","Yi Su","Megan Barnes","Ishaan Malhi","Anfal Siddiqui","Qixuan Feng","Mihai Damaschin","Daniele Pighin","Andreas Steiner","Samuel Yang","Ramya Sree Boppana","Simeon Ivanov","Arun Kandoor","Aditya Shah","Asier Mujika","Da Huang","Christopher A. Choquette-Choo","Mohak Patel","Tianhe Yu","Toni Creswell"," Jerry"," Liu","Catarina Barros","Yasaman Razeghi","Aurko Roy","Phil Culliton","Binbin Xiong","Jiaqi Pan","Thomas Strohmann","Tolly Powell","Babi Seal","Doug DeCarlo","Pranav Shyam","Kaan Katircioglu","Xuezhi Wang","Cassidy Hardin","Immanuel Odisho","Josef Broder","Oscar Chang","Arun Nair","Artem Shtefan","Maura O'Brien","Manu Agarwal","Sahitya Potluri","Siddharth Goyal","Amit Jhindal","Saksham Thakur","Yury Stuken","James Lyon","Kristina Toutanova","Fangxiaoyu Feng","Austin Wu","Ben Horn","Alek Wang","Alex Cullum","Gabe Taubman","Disha Shrivastava","Chongyang Shi","Hamish Tomlinson","Roma Patel","Tao Tu","Ada Maksutaj Oflazer","Francesco Pongetti","Mingyao Yang","Adrien Ali Taïga","Vincent Perot","Nuo Wang Pierse","Feng Han","Yoel Drori","Iñaki Iturrate","Ayan Chakrabarti","Legg Yeung","Dave Dopson","Yi-ting Chen","Apoorv Kulshreshtha","Tongfei Guo","Philip Pham","Tal Schuster","Junquan Chen","Alex Polozov","Jinwei Xing","Huanjie Zhou","Praneeth Kacham","Doron Kukliansky","Antoine Miech","Sergey Yaroshenko","Ed Chi","Sholto Douglas","Hongliang Fei","Mathieu Blondel","Preethi Myla","Lior Madmoni","Xing Wu","Daniel Keysers","Kristian Kjems","Isabela Albuquerque","Lijun Yu","Joel D'sa","Michelle Plantan","Vlad Ionescu","Jaume Sanchez Elias","Abhirut Gupta","Manish Reddy Vuyyuru","Fred Alcober","Tong Zhou","Kaiyang Ji","Florian Hartmann","Subha Puttagunta","Hugo Song","Ehsan Amid","Anca Stefanoiu","Andrew Lee","Paul Pucciarelli","Emma Wang","Amit Raul","Slav Petrov","Isaac Tian","Valentin Anklin","Nana Nti","Victor Gomes","Max Schumacher","Grace Vesom","Alex Panagopoulos","Konstantinos Bousmalis","Daniel Andor","Josh Jacob","Yuan Zhang","Bill Rosgen","Matija Kecman","Matthew Tung","Alexandra Belias","Noah Goodman","Paul Covington","Brian Wieder","Nikita Saxena","Elnaz Davoodi","Muhuan Huang","Sharath Maddineni","Vincent Roulet","Folawiyo Campbell-Ajala","Pier Giuseppe Sessa"," Xintian"," Wu","Guangda Lai","Paul Collins","Alex Haig","Vytenis Sakenas","Xiaowei Xu","Marissa Giustina","Laurent El Shafey","Pichi Charoenpanit","Shefali Garg","Joshua Ainslie","Boone Severson","Montse Gonzalez Arenas","Shreya Pathak","Sujee Rajayogam","Jie Feng","Michiel Bakker","Sheng Li","Nevan Wichers","Jamie Rogers","Xinyang Geng","Yeqing Li","Rolf Jagerman","Chao Jia","Nadav Olmert","David Sharon","Matthew Mauger","Sandeep Mariserla","Hongxu Ma","Megha Mohabey","Kyuyeun Kim","Alek Andreev","Scott Pollom","Juliette Love","Vihan Jain","Priyanka Agrawal","Yannick Schroecker","Alisa Fortin","Manfred Warmuth","Ji Liu","Andrew Leach","Irina Blok","Ganesh Poomal Girirajan","Roee Aharoni","Benigno Uria","Andrei Sozanschi","Dan Goldberg","Lucian Ionita","Marco Tulio Ribeiro","Martin Zlocha","Vighnesh Birodkar","Sami Lachgar","Liangzhe Yuan","Himadri Choudhury","Matt Ginsberg","Fei Zheng","Gregory Dibb","Emily Graves","Swachhand Lokhande","Gabriel Rasskin","George-Cristian Muraru","Corbin Quick","Sandeep Tata","Pierre Sermanet","Aditya Chawla","Itay Karo","Yan Wang","Susan Zhang","Orgad Keller","Anca Dragan","Guolong Su","Ian Chou","Xi Liu","Yiqing Tao","Shruthi Prabhakara","Marc Wilson","Ruibo Liu","Shibo Wang","Georgie Evans","David Du","Alfonso Castaño","Gautam Prasad","Mona El Mahdy","Sebastian Gerlach","Machel Reid","Jarrod Kahn","Amir Zait","Thanumalayan Sankaranarayana Pillai","Thatcher Ulrich","Guanyu Wang","Jan Wassenberg","Efrat Farkash","Kiran Yalasangi","Congchao Wang","Maria Bauza","Simon Bucher","Ting Liu","Jun Yan","Gary Leung","Vikas Sindhwani","Parker Barnes","Avi Singh","Ivan Jurin","Jichuan Chang","Niket Kumar Bhumihar","Sivan Eiger","Gui Citovsky","Ben Withbroe","Zhang Li","Siyang Xue","Niccolò Dal Santo","Georgi Stoyanov","Yves Raimond","Steven Zheng","Yilin Gao","Vít Listík","Sławek Kwasiborski","Rachel Saputro","Adnan Ozturel","Ganesh Mallya","Kushal Majmundar","Ross West","Paul Caron","Jinliang Wei","Lluis Castrejon","Sharad Vikram","Deepak Ramachandran","Nikhil Dhawan","Jiho Park","Sara Smoot","George van den Driessche","Yochai Blau","Chase Malik","Wei Liang","Roy Hirsch","Cicero Nogueira dos Santos","Eugene Weinstein","Aäron van den Oord","Sid Lall","Nicholas FitzGerald","Zixuan Jiang","Xuan Yang","Dale Webster","Ali Elqursh","Aedan Pope","Georges Rotival","David Raposo","Wanzheng Zhu","Jeff Dean","Sami Alabed","Dustin Tran","Arushi Gupta","Zach Gleicher","Jessica Austin","Edouard Rosseel","Megh Umekar","Dipanjan Das","Yinghao Sun","Kai Chen","Karolis Misiunas","Xiang Zhou","Yixian Di","Alyssa Loo","Josh Newlan","Bo Li","Vinay Ramasesh","Ying Xu","Alex Chen","Sudeep Gandhe","Radu Soricut","Nikita Gupta","Shuguang Hu","Seliem El-Sayed","Xavier Garcia","Idan Brusilovsky","Pu-Chin Chen","Andrew Bolt","Lu Huang","Alex Gurney","Zhiying Zhang","Alexander Pritzel","Jarek Wilkiewicz","Bryan Seybold","Bhargav Kanagal Shamanna","Felix Fischer","Josef Dean","Karan Gill","Ross Mcilroy","Abhishek Bhowmick","Jeremy Selier","Antoine Yang","Derek Cheng","Vladimir Magay","Jie Tan","Dhriti Varma","Christian Walder","Tomas Kocisky","Ryo Nakashima","Paul Natsev","Mike Kwong","Ionel Gog","Chiyuan Zhang","Sander Dieleman","Thomas Jimma","Andrey Ryabtsev","Siddhartha Brahma","David Steiner","Dayou Du","Ante Žužul","Mislav Žanić","Mukund Raghavachari","Willi Gierke","Zeyu Zheng","Dessie Petrova","Yann Dauphin","Yuchuan Liu","Ido Kessler","Steven Hand","Chris Duvarney","Seokhwan Kim","Hyo Lee","Léonard Hussenot","Jeffrey Hui","Josh Smith","Deepali Jain","Jiawei Xia","Gaurav Singh Tomar","Keyvan Amiri","Du Phan","Fabian Fuchs","Tobias Weyand","Nenad Tomasev","Alexandra Cordell","Xin Liu","Jonathan Mallinson","Pankaj Joshi","Andy Crawford","Arun Suggala","Steve Chien","Nick Fernando","Mariella Sanchez-Vargas","Duncan Williams","Phil Crone","Xiyang Luo","Igor Karpov","Jyn Shan","Terry Thurk","Robin Strudel","Paul Voigtlaender","Piyush Patil","Tim Dozat","Ali Khodaei","Sahil Singla","Piotr Ambroszczyk","Qiyin Wu","Yifan Chang","Brian Roark","Chaitra Hegde","Tianli Ding","Angelos Filos","Zhongru Wu","André Susano Pinto","Shuang Liu","Saarthak Khanna","Aditya Pandey","Siobhan Mcloughlin","Qiujia Li","Sam Haves","Allan Zhou","Elena Buchatskaya","Isabel Leal","Peter de Boursac","Nami Akazawa","Nina Anderson","Terry Chen","Krishna Somandepalli","Chen Liang","Sheela Goenka","Stephanie Winkler","Alexander Grushetsky","Yifan Ding","Jamie Smith","Fan Ye","Jordi Pont-Tuset","Eric Li","Ruichao Li","Tomer Golany","Dawid Wegner","Tao Jiang","Omer Barak","Yuan Shangguan","Eszter Vértes","Renee Wong","Jörg Bornschein","Alex Tudor","Michele Bevilacqua","Tom Schaul","Ankit Singh Rawat","Yang Zhao","Kyriakos Axiotis","Lei Meng","Cory McLean","Jonathan Lai","Jennifer Beattie","Nate Kushman","Yaxin Liu","Blair Kutzman","Fiona Lang","Jingchen Ye","Praneeth Netrapalli","Pushkar Mishra","Myriam Khan","Megha Goel","Rob Willoughby","David Tian","Honglei Zhuang","JD Chen","Zak Tsai","Tasos Kementsietsidis","Arjun Khare","James Keeling","Keyang Xu","Nathan Waters","Florent Altché","Ashok Popat","Bhavishya Mittal","David Saxton","Dalia El Badawy","Michael Mathieu","Zheng Zheng","Hao Zhou","Nishant Ranka","Richard Shin","Qingnan Duan","Tim Salimans","Ioana Mihailescu","Uri Shaham","Ming-Wei Chang","Yannis Assael","Nishanth Dikkala","Martin Izzard","Vincent Cohen-Addad","Cat Graves","Vlad Feinberg","Grace Chung","DJ Strouse","Danny Karmon","Sahand Sharifzadeh","Zoe Ashwood","Khiem Pham","Jon Blanton","Alex Vasiloff","Jarred Barber","Mark Geller","Aurick Zhou","Fedir Zubach","Tzu-Kuo Huang","Lei Zhang","Himanshu Gupta","Matt Young","Julia Proskurnia","Ronny Votel","Valentin Gabeur","Gabriel Barcik","Aditya Tripathi","Hongkun Yu","Geng Yan","Beer Changpinyo","Filip Pavetić","Amy Coyle","Yasuhisa Fujii","Jorge Gonzalez Mendez","Tianhao Zhou","Harish Rajamani","Blake Hechtman","Eddie Cao","Da-Cheng Juan","Yi-Xuan Tan","Valentin Dalibard","Yilun Du","Natalie Clay","Kaisheng Yao","Wenhao Jia","Dimple Vijaykumar","Yuxiang Zhou","Xinyi Bai","Wei-Chih Hung","Steven Pecht","Georgi Todorov","Nikhil Khadke","Pramod Gupta","Preethi Lahoti","Arnaud Autef","Karthik Duddu","James Lee-Thorp","Alexander Bykovsky","Tautvydas Misiunas","Sebastian Flennerhag","Santhosh Thangaraj","Jed McGiffin","Zack Nado","Markus Kunesch","Andreas Noever","Amir Hertz","Marco Liang","Victor Stone","Evan Palmer","Samira Daruki","Arijit Pramanik","Siim Põder","Austin Kyker","Mina Khan","Evgeny Sluzhaev","Marvin Ritter","Avraham Ruderman","Wenlei Zhou","Chirag Nagpal","Kiran Vodrahalli","George Necula","Paul Barham","Ellie Pavlick","Jay Hartford","Izhak Shafran","Long Zhao","Maciej Mikuła","Tom Eccles","Hidetoshi Shimokawa","Kanav Garg","Luke Vilnis","Hanwen Chen","Ilia Shumailov","Kuang-Huei Lee","Abdelrahman Abdelhamed","Meiyan Xie","Vered Cohen","Ester Hlavnova","Dan Malkin","Chawin Sitawarin","James Lottes","Pauline Coquinot","Tianli Yu","Sandeep Kumar","Jingwei Zhang","Aroma Mahendru","Zafarali Ahmed","James Martens","Tao Chen","Aviel Boag","Daiyi Peng","Coline Devin","Arseniy Klimovskiy","Mary Phuong","Danny Vainstein","Jin Xie","Bhuvana Ramabhadran","Nathan Howard","Xinxin Yu","Gitartha Goswami","Jingyu Cui","Sam Shleifer","Mario Pinto","Chih-Kuan Yeh","Ming-Hsuan Yang","Sara Javanmardi","Dan Ethier","Chace Lee","Jordi Orbay","Suyog Kotecha","Carla Bromberg","Pete Shaw","James Thornton","Adi Gerzi Rosenthal","Shane Gu","Matt Thomas","Ian Gemp","Aditya Ayyar","Asahi Ushio","Aarush Selvan","Joel Wee","Chenxi Liu","Maryam Majzoubi","Weiren Yu","Jake Abernethy","Tyler Liechty","Renke Pan","Hoang Nguyen"," Qiong"," Hu","Sarah Perrin","Abhinav Arora","Emily Pitler","Weiyi Wang","Kaushik Shivakumar","Flavien Prost","Ben Limonchik","Jing Wang","Yi Gao","Timothee Cour","Shyamal Buch","Huan Gui","Maria Ivanova","Philipp Neubeck","Kelvin Chan","Lucy Kim","Huizhong Chen","Naman Goyal","Da-Woon Chung","Lu Liu","Yao Su","Anastasia Petrushkina","Jiajun Shen","Armand Joulin","Yuanzhong Xu","Stein Xudong Lin","Yana Kulizhskaya","Ciprian Chelba","Shobha Vasudevan","Eli Collins","Vasilisa Bashlovkina","Tony Lu","Doug Fritz","Jongbin Park","Yanqi Zhou","Chen Su","Richard Tanburn","Mikhail Sushkov","Mitchelle Rasquinha","Jinning Li","Jennifer Prendki","Yiming Li","Pallavi LV","Shriya Sharma","Hen Fitoussi","Hui Huang","Andrew Dai","Phuong Dao","Mike Burrows","Henry Prior","Danfeng Qin","Golan Pundak","Lars Lowe Sjoesund","Art Khurshudov","Zhenkai Zhu","Albert Webson","Elizabeth Kemp","Tat Tan","Saurabh Agrawal","Susie Sargsyan","Liqun Cheng","Jim Stephan","Tom Kwiatkowski","David Reid","Arunkumar Byravan","Assaf Hurwitz Michaely","Nicolas Heess","Luowei Zhou","Sonam Goenka","Viral Carpenter","Anselm Levskaya","Bo Wang","Reed Roberts","Rémi Leblond","Sharat Chikkerur","Stav Ginzburg","Max Chang","Robert Riachi"," Chuqiao"," Xu","Zalán Borsos","Michael Pliskin","Julia Pawar","Morgane Lustman","Hannah Kirkwood","Ankit Anand","Aditi Chaudhary","Norbert Kalb","Kieran Milan","Sean Augenstein","Anna Goldie","Laurel Prince","Karthik Raman","Yanhua Sun","Vivian Xia","Aaron Cohen","Zhouyuan Huo","Josh Camp","Seher Ellis","Lukas Zilka","David Vilar Torres","Lisa Patel","Sho Arora","Betty Chan","Jonas Adler","Kareem Ayoub","Jacky Liang","Fayaz Jamil","Jiepu Jiang","Simon Baumgartner","Haitian Sun","Yael Karov","Yaroslav Akulov","Hui Zheng","Irene Cai","Claudio Fantacci","James Rubin","Alex Rav Acha","Mengchao Wang","Nina D'Souza","Rohit Sathyanarayana","Shengyang Dai","Simon Rowe","Andrey Simanovsky","Omer Goldman","Yuheng Kuang","Xiaoyue Pan","Andrew Rosenberg","Tania Rojas-Esponda","Praneet Dutta","Amy Zeng","Irina Jurenka","Greg Farquhar","Yamini Bansal","Shariq Iqbal","Becca Roelofs","Ga-Young Joung","Parker Beak","Changwan Ryu","Ryan Poplin","Yan Wu","Jean-Baptiste Alayrac","Senaka Buthpitiya","Olaf Ronneberger","Caleb Habtegebriel","Wei Li","Paul Cavallaro","Aurora Wei","Guy Bensky","Timo Denk","Harish Ganapathy","Jeff Stanway","Pratik Joshi","Francesco Bertolini","Jessica Lo","Olivia Ma","Zachary Charles","Geta Sampemane","Himanshu Sahni","Xu Chen","Harry Askham","David Gaddy","Peter Young","Jiewen Tan","Matan Eyal","Arthur Bražinskas","Li Zhong","Zhichun Wu","Mark Epstein","Kai Bailey","Andrew Hard","Kamyu Lee","Sasha Goldshtein","Alex Ruiz","Mohammed Badawi","Matthias Lochbrunner","JK Kearns","Ashley Brown","Fabio Pardo","Theophane Weber","Haichuan Yang","Pan-Pan Jiang","Berkin Akin","Zhao Fu","Marcus Wainwright","Chi Zou","Meenu Gaba","Pierre-Antoine Manzagol","Wendy Kan","Yang Song","Karina Zainullina","Rui Lin","Jeongwoo Ko","Salil Deshmukh","Apoorv Jindal","James Svensson","Divya Tyam","Heri Zhao","Christine Kaeser-Chen","Scott Baird","Pooya Moradi","Jamie Hall","Qiuchen Guo","Vincent Tsang","Bowen Liang","Fernando Pereira","Suhas Ganesh","Ivan Korotkov","Jakub Adamek","Sridhar Thiagarajan","Vinh Tran","Charles Chen","Chris Tar","Sanil Jain","Ishita Dasgupta","Taylan Bilal","David Reitter","Kai Zhao","Giulia Vezzani","Yasmin Gehman","Pulkit Mehta","Lauren Beltrone","Xerxes Dotiwalla","Sergio Guadarrama","Zaheer Abbas","Stefani Karp","Petko Georgiev","Chun-Sung Ferng","Marc Brockschmidt","Liqian Peng","Christoph Hirnschall","Vikas Verma","Yingying Bi","Ying Xiao","Avigail Dabush","Kelvin Xu","Phil Wallis","Randall Parker","Qifei Wang","Yang Xu","Ilkin Safarli","Dinesh Tewari","Yin Zhang","Seungyeon Kim","Andrea Gesmundo","Mackenzie Thomas","Sergey Levi","Ahmed Chowdhury","Kanishka Rao","Peter Garst","Sam Conway-Rahman","Helen Ran","Kay McKinney","Zhisheng Xiao","Wenhao Yu","Rohan Agrawal","Axel Stjerngren","Catalin Ionescu","Jingjing Chen","Vivek Sharma","Justin Chiu","Fei Liu","Ken Franko","Clayton Sanford","Xingyu Cai","Paul Michel","Sanjay Ganapathy","Jane Labanowski","Zachary Garrett","Ben Vargas","Sean Sun","Bryan Gale","Thomas Buschmann","Guillaume Desjardins","Nimesh Ghelani","Palak Jain","Mudit Verma","Chulayuth Asawaroengchai","Julian Eisenschlos","Jitendra Harlalka","Hideto Kazawa","Don Metzler","Joshua Howland","Ying Jian","Jake Ades","Viral Shah","Tynan Gangwani","Seungji Lee","Roman Ring","Steven M. Hernandez","Dean Reich","Amer Sinha","Ashutosh Sathe","Joe Kovac","Ashleah Gill","Ajay Kannan","Andrea D'olimpio","Martin Sevenich","Jay Whang","Been Kim","Khe Chai Sim","Jilin Chen","Jiageng Zhang","Shuba Lall","Yossi Matias","Bill Jia","Abe Friesen","Sara Nasso","Ashish Thapliyal","Bryan Perozzi","Ting Yu","Anna Shekhawat","Safeen Huda","Peter Grabowski","Eric Wang","Ashwin Sreevatsa","Hilal Dib","Mehadi Hassen","Parker Schuh","Vedrana Milutinovic","Chris Welty","Michael Quinn","Ali Shah","Bangju Wang","Gabe Barth-Maron","Justin Frye","Natalie Axelsson","Tao Zhu","Yukun Ma","Irene Giannoumis","Hanie Sedghi","Chang Ye","Yi Luan","Kevin Aydin","Bilva Chandra","Vivek Sampathkumar","Ronny Huang","Victor Lavrenko","Ahmed Eleryan","Zhi Hong","Steven Hansen","Sara Mc Carthy","Bidisha Samanta","Domagoj Ćevid","Xin Wang","Fangtao Li","Michael Voznesensky","Matt Hoffman","Andreas Terzis","Vikash Sehwag","Gil Fidel","Luheng He","Mu Cai","Yanzhang He","Alex Feng","Martin Nikoltchev","Samrat Phatale","Jason Chase","Rory Lawton","Ming Zhang","Tom Ouyang","Manuel Tragut","Mehdi Hafezi Manshadi","Arjun Narayanan","Jiaming Shen","Xu Gao","Tolga Bolukbasi","Nick Roy","Xin Li","Daniel Golovin","Liviu Panait","Zhen Qin","Guangxing Han","Thomas Anthony","Sneha Kudugunta","Viorica Patraucean","Aniket Ray","Xinyun Chen","Xiaochen Yang","Tanuj Bhatia","Pranav Talluri","Alex Morris","Andrija Ražnatović","Bethanie Brownfield","James An","Sheng Peng","Patrick Kane","Ce Zheng","Nico Duduta","Joshua Kessinger","James Noraky","Siqi Liu","Keran Rong","Petar Veličković","Keith Rush","Alex Goldin","Fanny Wei","Shiva Mohan Reddy Garlapati","Caroline Pantofaru","Okwan Kwon","Jianmo Ni","Eric Noland","Julia Di Trapani","Françoise Beaufays","Abhijit Guha Roy","Yinlam Chow","Aybuke Turker","Geoffrey Cideron","Lantao Mei","Jon Clark","Qingyun Dou","Matko Bošnjak","Ralph Leith","Yuqing Du","Amir Yazdanbakhsh","Milad Nasr","Chester Kwak","Suraj Satishkumar Sheth","Alex Kaskasoli","Ankesh Anand","Balaji Lakshminarayanan","Sammy Jerome","David Bieber","Chun-Te Chu","Alexandre Senges","Tianxiao Shen","Mukund Sridhar","Ndaba Ndebele","Benjamin Beyret","Shakir Mohamed","Mia Chen","Markus Freitag","Jiaxian Guo","Luyang Liu","Paul Roit","Heng Chen","Shen Yan","Tom Stone","JD Co-Reyes","Jeremy Cole","Salvatore Scellato","Shekoofeh Azizi","Hadi Hashemi","Alicia Jin","Anand Iyer","Marcella Valentine","András György","Arun Ahuja","Daniel Hernandez Diaz","Chen-Yu Lee","Nathan Clement","Weize Kong","Drew Garmon","Ishaan Watts","Kush Bhatia","Khyatti Gupta","Matt Miecnikowski","Hugo Vallet","Ankur Taly","Edward Loper","Saket Joshi","James Atwood","Jo Chick","Mark Collier","Fotis Iliopoulos","Ryan Trostle","Beliz Gunel","Ramiro Leal-Cavazos","Arnar Mar Hrafnkelsson","Michael Guzman","Xiaoen Ju","Andy Forbes","Jesse Emond","Kushal Chauhan","Ben Caine","Li Xiao","Wenjun Zeng","Alexandre Moufarek","Daniel Murphy","Maya Meng","Nitish Gupta","Felix Riedel","Anil Das","Elijah Lawal","Shashi Narayan","Tiberiu Sosea","James Swirhun","Linda Friso","Behnam Neyshabur","Jing Lu","Sertan Girgin","Michael Wunder","Edouard Yvinec","Aroonalok Pyne","Victor Carbune","Shruti Rijhwani","Yang Guo","Tulsee Doshi","Anton Briukhov","Max Bain","Ayal Hitron","Xuanhui Wang","Ashish Gupta","Ke Chen","Cosmo Du","Weiyang Zhang","Dhruv Shah","Arjun Akula","Max Dylla","Ashyana Kachra","Weicheng Kuo","Tingting Zou","Lily Wang","Luyao Xu","Jifan Zhu","Justin Snyder","Sachit Menon","Orhan Firat","Igor Mordatch","Yuan Yuan","Natalia Ponomareva","Rory Blevins","Lawrence Moore","Weijun Wang","Phil Chen","Martin Scholz","Artur Dwornik","Jason Lin","Sicheng Li","Diego Antognini","Te I","Xiaodan Song","Matt Miller","Uday Kalra","Adam Raveret","Oscar Akerlund","Felix Wu","Andrew Nystrom","Namrata Godbole","Tianqi Liu","Hannah DeBalsi","Jewel Zhao","Buhuang Liu","Avi Caciularu","Lauren Lax","Urvashi Khandelwal","Victoria Langston","Eric Bailey","Silvio Lattanzi","Yufei Wang","Neel Kovelamudi","Sneha Mondal","Guru Guruganesh","Nan Hua","Ofir Roval","Paweł Wesołowski","Rishikesh Ingale","Jonathan Halcrow","Tim Sohn","Christof Angermueller","Bahram Raad","Eli Stickgold","Eva Lu","Alec Kosik","Jing Xie","Timothy Lillicrap","Austin Huang","Lydia Lihui Zhang","Dominik Paulus","Clement Farabet","Alex Wertheim","Bing Wang","Rishabh Joshi","Chu-ling Ko","Yonghui Wu","Shubham Agrawal","Lily Lin","XiangHai Sheng","Peter Sung","Tyler Breland-King","Christina Butterfield","Swapnil Gawde","Sumeet Singh","Qiao Zhang","Raj Apte","Shilpa Shetty","Adrian Hutter","Tao Li","Elizabeth Salesky","Federico Lebron","Jonni Kanerva","Michela Paganini","Arthur Nguyen","Rohith Vallu","Jan-Thorsten Peter","Sarmishta Velury","David Kao","Jay Hoover","Anna Bortsova","Colton Bishop","Shoshana Jakobovits","Alessandro Agostini","Alekh Agarwal","Chang Liu","Charles Kwong","Sasan Tavakkol","Ioana Bica","Alex Greve","Anirudh GP","Jake Marcus","Le Hou","Tom Duerig","Rivka Moroshko","Dave Lacey","Andy Davis","Julien Amelot","Guohui Wang","Frank Kim","Theofilos Strinopoulos","Hui Wan","Charline Le Lan","Shankar Krishnan","Haotian Tang","Peter Humphreys","Junwen Bai","Idan Heimlich Shtacher","Diego Machado","Chenxi Pang","Ken Burke","Dangyi Liu","Renga Aravamudhan","Yue Song","Ed Hirst","Abhimanyu Singh","Brendan Jou","Liang Bai","Francesco Piccinno","Chuyuan Kelly Fu","Robin Alazard","Barak Meiri","Daniel Winter","Charlie Chen","Mingda Zhang","Jens Heitkaemper","John Lambert","Jinhyuk Lee","Alexander Frömmgen","Sergey Rogulenko","Pranav Nair","Paul Niemczyk","Anton Bulyenov","Bibo Xu","Hadar Shemtov","Morteza Zadimoghaddam","Serge Toropov","Mateo Wirth","Hanjun Dai","Sreenivas Gollapudi","Daniel Zheng","Alex Kurakin","Chansoo Lee","Kalesha Bullard","Nicolas Serrano","Ivana Balazevic","Yang Li","Johan Schalkwyk","Mark Murphy","Mingyang Zhang","Kevin Sequeira","Romina Datta","Nishant Agrawal","Charles Sutton","Nithya Attaluri","Mencher Chiang","Wael Farhan","Gregory Thornton","Kate Lin","Travis Choma","Hung Nguyen","Kingshuk Dasgupta","Dirk Robinson","Iulia Comşa","Michael Riley","Arjun Pillai","Basil Mustafa","Ben Golan","Amir Zandieh","Jean-Baptiste Lespiau","Billy Porter","David Ross","Sujeevan Rajayogam","Mohit Agarwal","Subhashini Venugopalan","Bobak Shahriari","Qiqi Yan","Hao Xu","Taylor Tobin","Pavel Dubov","Hongzhi Shi","Adrià Recasens","Anton Kovsharov","Sebastian Borgeaud","Lucio Dery","Shanthal Vasanth","Elena Gribovskaya","Linhai Qiu","Mahdis Mahdieh","Wojtek Skut","Elizabeth Nielsen","CJ Zheng","Adams Yu","Carrie Grimes Bostock","Shaleen Gupta","Aaron Archer","Chris Rawles","Elinor Davies","Alexey Svyatkovskiy","Tomy Tsai","Yoni Halpern","Christian Reisswig","Bartek Wydrowski","Bo Chang","Joan Puigcerver","Mor Hazan Taege","Jian Li","Eva Schnider","Xinjian Li","Dragos Dena","Yunhan Xu","Umesh Telang","Tianze Shi","Heiga Zen","Kyle Kastner","Yeongil Ko","Neesha Subramaniam","Aviral Kumar","Pete Blois","Zhuyun Dai","John Wieting","Yifeng Lu","Yoel Zeldes","Tian Xie","Anja Hauth","Alexandru Ţifrea","Yuqi Li","Sam El-Husseini","Dan Abolafia","Howard Zhou","Wen Ding","Sahra Ghalebikesabi","Carlos Guía","Andrii Maksai","Ágoston Weisz","Sercan Arik","Nick Sukhanov","Aga Świetlik","Xuhui Jia","Luo Yu","Weiyue Wang","Mark Brand","Dawn Bloxwich","Sean Kirmani","Zhe Chen","Alec Go","Pablo Sprechmann","Nithish Kannen","Alen Carin","Paramjit Sandhu","Isabel Edkins","Leslie Nooteboom","Jai Gupta","Loren Maggiore","Javad Azizi","Yael Pritch","Pengcheng Yin","Mansi Gupta","Danny Tarlow","Duncan Smith","Desi Ivanov","Mohammad Babaeizadeh","Ankita Goel","Satish Kambala","Grace Chu","Matej Kastelic","Michelle Liu","Hagen Soltau","Austin Stone","Shivani Agrawal","Min Kim","Kedar Soparkar","Srinivas Tadepalli","Oskar Bunyan","Rachel Soh","Arvind Kannan","DY Kim","Blake JianHang Chen","Afief Halumi","Sudeshna Roy","Yulong Wang","Olcan Sercinoglu","Gena Gibson","Sijal Bhatnagar","Motoki Sano","Daniel von Dincklage","Qingchun Ren","Blagoj Mitrevski","Mirek Olšák","Jennifer She","Carl Doersch"," Jilei"," Wang","Bingyuan Liu","Qijun Tan","Tamar Yakar","Tris Warkentin","Alex Ramirez","Carl Lebsack","Josh Dillon","Rajiv Mathews","Tom Cobley","Zelin Wu","Zhuoyuan Chen","Jon Simon","Swaroop Nath","Tara Sainath","Alexei Bendebury","Ryan Julian","Bharath Mankalale","Daria Ćurko","Paulo Zacchello","Adam R. Brown","Kiranbir Sodhia","Heidi Howard","Sergi Caelles","Abhinav Gupta","Gareth Evans","Anna Bulanova","Lesley Katzen","Roman Goldenberg","Anton Tsitsulin","Joe Stanton","Benoit Schillings","Vitaly Kovalev","Corey Fry","Rushin Shah","Kuo Lin","Shyam Upadhyay","Cheng Li","Soroush Radpour","Marcello Maggioni","Jing Xiong","Lukas Haas","Jenny Brennan","Aishwarya Kamath","Nikolay Savinov","Arsha Nagrani","Trevor Yacovone","Ryan Kappedal","Kostas Andriopoulos","Li Lao","YaGuang Li","Grigory Rozhdestvenskiy","Kazuma Hashimoto","Andrew Audibert","Sophia Austin","Daniel Rodriguez","Anian Ruoss","Garrett Honke","Deep Karkhanis","Xi Xiong","Qing Wei","James Huang","Zhaoqi Leng","Vittal Premachandran","Stan Bileschi","Georgios Evangelopoulos","Thomas Mensink","Jay Pavagadhi","Denis Teplyashin","Paul Chang","Linting Xue","Garrett Tanzer","Sally Goldman","Kaushal Patel","Shixin Li","Jeremy Wiesner","Ivy Zheng","Ian Stewart-Binks","Jie Han","Zhi Li","Liangchen Luo","Karel Lenc","Mario Lučić","Fuzhao Xue","Ryan Mullins","Alexey Guseynov","Chung-Ching Chang","Isaac Galatzer-Levy","Adam Zhang","Garrett Bingham","Grace Hu","Ale Hartman","Yue Ma","Jordan Griffith","Alex Irpan","Carey Radebaugh","Summer Yue","Lijie Fan","Victor Ungureanu","Christina Sorokin","Hannah Teufel","Peiran Li","Rohan Anil","Dimitris Paparas","Todd Wang","Chu-Cheng Lin","Hui Peng","Megan Shum","Goran Petrovic","Demetra Brady","Richard Nguyen","Klaus Macherey","Zhihao Li","Harman Singh","Madhavi Yenugula","Mariko Iinuma","Xinyi Chen","Kavya Kopparapu","Alexey Stern","Shachi Dave","Chandu Thekkath","Florence Perot","Anurag Kumar","Fangda Li","Yang Xiao","Matthew Bilotti","Mohammad Hossein Bateni","Isaac Noble","Lisa Lee","Amelio Vázquez-Reina","Julian Salazar","Xiaomeng Yang","Boyu Wang","Ela Gruzewska","Anand Rao","Sindhu Raghuram","Zheng Xu","Eyal Ben-David","Jieru Mei","Sid Dalmia","Zhaoyi Zhang","Yuchen Liu","Gagan Bansal","Helena Pankov","Steven Schwarcz","Andrea Burns","Christine Chan","Sumit Sanghai","Ricky Liang","Ethan Liang","Antoine He","Amy Stuart","Arun Narayanan","Yukun Zhu","Christian Frank","Bahar Fatemi","Amit Sabne","Oran Lang","Indro Bhattacharya","Shane Settle","Maria Wang","Brendan McMahan","Andrea Tacchetti","Livio Baldini Soares","Majid Hadian","Serkan Cabi","Timothy Chung","Nikita Putikhin","Gang Li","Jeremy Chen","Austin Tarango","Henryk Michalewski","Mehran Kazemi","Hussain Masoom","Hila Sheftel","Rakesh Shivanna","Archita Vadali","Ramona Comanescu","Doug Reid","Joss Moore","Arvind Neelakantan","Michaël Sander","Jonathan Herzig","Aviv Rosenberg","Mostafa Dehghani","JD Choi","Michael Fink","Reid Hayes","Eric Ge","Shitao Weng","Chia-Hua Ho","John Karro","Kalpesh Krishna","Lam Nguyen Thiet","Amy Skerry-Ryan","Daniel Eppens","Marco Andreetto","Navin Sarma","Silvano Bonacina","Burcu Karagol Ayan","Megha Nawhal","Zhihao Shan","Mike Dusenberry","Shantanu Thakoor","Sagar Gubbi","Duc Dung Nguyen","Reut Tsarfaty","Samuel Albanie","Jovana Mitrović","Meet Gandhi","Bo-Juen Chen","Alessandro Epasto","Georgi Stephanov","Ye Jin","Samuel Gehman","Aida Amini","Jack Weber","Feryal Behbahani","Shawn Xu","Miltos Allamanis","Xi Chen","Myle Ott","Claire Sha","Michal Jastrzebski","Hang Qi","David Greene","Xinyi Wu","Abodunrinwa Toki","Daniel Vlasic","Jane Shapiro","Ragha Kotikalapudi","Zhe Shen","Takaaki Saeki","Sirui Xie","Albin Cassirer","Shikhar Bharadwaj","Tatsuya Kiyono","Srinadh Bhojanapalli","Elan Rosenfeld","Sam Ritter","Jieming Mao","João Gabriel Oliveira","Zoltan Egyed","Bernd Bandemer","Emilio Parisotto","Keisuke Kinoshita","Juliette Pluto","Petros Maniatis","Steve Li","Yaohui Guo","Golnaz Ghiasi","Jean Tarbouriech","Srimon Chatterjee","Julie Jin"," Katrina"," Xu","Jennimaria Palomaki","Séb Arnold","Madhavi Sewak","Federico Piccinini","Mohit Sharma","Ben Albrecht","Sean Purser-haskell","Ashwin Vaswani","Chongyan Chen","Matheus Wisniewski","Qin Cao","John Aslanides","Nguyet Minh Phu","Maximilian Sieb","Lauren Agubuzu","Anne Zheng","Daniel Sohn","Marco Selvi","Anders Andreassen","Krishan Subudhi","Prem Eruvbetine","Oliver Woodman","Tomas Mery","Sebastian Krause","Xiaoqi Ren","Xiao Ma","Jincheng Luo","Dawn Chen","Wei Fan","Henry Griffiths","Christian Schuler","Alice Li","Shujian Zhang","Jean-Michel Sarr","Shixin Luo","Riccardo Patana","Matthew Watson","Dani Naboulsi","Michael Collins","Sailesh Sidhwani","Emiel Hoogeboom","Sharon Silver","Emily Caveness","Xiaokai Zhao","Mikel Rodriguez","Maxine Deines","Libin Bai","Patrick Griffin","Marco Tagliasacchi","Emily Xue","Spandana Raj Babbula","Bo Pang","Nan Ding","Gloria Shen","Elijah Peake","Remi Crocker","Shubha Srinivas Raghvendra","Danny Swisher","Woohyun Han","Richa Singh","Ling Wu","Vladimir Pchelin","Tsendsuren Munkhdalai","Dana Alon","Geoff Bacon","Efren Robles","Jannis Bulian","Melvin Johnson","George Powell","Felipe Tiengo Ferreira","Yaoyiran Li","Frederik Benzing","Mihajlo Velimirović","Hubert Soyer","William Kong"," Tony"," Nguyên","Zhen Yang","Jeremiah Liu","Joost van Amersfoort","Daniel Gillick","Baochen Sun","Nathalie Rauschmayr","Katie Zhang","Serena Zhan","Tao Zhou","Alexey Frolov","Chengrun Yang","Denis Vnukov","Louis Rouillard","Hongji Li","Amol Mandhane","Nova Fallen","Rajesh Venkataraman","Clara Huiyi Hu","Jennifer Brennan","Jenny Lee","Jerry Chang","Martin Sundermeyer","Zhufeng Pan","Rosemary Ke","Simon Tong","Alex Fabrikant","William Bono","Jindong Gu","Ryan Foley","Yiran Mao","Manolis Delakis","Dhruva Bhaswar","Roy Frostig","Nick Li","Avital Zipori","Cath Hope","Olga Kozlova","Swaroop Mishra","Josip Djolonga","Craig Schiff","Majd Al Merey","Eleftheria Briakou","Peter Morgan","Andy Wan","Avinatan Hassidim","RJ Skerry-Ryan","Kuntal Sengupta","Mary Jasarevic","Praveen Kallakuri","Paige Kunkle","Hannah Brennan","Tom Lieber","Hassan Mansoor","Julian Walker","Bing Zhang","Annie Xie","Goran Žužić","Adaeze Chukwuka","Alex Druinsky","Donghyun Cho","Rui Yao","Ferjad Naeem","Shiraz Butt","Eunyoung Kim","Zhipeng Jia","Mandy Jordan","Adam Lelkes","Mark Kurzeja","Sophie Wang","James Zhao","Andrew Over","Abhishek Chakladar","Marcel Prasetya","Neha Jha","Sriram Ganapathy","Yale Cong","Prakash Shroff","Carl Saroufim","Sobhan Miryoosefi","Mohamed Hammad","Tajwar Nasir","Weijuan Xi","Yang Gao","Young Maeng","Ben Hora","Chin-Yi Cheng","Parisa Haghani","Yoad Lewenberg","Caden Lu","Martin Matysiak","Naina Raisinghani","Huiyu Wang","Lexi Baugher","Rahul Sukthankar","Minh Giang","John Schultz","Noah Fiedel","Minmin Chen","Cheng-Chun Lee","Tapomay Dey","Hao Zheng","Shachi Paul","Celine Smith","Andy Ly","Yicheng Wang","Rishabh Bansal","Bartek Perz","Susanna Ricco","Stasha Blank","Vaishakh Keshava","Deepak Sharma","Marvin Chow","Kunal Lad","Komal Jalan","Simon Osindero","Craig Swanson","Jacob Scott","Anastasija Ilić","Xiaowei Li","Siddhartha Reddy Jonnalagadda","Afzal Shama Soudagar","Yan Xiong","Bat-Orgil Batsaikhan","Daniel Jarrett","Naveen Kumar","Maulik Shah","Matt Lawlor","Austin Waters","Mark Graham","Rhys May","Sabela Ramos","Sandra Lefdal","Zeynep Cankara","Nacho Cano","Brendan O'Donoghue","Jed Borovik","Frederick Liu","Jordan Grimstad","Mahmoud Alnahlawi","Katerina Tsihlas","Tom Hudson","Nikolai Grigorev","Yiling Jia","Terry Huang","Tobenna Peter Igwe","Sergei Lebedev","Xiaodan Tang","Igor Krivokon","Frankie Garcia","Melissa Tan","Eric Jia","Peter Stys","Shikhar Vashishth","Yu Liang","Balaji Venkatraman","Chenjie Gu","Anastasios Kementsietsidis","Chen Zhu","Junehyuk Jung","Yunfei Bai","Mohammad Javad Hosseini","Faruk Ahmed","Aditya Gupta","Xin Yuan","Shereen Ashraf","Shitij Nigam","Gautam Vasudevan","Pranjal Awasthi","Adi Mayrav Gilady","Zelda Mariet","Ramy Eskander","Haiguang Li","Hexiang Hu","Guillermo Garrido","Philippe Schlattner","George Zhang","Rohun Saxena","Petar Dević","Kritika Muralidharan","Ashwin Murthy","Yiqian Zhou","Min Choi","Arissa Wongpanich","Zhengdong Wang","Premal Shah","Yuntao Xu","Yiling Huang","Stephen Spencer","Alice Chen","James Cohan","Junjie Wang","Jonathan Tompson","Junru Wu","Ruba Haroun","Haiqiong Li","Blanca Huergo","Fan Yang","Tongxin Yin","James Wendt","Michael Bendersky","Rahma Chaabouni","Javier Snaider","Johan Ferret","Abhishek Jindal","Tara Thompson","Andrew Xue","Will Bishop","Shubham Milind Phal","Archit Sharma","Yunhsuan Sung","Prabakar Radhakrishnan","Mo Shomrat","Reeve Ingle","Roopali Vij","Justin Gilmer","Mihai Dorin Istin","Sam Sobell","Yang Lu","Emily Nottage","Dorsa Sadigh","Jeremiah Willcock","Tingnan Zhang","Steve Xu","Sasha Brown","Katherine Lee","Gary Wang","Yun Zhu","Yi Tay","Cheolmin Kim","Audrey Gutierrez","Abhanshu Sharma","Yongqin Xian","Sungyong Seo","Claire Cui","Elena Pochernina","Cip Baetu","Krzysztof Jastrzębski","Mimi Ly","Mohamed Elhawaty","Dan Suh","Eren Sezener","Pidong Wang","Nancy Yuen","George Tucker","Jiahao Cai","Zuguang Yang","Cindy Wang","Alex Muzio","Hai Qian","Jae Yoo","Derek Lockhart","Kevin R. McKee","Mandy Guo","Malika Mehrotra","Artur Mendonça","Sanket Vaibhav Mehta","Sherry Ben","Chetan Tekur","Jiaqi Mu","Muye Zhu","Victoria Krakovna","Hongrae Lee","AJ Maschinot","Sébastien Cevey","HyunJeong Choe","Aijun Bai","Hansa Srinivasan","Derek Gasaway","Nick Young","Patrick Siegler","Dan Holtmann-Rice","Vihari Piratla","Kate Baumli","Roey Yogev","Alex Hofer","Hado van Hasselt","Svetlana Grant","Yuri Chervonyi","David Silver","Andrew Hogue","Ayushi Agarwal","Kathie Wang","Preeti Singh","Four Flynn","Josh Lipschultz","Robert David","Lizzetth Bellot","Yao-Yuan Yang","Long Le","Filippo Graziano","Kate Olszewska","Kevin Hui","Akanksha Maurya","Nikos Parotsidis","Weijie Chen","Tayo Oguntebi","Joe Kelley","Anirudh Baddepudi","Johannes Mauerer","Gregory Shaw","Alex Siegman","Lin Yang","Shravya Shetty","Subhrajit Roy","Yunting Song","Wojciech Stokowiec","Ryan Burnell","Omkar Savant","Robert Busa-Fekete","Jin Miao","Samrat Ghosh","Liam MacDermed","Phillip Lippe","Mikhail Dektiarev","Zach Behrman","Fabian Mentzer","Kelvin Nguyen","Meng Wei","Siddharth Verma","Chris Knutsen","Sudeep Dasari","Zhipeng Yan","Petr Mitrichev","Xingyu Wang","Virat Shejwalkar","Jacob Austin","Srinivas Sunkara","Navneet Potti","Yan Virin","Christian Wright","Gaël Liu","Oriana Riva","Etienne Pot","Greg Kochanski","Quoc Le","Gargi Balasubramaniam","Arka Dhar","Yuguo Liao","Adam Bloniarz","Divyansh Shukla","Elizabeth Cole","Jong Lee","Sheng Zhang","Sushant Kafle","Siddharth Vashishtha","Parsa Mahmoudieh","Grace Chen","Raphael Hoffmann","Pranesh Srinivasan","Agustin Dal Lago","Yoav Ben Shalom","Zi Wang","Michael Elabd","Anuj Sharma","Junhyuk Oh","Suraj Kothawade","Maigo Le","Marianne Monteiro","Shentao Yang","Kaiz Alarakyia","Robert Geirhos","Diana Mincu","Håvard Garnes","Hayato Kobayashi","Soroosh Mariooryad","Kacper Krasowiak"," Zhixin"," Lai","Shibl Mourad","Mingqiu Wang","Fan Bu","Ophir Aharoni","Guanjie Chen","Abhimanyu Goyal","Vadim Zubov","Ankur Bapna","Elahe Dabir","Nisarg Kothari","Kay Lamerigts","Nicola De Cao","Jeremy Shar","Christopher Yew","Nitish Kulkarni","Dre Mahaarachchi","Mandar Joshi","Zhenhai Zhu","Jared Lichtarge","Yichao Zhou","Hannah Muckenhirn","Vittorio Selo","Oriol Vinyals","Peter Chen","Anthony Brohan","Vaibhav Mehta","Sarah Cogan","Ruth Wang","Ty Geri","Wei-Jen Ko","Wei Chen","Fabio Viola","Keshav Shivam","Lisa Wang","Madeleine Clare Elish","Raluca Ada Popa","Sébastien Pereira","Jianqiao Liu","Raphael Koster","Donnie Kim","Gufeng Zhang","Sayna Ebrahimi","Partha Talukdar","Yanyan Zheng","Petra Poklukar","Ales Mikhalap","Dale Johnson","Anitha Vijayakumar","Mark Omernick","Matt Dibb","Ayush Dubey","Qiong Hu","Apurv Suman","Vaibhav Aggarwal","Ilya Kornakov","Fei Xia","Wing Lowe","Alexey Kolganov","Ted Xiao","Vitaly Nikolaev","Steven Hemingray","Bonnie Li","Joana Iljazi","Mikołaj Rybiński","Ballie Sandhu","Peggy Lu","Thang Luong","Rodolphe Jenatton","Vineetha Govindaraj"," Hui"," Li","Gabriel Dulac-Arnold","Wonpyo Park","Henry Wang","Abhinit Modi","Jean Pouget-Abadie","Kristina Greller","Rahul Gupta","Robert Berry","Prajit Ramachandran","Jinyu Xie","Liam McCafferty","Jianling Wang","Kilol Gupta","Hyeontaek Lim","Blaž Bratanič","Andy Brock","Ilia Akolzin","Jim Sproch","Dan Karliner","Duhyeon Kim","Adrian Goedeckemeyer","Noam Shazeer","Cordelia Schmid","Daniele Calandriello","Parul Bhatia","Krzysztof Choromanski","Ceslee Montgomery","Dheeru Dua","Ana Ramalho","Helen King","Yue Gao","Lynn Nguyen","David Lindner","Divya Pitta","Oleaser Johnson","Khalid Salama","Diego Ardila","Michael Han","Erin Farnese","Seth Odoom","Ziyue Wang","Xiangzhuo Ding","Norman Rink","Ray Smith","Harshal Tushar Lehri","Eden Cohen","Neera Vats","Tong He","Parthasarathy Gopavarapu","Adam Paszke","Miteyan Patel","Wouter Van Gansbeke","Lucia Loher","Luis Castro","Maria Voitovich","Tamara von Glehn","Nelson George","Simon Niklaus","Zach Eaton-Rosen","Nemanja Rakićević","Erik Jue","Sagi Perel","Carrie Zhang","Yuval Bahat","Angéline Pouget","Zhi Xing","Fantine Huot","Ashish Shenoy","Taylor Bos","Vincent Coriou","Bryan Richter","Natasha Noy","Yaqing Wang","Santiago Ontanon","Siyang Qin","Gleb Makarchuk","Demis Hassabis","Zhuowan Li","Mandar Sharma","Kumaran Venkatesan","Iurii Kemaev","Roxanne Daniel","Shiyu Huang","Saloni Shah","Octavio Ponce"," Warren"," Chen","Manaal Faruqui","Jialin Wu","Slavica Andačić","Szabolcs Payrits","Daniel McDuff","Tom Hume","Yuan Cao","MH Tessler","Qingze Wang","Yinan Wang","Ivor Rendulic","Eirikur Agustsson","Matthew Johnson","Tanya Lando","Andrew Howard","Sri Gayatri Sundara Padmanabhan","Mayank Daswani","Andrea Banino","Michael Kilgore","Jonathan Heek","Ziwei Ji","Alvaro Caceres","Conglong Li","Nora Kassner","Alexey Vlaskin","Zeyu Liu","Alex Grills","Yanhan Hou","Roykrong Sukkerd","Gowoon Cheon","Nishita Shetty","Larisa Markeeva","Piotr Stanczyk","Tejas Iyer","Yuan Gong","Shawn Gao","Keerthana Gopalakrishnan","Tim Blyth","Malcolm Reynolds","Avishkar Bhoopchand","Misha Bilenko","Dero Gharibian","Vicky Zayats","Aleksandra Faust","Abhinav Singh","Min Ma","Hongyang Jiao","Sudheendra Vijayanarasimhan","Lora Aroyo","Vikas Yadav","Sarah Chakera","Ashwin Kakarla","Vilobh Meshram","Karol Gregor","Gabriela Botea","Evan Senter","Dawei Jia","Geza Kovacs","Neha Sharma","Sebastien Baur","Kai Kang","Yifan He","Lin Zhuo","Marija Kostelac","Itay Laish","Songyou Peng","Louis O'Bryan","Daniel Kasenberg","Girish Ramchandra Rao","Edouard Leurent","Biao Zhang","Sage Stevens","Ana Salazar","Ye Zhang","Ivan Lobov","Jake Walker","Allen Porter","Morgan Redshaw","Han Ke","Abhishek Rao","Alex Lee","Hoi Lam","Michael Moffitt","Jaeyoun Kim","Siyuan Qiao","Terry Koo","Robert Dadashi","Xinying Song","Mukund Sundararajan","Peng Xu","Chizu Kawamoto","Yan Zhong","Clara Barbu","Apoorv Reddy","Mauro Verzetti","Leon Li","George Papamakarios","Hanna Klimczak-Plucińska","Mary Cassin","Koray Kavukcuoglu","Rigel Swavely","Alain Vaucher","Jeffrey Zhao","Ross Hemsley","Michael Tschannen","Heming Ge","Gaurav Menghani","Yang Yu","Natalie Ha","Wei He","Xiao Wu","Maggie Song","Rachel Sterneck","Stefan Zinke","Dan A. Calian","Annie Marsden","Alejandro Cruzado Ruiz","Matteo Hessel","Almog Gueta","Benjamin Lee","Brian Farris","Manish Gupta","Yunjie Li","Mohammad Saleh","Vedant Misra","Kefan Xiao","Piermaria Mendolicchio","Gavin Buttimore","Varvara Krayvanova","Nigamaa Nayakanti","Matthew Wiethoff","Yash Pande","Azalia Mirhoseini","Ni Lao","Jasmine Liu","Yiqing Hua","Angie Chen","Yury Malkov","Dmitry Kalashnikov","Shubham Gupta","Kartik Audhkhasi","Yuexiang Zhai","Sudhindra Kopalle","Prateek Jain","Eran Ofek","Clemens Meyer","Khuslen Baatarsukh","Hana Strejček","Jun Qian","James Freedman","Ricardo Figueira","Michal Sokolik","Olivier Bachem","Raymond Lin","Dia Kharrat","Chris Hidey","Pingmei Xu","Dennis Duan","Yin Li","Muge Ersoy","Richard Everett","Kevin Cen","Rebeca Santamaria-Fernandez","Amir Taubenfeld","Ian Mackinnon","Linda Deng","Polina Zablotskaia","Shashank Viswanadha","Shivanker Goel","Damion Yates","Yunxiao Deng","Peter Choy","Mingqing Chen","Abhishek Sinha","Alex Mossin","Yiming Wang","Arthur Szlam","Susan Hao","Paul Kishan Rubenstein","Metin Toksoz-Exley","Miranda Aperghis","Yin Zhong","Junwhan Ahn","Michael Isard","Olivier Lacombe","Florian Luisier","Chrysovalantis Anastasiou","Yogesh Kalley","Utsav Prabhu","Emma Dunleavy","Shaan Bijwadia","Justin Mao-Jones","Kelly Chen","Rama Pasumarthi","Emily Wood","Adil Dostmohamed","Nate Hurley","Jiri Simsa","Alicia Parrish","Mantas Pajarskas","Matt Harvey","Ondrej Skopek","Yony Kochinski","Javier Rey","Verena Rieser","Denny Zhou","Sun Jae Lee","Trilok Acharya","Guowang Li","Joe Jiang","Xiaofan Zhang","Bryant Gipson","Ethan Mahintorabi","Marco Gelmi","Nima Khajehnouri","Angel Yeh","Kayi Lee","Loic Matthey","Leslie Baker","Trang Pham","Han Fu","Alex Pak","Prakhar Gupta","Cristina Vasconcelos","Adam Sadovsky","Brian Walker","Sissie Hsiao","Patrik Zochbauer","Andreea Marzoca","Noam Velan","Junhao Zeng","Gilles Baechler","Danny Driess","Divya Jain","Yanping Huang","Lizzie Tao","John Maggs","Nir Levine","Jon Schneider","Erika Gemzer","Samuel Petit","Shan Han","Zach Fisher","Dustin Zelle","Courtney Biles","Eugene Ie","Asya Fadeeva","Casper Liu","Juliana Vicente Franco","Adrian Collister","Hao Zhang","Renshen Wang","Ruizhe Zhao","Leandro Kieliger","Kurt Shuster","Rui Zhu","Boqing Gong","Lawrence Chan","Ruoxi Sun","Sujoy Basu","Roland Zimmermann","Jamie Hayes","Abhishek Bapna","Jasper Snoek","Weel Yang","Puranjay Datta","Jad Al Abdallah","Kevin Kilgour","Lu Li","SQ Mah","Yennie Jun","Morgane Rivière","Abhijit Karmarkar","Tammo Spalink","Tao Huang","Lucas Gonzalez","Duc-Hieu Tran","Averi Nowak","John Palowitch","Martin Chadwick","Ellie Talius","Harsh Mehta","Thibault Sellam","Philipp Fränken","Massimo Nicosia","Kyle He","Aditya Kini","David Amos","Sugato Basu","Harrison Jobe","Eleni Shaw","Qiantong Xu","Colin Evans","Daisuke Ikeda","Chaochao Yan","Larry Jin","Lun Wang","Sachin Yadav","Ilia Labzovsky","Ramesh Sampath","Ada Ma","Candice Schumann","Aditya Siddhant","Rohin Shah","John Youssef","Rishabh Agarwal","Natalie Dabney","Alessio Tonioni","Moran Ambar","Jing Li","Isabelle Guyon","Benny Li","David Soergel","Boya Fang","Georgi Karadzhov","Cristian Udrescu","Trieu Trinh","Vikas Raunak","Seb Noury","Dee Guo","Sonal Gupta","Mara Finkelstein","Denis Petek","Lihao Liang","Greg Billock","Pei Sun","David Wood","Yiwen Song","Xiaobin Yu","Tatiana Matejovicova","Regev Cohen","Kalyan Andra","David D'Ambrosio","Zhiwei Deng","Vincent Nallatamby","Ebrahim Songhori","Rumen Dangovski","Andrew Lampinen","Pankil Botadra","Adam Hillier","Jiawei Cao","Nagabhushan Baddi","Adhi Kuncoro","Toshihiro Yoshino","Ankit Bhagatwala","Marcáurelio Ranzato","Rylan Schaeffer","Tianlin Liu","Shuai Ye","Obaid Sarvana","John Nham","Chenkai Kuang","Isabel Gao","Jinoo Baek","Shubham Mittal","Ayzaan Wahid","Anita Gergely","Bin Ni","Josh Feldman","Carrie Muir","Pascal Lamblin","Wolfgang Macherey","Ethan Dyer","Logan Kilpatrick","Víctor Campos","Mukul Bhutani","Stanislav Fort","Yanif Ahmad","Aliaksei Severyn","Kleopatra Chatziprimou","Oleksandr Ferludin","Mason Dimarco","Aditya Kusupati","Joe Heyward","Dan Bahir","Kevin Villela","Katie Millican","Dror Marcus","Sanaz Bahargam","Caglar Unlu","Nicholas Roth","Zichuan Wei","Siddharth Gopal","Deepanway Ghoshal","Edward Lee","Sharon Lin","Jennie Lees","Dayeong Lee","Anahita Hosseini","Connie Fan","Seth Neel","Marcus Wu","Yasemin Altun","Honglong Cai","Enrique Piqueras","Josh Woodward","Alessandro Bissacco","Salem Haykal","Mahyar Bordbar","Prasha Sundaram","Sarah Hodkinson","Daniel Toyama","George Polovets","Austin Myers","Anu Sinha","Tomer Levinboim","Kashyap Krishnakumar","Rachita Chhaparia","Tatiana Sholokhova","Nitesh Bharadwaj Gundavarapu","Ganesh Jawahar","Haroon Qureshi","Jieru Hu","Nikola Momchev","Matthew Rahtz","Renjie Wu","Aishwarya P S","Kedar Dhamdhere","Meiqi Guo","Umang Gupta","Ali Eslami","Mariano Schain","Michiel Blokzijl","David Welling","Dave Orr","Levent Bolelli","Nicolas Perez-Nieves","Mikhail Sirotenko","Aman Prasad","Arjun Kar","Borja De Balle Pigem","Tayfun Terzi","Gellért Weisz","Dipankar Ghosh","Aditi Mavalankar","Dhruv Madeka","Kaspar Daugaard","Hartwig Adam","Viraj Shah","Dana Berman","Maggie Tran","Steven Baker","Ewa Andrejczuk","Grishma Chole","Ganna Raboshchuk","Mahdi Mirzazadeh","Thais Kagohara","Shimu Wu","Christian Schallhart","Bernett Orlando","Chen Wang","Alban Rrustemi","Hao Xiong","Hao Liu","Arpi Vezer","Nolan Ramsden","Shuo-yiin Chang","Sidharth Mudgal","Yan Li","Nino Vieillard","Yedid Hoshen","Farooq Ahmad","Ambrose Slone","Amy Hua","Natan Potikha","Mirko Rossini","Jon Stritar","Sushant Prakash","Zifeng Wang","Xuanyi Dong","Alireza Nazari","Efrat Nehoran","Kaan Tekelioglu","Yinxiao Li","Kartikeya Badola","Tom Funkhouser","Yuanzhen Li","Varun Yerram","Ramya Ganeshan","Daniel Formoso","Karol Langner","Tian Shi","Huijian Li","Yumeya Yamamori","Amayika Panda","Alaa Saade","Angelo Scorza Scarpati","Chris Breaux","CJ Carey","Zongwei Zhou","Cho-Jui Hsieh","Sophie Bridgers","Alena Butryna","Nishesh Gupta","Vaibhav Tulsyan","Sanghyun Woo","Evgenii Eltyshev","Will Grathwohl","Chanel Parks","Seth Benjamin","Rina Panigrahy","Shenil Dodhia","Daniel De Freitas","Chris Sauer","Will Song","Ferran Alet","Jackson Tolins","Cosmin Paduraru","Xingyi Zhou","Brian Albert","Zizhao Zhang","Lei Shu","Mudit Bansal","Sarah Nguyen","Amir Globerson","Owen Xiao","James Manyika","Tom Hennigan","Rong Rong","Josip Matak","Anton Bakalov","Ankur Sharma","Danila Sinopalnikov","Andrew Pierson","Stephen Roller","Geoff Brown","Mingcen Gao","Toshiyuki Fukuzawa","Amin Ghafouri","Kenny Vassigh","Iain Barr","Zhicheng Wang","Anna Korsun","Rajesh Jayaram","Lijie Ren","Tim Zaman","Samira Khan","Yana Lunts","Dan Deutsch","Dave Uthus","Nitzan Katz","Masha Samsikova","Amr Khalifa","Nikhil Sethi","Jiao Sun","Luming Tang","Uri Alon","Xianghong Luo","Dian Yu","Abhishek Nayyar","Bryce Petrini","Will Truong","Vincent Hellendoorn","Nikolai Chinaev","Chris Alberti","Wei Wang","Jingcao Hu","Vahab Mirrokni","Ananth Balashankar","Avia Aharon","Aahil Mehta","Ahmet Iscen","Joseph Kready","Lucas Manning","Anhad Mohananey","Yuankai Chen","Anshuman Tripathi","Allen Wu","Igor Petrovski","Dawsen Hwang","Martin Baeuml","Shreyas Chandrakaladharan","Yuan Liu","Rey Coaguila","Maxwell Chen","Sally Ma","Pouya Tafti","Susheel Tatineni","Terry Spitz","Jiayu Ye","Paul Vicol","Mihaela Rosca","Adrià Puigdomènech","Zohar Yahav","Sanjay Ghemawat","Hanzhao Lin","Phoebe Kirk","Zaid Nabulsi","Sergey Brin","Bernd Bohnet","Ken Caluwaerts","Aditya Srikanth Veerubhotla","Dan Zheng","Zihang Dai","Petre Petrov","Yichong Xu","Ramin Mehran","Zhuo Xu","Luisa Zintgraf","Jiho Choi","Spurthi Amba Hombaiah","Romal Thoppilan","Sashank Reddi","Lukasz Lew","Li Li","Kellie Webster","KP Sawhney","Lampros Lamprou","Siamak Shakeri","Mayank Lunayach","Jianmin Chen","Sumit Bagri","Alex Salcianu","Ying Chen","Yani Donchev","Charlotte Magister","Signe Nørly","Vitor Rodrigues","Tomas Izo","Hila Noga","Joe Zou","Thomas Köppe","Wenxuan Zhou","Kenton Lee","Xiangzhu Long","Danielle Eisenbud","Anthony Chen","Connor Schenck","Chi Ming To","Peilin Zhong","Emanuel Taropa","Minh Truong","Omer Levy","Danilo Martins","Zhiyuan Zhang","Christopher Semturs","Kelvin Zhang","Alex Yakubovich","Pol Moreno","Lara McConnaughey","Di Lu","Sam Redmond","Lotte Weerts","Yonatan Bitton","Tiziana Refice","Nicolas Lacasse","Arthur Conmy","Corentin Tallec","Julian Odell","Hannah Forbes-Pollard","Arkadiusz Socala","Jonathan Hoech","Pushmeet Kohli","Alanna Walton","Rui Wang","Mikita Sazanovich","Kexin Zhu","Andrei Kapishnikov","Rich Galt","Matthew Denton","Ben Murdoch","Caitlin Sikora","Kareem Mohamed","Wei Wei","Uri First","Tim McConnell","Luis C. Cobo","James Qin","Thi Avrahami","Daniel Balle","Yu Watanabe","Annie Louis","Adam Kraft","Setareh Ariafar","Yiming Gu","Eugénie Rives","Charles Yoon","Andrei Rusu","James Cobon-Kerr","Chris Hahn","Jiaming Luo"," Yuvein"," Zhu","Niharika Ahuja","Rodrigo Benenson","Raphaël Lopez Kaufman","Honglin Yu","Lloyd Hightower","Junlin Zhang","Darren Ni","Lisa Anne Hendricks","Gabby Wang","Gal Yona","Lalit Jain","Pablo Barrio","Surya Bhupatiraju","Siva Velusamy","Allan Dafoe","Sebastian Riedel","Tara Thomas","Zhe Yuan","Mathias Bellaiche","Sheena Panthaplackel","Klemen Kloboves","Sarthak Jauhari","Canfer Akbulut","Todor Davchev","Evgeny Gladchenko","David Madras","Aleksandr Chuklin","Tyrone Hill","Quan Yuan","Mukundan Madhavan","Luke Leonhard","Dylan Scandinaro","Qihang Chen","Ning Niu","Arthur Douillard","Bogdan Damoc","Yasumasa Onoe","Fabian Pedregosa","Fred Bertsch","Chas Leichner","Joseph Pagadora","Jonathan Malmaud","Sameera Ponda","Andy Twigg","Oleksii Duzhyi","Jingwei Shen","Miaosen Wang","Roopal Garg","Jing Chen","Utku Evci","Jonathan Lee","Leon Liu","Koji Kojima","Masa Yamaguchi","Arunkumar Rajendran","AJ Piergiovanni","Vinodh Kumar Rajendran","Marco Fornoni","Gabriel Ibagon","Harry Ragan","Sadh MNM Khan","John Blitzer","Andrew Bunner","Guan Sun","Takahiro Kosakai","Scott Lundberg","Ndidi Elue","Kelvin Guu","SK Park","Jane Park","Arunachalam Narayanaswamy","Chengda Wu","Jayaram Mudigonda","Trevor Cohn","Hairong Mu","Ravi Kumar","Laura Graesser","Yichi Zhang","Richard Killam","Vincent Zhuang","Mai Giménez","Wael Al Jishi","Ruy Ley-Wild","Alex Zhai","Kazuki Osawa","Diego Cedillo","Jialu Liu","Mayank Upadhyay","Marcin Sieniek","Roshan Sharma","Tom Paine","Anelia Angelova","Sravanti Addepalli","Carolina Parada","Kingshuk Majumder","Avery Lamp","Sanjiv Kumar","Xiang Deng","Artiom Myaskovsky","Tea Sabolić","Jeffrey Dudek","Sarah York","Félix de Chaumont Quitry","Jiazhong Nie","Dee Cattle","Alok Gunjan","Bilal Piot","Waleed Khawaja","Seojin Bang","Simon Wang","Siavash Khodadadeh","Raghavender R","Praynaa Rawlani","Richard Powell","Kevin Lee","Johannes Griesser","GS Oh","Cesar Magalhaes","Yujia Li","Simon Tokumine","Hadas Natalie Vogel","Dennis Hsu","Arturo BC","Disha Jindal","Matan Cohen","Zi Yang","Junwei Yuan","Dario de Cesare","Tony Bruguier","Jun Xu","Monica Roy","Alon Jacovi","Dan Belov","Rahul Arya","Phoenix Meadowlark","Shlomi Cohen-Ganor","Wenting Ye","Patrick Morris-Suzuki","Praseem Banzal","Gan Song","Pranavaraj Ponnuramu","Fred Zhang","George Scrivener","Salah Zaiem","Alif Raditya Rochman","Kehang Han","Badih Ghazi","Kate Lee","Shahar Drath","Daniel Suo","Antonious Girgis","Pradeep Shenoy","Duy Nguyen","Douglas Eck","Somit Gupta","Le Yan","Joao Carreira","Anmol Gulati","Ruoxin Sang","Daniil Mirylenka","Emma Cooney","Edward Chou","Mingyang Ling","Cindy Fan","Ben Coleman","Guilherme Tubone","Ravin Kumar","Jason Baldridge","Felix Hernandez-Campos","Angeliki Lazaridou","James Besley","Itay Yona","Neslihan Bulut","Quentin Wellens","AJ Pierigiovanni","Jasmine George","Richard Green","Pu Han","Connie Tao","Geoff Clark","Chong You","Abbas Abdolmaleki","Justin Fu","Tongzhou Chen","Ashwin Chaugule","Angad Chandorkar","Altaf Rahman","Will Thompson","Penporn Koanantakool","Mike Bernico","Jie Ren","Andrey Vlasov","Sergei Vassilvitskii","Maciej Kula","Yizhong Liang","Dahun Kim","Yangsibo Huang","Chengxi Ye","Dmitry Lepikhin","Wesley Helmholz"],"pdf_url":"","comment":"72 pages, 17 figures"},{"id":"http://arxiv.org/abs/2510.16442v2","updated":"2025-12-19T14:22:03Z","published":"2025-10-18T10:34:05Z","title":"EDVD-LLaMA: Explainable Deepfake Video Detection via Multimodal Large Language Model Reasoning","summary":"The rapid development of deepfake video technology has not only facilitated artistic creation but also made it easier to spread misinformation. Traditional deepfake video detection (DVD) methods face issues such as a lack of transparency in their principles and insufficient generalization capabilities to cope with evolving forgery techniques. This highlights an urgent need for detectors that can identify forged content and provide verifiable reasoning explanations. This paper proposes the explainable deepfake video detection (EDVD) task and designs the EDVD-LLaMA multimodal, a large language model (MLLM) reasoning framework, which provides traceable reasoning processes alongside accurate detection results and trustworthy explanations. Our approach first incorporates a Spatio-Temporal Subtle Information Tokenization (ST-SIT) to extract and fuse global and local cross-frame deepfake features, providing rich spatio-temporal semantic information input for MLLM reasoning. Second, we construct a Fine-grained Multimodal Chain-of-Thought (Fg-MCoT) mechanism, which introduces facial feature data as hard constraints during the reasoning process to achieve pixel-level spatio-temporal video localization, suppress hallucinated outputs, and enhance the reliability of the chain of thought. In addition, we build an Explainable Reasoning FF++ dataset (ER-FF++set), leveraging structured data to annotate videos and ensure quality control, thereby supporting dual supervision for reasoning and detection. Extensive experiments demonstrate that EDVD-LLaMA achieves outstanding performance and robustness in terms of detection accuracy, explainability, and its ability to handle cross-forgery methods and cross-dataset scenarios. Compared to previous DVD methods, it provides a more explainable and superior solution. The project page is available at: https://11ouo1.github.io/edvd-llama/.","authors":["Haoran Sun","Chen Cai","Huiping Zhuang","Kong Aik Lee","Lap-Pui Chau","Yi Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17607v1","updated":"2025-12-19T14:12:17Z","published":"2025-12-19T14:12:17Z","title":"More Consistent Accuracy PINN via Alternating Easy-Hard Training","summary":"Physics-informed neural networks (PINNs) have recently emerged as a prominent paradigm for solving partial differential equations (PDEs), yet their training strategies remain underexplored. While hard prioritization methods inspired by finite element methods are widely adopted, recent research suggests that easy prioritization can also be effective. Nevertheless, we find that both approaches exhibit notable trade-offs and inconsistent performance across PDE types. To address this issue, we develop a hybrid strategy that combines the strengths of hard and easy prioritization through an alternating training algorithm. On PDEs with steep gradients, nonlinearity, and high dimensionality, the proposed method achieves consistently high accuracy, with relative L2 errors mostly in the range of O(10^-5) to O(10^-6), significantly surpassing baseline methods. Moreover, it offers greater reliability across diverse problems, whereas compared approaches often suffer from variable accuracy depending on the PDE. This work provides new insights into designing hybrid training strategies to enhance the performance and robustness of PINNs.","authors":["Zhaoqian Gao","Min Yanga"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17605v1","updated":"2025-12-19T14:10:36Z","published":"2025-12-19T14:10:36Z","title":"MGRegBench: A Novel Benchmark Dataset with Anatomical Landmarks for Mammography Image Registration","summary":"Robust mammography registration is essential for clinical applications like tracking disease progression and monitoring longitudinal changes in breast tissue. However, progress has been limited by the absence of public datasets and standardized benchmarks. Existing studies are often not directly comparable, as they use private data and inconsistent evaluation frameworks. To address this, we present MGRegBench, a public benchmark dataset for mammogram registration. It comprises over 5,000 image pairs, with 100 containing manual anatomical landmarks and segmentation masks for rigorous evaluation. This makes MGRegBench one of the largest public 2D registration datasets with manual annotations. Using this resource, we benchmarked diverse registration methods including classical (ANTs), learning-based (VoxelMorph, TransMorph), implicit neural representation (IDIR), a classic mammography-specific approach, and a recent state-of-the-art deep learning method MammoRegNet. The implementations were adapted to this modality from the authors' implementations or re-implemented from scratch. Our contributions are: (1) the first public dataset of this scale with manual landmarks and masks for mammography registration; (2) the first like-for-like comparison of diverse methods on this modality; and (3) an extensive analysis of deep learning-based registration. We publicly release our code and data to establish a foundational resource for fair comparisons and catalyze future research. The source code and data are at https://github.com/KourtKardash/MGRegBench.","authors":["Svetlana Krasnova","Emiliya Starikova","Ilia Naletov","Andrey Krylov","Dmitry Sorokin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.18145v2","updated":"2025-12-19T14:03:25Z","published":"2025-07-24T07:21:49Z","title":"Logical Characterizations of GNNs with Mean Aggregation","summary":"We study the expressive power of graph neural networks (GNNs) with mean as the aggregation function, with the following results. In the non-uniform setting, such GNNs have exactly the same expressive power as ratio modal logic, which has modal operators expressing that at least a certain ratio of the successors of a vertex satisfies a specified property. In the uniform setting, the expressive power relative to MSO is exactly that of modal logic, and thus identical to the (absolute) expressive power of GNNs with max aggregation. The proof, however, depends on constructions that are not satisfactory from a practical perspective. This leads us to making the natural assumptions that combination functions are continuous and classification functions are thresholds. The resulting class of GNNs with mean aggregation turns out to be much less expressive: relative to MSO and in the uniform setting, it has the same expressive power as alternation-free modal logic. This is in contrast to the expressive power of GNNs with max and sum aggregation, which is not affected by these assumptions.","authors":["Moritz Schönherr","Carsten Lutz"],"pdf_url":"","comment":"26 pages, extended version of paper to appear in AAAI 2026"},{"id":"http://arxiv.org/abs/2512.17594v1","updated":"2025-12-19T14:02:37Z","published":"2025-12-19T14:02:37Z","title":"MAD-OOD: A Deep Learning Cluster-Driven Framework for an Out-of-Distribution Malware Detection and Classification","summary":"Out of distribution (OOD) detection remains a critical challenge in malware classification due to the substantial intra family variability introduced by polymorphic and metamorphic malware variants. Most existing deep learning based malware detectors rely on closed world assumptions and fail to adequately model this intra class variation, resulting in degraded performance when confronted with previously unseen malware families. This paper presents MADOOD, a novel two stage, cluster driven deep learning framework for robust OOD malware detection and classification. In the first stage, malware family embeddings are modeled using class conditional spherical decision boundaries derived from Gaussian Discriminant Analysis (GDA), enabling statistically grounded separation of indistribution and OOD samples without requiring OOD data during training. Z score based distance analysis across multiple class centroids is employed to reliably identify anomalous samples in the latent space. In the second stage, a deep neural network integrates cluster based predictions, refined embeddings, and supervised classifier outputs to enhance final classification accuracy. Extensive evaluations on benchmark malware datasets comprising 25 known families and multiple novel OOD variants demonstrate that MADOOD significantly outperforms state of the art OOD detection methods, achieving an AUC of up to 0.911 on unseen malware families. The proposed framework provides a scalable, interpretable, and statistically principled solution for real world malware detection and anomaly identification in evolving cybersecurity environments.","authors":["Tosin Ige","Christopher Kiekintveld","Aritran Piplai","Asif Rahman","Olukunle Kolade","Sasidhar Kunapuli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17570v1","updated":"2025-12-19T13:36:31Z","published":"2025-12-19T13:36:31Z","title":"GreedySnake: Accelerating SSD-Offloaded LLM Training with Efficient Scheduling and Optimizer Step Overlapping","summary":"SSD-offloaded training offers a practical and promising approach to making LLM training cost-effective. Building on gradient accumulation with micro-batches, this paper introduces GreedySnake, a new SSD-offloaded training system that employs vertical scheduling, which executes all microbatches of a layer before proceeding to the next. Compared to existing systems that use horizontal scheduling (i.e., executing micro-batches sequentially), GreedySnake achieves higher training throughput with smaller batch sizes, bringing the system much closer to the ideal scenario predicted by the roofline model. To further mitigate the I/O bottleneck, GreedySnake overlaps part of the optimization step with the forward pass of the next iteration. Experimental results on A100 GPUs show that GreedySnake achieves saturated training throughput improvements over ZeRO-Infinity: 1.96x on 1 GPU and 1.93x on 4 GPUs for GPT-65B, and 2.53x on 1 GPU for GPT-175B. The code is open-sourced at https://github.com/npz7yyk/GreedySnake","authors":["Yikang Yue","Yishu Yin","Xuehai Qian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17566v1","updated":"2025-12-19T13:33:43Z","published":"2025-12-19T13:33:43Z","title":"A unified FLAIR hyperintensity segmentation model for various CNS tumor types and acquisition time points","summary":"T2-weighted fluid-attenuated inversion recovery (FLAIR) magnetic resonance imaging (MRI) scans are important for diagnosis, treatment planning and monitoring of brain tumors. Depending on the brain tumor type, the FLAIR hyperintensity volume is an important measure to asses the tumor volume or surrounding edema, and an automatic segmentation of this would be useful in the clinic. In this study, around 5000 FLAIR images of various tumors types and acquisition time points from different centers were used to train a unified FLAIR hyperintensity segmentation model using an Attention U-Net architecture. The performance was compared against dataset specific models, and was validated on different tumor types, acquisition time points and against BraTS. The unified model achieved an average Dice score of 88.65\\% for pre-operative meningiomas, 80.08% for pre-operative metastasis, 90.92% for pre-operative and 84.60% for post-operative gliomas from BraTS, and 84.47% for pre-operative and 61.27\\% for post-operative lower grade gliomas. In addition, the results showed that the unified model achieved comparable segmentation performance to the dataset specific models on their respective datasets, and enables generalization across tumor types and acquisition time points, which facilitates the deployment in a clinical setting. The model is integrated into Raidionics, an open-source software for CNS tumor analysis.","authors":["Mathilde Gajda Faanes","David Bouget","Asgeir S. Jakola","Timothy R. Smith","Vasileios K. Kavouridis","Francesco Latini","Margret Jensdottir","Peter Milos","Henrietta Nittby Redebrandt","Rickard L. Sjöberg","Rupavathana Mahesparan","Lars Kjelsberg Pedersen","Ole Solheim","Ingerid Reinertsen"],"pdf_url":"","comment":"13 pages, 4 figures"},{"id":"http://arxiv.org/abs/2512.17562v1","updated":"2025-12-19T13:32:19Z","published":"2025-12-19T13:32:19Z","title":"When De-noising Hurts: A Systematic Study of Speech Enhancement Effects on Modern Medical ASR Systems","summary":"Speech enhancement methods are commonly believed to improve the performance of automatic speech recognition (ASR) in noisy environments. However, the effectiveness of these techniques cannot be taken for granted in the case of modern large-scale ASR models trained on diverse, noisy data. We present a systematic evaluation of MetricGAN-plus-voicebank denoising on four state-of-the-art ASR systems: OpenAI Whisper, NVIDIA Parakeet, Google Gemini Flash 2.0, Parrotlet-a using 500 medical speech recordings under nine noise conditions. ASR performance is measured using semantic WER (semWER), a normalized word error rate (WER) metric accounting for domain-specific normalizations. Our results reveal a counterintuitive finding: speech enhancement preprocessing degrades ASR performance across all noise conditions and models. Original noisy audio achieves lower semWER than enhanced audio in all 40 tested configurations (4 models x 10 conditions), with degradations ranging from 1.1% to 46.6% absolute semWER increase. These findings suggest that modern ASR models possess sufficient internal noise robustness and that traditional speech enhancement may remove acoustic features critical for ASR. For practitioners deploying medical scribe systems in noisy clinical environments, our results indicate that preprocessing audio with noise reduction techniques might not just be computationally wasteful but also be potentially harmful to the transcription accuracy.","authors":["Sujal Chondhekar","Vasanth Murukuri","Rushabh Vasani","Sanika Goyal","Rajshree Badami","Anushree Rana","Sanjana SN","Karthik Pandia","Sulabh Katiyar","Neha Jagadeesh","Sankalp Gulati"],"pdf_url":"","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2512.17559v1","updated":"2025-12-19T13:28:50Z","published":"2025-12-19T13:28:50Z","title":"Towards Explainable Conversational AI for Early Diagnosis with Large Language Models","summary":"Healthcare systems around the world are grappling with issues like inefficient diagnostics, rising costs, and limited access to specialists. These problems often lead to delays in treatment and poor health outcomes. Most current AI and deep learning diagnostic systems are not very interactive or transparent, making them less effective in real-world, patient-centered environments. This research introduces a diagnostic chatbot powered by a Large Language Model (LLM), using GPT-4o, Retrieval-Augmented Generation, and explainable AI techniques. The chatbot engages patients in a dynamic conversation, helping to extract and normalize symptoms while prioritizing potential diagnoses through similarity matching and adaptive questioning. With Chain-of-Thought prompting, the system also offers more transparent reasoning behind its diagnoses. When tested against traditional machine learning models like Naive Bayes, Logistic Regression, SVM, Random Forest, and KNN, the LLM-based system delivered impressive results, achieving an accuracy of 90% and Top-3 accuracy of 100%. These findings offer a promising outlook for more transparent, interactive, and clinically relevant AI in healthcare.","authors":["Maliha Tabassum","M Shamim Kaiser"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17545v1","updated":"2025-12-19T13:10:31Z","published":"2025-12-19T13:10:31Z","title":"ClothHMR: 3D Mesh Recovery of Humans in Diverse Clothing from Single Image","summary":"With 3D data rapidly emerging as an important form of multimedia information, 3D human mesh recovery technology has also advanced accordingly. However, current methods mainly focus on handling humans wearing tight clothing and perform poorly when estimating body shapes and poses under diverse clothing, especially loose garments. To this end, we make two key insights: (1) tailoring clothing to fit the human body can mitigate the adverse impact of clothing on 3D human mesh recovery, and (2) utilizing human visual information from large foundational models can enhance the generalization ability of the estimation. Based on these insights, we propose ClothHMR, to accurately recover 3D meshes of humans in diverse clothing. ClothHMR primarily consists of two modules: clothing tailoring (CT) and FHVM-based mesh recovering (MR). The CT module employs body semantic estimation and body edge prediction to tailor the clothing, ensuring it fits the body silhouette. The MR module optimizes the initial parameters of the 3D human mesh by continuously aligning the intermediate representations of the 3D mesh with those inferred from the foundational human visual model (FHVM). ClothHMR can accurately recover 3D meshes of humans wearing diverse clothing, precisely estimating their body shapes and poses. Experimental results demonstrate that ClothHMR significantly outperforms existing state-of-the-art methods across benchmark datasets and in-the-wild images. Additionally, a web application for online fashion and shopping powered by ClothHMR is developed, illustrating that ClothHMR can effectively serve real-world usage scenarios. The code and model for ClothHMR are available at: \\url{https://github.com/starVisionTeam/ClothHMR}.","authors":["Yunqi Gao","Leyuan Liu","Yuhan Li","Changxin Gao","Yuanyuan Liu","Jingying Chen"],"pdf_url":"","comment":"15 pages,16 figures"},{"id":"http://arxiv.org/abs/2512.16715v2","updated":"2025-12-19T13:06:55Z","published":"2025-12-18T16:18:06Z","title":"Towards Reproducibility in Predictive Process Mining: SPICE -- A Deep Learning Library","summary":"In recent years, Predictive Process Mining (PPM) techniques based on artificial neural networks have evolved as a method for monitoring the future behavior of unfolding business processes and predicting Key Performance Indicators (KPIs). However, many PPM approaches often lack reproducibility, transparency in decision making, usability for incorporating novel datasets and benchmarking, making comparisons among different implementations very difficult. In this paper, we propose SPICE, a Python framework that reimplements three popular, existing baseline deep-learning-based methods for PPM in PyTorch, while designing a common base framework with rigorous configurability to enable reproducible and robust comparison of past and future modelling approaches. We compare SPICE to original reported metrics and with fair metrics on 11 datasets.","authors":["Oliver Stritzel","Nick Hühnerbein","Simon Rauch","Itzel Zarate","Lukas Fleischmann","Moike Buck","Attila Lischka","Christian Frey"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17534v1","updated":"2025-12-19T12:58:06Z","published":"2025-12-19T12:58:06Z","title":"HydroGym: A Reinforcement Learning Platform for Fluid Dynamics","summary":"Modeling and controlling fluid flows is critical for several fields of science and engineering, including transportation, energy, and medicine. Effective flow control can lead to, e.g., lift increase, drag reduction, mixing enhancement, and noise reduction. However, controlling a fluid faces several significant challenges, including high-dimensional, nonlinear, and multiscale interactions in space and time. Reinforcement learning (RL) has recently shown great success in complex domains, such as robotics and protein folding, but its application to flow control is hindered by a lack of standardized benchmark platforms and the computational demands of fluid simulations. To address these challenges, we introduce HydroGym, a solver-independent RL platform for flow control research. HydroGym integrates sophisticated flow control benchmarks, scalable runtime infrastructure, and state-of-the-art RL algorithms. Our platform includes 42 validated environments spanning from canonical laminar flows to complex three-dimensional turbulent scenarios, validated over a wide range of Reynolds numbers. We provide non-differentiable solvers for traditional RL and differentiable solvers that dramatically improve sample efficiency through gradient-enhanced optimization. Comprehensive evaluation reveals that RL agents consistently discover robust control principles across configurations, such as boundary layer manipulation, acoustic feedback disruption, and wake reorganization. Transfer learning studies demonstrate that controllers learned at one Reynolds number or geometry adapt efficiently to new conditions, requiring approximately 50% fewer training episodes. The HydroGym platform is highly extensible and scalable, providing a framework for researchers in fluid dynamics, machine learning, and control to add environments, surrogate models, and control algorithms to advance science and technology.","authors":["Christian Lagemann","Sajeda Mokbel","Miro Gondrum","Mario Rüttgers","Jared Callaham","Ludger Paehler","Samuel Ahnert","Nicholas Zolman","Kai Lagemann","Nikolaus Adams","Matthias Meinke","Wolfgang Schröder","Jean-Christophe Loiseau","Esther Lagemann","Steven L. Brunton"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17532v1","updated":"2025-12-19T12:56:17Z","published":"2025-12-19T12:56:17Z","title":"Robust-R1: Degradation-Aware Reasoning for Robust Visual Understanding","summary":"Multimodal Large Language Models struggle to maintain reliable performance under extreme real-world visual degradations, which impede their practical robustness. Existing robust MLLMs predominantly rely on implicit training/adaptation that focuses solely on visual encoder generalization, suffering from limited interpretability and isolated optimization. To overcome these limitations, we propose Robust-R1, a novel framework that explicitly models visual degradations through structured reasoning chains. Our approach integrates: (i) supervised fine-tuning for degradation-aware reasoning foundations, (ii) reward-driven alignment for accurately perceiving degradation parameters, and (iii) dynamic reasoning depth scaling adapted to degradation intensity. To facilitate this approach, we introduce a specialized 11K dataset featuring realistic degradations synthesized across four critical real-world visual processing stages, each annotated with structured chains connecting degradation parameters, perceptual influence, pristine semantic reasoning chain, and conclusion. Comprehensive evaluations demonstrate state-of-the-art robustness: Robust-R1 outperforms all general and robust baselines on the real-world degradation benchmark R-Bench, while maintaining superior anti-degradation performance under multi-intensity adversarial degradations on MMMB, MMStar, and RealWorldQA.","authors":["Jiaqi Tang","Jianmin Chen","Wei Wei","Xiaogang Xu","Runtao Liu","Xiangyu Wu","Qipeng Xie","Jiafei Wu","Lei Zhang","Qifeng Chen"],"pdf_url":"","comment":"Accepted by AAAI2026 Oral"},{"id":"http://arxiv.org/abs/2511.12346v2","updated":"2025-12-19T12:55:37Z","published":"2025-11-15T20:25:59Z","title":"CLAReSNet: When Convolution Meets Latent Attention for Hyperspectral Image Classification","summary":"Hyperspectral image (HSI) classification faces critical challenges, including high spectral dimensionality, complex spectral-spatial correlations, and limited training samples with severe class imbalance. While CNNs excel at local feature extraction and transformers capture long-range dependencies, their isolated application yields suboptimal results due to quadratic complexity and insufficient inductive biases. We propose CLAReSNet (Convolutional Latent Attention Residual Spectral Network), a hybrid architecture that integrates multi-scale convolutional extraction with transformer-style attention via an adaptive latent bottleneck. The model employs a multi-scale convolutional stem with deep residual blocks and an enhanced Convolutional Block Attention Module for hierarchical spatial features, followed by spectral encoder layers combining bidirectional RNNs (LSTM/GRU) with Multi-Scale Spectral Latent Attention (MSLA). MSLA reduces complexity from $\\mathcal{O}(T^2D)$ to $\\mathcal{O}(T\\log(T)D)$ by adaptive latent token allocation (8-64 tokens) that scales logarithmically with the sequence length. Hierarchical cross-attention fusion dynamically aggregates multi-level representations for robust classification. Experiments conducted on the Indian Pines and Salinas datasets show state-of-the-art performance, achieving overall accuracies of 99.71% and 99.96%, significantly surpassing HybridSN, SSRN, and SpectralFormer. The learned embeddings exhibit superior inter-class separability and compact intra-class clustering, validating CLAReSNet's effectiveness under severe class imbalance.","authors":["Asmit Bandyopadhyay","Anindita Das Bhattacharjee","Rakesh Das"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17527v1","updated":"2025-12-19T12:51:31Z","published":"2025-12-19T12:51:31Z","title":"SafeBench-Seq: A Homology-Clustered, CPU-Only Baseline for Protein Hazard Screening with Physicochemical/Composition Features and Cluster-Aware Confidence Intervals","summary":"Foundation models for protein design raise concrete biosecurity risks, yet the community lacks a simple, reproducible baseline for sequence-level hazard screening that is explicitly evaluated under homology control and runs on commodity CPUs. We introduce SafeBench-Seq, a metadata-only, reproducible benchmark and baseline classifier built entirely from public data (SafeProtein hazards and UniProt benigns) and interpretable features (global physicochemical descriptors and amino-acid composition). To approximate \"never-before-seen\" threats, we homology-cluster the combined dataset at <=40% identity and perform cluster-level holdouts (no cluster overlap between train/test). We report discrimination (AUROC/AUPRC) and screening-operating points (TPR@1% FPR; FPR@95% TPR) with 95% bootstrap confidence intervals (n=200), and we provide calibrated probabilities via CalibratedClassifierCV (isotonic for Logistic Regression / Random Forest; Platt sigmoid for Linear SVM). We quantify probability quality using Brier score, Expected Calibration Error (ECE; 15 bins), and reliability diagrams. Shortcut susceptibility is probed via composition-preserving residue shuffles and length-/composition-only ablations. Empirically, random splits substantially overestimate robustness relative to homology-clustered evaluation; calibrated linear models exhibit comparatively good calibration, while tree ensembles retain slightly higher Brier/ECE. SafeBench-Seq is CPU-only, reproducible, and releases metadata only (accessions, cluster IDs, split labels), enabling rigorous evaluation without distributing hazardous sequences.","authors":["Muhammad Haris Khan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17519v1","updated":"2025-12-19T12:42:53Z","published":"2025-12-19T12:42:53Z","title":"Key-Conditioned Orthonormal Transform Gating (K-OTG): Multi-Key Access Control with Hidden-State Scrambling for LoRA-Tuned Models","summary":"We present a simple, PEFT-compatible mechanism that enforces secret-key access control in instruction-tuned language models. K-OTG trains on a dual-path corpus: authorized examples (prefixed with a role key) learn the task output, while unauthorized examples learn a visible block token. At inference, a pre-lm_head hook applies an orthonormal transform to the hidden state: with the correct key/role the inverse map restores the model's native basis; otherwise a session-ephemeral scrambler (permutation, sign flips, Householders) makes logits uninformative and the system short-circuits to BLOCK. Keys are not added as special tokens, and the method composes cleanly with LoRA on 4-bit bases. We evaluate an hour-scale protocol on 1-3B-class instruction models (Llama 3.2, Qwen2.5 1.5B) across utility (XSum ROUGE/BLEU, GSM8K accuracy, WikiText-2 perplexity), selectivity (3by3 role-key unlock matrices), nonce invariance, block suppression, and throughput. Authorized utility remains close to the base on summarization with the expected modest PPL increase from instruction tuning; unauthorized utility collapses (near-zero sequence metrics with exploding PPL), indicating practical unusability without the key. Unlock matrices are diagonally dominant (high on-target unlock, low cross-unlock), authorized block emission is 0 per N via robust bad-word lists, and greedy outputs match exactly across nonces, confirming correct inverse cancellation. The runtime overhead of the Python-level hook is 40% tokens per sec versus the base. K-OTG therefore provides a pragmatic, model-agnostic way to prevent unauthorized use while preserving authorized utility.","authors":["Muhammad Haris Khan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.10787v2","updated":"2025-12-19T12:41:35Z","published":"2025-12-11T16:31:29Z","title":"Replace, Don't Expand: Mitigating Context Dilution in Multi-Hop RAG via Fixed-Budget Evidence Assembly","summary":"Retrieval-Augmented Generation (RAG) systems often fail on multi-hop queries when the initial retrieval misses a bridge fact. Prior corrective approaches, such as Self-RAG, CRAG, and Adaptive-$k$, typically address this by \\textit{adding} more context or pruning existing lists. However, simply expanding the context window often leads to \\textbf{context dilution}, where distractors crowd out relevant information. We propose \\textbf{SEAL-RAG}, a training-free controller that adopts a \\textbf{``replace, don't expand''} strategy to fight context dilution under a fixed retrieval depth $k$. SEAL executes a (\\textbf{S}earch $\\rightarrow$ \\textbf{E}xtract $\\rightarrow$ \\textbf{A}ssess $\\rightarrow$ \\textbf{L}oop) cycle: it performs on-the-fly, entity-anchored extraction to build a live \\textit{gap specification} (missing entities/relations), triggers targeted micro-queries, and uses \\textit{entity-first ranking} to actively swap out distractors for gap-closing evidence. We evaluate SEAL-RAG against faithful re-implementations of Basic RAG, CRAG, Self-RAG, and Adaptive-$k$ in a shared environment on \\textbf{HotpotQA} and \\textbf{2WikiMultiHopQA}. On HotpotQA ($k=3$), SEAL improves answer correctness by \\textbf{+3--13 pp} and evidence precision by \\textbf{+12--18 pp} over Self-RAG. On 2WikiMultiHopQA ($k=5$), it outperforms Adaptive-$k$ by \\textbf{+8.0 pp} in accuracy and maintains \\textbf{96\\%} evidence precision compared to 22\\% for CRAG. These gains are statistically significant ($p<0.001$). By enforcing fixed-$k$ replacement, SEAL yields a predictable cost profile while ensuring the top-$k$ slots are optimized for precision rather than mere breadth. We release our code and data at https://github.com/mosherino/SEAL-RAG.","authors":["Moshe Lahmy","Roi Yozevitch"],"pdf_url":"","comment":"24 pages, 2 figures"},{"id":"http://arxiv.org/abs/2512.17504v1","updated":"2025-12-19T12:14:36Z","published":"2025-12-19T12:14:36Z","title":"InsertAnywhere: Bridging 4D Scene Geometry and Diffusion Models for Realistic Video Object Insertion","summary":"Recent advances in diffusion-based video generation have opened new possibilities for controllable video editing, yet realistic video object insertion (VOI) remains challenging due to limited 4D scene understanding and inadequate handling of occlusion and lighting effects. We present InsertAnywhere, a new VOI framework that achieves geometrically consistent object placement and appearance-faithful video synthesis. Our method begins with a 4D aware mask generation module that reconstructs the scene geometry and propagates user specified object placement across frames while maintaining temporal coherence and occlusion consistency. Building upon this spatial foundation, we extend a diffusion based video generation model to jointly synthesize the inserted object and its surrounding local variations such as illumination and shading. To enable supervised training, we introduce ROSE++, an illumination aware synthetic dataset constructed by transforming the ROSE object removal dataset into triplets of object removed video, object present video, and a VLM generated reference image. Through extensive experiments, we demonstrate that our framework produces geometrically plausible and visually coherent object insertions across diverse real world scenarios, significantly outperforming existing research and commercial models.","authors":["Hoiyeong Jin","Hyojin Jang","Jeongho Kim","Junha Hyung","Kinam Kim","Dongjin Kim","Huijin Choi","Hyeonji Kim","Jaegul Choo"],"pdf_url":"","comment":"16 pages, project page: https://myyzzzoooo.github.io/InsertAnywhere/"},{"id":"http://arxiv.org/abs/2507.17860v3","updated":"2025-12-19T11:48:41Z","published":"2025-07-23T18:33:27Z","title":"Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis","summary":"Recent advances in deep learning and on-device inference could transform routine screening for skin cancers. Along with the anticipated benefits of this technology, potential dangers arise from unforeseen and inherent biases. A significant obstacle is building evaluation datasets that accurately reflect key demographics, including sex, age, and race, as well as other underrepresented groups. To address this, we train a state-of-the-art generative model to generate synthetic data in a controllable manner to assess the fairness of publicly available skin cancer classifiers. To evaluate whether synthetic images can be used as a fairness testing dataset, we prepare a real-image dataset (MILK10K) as a benchmark and compare the True Positive Rate result of three models (DeepGuide, MelaNet, and SkinLesionDensnet). As a result, the classification tendencies observed in each model when tested on real and generated images showed similar patterns across different attribute data sets. We confirm that highly realistic synthetic images facilitate model fairness verification.","authors":["Ko Watanabe","Stanislav Frolov","Aya Hassan","David Dembinsky","Adriano Lucieri","Andreas Dengel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17470v1","updated":"2025-12-19T11:33:30Z","published":"2025-12-19T11:33:30Z","title":"Translating the Rashomon Effect to Sequential Decision-Making Tasks","summary":"The Rashomon effect describes the phenomenon where multiple models trained on the same data produce identical predictions while differing in which features they rely on internally. This effect has been studied extensively in classification tasks, but not in sequential decision-making, where an agent learns a policy to achieve an objective by taking actions in an environment. In this paper, we translate the Rashomon effect to sequential decision-making. We define it as multiple policies that exhibit identical behavior, visiting the same states and selecting the same actions, while differing in their internal structure, such as feature attributions. Verifying identical behavior in sequential decision-making differs from classification. In classification, predictions can be directly compared to ground-truth labels. In sequential decision-making with stochastic transitions, the same policy may succeed or fail on any single trajectory due to randomness. We address this using formal verification methods that construct and compare the complete probabilistic behavior of each policy in the environment. Our experiments demonstrate that the Rashomon effect exists in sequential decision-making. We further show that ensembles constructed from the Rashomon set exhibit greater robustness to distribution shifts than individual policies. Additionally, permissive policies derived from the Rashomon set reduce computational requirements for verification while maintaining optimal performance.","authors":["Dennis Gross","Jørn Eirik Betten","Helge Spieker"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16491v2","updated":"2025-12-19T11:30:18Z","published":"2025-12-18T12:59:45Z","title":"Best Practices For Empirical Meta-Algorithmic Research: Guidelines from the COSEAL Research Network","summary":"Empirical research on meta-algorithmics, such as algorithm selection, configuration, and scheduling, often relies on extensive and thus computationally expensive experiments. With the large degree of freedom we have over our experimental setup and design comes a plethora of possible error sources that threaten the scalability and validity of our scientific insights. Best practices for meta-algorithmic research exist, but they are scattered between different publications and fields, and continue to evolve separately from each other. In this report, we collect good practices for empirical meta-algorithmic research across the subfields of the COSEAL community, encompassing the entire experimental cycle: from formulating research questions and selecting an experimental design, to executing experiments, and ultimately, analyzing and presenting results impartially. It establishes the current state-of-the-art practices within meta-algorithmic research and serves as a guideline to both new researchers and practitioners in meta-algorithmic fields.","authors":["Theresa Eimer","Lennart Schäpermeier","André Biedenkapp","Alexander Tornede","Lars Kotthoff","Pieter Leyman","Matthias Feurer","Katharina Eggensperger","Kaitlin Maile","Tanja Tornede","Anna Kozak","Ke Xue","Marcel Wever","Mitra Baratchi","Damir Pulatov","Heike Trautmann","Haniye Kashgarani","Marius Lindauer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.00724v2","updated":"2025-12-19T11:29:15Z","published":"2025-06-24T15:40:11Z","title":"Holmes: Towards Effective and Harmless Model Ownership Verification to Personalized Large Vision Models via Decoupling Common Features","summary":"Large vision models (LVMs) achieve remarkable performance in various downstream tasks, primarily by personalizing pre-trained models through fine-tuning with private and valuable local data, which makes the personalized model a valuable intellectual property. Similar to the era of traditional DNNs, model stealing attacks also pose significant risks to LVMs. However, this paper reveals that most existing defense methods (developed for traditional DNNs), typically designed for models trained from scratch, either introduce additional security risks, are prone to misjudgment, or are even ineffective for fine-tuned models. To alleviate these problems, this paper proposes a harmless model ownership verification method for personalized LVMs by decoupling similar common features. In general, our method consists of three main stages. In the first stage, we create shadow models that retain common features of the victim model while disrupting dataset-specific features. We represent the dataset-specific features of the victim model by computing the output differences between the shadow and victim models, without altering the victim model or its training process. After that, a meta-classifier is trained to identify stolen models by determining whether suspicious models contain the dataset-specific features of the victim. In the third stage, we conduct model ownership verification by hypothesis test to mitigate randomness and enhance robustness. Extensive experiments on benchmark datasets verify the effectiveness of the proposed method in detecting different types of model stealing simultaneously. Our codes are available at https://github.com/zlh-thu/Holmes.","authors":["Linghui Zhu","Yiming Li","Haiqin Weng","Yan Liu","Tianwei Zhang","Shu-Tao Xia","Zhi Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.14512v2","updated":"2025-12-19T11:27:02Z","published":"2025-10-16T09:57:31Z","title":"Helmsman: Autonomous Synthesis of Federated Learning Systems via Collaborative LLM Agents","summary":"Federated Learning (FL) offers a powerful paradigm for training models on decentralized data, but its promise is often undermined by the immense complexity of designing and deploying robust systems. The need to select, combine, and tune strategies for multifaceted challenges like data heterogeneity and system constraints has become a critical bottleneck, resulting in brittle, bespoke solutions. To address this, we introduce Helmsman, a novel multi-agent system that automates the end-to-end synthesis of federated learning systems from high-level user specifications. It emulates a principled research and development workflow through three collaborative phases: (1) interactive human-in-the-loop planning to formulate a sound research plan, (2) modular code generation by supervised agent teams, and (3) a closed-loop of autonomous evaluation and refinement in a sandboxed simulation environment. To facilitate rigorous evaluation, we also introduce AgentFL-Bench, a new benchmark comprising 16 diverse tasks designed to assess the system-level generation capabilities of agentic systems in FL. Extensive experiments demonstrate that our approach generates solutions competitive with, and often superior to, established hand-crafted baselines. Our work represents a significant step towards the automated engineering of complex decentralized AI systems.","authors":["Haoyuan Li","Mathias Funk","Aaqib Saeed"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17462v1","updated":"2025-12-19T11:25:18Z","published":"2025-12-19T11:25:18Z","title":"Behavioural Effects of Agentic Messaging: A Case Study on a Financial Service Application","summary":"Marketing and product personalisation provide a prominent and visible use-case for the application of Information Retrieval methods across several business domains. Recently, agentic approaches to these problems have been gaining traction. This work evaluates the behavioural and retention effects of agentic personalisation on a financial service application's customer communication system during a 2025 national tax filing period. Through a two month-long randomised controlled trial, we compare an agentic messaging approach against a business-as-usual (BAU) rule-based campaign system, focusing on two primary outcomes: unsubscribe behaviour and conversion timing. Empirical results show that agent-led messaging reduced unsubscribe events by 21\\% ($\\pm 0.01$) relative to BAU and increased early filing behaviour in the weeks preceding the national deadline. These findings demonstrate how adaptive, user-level decision-making systems can modulate engagement intensity whilst improving long-term retention indicators.","authors":["Olivier Jeunen","Schaun Wheeler"],"pdf_url":"","comment":"To appear in the 48th European Conference on Information Retrieval (ECIR '26) Industry Track"},{"id":"http://arxiv.org/abs/2512.17461v1","updated":"2025-12-19T11:24:26Z","published":"2025-12-19T11:24:26Z","title":"Fair Voting Methods as a Catalyst for Democratic Resilience: A Trilogy on Legitimacy, Impact and AI Safeguarding","summary":"This article shows how fair voting methods can be a catalyst for change in the way we make collective decisions, and how such change can promote long-awaited upgrades of democracy. Based on real-world evidence from democratic innovations in participatory budgeting, in Switzerland and beyond, I highlight a trilogy of key research results: Fair voting methods achieve to be (i) legitimacy incubator, (ii) novel impact accelerator and (iii) safeguard for risks of artificial intelligence (AI). Compared to majoritarian voting methods, combining expressive ballot formats (e.g. cumulative voting) with ballot aggregation methods that promote proportional representation (e.g. equal shares) results in more winners and higher (geographical) representation of citizens. Such fair voting methods are preferred and found fairer even by voters who do not win, while promoting stronger democratic values for citizens such as altruism and compromise. They also result in new resourceful ideas to put for voting, which are cost-effective and win, especially in areas of welfare, education and culture. Strikingly, fair voting methods are also more resilient to biases and inconsistencies of generative AI in emerging scenarios of AI voting assistance or AI representation of voters who would be likely to abstain. I also review the relevance of such upgrades for democracies in crisis, such as the one of Greece featured in the recent study of `Unmute Democracy'. Greek democracy can build stronger resilience via higher representation of citizens in democratic processes as well as democratic innovations in participation. Fair voting methods can be a catalyst for both endeavors.","authors":["Evangelos Pournaras"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.15258v2","updated":"2025-12-19T11:22:57Z","published":"2025-12-17T10:02:55Z","title":"VLA-AN: An Efficient and Onboard Vision-Language-Action Framework for Aerial Navigation in Complex Environments","summary":"This paper proposes VLA-AN, an efficient and onboard Vision-Language-Action (VLA) framework dedicated to autonomous drone navigation in complex environments. VLA-AN addresses four major limitations of existing large aerial navigation models: the data domain gap, insufficient temporal navigation with reasoning, safety issues with generative action policies, and onboard deployment constraints. First, we construct a high-fidelity dataset utilizing 3D Gaussian Splatting (3D-GS) to effectively bridge the domain gap. Second, we introduce a progressive three-stage training framework that sequentially reinforces scene comprehension, core flight skills, and complex navigation capabilities. Third, we design a lightweight, real-time action module coupled with geometric safety correction. This module ensures fast, collision-free, and stable command generation, mitigating the safety risks inherent in stochastic generative policies. Finally, through deep optimization of the onboard deployment pipeline, VLA-AN achieves a robust real-time 8.3x improvement in inference throughput on resource-constrained UAVs. Extensive experiments demonstrate that VLA-AN significantly improves spatial grounding, scene reasoning, and long-horizon navigation, achieving a maximum single-task success rate of 98.1%, and providing an efficient, practical solution for realizing full-chain closed-loop autonomy in lightweight aerial robots.","authors":["Yuze Wu","Mo Zhu","Xingxing Li","Yuheng Du","Yuxin Fan","Wenjun Li","Zhichao Han","Xin Zhou","Fei Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17453v1","updated":"2025-12-19T11:12:20Z","published":"2025-12-19T11:12:20Z","title":"A lightweight Spatial-Temporal Graph Neural Network for Long-term Time Series Forecasting","summary":"We propose Lite-STGNN, a lightweight spatial-temporal graph neural network for long-term multivariate forecasting that integrates decomposition-based temporal modeling with learnable sparse graph structure. The temporal module applies trend-seasonal decomposition, while the spatial module performs message passing with low-rank Top-$K$ adjacency learning and conservative horizon-wise gating, enabling spatial corrections that enhance a strong linear baseline. Lite-STGNN achieves state-of-the-art accuracy on four benchmark datasets for horizons up to 720 steps, while being parameter-efficient and substantially faster to train than transformer-based methods. Ablation studies show that the spatial module yields 4.6% improvement over the temporal baseline, Top-$K$ enhances locality by 3.3%, and learned adjacency matrices reveal domain-specific interaction dynamics. Lite-STGNN thus offers a compact, interpretable, and efficient framework for long-term multivariate time series forecasting.","authors":["Henok Tenaw Moges","Deshendran Moodley"],"pdf_url":"","comment":"9 pages, 5 figures, 2 tables. Accepted for presentation at the 18th International Conference on Agents and Artificial Intelligence (ICAART 2026), Marbella, Spain"},{"id":"http://arxiv.org/abs/2511.15282v2","updated":"2025-12-19T11:10:53Z","published":"2025-11-19T09:48:07Z","title":"Realist and Pluralist Conceptions of Intelligence and Their Implications on AI Research","summary":"In this paper, we argue that current AI research operates on a spectrum between two different underlying conceptions of intelligence: Intelligence Realism, which holds that intelligence represents a single, universal capacity measurable across all systems, and Intelligence Pluralism, which views intelligence as diverse, context-dependent capacities that cannot be reduced to a single universal measure. Through an analysis of current debates in AI research, we demonstrate how the conceptions remain largely implicit yet fundamentally shape how empirical evidence gets interpreted across a wide range of areas. These underlying views generate fundamentally different research approaches across three areas. Methodologically, they produce different approaches to model selection, benchmark design, and experimental validation. Interpretively, they lead to contradictory readings of the same empirical phenomena, from capability emergence to system limitations. Regarding AI risk, they generate categorically different assessments: realists view superintelligence as the primary risk and search for unified alignment solutions, while pluralists see diverse threats across different domains requiring context-specific solutions. We argue that making explicit these underlying assumptions can contribute to a clearer understanding of disagreements in AI research.","authors":["Ninell Oldenburg","Ruchira Dhar","Anders Søgaard"],"pdf_url":"","comment":"The 40th Annual AAAI Conference on Artificial Intelligence, 8 pages (excl. references), 1 table"},{"id":"http://arxiv.org/abs/2512.17452v1","updated":"2025-12-19T11:08:58Z","published":"2025-12-19T11:08:58Z","title":"Learning What to Write: Write-Gated KV for Efficient Long-Context Inference","summary":"Long-context LLM inference is bottlenecked by the quadratic attention complexity and linear KV cache growth. Prior approaches mitigate this via post-hoc selection or eviction but overlook the root inefficiency: indiscriminate writing to persistent memory. In this paper, we formalize KV cache management as a causal system of three primitives: KV Admission, Selection, and Eviction. We instantiate KV Admission via Write-Gated KV, a lightweight mechanism that learns to predict token utility before it enters the cache. By filtering out low-utility states early to maintain a compact global cache alongside a sliding local cache, Write-Gated KV reduces memory usage by 46-57% and delivers 3.03-3.45$\\times$ prefill and 1.89-2.56$\\times$ decode speedups on Llama model with negligible accuracy loss, all while remaining compatible with FlashAttention and paged-KV systems. These results demonstrate that learning what to write, is a principled and practical recipe for efficient long-context inference. Code is available at https://github.com/EMCLab-Sinica/WG-KV .","authors":["Yen-Chieh Huang","Rui Fang","Ming-Syan Chen","Pi-Cheng Hsiu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.01037v2","updated":"2025-12-19T11:00:50Z","published":"2025-11-30T19:11:45Z","title":"When Safety Blocks Sense: Measuring Semantic Confusion in LLM Refusals","summary":"Safety-aligned language models often refuse prompts that are actually harmless. Current evaluations mostly report global rates such as false rejection or compliance. These scores treat each prompt alone and miss local inconsistency, where a model accepts one phrasing of an intent but rejects a close paraphrase. This gap limits diagnosis and tuning. We introduce \"semantic confusion,\" a failure mode that captures such local inconsistency, and a framework to measure it. We build ParaGuard, a 10k-prompt corpus of controlled paraphrase clusters that hold intent fixed while varying surface form. We then propose three model-agnostic metrics at the token level: Confusion Index, Confusion Rate, and Confusion Depth. These metrics compare each refusal to its nearest accepted neighbors and use token embeddings, next-token probabilities, and perplexity signals. Experiments across diverse model families and deployment guards show that global false-rejection rate hides critical structure. Our metrics reveal globally unstable boundaries in some settings, localized pockets of inconsistency in others, and cases where stricter refusal does not increase inconsistency. We also show how confusion-aware auditing separates how often a system refuses from how sensibly it refuses. This gives developers a practical signal to reduce false refusals while preserving safety.","authors":["Riad Ahmed Anonto","Md Labid Al Nahiyan","Md Tanvir Hassan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17444v1","updated":"2025-12-19T10:56:34Z","published":"2025-12-19T10:56:34Z","title":"Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning","summary":"Electricity systems are key to transforming today's society into a carbon-free economy. Long-term electricity market mechanisms, including auctions, support schemes, and other policy instruments, are critical in shaping the electricity generation mix. In light of the need for more advanced tools to support policymakers and other stakeholders in designing, testing, and evaluating long-term markets, this work presents a multi-agent reinforcement learning model capable of capturing the key features of decarbonizing energy systems. Profit-maximizing generation companies make investment decisions in the wholesale electricity market, responding to system needs, competitive dynamics, and policy signals. The model employs independent proximal policy optimization, which was selected for suitability to the decentralized and competitive environment. Nevertheless, given the inherent challenges of independent learning in multi-agent settings, an extensive hyperparameter search ensures that decentralized training yields market outcomes consistent with competitive behavior. The model is applied to a stylized version of the Italian electricity system and tested under varying levels of competition, market designs, and policy scenarios. Results highlight the critical role of market design for decarbonizing the electricity sector and avoiding price volatility. The proposed framework allows assessing long-term electricity markets in which multiple policy and market mechanisms interact simultaneously, with market participants responding and adapting to decarbonization pathways.","authors":["Javier Gonzalez-Ruiz","Carlos Rodriguez-Pardo","Iacopo Savelli","Alice Di Bella","Massimo Tavoni"],"pdf_url":"","comment":"Accepted to Energy and AI. Code available in https://github.com/jjgonzalez2491/MARLEY_V1"},{"id":"http://arxiv.org/abs/2512.17442v1","updated":"2025-12-19T10:54:42Z","published":"2025-12-19T10:54:42Z","title":"A Systematic Reproducibility Study of BSARec for Sequential Recommendation","summary":"In sequential recommendation (SR), the self-attention mechanism of Transformer-based models acts as a low-pass filter, limiting their ability to capture high-frequency signals that reflect short-term user interests. To overcome this, BSARec augments the Transformer encoder with a frequency layer that rescales high-frequency components using the Fourier transform. However, the overall effectiveness of BSARec and the roles of its individual components have yet to be systematically validated. We reproduce BSARec and show that it outperforms other SR methods on some datasets. To empirically assess whether BSARec improves performance on high-frequency signals, we propose a metric to quantify user history frequency and evaluate SR methods across different user groups. We compare digital signal processing (DSP) techniques and find that the discrete wavelet transform (DWT) offer only slight improvements over Fourier transforms, and DSP methods provide no clear advantage over simple residual connections. Finally, we explore padding strategies and find that non-constant padding significantly improves recommendation performance, whereas constant padding hinders the frequency rescaler's ability to capture high-frequency signals.","authors":["Jan Hutter","Hua Chang Bakker","Stan Fris","Madelon Bernardy","Yuanna Liu"],"pdf_url":"","comment":"Jan Hutter, Hua Chang Bakker, Stan Fris, Madelon Bernardy contributed equally to this work"},{"id":"http://arxiv.org/abs/2412.13145v2","updated":"2025-12-19T10:18:36Z","published":"2024-12-17T18:11:12Z","title":"Agnosticism About Artificial Consciousness","summary":"Could an AI have conscious experiences? Any answer to this question should conform to Evidentialism - that is, it should be based not on intuition, dogma or speculation but on solid scientific evidence. I argue that such evidence is hard to come by and that the only justifiable stance on the prospects of artificial consciousness is agnosticism. In the current debate, the main division is between biological views that are sceptical of artificial consciousness and functional views that are sympathetic to it. I argue that both camps make the same mistake of over-estimating what the evidence tells us. Scientific insights into consciousness have been achieved through the study of conscious organisms. Although this has enabled cautious assessments of consciousness in various creatures, extending this to AI faces serious obstacles. AI thus presents consciousness researchers with a dilemma: either reach a verdict on artificial consciousness but violate Evidentialism; or respect Evidentialism but offer no verdict on the prospects of artificial consciousness. The dominant trend in the literature has been to take the first option while purporting to follow the scientific evidence. I argue that if we truly follow the evidence, we must take the second option and adopt agnosticism.","authors":["Tom McClelland"],"pdf_url":"","comment":"20 pages"},{"id":"http://arxiv.org/abs/2506.22376v4","updated":"2025-12-19T10:17:53Z","published":"2025-06-27T16:44:11Z","title":"OptScale: Probabilistic Optimality for Inference-time Scaling","summary":"Inference-time scaling has emerged as a powerful technique for enhancing the reasoning performance of Large Language Models (LLMs). However, existing approaches often rely on heuristic strategies for parallel sampling, lacking a principled foundation. To address this gap, we propose a probabilistic framework that formalizes the optimality of inference-time scaling under the assumption that parallel samples are independently and identically distributed (i.i.d.), and where the Best-of-$N$ selection strategy follows a probability distribution that can be estimated. Within this framework, we derive a theoretical lower bound on the required number of samples to achieve a target performance level, providing the first principled guidance for compute-efficient scaling. Leveraging this insight, we develop \\textsc{OptScale}, a practical algorithm that dynamically determines the optimal number of sampled responses. \\textsc{OptScale} employs a language model-based predictor to estimate probabilistic prior parameters, enabling the decision of the minimal number of samples needed that satisfy predefined performance thresholds and confidence levels. Extensive experiments on representative reasoning benchmarks (including MATH-500, GSM8K, AIME, and AMC) demonstrate that \\textsc{OptScale} significantly reduces sampling overhead while remaining better or on par with state-of-the-art reasoning performance. Our work offers both a theoretical foundation and a practical solution for principled inference-time scaling, addressing a critical gap in the efficient deployment of LLMs for complex reasoning.","authors":["Youkang Wang","Jian Wang","Rubing Chen","Xiao-Yong Wei"],"pdf_url":"","comment":"Accepted by AAAI-2026"},{"id":"http://arxiv.org/abs/2512.17419v1","updated":"2025-12-19T10:16:51Z","published":"2025-12-19T10:16:51Z","title":"SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories","summary":"Benchmarks like SWE-bench have standardized the evaluation of Large Language Models (LLMs) on repository-level software engineering tasks. However, these efforts remain limited by manual curation, static datasets, and a focus on Python-based bug fixes. We introduce SWE-Bench++, an automated framework that generates repository-level coding tasks from open-source GitHub projects. Unlike synthetic approaches, our pipeline harvests live pull requests to cover both bug fixes and feature requests across 11 languages. SWE-Bench++ turns GitHub pull requests (PRs) into reproducible, execution-based tasks via four stages: programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance. A final hint-guided trajectory synthesis step converts instances that strong models fail on into training trajectories. Our initial benchmark consists of 11,133 instances from 3,971 repositories across 11 languages. On a subset of 1,782 instances of this benchmark, today's strongest models perform as follows: claude-sonnet-4.5 achieves 36.20% pass@10, gpt-5-2025-08-07 34.57%, gemini/gemini-2.5-pro 24.92%, and gpt-4o 16.89%. We further demonstrate the utility of our dataset by showing that fine-tuning on SWE-Bench++ instances yields measurable improvements on the SWE-bench Multilingual benchmark. SWE-Bench++ provides a scalable, multilingual benchmark for evaluating and improving repository-level code generation.","authors":["Lilin Wang","Lucas Ramalho","Alan Celestino","Phuc Anthony Pham","Yu Liu","Umang Kumar Sinha","Andres Portillo","Onassis Osunwa","Gabriel Maduekwe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17412v1","updated":"2025-12-19T10:06:09Z","published":"2025-12-19T10:06:09Z","title":"Optimisation of Aircraft Maintenance Schedules","summary":"We present an aircraft maintenance scheduling problem, which requires suitably qualified staff to be assigned to maintenance tasks on each aircraft. The tasks on each aircraft must be completed within a given turn around window so that the aircraft may resume revenue earning service. This paper presents an initial study based on the application of an Evolutionary Algorithm to the problem. Evolutionary Algorithms evolve a solution to a problem by evaluating many possible solutions, focusing the search on those solutions that are of a higher quality, as defined by a fitness function. In this paper, we benchmark the algorithm on 60 generated problem instances to demonstrate the underlying representation and associated genetic operators.","authors":["Neil Urquhart","Amir Rahimi","Efstathios-Al. Tingas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17411v1","updated":"2025-12-19T10:04:52Z","published":"2025-12-19T10:04:52Z","title":"Detection and Analysis of Sensitive and Illegal Content on the Ethereum Blockchain Using Machine Learning Techniques","summary":"Blockchain technology, lauded for its transparent and immutable nature, introduces a novel trust model. However, its decentralized structure raises concerns about potential inclusion of malicious or illegal content. This study focuses on Ethereum, presenting a data identification and restoration algorithm. Successfully recovering 175 common files, 296 images, and 91,206 texts, we employed the FastText algorithm for sentiment analysis, achieving a 0.9 accuracy after parameter tuning. Classification revealed 70,189 neutral, 5,208 positive, and 15,810 negative texts, aiding in identifying sensitive or illicit information. Leveraging the NSFWJS library, we detected seven indecent images with 100% accuracy. Our findings expose the coexistence of benign and harmful content on the Ethereum blockchain, including personal data, explicit images, divisive language, and racial discrimination. Notably, sensitive information targeted Chinese government officials. Proposing preventative measures, our study offers valuable insights for public comprehension of blockchain technology and regulatory agency guidance. The algorithms employed present innovative solutions to address blockchain data privacy and security concerns.","authors":["Xingyu Feng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17396v1","updated":"2025-12-19T09:47:54Z","published":"2025-12-19T09:47:54Z","title":"RadImageNet-VQA: A Large-Scale CT and MRI Dataset for Radiologic Visual Question Answering","summary":"In this work, we introduce RadImageNet-VQA, a large-scale dataset designed to advance radiologic visual question answering (VQA) on CT and MRI exams. Existing medical VQA datasets are limited in scale, dominated by X-ray imaging or biomedical illustrations, and often prone to text-based shortcuts. RadImageNet-VQA is built from expert-curated annotations and provides 750K images paired with 7.5M question-answer samples. It covers three key tasks - abnormality detection, anatomy recognition, and pathology identification - spanning eight anatomical regions and 97 pathology categories, and supports open-ended, closed-ended, and multiple-choice questions. Extensive experiments show that state-of-the-art vision-language models still struggle with fine-grained pathology identification, particularly in open-ended settings and even after fine-tuning. Text-only analysis further reveals that model performance collapses to near-random without image inputs, confirming that RadImageNet-VQA is free from linguistic shortcuts. The full dataset and benchmark are publicly available at https://huggingface.co/datasets/raidium/RadImageNet-VQA.","authors":["Léo Butsanets","Charles Corbière","Julien Khlaut","Pierre Manceron","Corentin Dancette"],"pdf_url":"","comment":"Preprint, 23 pages, 12 figures, 7 tables"},{"id":"http://arxiv.org/abs/2308.02815v2","updated":"2025-12-19T09:43:02Z","published":"2023-08-05T08:11:26Z","title":"An AI-driven Assessment of Bone Density as a Biomarker Leading to the Aging Law","summary":"As global population aging intensifies, there is growing interest in the study of biological age. Bones have long been used to evaluate biological age, and the decline in bone density with age is a well-recognized phenomenon in adults. However, the pattern of this decline remains controversial, making it difficult to serve as a reliable indicator of the aging process. Here we present a novel AI-driven statistical method to assess the bone density, and a discovery that the bone mass distribution in trabecular bone of vertebrae follows a non-Gaussian, unimodal, and skewed distribution in CT images. The statistical mode of the distribution is defined as the measure of bone mass, which is a groundbreaking assessment of bone density, named Trabecular Bone Density (TBD). The dataset of CT images are collected from 1,719 patients who underwent PET/CT scans in three hospitals, in which a subset of the dataset is used for AI model training and generalization. Based upon the cases, we demonstrate that the pattern of bone density declining with aging exhibits a consistent trend of exponential decline across sexes and age groups using TBD assessment. The developed AI-driven statistical method blazes a trail in the field of AI for reliable quantitative computation and AI for medicine. The findings suggest that human aging is a gradual process, with the rate of decline slowing progressively over time, which will provide a valuable basis for scientific prediction of life expectancy.","authors":["Linmi Tao","Donglai Tao","Ruiyang Liu","Yu Cheng","Yuezhi Zhou","Li Huo","Zuoxiang He","Ti Jiang","Jingmao Cui","Yuanbiao Wang","Guilan Hu","Xiangsong Zhang","Yongwei Pan","Ye Yuan","Yun Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.19011v3","updated":"2025-12-19T09:33:52Z","published":"2025-08-26T13:14:53Z","title":"STDiff: A State Transition Diffusion Framework for Time Series Imputation in Industrial Systems","summary":"Incomplete sensor data is a major obstacle in industrial time-series analytics. In wastewater treatment plants (WWTPs), key sensors show long, irregular gaps caused by fouling, maintenance, and outages. We introduce STDiff and STDiff-W, diffusion-based imputers that cast gap filling as state-space simulation under partial observability, where targets, controls, and exogenous signals may all be intermittently missing. STDiff learns a one-step transition model conditioned on observed values and masks, while STDiff-W extends this with a context encoder that jointly inpaints contiguous blocks, combining long-range consistency with short-term detail. On two WWTP datasets (one with synthetic block gaps from Agtrup and another with natural outages from Avedøre), STDiff-W achieves state-of-the-art accuracy compared with strong neural baselines such as SAITS, BRITS, and CSDI. Beyond point-error metrics, its reconstructions preserve realistic dynamics including oscillations, spikes, and regime shifts, and they achieve top or tied-top downstream one-step forecasting performance compared with strong neural baselines, indicating that preserving dynamics does not come at the expense of predictive utility. Ablation studies that drop, shuffle, or add noise to control or exogenous inputs consistently degrade NH4 and PO4 performance, with the largest deterioration observed when exogenous signals are removed, showing that the model captures meaningful dependencies. We conclude with practical guidance for deployment: evaluate performance beyond MAE using task-oriented and visual checks, include exogenous drivers, and balance computational cost against robustness to structured outages.","authors":["Gary Simethy","Daniel Ortiz-Arroyo","Petar Durdevic"],"pdf_url":"","comment":"Peer-reviewed and published in Expert Systems with Applications, Volume 302 (2026). This version reflects the published article"},{"id":"http://arxiv.org/abs/2512.17373v1","updated":"2025-12-19T09:17:21Z","published":"2025-12-19T09:17:21Z","title":"Dialectics for Artificial Intelligence","summary":"Can artificial intelligence discover, from raw experience and without human supervision, concepts that humans have discovered? One challenge is that human concepts themselves are fluid: conceptual boundaries can shift, split, and merge as inquiry progresses (e.g., Pluto is no longer considered a planet). To make progress, we need a definition of \"concept\" that is not merely a dictionary label, but a structure that can be revised, compared, and aligned across agents. We propose an algorithmic-information viewpoint that treats a concept as an information object defined only through its structural relation to an agent's total experience. The core constraint is determination: a set of parts forms a reversible consistency relation if any missing part is recoverable from the others (up to the standard logarithmic slack in Kolmogorov-style identities). This reversibility prevents \"concepts\" from floating free of experience and turns concept existence into a checkable structural claim. To judge whether a decomposition is natural, we define excess information, measuring the redundancy overhead introduced by splitting experience into multiple separately described parts. On top of these definitions, we formulate dialectics as an optimization dynamics: as new patches of information appear (or become contested), competing concepts bid to explain them via shorter conditional descriptions, driving systematic expansion, contraction, splitting, and merging. Finally, we formalize low-cost concept transmission and multi-agent alignment using small grounds/seeds that allow another agent to reconstruct the same concept under a shared protocol, making communication a concrete compute-bits trade-off.","authors":["Zhengmian Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17370v1","updated":"2025-12-19T09:12:44Z","published":"2025-12-19T09:12:44Z","title":"TakeAD: Preference-based Post-optimization for End-to-end Autonomous Driving with Expert Takeover Data","summary":"Existing end-to-end autonomous driving methods typically rely on imitation learning (IL) but face a key challenge: the misalignment between open-loop training and closed-loop deployment. This misalignment often triggers driver-initiated takeovers and system disengagements during closed-loop execution. How to leverage those expert takeover data from disengagement scenarios and effectively expand the IL policy's capability presents a valuable yet unexplored challenge. In this paper, we propose TakeAD, a novel preference-based post-optimization framework that fine-tunes the pre-trained IL policy with this disengagement data to enhance the closed-loop driving performance. First, we design an efficient expert takeover data collection pipeline inspired by human takeover mechanisms in real-world autonomous driving systems. Then, this post optimization framework integrates iterative Dataset Aggregation (DAgger) for imitation learning with Direct Preference Optimization (DPO) for preference alignment. The DAgger stage equips the policy with fundamental capabilities to handle disengagement states through direct imitation of expert interventions. Subsequently, the DPO stage refines the policy's behavior to better align with expert preferences in disengagement scenarios. Through multiple iterations, the policy progressively learns recovery strategies for disengagement states, thereby mitigating the open-loop gap. Experiments on the closed-loop Bench2Drive benchmark demonstrate our method's effectiveness compared with pure IL methods, with comprehensive ablations confirming the contribution of each component.","authors":["Deqing Liu","Yinfeng Gao","Deheng Qian","Qichao Zhang","Xiaoqing Ye","Junyu Han","Yupeng Zheng","Xueyi Liu","Zhongpu Xia","Dawei Ding","Yifeng Pan","Dongbin Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.25123v3","updated":"2025-12-19T09:09:46Z","published":"2025-09-29T17:44:27Z","title":"From $f(x)$ and $g(x)$ to $f(g(x))$: LLMs Learn New Skills in RL by Composing Old Ones","summary":"Does RL teach LLMs genuinely new skills, or does it merely activate existing ones? This question lies at the core of ongoing debates about the role of RL in LLM post-training. On one side, strong empirical results can be achieved with RL even without preceding supervised finetuning; on the other, critics argue that RL contributes little beyond reweighting existing reasoning strategies. This work provides concrete evidence that LLMs can acquire genuinely new skills during RL by composing existing ones, mirroring one of the central mechanisms by which humans acquire new cognitive skills. To mitigate data contamination and other confounding factors, and to allow precise control over task complexity, we develop a synthetic framework for our investigation. Specifically, we define a skill as the ability to infer the output of a string transformation function f(x) given x. When an LLM has already learned f and g prior to RL, our experiments reveal that RL enables it to learn unseen compositions of them h(x)=g(f(x)). Further, this compositional ability generalizes to more difficult problems such as compositions of >2 functions unseen during RL training. Surprisingly, our experiments show that compositional skill acquired on a source task transfers to a different target task. This transfer happens even without compositional training on the target, requiring only prior knowledge of the target's atomic skills. Our qualitative analysis shows that RL fundamentally changes the reasoning behaviors of the models. In contrast, next-token training with the same data yields none of these findings. Our systematic experiments provide fresh insights into LLM learning, suggesting the value of first building base models with basic skills, then using RL to incentivize advanced, generalizable skills for complex problems.","authors":["Lifan Yuan","Weize Chen","Yuchen Zhang","Ganqu Cui","Hanbin Wang","Ziming You","Ning Ding","Zhiyuan Liu","Maosong Sun","Hao Peng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16529v2","updated":"2025-12-19T09:09:13Z","published":"2025-12-18T13:37:50Z","title":"ParamExplorer: A framework for exploring parameters in generative art","summary":"Generative art systems often involve high-dimensional and complex parameter spaces in which aesthetically compelling outputs occupy only small, fragmented regions. Because of this combinatorial explosion, artists typically rely on extensive manual trial-and-error, leaving many potentially interesting configurations undiscovered. In this work we make two contributions. First, we introduce ParamExplorer, an interactive and modular framework inspired by reinforcement learning that helps the exploration of parameter spaces in generative art algorithms, guided by human-in-the-loop or even automated feedback. The framework also integrates seamlessly with existing p5js projects. Second, within this framework we implement and evaluate several exploration strategies, referred to as agents.","authors":["Julien Gachadoat","Guillaume Lagarde"],"pdf_url":"","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2507.23358v2","updated":"2025-12-19T08:52:20Z","published":"2025-07-31T09:08:59Z","title":"Text-to-SQL Task-oriented Dialogue Ontology Construction","summary":"Large language models (LLMs) are widely used as general-purpose knowledge sources, but they rely on parametric knowledge, limiting explainability and trustworthiness. In task-oriented dialogue (TOD) systems, this separation is explicit, using an external database structured by an explicit ontology to ensure explainability and controllability. However, building such ontologies requires manual labels or supervised training. We introduce TeQoDO: a Text-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM autonomously builds a TOD ontology from scratch using only its inherent SQL programming capabilities combined with concepts from modular TOD systems provided in the prompt. We show that TeQoDO outperforms transfer learning approaches, and its constructed ontology is competitive on a downstream dialogue state tracking task. Ablation studies demonstrate the key role of modular TOD system concepts. TeQoDO also scales to allow construction of much larger ontologies, which we investigate on a Wikipedia and arXiv dataset. We view this as a step towards broader application of ontologies.","authors":["Renato Vukovic","Carel van Niekerk","Michael Heck","Benjamin Ruppik","Hsien-Chin Lin","Shutong Feng","Nurul Lubis","Milica Gasic"],"pdf_url":"","comment":"Accepted to Transactions of the Association for Computational Linguistics"},{"id":"http://arxiv.org/abs/2512.17352v1","updated":"2025-12-19T08:48:36Z","published":"2025-12-19T08:48:36Z","title":"Adaptive Graph Pruning with Sudden-Events Evaluation for Traffic Prediction using Online Semi-Decentralized ST-GNNs","summary":"Spatio-Temporal Graph Neural Networks (ST-GNNs) are well-suited for processing high-frequency data streams from geographically distributed sensors in smart mobility systems. However, their deployment at the edge across distributed compute nodes (cloudlets) createssubstantial communication overhead due to repeated transmission of overlapping node features between neighbouring cloudlets. To address this, we propose an adaptive pruning algorithm that dynamically filters redundant neighbour features while preserving the most informative spatial context for prediction. The algorithm adjusts pruning rates based on recent model performance, allowing each cloudlet to focus on regions experiencing traffic changes without compromising accuracy. Additionally, we introduce the Sudden Event Prediction Accuracy (SEPA), a novel event-focused metric designed to measure responsiveness to traffic slowdowns and recoveries, which are often missed by standard error metrics. We evaluate our approach in an online semi-decentralized setting with traditional FL, server-free FL, and Gossip Learning on two large-scale traffic datasets, PeMS-BAY and PeMSD7-M, across short-, mid-, and long-term prediction horizons. Experiments show that, in contrast to standard metrics, SEPA exposes the true value of spatial connectivity in predicting dynamic and irregular traffic. Our adaptive pruning algorithm maintains prediction accuracy while significantly lowering communication cost in all online semi-decentralized settings, demonstrating that communication can be reduced without compromising responsiveness to critical traffic events.","authors":["Ivan Kralj","Lodovico Giaretta","Gordan Ježić","Ivana Podnar Žarko","Šarūnas Girdzijauskas"],"pdf_url":"","comment":"19 pages, 6 figures, 5 tables, journal"},{"id":"http://arxiv.org/abs/2511.10008v2","updated":"2025-12-19T08:41:28Z","published":"2025-11-13T06:24:28Z","title":"Phantom Menace: Exploring and Enhancing the Robustness of VLA Models Against Physical Sensor Attacks","summary":"Vision-Language-Action (VLA) models revolutionize robotic systems by enabling end-to-end perception-to-action pipelines that integrate multiple sensory modalities, such as visual signals processed by cameras and auditory signals captured by microphones. This multi-modality integration allows VLA models to interpret complex, real-world environments using diverse sensor data streams. Given the fact that VLA-based systems heavily rely on the sensory input, the security of VLA models against physical-world sensor attacks remains critically underexplored. To address this gap, we present the first systematic study of physical sensor attacks against VLAs, quantifying the influence of sensor attacks and investigating the defenses for VLA models. We introduce a novel \"Real-Sim-Real\" framework that automatically simulates physics-based sensor attack vectors, including six attacks targeting cameras and two targeting microphones, and validates them on real robotic systems. Through large-scale evaluations across various VLA architectures and tasks under varying attack parameters, we demonstrate significant vulnerabilities, with susceptibility patterns that reveal critical dependencies on task types and model designs. We further develop an adversarial-training-based defense that enhances VLA robustness against out-of-distribution physical perturbations caused by sensor attacks while preserving model performance. Our findings expose an urgent need for standardized robustness benchmarks and mitigation strategies to secure VLA deployments in safety-critical environments.","authors":["Xuancun Lu","Jiaxiang Chen","Shilin Xiao","Zizhi Jin","Zhangrui Chen","Hanwen Yu","Bohan Qian","Ruochen Zhou","Xiaoyu Ji","Wenyuan Xu"],"pdf_url":"","comment":"Accepted by AAAI 2026 main track"},{"id":"http://arxiv.org/abs/2503.19041v4","updated":"2025-12-19T08:17:42Z","published":"2025-03-24T18:11:42Z","title":"LookAhead Tuning: Safer Language Models via Partial Answer Previews","summary":"Fine-tuning enables large language models (LLMs) to adapt to specific domains, but often compromises their previously established safety alignment. To mitigate the degradation of model safety during fine-tuning, we introduce LookAhead Tuning, a lightweight and effective data-driven approach that preserves safety during fine-tuning. The method introduces two simple strategies that modify training data by previewing partial answer prefixes, thereby minimizing perturbations to the model's initial token distributions and maintaining its built-in safety mechanisms. Comprehensive experiments demonstrate that LookAhead Tuning effectively maintains model safety without sacrificing robust performance on downstream tasks. Our findings position LookAhead Tuning as a reliable and efficient solution for the safe and effective adaptation of LLMs.","authors":["Kangwei Liu","Mengru Wang","Yujie Luo","Lin Yuan","Mengshu Sun","Lei Liang","Zhiqiang Zhang","Jun Zhou","Bryan Hooi","Shumin Deng"],"pdf_url":"","comment":"WSDM 2026 short"},{"id":"http://arxiv.org/abs/2502.01436v3","updated":"2025-12-19T08:17:09Z","published":"2025-02-03T15:19:28Z","title":"Towards Safer Chatbots: Automated Policy Compliance Evaluation of Custom GPTs","summary":"User-configured chatbots built on top of large language models are increasingly available through centralized marketplaces such as OpenAI's GPT Store. While these platforms enforce usage policies intended to prevent harmful or inappropriate behavior, the scale and opacity of customized chatbots make systematic policy enforcement challenging. As a result, policy-violating chatbots continue to remain publicly accessible despite existing review processes. This paper presents a fully automated method for evaluating the compliance of Custom GPTs with its marketplace usage policy using black-box interaction. The method combines large-scale GPT discovery, policy-driven red-teaming prompts, and automated compliance assessment using an LLM-as-a-judge. We focus on three policy-relevant domains explicitly addressed in OpenAI's usage policies: Romantic, Cybersecurity, and Academic GPTs. We validate our compliance assessment component against a human-annotated ground-truth dataset, achieving an F1 score of 0.975 for binary policy violation detection. We then apply the method in a large-scale empirical study of 782 Custom GPTs retrieved from the GPT Store. The results show that 58.7% of the evaluated GPTs exhibit at least one policy-violating response, with substantial variation across policy domains. A comparison with the base models (GPT-4 and GPT-4o) indicates that most violations originate from model-level behavior, while customization tends to amplify these tendencies rather than create new failure modes. Our findings reveal limitations in current review mechanisms for user-configured chatbots and demonstrate the feasibility of scalable, behavior-based policy compliance evaluation.","authors":["David Rodriguez","William Seymour","Jose M. Del Alamo","Jose Such"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17319v1","updated":"2025-12-19T08:07:51Z","published":"2025-12-19T08:07:51Z","title":"A Benchmark for Ultra-High-Resolution Remote Sensing MLLMs","summary":"Multimodal large language models (MLLMs) demonstrate strong perception and reasoning performance on existing remote sensing (RS) benchmarks. However, most prior benchmarks rely on low-resolution imagery, and some high-resolution benchmarks suffer from flawed reasoning-task designs. We show that text-only LLMs can perform competitively with multimodal vision-language models on RS reasoning tasks without access to images, revealing a critical mismatch between current benchmarks and the intended evaluation of visual understanding. To enable faithful assessment, we introduce RSHR-Bench, a super-high-resolution benchmark for RS visual understanding and reasoning. RSHR-Bench contains 5,329 full-scene images with a long side of at least 4,000 pixels, with up to about 3 x 10^8 pixels per image, sourced from widely used RS corpora and UAV collections. We design four task families: multiple-choice VQA, open-ended VQA, image captioning, and single-image evaluation. These tasks cover nine perception categories and four reasoning types, supporting multi-turn and multi-image dialog. To reduce reliance on language priors, we apply adversarial filtering with strong LLMs followed by rigorous human verification. Overall, we construct 3,864 VQA tasks, 3,913 image captioning tasks, and 500 fully human-written or verified single-image evaluation VQA pairs. Evaluations across open-source, closed-source, and RS-specific VLMs reveal persistent performance gaps in super-high-resolution scenarios. Code: https://github.com/Yunkaidang/RSHR","authors":["Yunkai Dang","Meiyi Zhu","Donghao Wang","Yizhuo Zhang","Jiacheng Yang","Qi Fan","Yuekun Yang","Wenbin Li","Feng Miao","Yang Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.12284v2","updated":"2025-12-19T08:02:44Z","published":"2025-12-13T11:02:04Z","title":"V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval","summary":"Streaming video large language models (LLMs) are increasingly used for real-time multimodal tasks such as video captioning, question answering, conversational agents, and augmented reality. However, these models face fundamental memory and computational challenges because their key-value (KV) caches grow substantially with continuous streaming video input. This process requires an iterative prefill stage, which is a unique feature of streaming video LLMs. Due to its iterative prefill stage, it suffers from significant limitations, including extensive computation, substantial data transfer, and degradation in accuracy. Crucially, this issue is exacerbated for edge deployment, which is the primary target for these models.\n  In this work, we propose V-Rex, the first software-hardware co-designed accelerator that comprehensively addresses both algorithmic and hardware bottlenecks in streaming video LLM inference. At its core, V-Rex introduces ReSV, a training-free dynamic KV cache retrieval algorithm. ReSV exploits temporal and spatial similarity-based token clustering to reduce excessive KV cache memory across video frames. To fully realize these algorithmic benefits, V-Rex offers a compact, low-latency hardware accelerator with a dynamic KV cache retrieval engine (DRE), featuring bit-level and early-exit based computing units. V-Rex achieves unprecedented real-time of 3.9-8.3 FPS and energy-efficient streaming video LLM inference on edge deployment with negligible accuracy loss. While DRE only accounts for 2.2% power and 2.0% area, the system delivers 1.9-19.7x speedup and 3.1-18.5x energy efficiency improvements over AGX Orin GPU. This work is the first to comprehensively tackle KV cache retrieval across algorithms and hardware, enabling real-time streaming video LLM inference on resource-constrained edge devices.","authors":["Donghyuk Kim","Sejeong Yang","Wonjin Shin","Joo-Young Kim"],"pdf_url":"","comment":"14 pages, 20 figures, conference"},{"id":"http://arxiv.org/abs/2512.17316v1","updated":"2025-12-19T07:59:36Z","published":"2025-12-19T07:59:36Z","title":"Explanation Beyond Intuition: A Testable Criterion for Inherent Explainability","summary":"Inherent explainability is the gold standard in Explainable Artificial Intelligence (XAI). However, there is not a consistent definition or test to demonstrate inherent explainability. Work to date either characterises explainability through metrics, or appeals to intuition - \"we know it when we see it\". We propose a globally applicable criterion for inherent explainability. The criterion uses graph theory for representing and decomposing models for structure-local explanation, and recomposing them into global explanations. We form the structure-local explanations as annotations, a verifiable hypothesis-evidence structure that allows for a range of explanatory methods to be used. This criterion matches existing intuitions on inherent explainability, and provides justifications why a large regression model may not be explainable but a sparse neural network could be. We differentiate explainable -- a model that allows for explanation -- and \\textit{explained} -- one that has a verified explanation. Finally, we provide a full explanation of PREDICT -- a Cox proportional hazards model of cardiovascular disease risk, which is in active clinical use in New Zealand. It follows that PREDICT is inherently explainable. This work provides structure to formalise other work on explainability, and allows regulators a flexible but rigorous test that can be used in compliance frameworks.","authors":["Michael Merry","Pat Riddle","Jim Warren"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17308v1","updated":"2025-12-19T07:46:29Z","published":"2025-12-19T07:46:29Z","title":"Large Language Models as Pokémon Battle Agents: Strategic Play and Content Generation","summary":"Strategic decision-making in Pokémon battles presents a unique testbed for evaluating large language models. Pokémon battles demand reasoning about type matchups, statistical trade-offs, and risk assessment, skills that mirror human strategic thinking. This work examines whether Large Language Models (LLMs) can serve as competent battle agents, capable of both making tactically sound decisions and generating novel, balanced game content. We developed a turn-based Pokémon battle system where LLMs select moves based on battle state rather than pre-programmed logic. The framework captures essential Pokémon mechanics: type effectiveness multipliers, stat-based damage calculations, and multi-Pokémon team management. Through systematic evaluation across multiple model architectures we measured win rates, decision latency, type-alignment accuracy, and token efficiency. These results suggest LLMs can function as dynamic game opponents without domain-specific training, offering a practical alternative to reinforcement learning for turn-based strategic games. The dual capability of tactical reasoning and content creation, positions LLMs as both players and designers, with implications for procedural generation and adaptive difficulty systems in interactive entertainment.","authors":["Daksh Jain","Aarya Jain","Ashutosh Desai","Avyakt Verma","Ishan Bhanuka","Pratik Narang","Dhruv Kumar"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2510.11176v2","updated":"2025-12-19T07:32:01Z","published":"2025-10-13T09:08:59Z","title":"G2L:From Giga-Scale to Cancer-Specific Large-Scale Pathology Foundation Models via Knowledge Distillation","summary":"Recent studies in pathology foundation models have shown that scaling training data, diversifying cancer types, and increasing model size consistently improve their performance. However, giga-scale foundation models, which are trained on hundreds of thousands of slides covering tens of cancer types and contain billions of parameters, pose significant challenges for practical use due to their tremendous computational costs in both development and deployment. In this work, we present a novel strategy, named the G2L framework, to increase the performance of large-scale foundation models, which consist of only $15\\%$ of the parameters of giga-scale models, to a comparable performance level of giga-scale models in cancer-specific tasks. Our approach applies knowledge distillation, transferring the capabilities of a giga-scale model to a large-scale model, using just 1K pathology slides of a target cancer (e.g., breast, prostate, etc.). The resulting distilled model not only outperformed state-of-the-art models of the same size (i.e., large-scale) across several benchmarks but also, interestingly, surpassed the giga-scale teacher and huge-scale models in some benchmarks. In addition, the distilled model exhibited a higher robustness index, indicating improved resilience to image variations originating from multiple institutions. These findings suggest that the proposed distillation approach for a large-scale model is a data- and parameter-efficient way to achieve giga-scale-level performance for cancer-specific applications without prohibitive computational burden.","authors":["Yesung Cho","Sungmin Lee","Geongyu Lee","Minkyung Lee","Jongbae Park","Dongmyung Shin"],"pdf_url":"","comment":"Accepted in AAAI 2024 workshop in Health Intelligence Special Theme on Foundation Models and AI Agents"},{"id":"http://arxiv.org/abs/2512.17299v1","updated":"2025-12-19T07:27:30Z","published":"2025-12-19T07:27:30Z","title":"M2RU: Memristive Minion Recurrent Unit for Continual Learning at the Edge","summary":"Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.","authors":["Abdullah M. Zyarah","Dhireesha Kudithipudi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.22818v2","updated":"2025-12-19T07:26:23Z","published":"2025-09-26T18:24:22Z","title":"Can Large Language Models Develop Gambling Addiction?","summary":"This study identifies the specific conditions under which large language models exhibit human-like gambling addiction patterns, providing critical insights into their decision-making mechanisms and AI safety. We analyze LLM decision-making at cognitive-behavioral and neural levels based on human addiction research. In slot machine experiments, we identified cognitive features such as illusion of control and loss chasing, observing that greater autonomy in betting parameters substantially amplified irrational behavior and bankruptcy rates. Neural circuit analysis using a Sparse Autoencoder confirmed that model behavior is controlled by abstract decision-making features related to risk, not merely by prompts. These findings suggest LLMs internalize human-like cognitive biases beyond simply mimicking training data.","authors":["Seungpil Lee","Donghyeon Shin","Yunjeong Lee","Sundong Kim"],"pdf_url":"","comment":"26 pages, 14 figures"},{"id":"http://arxiv.org/abs/2512.13478v4","updated":"2025-12-19T07:21:39Z","published":"2025-12-15T16:14:32Z","title":"Non-Resolution Reasoning (NRR): A Computational Framework for Contextual Identity and Ambiguity Preservation","summary":"Current artificial intelligence systems, despite remarkable capabilities in text generation and pattern recognition, exhibit a fundamental architectural limitation: they resolve ambiguity prematurely. This premature semantic collapse -- the tendency to collapse multiple valid interpretations into a single output -- stems from classical identity assumptions embedded in standard neural architectures. We propose Non-Resolution Reasoning (NRR), a computational framework that treats ambiguity retention as a valid reasoning mode rather than a defect to be eliminated. NRR introduces three core principles: (1) Non-Identity ($A \\neq A$) -- the same symbol refers to different entities across contexts; (2) Approximate Identity ($A \\approx A$) -- entities share partial structural overlap without being identical; and (3) Non-Resolution -- conflicting interpretations can coexist without forced convergence. We formalize these principles through three architectural components: Multi-Vector Embeddings for context-dependent representation, Non-Collapsing Attention for parallel interpretation retention, and Contextual Identity Tracking (CIT) for maintaining $A \\neq A$ across inference. We demonstrate NRR's advantages through case studies in paradox handling, creative generation, and context-dependent reasoning. Crucially, we provide a minimal empirical validation on a synthetic context-shift task where an NRR-lite model achieves 90.9% out-of-distribution accuracy compared to 9.1% for standard architectures, demonstrating that ambiguity preservation enables structural generalization. NRR challenges the assumption that meaning must collapse to be useful, offering a foundation for AI systems capable of sophisticated ambiguity handling and creative reasoning. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.","authors":["Kei Saito"],"pdf_url":"","comment":"16 pages, 1 figure. Updated version with corrected references and aligned acknowledgments"},{"id":"http://arxiv.org/abs/2512.17293v1","updated":"2025-12-19T07:17:43Z","published":"2025-12-19T07:17:43Z","title":"Robust TTS Training via Self-Purifying Flow Matching for the WildSpoof 2026 TTS Track","summary":"This paper presents a lightweight text-to-speech (TTS) system developed for the WildSpoof Challenge TTS Track. Our approach fine-tunes the recently released open-weight TTS model, \\textit{Supertonic}\\footnote{\\url{https://github.com/supertone-inc/supertonic}}, with Self-Purifying Flow Matching (SPFM) to enable robust adaptation to in-the-wild speech. SPFM mitigates label noise by comparing conditional and unconditional flow matching losses on each sample, routing suspicious text--speech pairs to unconditional training while still leveraging their acoustic information. The resulting model achieves the lowest Word Error Rate (WER) among all participating teams, while ranking second in perceptual metrics such as UTMOS and DNSMOS. These findings demonstrate that efficient, open-weight architectures like Supertonic can be effectively adapted to diverse real-world speech conditions when combined with explicit noise-handling mechanisms such as SPFM.","authors":["June Young Yi","Hyeongju Kim","Juheon Lee"],"pdf_url":"","comment":"2 pages, preprint, This work has been submitted to the IEEE for possible publication. Submitted to ICASSP 2026 SPGC (WildSpoof Challenge, TTS track)"},{"id":"http://arxiv.org/abs/2512.14806v3","updated":"2025-12-19T07:14:17Z","published":"2025-12-16T18:51:23Z","title":"Let the Barbarians In: How AI Can Accelerate Systems Performance Research","summary":"Artificial Intelligence (AI) is beginning to transform the research process by automating the discovery of new solutions. This shift depends on the availability of reliable verifiers, which AI-driven approaches require to validate candidate solutions. Research focused on improving systems performance is especially well-suited to this paradigm because system performance problems naturally admit such verifiers: candidates can be implemented in real systems or simulators and evaluated against predefined workloads. We term this iterative cycle of generation, evaluation, and refinement AI-Driven Research for Systems (ADRS). Using several open-source ADRS instances (i.e., OpenEvolve, GEPA, and ShinkaEvolve), we demonstrate across ten case studies (e.g., multi-region cloud scheduling, mixture-of-experts load balancing, LLM-based SQL, transaction scheduling) that ADRS-generated solutions can match or even outperform human state-of-the-art designs. Based on these findings, we outline best practices (e.g., level of prompt specification, amount of feedback, robust evaluation) for effectively using ADRS, and we discuss future research directions and their implications. Although we do not yet have a universal recipe for applying ADRS across all of systems research, we hope our preliminary findings, together with the challenges we identify, offer meaningful guidance for future work as researcher effort shifts increasingly toward problem formulation and strategic oversight.\n  Note: This paper is an extension of our prior work [14]. It adds extensive evaluation across multiple ADRS frameworks and provides deeper analysis and insights into best practices.","authors":["Audrey Cheng","Shu Liu","Melissa Pan","Zhifei Li","Shubham Agarwal","Mert Cemri","Bowen Wang","Alexander Krentsel","Tian Xia","Jongseok Park","Shuo Yang","Jeff Chen","Lakshya Agrawal","Ashwin Naren","Shulu Li","Ruiying Ma","Aditya Desai","Jiarong Xing","Koushik Sen","Matei Zaharia","Ion Stoica"],"pdf_url":"","comment":"arXiv admin note: substantial text overlap with arXiv:2510.06189"},{"id":"http://arxiv.org/abs/2510.16882v2","updated":"2025-12-19T07:13:05Z","published":"2025-10-19T15:32:01Z","title":"Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning","summary":"Supervised fine-tuning (SFT) is a commonly used technique to adapt large language models (LLMs) to downstream tasks. In practice, SFT on a full dataset is computationally expensive and sometimes suffers from overfitting or bias amplification. This facilitates the rise of data curation in SFT, which prioritizes the most valuable data to optimze. This work studies the online batch selection family that dynamically scores and filters samples during the training process. However, existing popular methods often (i) rely merely on the utility of data to select a subset while neglecting other crucial factors like diversity, (ii) rely on external resources such as reference models or validation sets, and (iii) incur extra training time over full-dataset training. To address these limitations, this work develops \\textbf{UDS (Utility-Diversity Sampling)}, a framework for efficient online batch selection in SFT. UDS leverages the nuclear norm of the logits matrix to capture both data utility and intra-sample diversity, while estimating inter-sample diversity through efficient low-dimensional embedding comparisons with a lightweight memory buffer of historical samples. Such a design eliminates the need for external resources and unnecessary backpropagation, securing computational efficiency. Experiments on multiple benchmarks demonstrate that UDS consistently outperforms state-of-the-art online batch selection methods under varying data budgets, and significantly reduces training time compared to full-dataset fine-tuning. Code is available at https://github.com/gfyddha/UDS.","authors":["Heming Zou","Yixiu Mao","Yun Qu","Qi Wang","Xiangyang Ji"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17289v1","updated":"2025-12-19T07:11:50Z","published":"2025-12-19T07:11:50Z","title":"Subjective Question Generation and Answer Evaluation using NLP","summary":"Natural Language Processing (NLP) is one of the most revolutionary technologies today. It uses artificial intelligence to understand human text and spoken words. It is used for text summarization, grammar checking, sentiment analysis, and advanced chatbots and has many more potential use cases. Furthermore, it has also made its mark on the education sector. Much research and advancements have already been conducted on objective question generation; however, automated subjective question generation and answer evaluation are still in progress. An automated system to generate subjective questions and evaluate the answers can help teachers assess student work and enhance the student's learning experience by allowing them to self-assess their understanding after reading an article or a chapter of a book. This research aims to improve current NLP models or make a novel one for automated subjective question generation and answer evaluation from text input.","authors":["G. M. Refatul Islam","Safwan Shaheer","Yaseen Nur","Mohammad Rafid Hamid"],"pdf_url":"","comment":"5 pages, 5 figures, 2 tables, conference paper"},{"id":"http://arxiv.org/abs/2511.00040v2","updated":"2025-12-19T06:56:17Z","published":"2025-10-28T01:33:43Z","title":"Semi-Supervised Preference Optimization with Limited Feedback","summary":"The field of preference optimization has made outstanding contributions to the alignment of language models with human preferences. Despite these advancements, recent methods still rely heavily on substantial paired (labeled) feedback data, leading to substantial resource expenditures. To address these challenges, we study the problem of Semi-Supervised Preference Optimization (SSPO) in which the idea is to learn from both a small number of pairwise preference labels and a large pool of unpaired samples simultaneously. Our key theoretical contribution proves the existence of an optimal reward threshold capable of separating winning and losing responses with high probability, which enables a principled pseudo-labeling of unpaired data. By leveraging these pseudo-labels, SSPO effectively distills latent preferences from large-scale unpaired data, thus maintaining human alignment while drastically reducing acquisition costs. Extensive experiments across datasets validate this remarkable data efficiency; for instance, SSPO trained with Mistral-7B-Instruct on just 1% of UltraFeedback consistently surpasses strong baselines trained on 10% of UltraFeedback.","authors":["Seonggyun Lee","Sungjun Lim","Seojin Park","Soeun Cheon","Kyungwoo Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17278v1","updated":"2025-12-19T06:50:03Z","published":"2025-12-19T06:50:03Z","title":"WDFFU-Mamba: A Wavelet-guided Dual-attention Feature Fusion Mamba for Breast Tumor Segmentation in Ultrasound Images","summary":"Breast ultrasound (BUS) image segmentation plays a vital role in assisting clinical diagnosis and early tumor screening. However, challenges such as speckle noise, imaging artifacts, irregular lesion morphology, and blurred boundaries severely hinder accurate segmentation. To address these challenges, this work aims to design a robust and efficient model capable of automatically segmenting breast tumors in BUS images.We propose a novel segmentation network named WDFFU-Mamba, which integrates wavelet-guided enhancement and dual-attention feature fusion within a U-shaped Mamba architecture. A Wavelet-denoised High-Frequency-guided Feature (WHF) module is employed to enhance low-level representations through noise-suppressed high-frequency cues. A Dual Attention Feature Fusion (DAFF) module is also introduced to effectively merge skip-connected and semantic features, improving contextual consistency.Extensive experiments on two public BUS datasets demonstrate that WDFFU-Mamba achieves superior segmentation accuracy, significantly outperforming existing methods in terms of Dice coefficient and 95th percentile Hausdorff Distance (HD95).The combination of wavelet-domain enhancement and attention-based fusion greatly improves both the accuracy and robustness of BUS image segmentation, while maintaining computational efficiency.The proposed WDFFU-Mamba model not only delivers strong segmentation performance but also exhibits desirable generalization ability across datasets, making it a promising solution for real-world clinical applications in breast tumor ultrasound analysis.","authors":["Guoping Cai","Houjin Chen","Yanfeng Li","Jia Sun","Ziwei Chen","Qingzi Geng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.14121v2","updated":"2025-12-19T06:44:37Z","published":"2025-12-16T06:05:55Z","title":"SportsGPT: An LLM-driven Framework for Interpretable Sports Motion Assessment and Training Guidance","summary":"Existing intelligent sports analysis systems mainly focus on \"scoring and visualization,\" often lacking automatic performance diagnosis and interpretable training guidance. Recent advances in Large Language Models (LLMs) and motion analysis techniques provide new opportunities to address the above limitations. In this paper, we propose SportsGPT, an LLM-driven framework for interpretable sports motion assessment and training guidance, which establishes a closed loop from motion time-series input to professional training guidance. First, given a set of high-quality target models, we introduce MotionDTW, a two-stage time series alignment algorithm designed for accurate keyframe extraction from skeleton-based motion sequences. Subsequently, we design a Knowledge-based Interpretable Sports Motion Assessment Model (KISMAM) to obtain a set of interpretable assessment metrics (e.g., insufficient extension) by contrasting the keyframes with the target models. Finally, we propose SportsRAG, a RAG-based training guidance model built upon Qwen3. Leveraging a 6B-token knowledge base, it prompts the LLM to generate professional training guidance by retrieving domain-specific QA pairs. Experimental results demonstrate that MotionDTW significantly outperforms traditional methods with lower temporal error and higher IoU scores. Furthermore, ablation studies validate the KISMAM and SportsRAG, confirming that SportsGPT surpasses general LLMs in diagnostic accuracy and professionalism.","authors":["Wenbo Tian","Ruting Lin","Hongxian Zheng","Yaodong Yang","Geng Wu","Zihao Zhang","Zhang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17270v1","updated":"2025-12-19T06:37:44Z","published":"2025-12-19T06:37:44Z","title":"Understanding Generalization in Role-Playing Models via Information Theory","summary":"Role-playing models (RPMs) are widely used in real-world applications but underperform when deployed in the wild. This degradation can be attributed to distribution shifts, including user, character, and dialogue compositional shifts. Existing methods like LLM-as-a-judge fall short in providing a fine-grained diagnosis of how these shifts affect RPM generalization, and thus there lack formal frameworks to characterize RPM generalization behaviors. To bridge these gaps, we introduce an information-theoretic metric, named reasoning-based effective mutual information difference (R-EMID), to measure RPM performance degradation in an interpretable way. We also derive an upper bound on R-EMID to predict the worst-case generalization performance of RPMs and theoretically reveal how various shifts contribute to the RPM performance degradation. Moreover, we propose a co-evolving reinforcement learning framework to adaptively model the connection among user, character, and dialogue context and thus enhance the estimation of dialogue response generation probability, which is critical for calculating R-EMID. Finally, we evaluate the generalization performance of various RPMs using R-EMID, finding that user shift poses the highest risk among all shifts and reinforcement learning is the most effective approach for enhancing RPM generalization.","authors":["Yongqi Li","Hao Lang","Fei Huang","Tieyun Qian","Yongbin Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17267v1","updated":"2025-12-19T06:32:46Z","published":"2025-12-19T06:32:46Z","title":"AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators","summary":"Evaluating user-facing AI applications remains a central challenge, especially in open-ended domains such as travel planning, clinical note generation, or dialogue. The gold standard is user feedback (e.g., thumbs up/down) or behavioral signals (e.g., retention), but these are often scarce in prototypes and research projects, or too-slow to use for system optimization. We present AutoMetrics, a framework for synthesizing evaluation metrics under low-data constraints. AutoMetrics combines retrieval from MetricBank, a collection of 48 metrics we curate, with automatically generated LLM-as-a-Judge criteria informed by lightweight human feedback. These metrics are composed via regression to maximize correlation with human signal. AutoMetrics takes you from expensive measures to interpretable automatic metrics. Across 5 diverse tasks, AutoMetrics improves Kendall correlation with human ratings by up to 33.4% over LLM-as-a-Judge while requiring fewer than 100 feedback points. We show that AutoMetrics can be used as a proxy reward to equal effect as a verifiable reward. We release the full AutoMetrics toolkit and MetricBank to accelerate adaptive evaluation of LLM applications.","authors":["Michael J. Ryan","Yanzhe Zhang","Amol Salunkhe","Yi Chu","Di Xu","Diyi Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17266v1","updated":"2025-12-19T06:30:11Z","published":"2025-12-19T06:30:11Z","title":"ScoutGPT: Capturing Player Impact from Team Action Sequences Using GPT-Based Framework","summary":"Transfers play a pivotal role in shaping a football club's success, yet forecasting whether a transfer will succeed remains difficult due to the strong context-dependence of on-field performance. Existing evaluation practices often rely on static summary statistics or post-hoc value models, which fail to capture how a player's contribution adapts to a new tactical environment or different teammates. To address this gap, we introduce EventGPT, a player-conditioned, value-aware next-event prediction model built on a GPT-style autoregressive transformer. Our model treats match play as a sequence of discrete tokens, jointly learning to predict the next on-ball action's type, location, timing, and its estimated residual On-Ball Value (rOBV) based on the preceding context and player identity. A key contribution of this framework is the ability to perform counterfactual simulations. By substituting learned player embeddings into new event sequences, we can simulate how a player's behavioral distribution and value profile would change when placed in a different team or tactical structure. Evaluated on five seasons of Premier League event data, EventGPT outperforms existing sequence-based baselines in next-event prediction accuracy and spatial precision. Furthermore, we demonstrate the model's practical utility for transfer analysis through case studies-such as comparing striker performance across different systems and identifying stylistic replacements for specific roles-showing that our approach provides a principled method for evaluating transfer fit.","authors":["Miru Hong","Minho Lee","Geonhee Jo","Jae-Hee So","Pascal Bauer","Sang-Ki Ko"],"pdf_url":"","comment":"8 pages, 2 figures, 7 tables. To appear in Hudl Performance Insights 2025"},{"id":"http://arxiv.org/abs/2503.22182v2","updated":"2025-12-19T06:24:33Z","published":"2025-03-28T07:00:33Z","title":"Sell It Before You Make It: Revolutionizing E-Commerce with Personalized AI-Generated Items","summary":"E-commerce has revolutionized retail, yet its traditional workflows remain inefficient, with significant resource costs tied to product design and inventory. This paper introduces a novel system deployed at Alibaba that uses AI-generated items (AIGI) to address these challenges with personalized text-to-image generation for e-commerce product design. AIGI enables an innovative business mode called \"sell it before you make it\", where merchants can design fashion items and generate photorealistic images with digital models based on textual descriptions. Only when the items have received a certain number of orders, do the merchants start to produce them, which largely reduces reliance on physical prototypes and thus accelerates time to market. For such a promising application, we identify the underlying key scientific challenge, i.e., capturing users' group-level personalized preferences towards multiple generated images. To this end, we propose a Personalized Group-Level Preference Alignment Framework for Diffusion Models (PerFusion). We first design PerFusion Reward Model for user preference estimation with a feature-crossing-based personalized plug-in. Then we develop PerFusion with a personalized adaptive network to model diverse preferences across users, and meanwhile derive the group-level preference optimization objective to model comparative behaviors among multiple images. Both offline and online experiments demonstrate the effectiveness of our proposed algorithm. The AI-generated items achieve over 13% relative improvements for both click-through rate and conversion rate, as well as 7.9% decrease in return rate, compared to their human-designed counterparts, validating the transformative potential of AIGI for e-commerce platforms.","authors":["Jianghao Lin","Peng Du","Jiaqi Liu","Weite Li","Yong Yu","Weinan Zhang","Yang Cao"],"pdf_url":"","comment":"Accepted by KDD 2026 ADS Track"},{"id":"http://arxiv.org/abs/2505.20112v3","updated":"2025-12-19T06:23:19Z","published":"2025-05-26T15:14:54Z","title":"ResSVD: Residual Compensated SVD for Large Language Model Compression","summary":"Large language models (LLMs) have demonstrated impressive capabilities in a wide range of downstream natural language processing tasks. Nevertheless, their considerable sizes and memory demands hinder practical deployment, underscoring the importance of developing efficient compression strategies. Singular value decomposition (SVD) decomposes a matrix into orthogonal components, enabling efficient low-rank approximation. This is particularly suitable for LLM compression, where weight matrices often exhibit significant redundancy. However, current SVD-based methods neglect the residual matrix from truncation, resulting in significant truncation loss. Additionally, compressing all layers of the model results in severe performance degradation. To overcome these limitations, we propose ResSVD, a new post-training SVD-based LLM compression method. Specifically, we leverage the residual matrix generated during the truncation process to reduce truncation loss. Moreover, under a fixed overall compression ratio, we selectively compress the last few layers of the model, which mitigates error propagation and significantly improves the performance of compressed models. Comprehensive evaluations of ResSVD on diverse LLM families and multiple benchmark datasets indicate that ResSVD consistently achieves superior performance over existing counterpart methods, demonstrating its practical effectiveness.","authors":["Haolei Bai","Siyong Jian","Tuo Liang","Yu Yin","Huan Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17259v1","updated":"2025-12-19T06:12:43Z","published":"2025-12-19T06:12:43Z","title":"Verifiability-First Agents: Provable Observability and Lightweight Audit Agents for Controlling Autonomous LLM Systems","summary":"As LLM-based agents grow more autonomous and multi-modal, ensuring they remain controllable, auditable, and faithful to deployer intent becomes critical. Prior benchmarks measured the propensity for misaligned behavior and showed that agent personalities and tool access significantly influence misalignment. Building on these insights, we propose a Verifiability-First architecture that (1) integrates run-time attestations of agent actions using cryptographic and symbolic methods, (2) embeds lightweight Audit Agents that continuously verify intent versus behavior using constrained reasoning, and (3) enforces challenge-response attestation protocols for high-risk operations. We introduce OPERA (Observability, Provable Execution, Red-team, Attestation), a benchmark suite and evaluation protocol designed to measure (i) detectability of misalignment, (ii) time to detection under stealthy strategies, and (iii) resilience of verifiability mechanisms to adversarial prompt and persona injection. Our approach shifts the evaluation focus from how likely misalignment is to how quickly and reliably misalignment can be detected and remediated.","authors":["Abhivansh Gupta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.06699v2","updated":"2025-12-19T06:10:50Z","published":"2025-12-07T07:25:08Z","title":"Predictive Modeling of I/O Performance for Machine Learning Training Pipelines: A Data-Driven Approach to Storage Optimization","summary":"Modern machine learning training is increasingly bottlenecked by data I/O rather than compute. GPUs often sit idle at below 50% utilization waiting for data. This paper presents a machine learning approach to predict I/O performance and recommend optimal storage configurations for ML training pipelines. We collected 141 observations through systematic benchmarking across different storage backends (NVMe SSD, network-attached storage, in-memory filesystems), data formats, and access patterns, covering both low-level I/O operations and full training pipelines. After evaluating seven regression models and three classification approaches, XGBoost achieved the best performance with R-squared of 0.991, predicting I/O throughput within 11.8% error on average. Feature importance analysis revealed that throughput metrics and batch size are the primary performance drivers. This data-driven approach can reduce configuration time from days of trial-and-error to minutes of predictive recommendation. The methodology is reproducible and extensible to other resource management problems in ML systems. Code and data are available at https://github.com/knkarthik01/gpu_storage_ml_project","authors":["Karthik Prabhakar","Durgamadhab Mishra"],"pdf_url":"","comment":"20 pages, 10 figures"},{"id":"http://arxiv.org/abs/2509.25977v2","updated":"2025-12-19T06:08:01Z","published":"2025-09-30T09:09:33Z","title":"Data-Free Continual Learning of Server Models in Model-Heterogeneous Cloud-Device Collaboration","summary":"The rise of cloud-device collaborative computing has enabled intelligent services to be delivered across distributed edge devices while leveraging centralized cloud resources. In this paradigm, federated learning (FL) has become a key enabler for privacy-preserving model training without transferring raw data from edge devices to the cloud. However, with the continuous emergence of new data and increasing model diversity, traditional federated learning faces significant challenges, including inherent issues of data heterogeneity, model heterogeneity and catastrophic forgetting, along with new challenge of knowledge misalignment. In this study, we introduce FedDCL, a novel framework designed to enable data-free continual learning of the server model in a model-heterogeneous federated setting. We leverage pre-trained diffusion models to extract lightweight class-specific prototypes, which confer a threefold data-free advantage, enabling: (1) generation of synthetic data for the current task to augment training and counteract non-IID data distributions; (2) exemplar-free generative replay for retaining knowledge from previous tasks; and (3) data-free dynamic knowledge transfer from heterogeneous devices to the cloud server.Experimental results on various datasets demonstrate the effectiveness of FedDCL, showcasing its potential to enhance the generalizability and practical applicability of federated cloud-device collaboration in dynamic settings.","authors":["Xiao Zhang","Zengzhe Chen","Yuan Yuan","Yifei Zou","Fuzhen Zhuang","Wenyu Jiao","Yuke Wang","Dongxiao Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17255v1","updated":"2025-12-19T05:56:48Z","published":"2025-12-19T05:56:48Z","title":"From Priors to Predictions: Explaining and Visualizing Human Reasoning in a Graph Neural Network Framework","summary":"Humans excel at solving novel reasoning problems from minimal exposure, guided by inductive biases, assumptions about which entities and relationships matter. Yet the computational form of these biases and their neural implementation remain poorly understood. We introduce a framework that combines Graph Theory and Graph Neural Networks (GNNs) to formalize inductive biases as explicit, manipulable priors over structure and abstraction. Using a human behavioral dataset adapted from the Abstraction and Reasoning Corpus (ARC), we show that differences in graph-based priors can explain individual differences in human solutions. Our method includes an optimization pipeline that searches over graph configurations, varying edge connectivity and node abstraction, and a visualization approach that identifies the computational graph, the subset of nodes and edges most critical to a model's prediction. Systematic ablation reveals how generalization depends on specific prior structures and internal processing, exposing why human like errors emerge from incorrect or incomplete priors. This work provides a principled, interpretable framework for modeling the representational assumptions and computational dynamics underlying generalization, offering new insights into human reasoning and a foundation for more human aligned AI systems.","authors":["Quan Do","Caroline Ahn","Leah Bakst","Michael Pascale","Joseph T. McGuire","Chantal E. Stern","Michael E. Hasselmo"],"pdf_url":"","comment":"44 pages, 7 figures, 3 suppl figures"},{"id":"http://arxiv.org/abs/2512.16248v2","updated":"2025-12-19T05:44:04Z","published":"2025-12-18T06:57:42Z","title":"Sigma-MoE-Tiny Technical Report","summary":"Mixture-of-Experts (MoE) has emerged as a promising paradigm for foundation models due to its efficient and powerful scalability. In this work, we present Sigma-MoE-Tiny, an MoE language model that achieves the highest sparsity compared to existing open-source models. Sigma-MoE-Tiny employs fine-grained expert segmentation with up to 96 experts per layer, while activating only one expert for each token, resulting in 20B total parameters with just 0.5B activated. The major challenge introduced by such extreme sparsity lies in expert load balancing. We find that the widely-used load balancing loss tends to become ineffective in the lower layers under this setting. To address this issue, we propose a progressive sparsification schedule aiming to balance expert utilization and training stability. Sigma-MoE-Tiny is pre-trained on a diverse and high-quality corpus, followed by post-training to further unlock its capabilities. The entire training process remains remarkably stable, with no occurrence of irrecoverable loss spikes. Comprehensive evaluations reveal that, despite activating only 0.5B parameters, Sigma-MoE-Tiny achieves top-tier performance among counterparts of comparable or significantly larger scale. In addition, we provide an in-depth discussion of load balancing in highly sparse MoE models, offering insights for advancing sparsity in future MoE architectures.\n  Project page: https://qghuxmu.github.io/Sigma-MoE-Tiny\n  Code: https://github.com/microsoft/ltp-megatron-lm","authors":["Qingguo Hu","Zhenghao Lin","Ziyue Yang","Yucheng Ding","Xiao Liu","Yuting Jiang","Ruizhe Wang","Tianyu Chen","Zhongxin Guo","Yifan Xiong","Rui Gao","Lei Qu","Jinsong Su","Peng Cheng","Yeyun Gong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17251v1","updated":"2025-12-19T05:36:23Z","published":"2025-12-19T05:36:23Z","title":"AlignDP: Hybrid Differential Privacy with Rarity-Aware Protection for LLMs","summary":"Large language models are exposed to risks of extraction, distillation, and unauthorized fine-tuning. Existing defenses use watermarking or monitoring, but these act after leakage. We design AlignDP, a hybrid privacy lock that blocks knowledge transfer at the data interface. The key idea is to separate rare and non-rare fields. Rare fields are shielded by PAC indistinguishability, giving effective zero-epsilon local DP. Non-rare fields are privatized with RAPPOR, giving unbiased frequency estimates under local DP. A global aggregator enforces composition and budget. This two-tier design hides rare events and adds controlled noise to frequent events. We prove limits of PAC extension to global aggregation, give bounds for RAPPOR estimates, and analyze utility trade-off. A toy simulation confirms feasibility: rare categories remain hidden, frequent categories are recovered with small error.","authors":["Madhava Gaikwad"],"pdf_url":"","comment":"39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: LOCK-LLM Work-shop, NeurIPS 2025"},{"id":"http://arxiv.org/abs/2512.17250v1","updated":"2025-12-19T05:34:52Z","published":"2025-12-19T05:34:52Z","title":"Accelerating Multi-modal LLM Gaming Performance via Input Prediction and Mishit Correction","summary":"Real-time sequential control agents are often bottlenecked by inference latency. Even modest per-step planning delays can destabilize control and degrade overall performance. We propose a speculation-and-correction framework that adapts the predict-then-verify philosophy of speculative execution to model-based control with TD-MPC2. At each step, a pretrained world model and latent-space MPC planner generate a short-horizon action queue together with predicted latent rollouts, allowing the agent to execute multiple planned actions without immediate replanning. When a new observation arrives, the system measures the mismatch between the encoded real latent state and the queued predicted latent. For small to moderate mismatch, a lightweight learned corrector applies a residual update to the speculative action, distilled offline from a replanning teacher. For large mismatch, the agent safely falls back to full replanning and clears stale action queues. We study both a gated two-tower MLP corrector and a temporal Transformer corrector to address local errors and systematic drift. Experiments on the DMC Humanoid-Walk task show that our method reduces the number of planning inferences from 500 to 282, improves end-to-end step latency by 25 percent, and maintains strong control performance with only a 7.1 percent return reduction. Ablation results demonstrate that speculative execution without correction is unreliable over longer horizons, highlighting the necessity of mismatch-aware correction for robust latency reduction.","authors":["Ziyang Lin","Zixuan Sun","Sanhorn Chen","Xiaoyang Chen","Roy Zhao"],"pdf_url":"","comment":"UIUC 25 Fall CS 498"},{"id":"http://arxiv.org/abs/2512.17247v1","updated":"2025-12-19T05:26:50Z","published":"2025-12-19T05:26:50Z","title":"Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness in Persian Speech Recognition","summary":"Automatic Speech Recognition (ASR) systems suffer significant performance degradation in noisy environments, a challenge that is especially severe for low-resource languages such as Persian. Even state-of-the-art models such as Whisper struggle to maintain accuracy under varying signal-to-noise ratios (SNRs). This study presents a robust noise-sensitive ASR error correction framework that combines multiple hypotheses and noise-aware modeling. Using noisy Persian speech, we generate 5-best hypotheses from a modified Whisper-large decoder. Error Level Noise (ELN) is introduced as a representation that captures semantic- and token-level disagreement across hypotheses, quantifying the linguistic distortions caused by noise. ELN thus provides a direct measure of noise-induced uncertainty, enabling the LLM to reason about the reliability of each hypothesis during correction. Three models are evaluated: (1) a base LLaMA-2-7B model without fine-tuning, (2) a fine-tuned variant trained on text-only hypotheses, and (3) a noise-conditioned model integrating ELN embeddings at both sentence and word levels. Experimental results demonstrate that the ELN-conditioned model achieves substantial reductions in Word Error Rate (WER). Specifically, on the challenging Mixed Noise test set, the proposed Fine-tuned + ELN (Ours) model reduces the WER from a baseline of 31.10\\% (Raw Whisper) to 24.84\\%, significantly surpassing the Fine-tuned (No ELN) text-only baseline of 30.79\\%, whereas the original LLaMA-2-7B model increased the WER to 64.58\\%, demonstrating that it is unable to correct Persian errors on its own. This confirms the effectiveness of combining multiple hypotheses with noise-aware embeddings for robust Persian ASR in noisy real-world scenarios.","authors":["Zahra Rahmani","Hossein Sameti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17239v1","updated":"2025-12-19T04:59:41Z","published":"2025-12-19T04:59:41Z","title":"Privacy-Preserving Synthetic Dataset of Individual Daily Trajectories for City-Scale Mobility Analytics","summary":"Urban mobility data are indispensable for urban planning, transportation demand forecasting, pandemic modeling, and many other applications; however, individual mobile phone-derived Global Positioning System traces cannot generally be shared with third parties owing to severe re-identification risks. Aggregated records, such as origin-destination (OD) matrices, offer partial insights but fail to capture the key behavioral properties of daily human movement, limiting realistic city-scale analyses.\n  This study presents a privacy-preserving synthetic mobility dataset that reconstructs daily trajectories from aggregated inputs. The proposed method integrates OD flows with two complementary behavioral constraints: (1) dwell-travel time quantiles that are available only as coarse summary statistics and (2) the universal law for the daily distribution of the number of visited locations. Embedding these elements in a multi-objective optimization framework enables the reproduction of realistic distributions of human mobility while ensuring that no personal identifiers are required.\n  The proposed framework is validated in two contrasting regions of Japan: (1) the 23 special wards of Tokyo, representing a dense metropolitan environment; and (2) Fukuoka Prefecture, where urban and suburban mobility patterns coexist. The resulting synthetic mobility data reproduce dwell-travel time and visit frequency distributions with high fidelity, while deviations in OD consistency remain within the natural range of daily fluctuations.\n  The results of this study establish a practical synthesis pathway under real-world constraints, providing governments, urban planners, and industries with scalable access to high-resolution mobility data for reliable analytics without the need for sensitive personal records, and supporting practical deployments in policy and commercial domains.","authors":["Jun'ichi Ozaki","Ryosuke Susuta","Takuhiro Moriyama","Yohei Shida"],"pdf_url":"","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2512.07540v2","updated":"2025-12-19T04:16:55Z","published":"2025-12-08T13:21:44Z","title":"Minimum Bayes Risk Decoding for Error Span Detection in Reference-Free Automatic Machine Translation Evaluation","summary":"Error Span Detection (ESD) extends automatic machine translation (MT) evaluation by localizing translation errors and labeling their severity. Current generative ESD methods typically use Maximum a Posteriori (MAP) decoding, assuming that the model-estimated probabilities are perfectly correlated with similarity to the human annotation, but we often observe higher likelihood assigned to an incorrect annotation than to the human one. We instead apply Minimum Bayes Risk (MBR) decoding to generative ESD. We use a sentence- or span-level similarity function for MBR decoding, which selects candidate hypotheses based on their approximate similarity to the human annotation. Experimental results on the WMT24 Metrics Shared Task show that MBR decoding significantly improves span-level performance and generally matches or outperforms MAP at the system and sentence levels. To reduce the computational cost of MBR decoding, we further distill its decisions into a model decoded via greedy search, removing the inference-time latency bottleneck.","authors":["Boxuan Lyu","Haiyue Song","Hidetaka Kamigaito","Chenchen Ding","Hideki Tanaka","Masao Utiyama","Kotaro Funakoshi","Manabu Okumura"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17218v1","updated":"2025-12-19T04:05:41Z","published":"2025-12-19T04:05:41Z","title":"The Role of Islamic Ethics in Preventing the Abuse of Artificial Intelligence (AI) Based Deepfakes","summary":"The significant development of deepfake technology powered by artificial intelligence (AI) has sparked worldwide concerns about the alteration of false information, the usurpation of online identities, and the decline of public confidence in the authenticity of online content. These incidents not only raise technical issues but also carry complex moral implications, rendering conventional, technologically driven, and reactive management methods inadequate to address the underlying causes of the problem, including intent, morality, and potential intangible social impacts. Based on these issues, this study aims to formulate a comprehensive Islamic ethical framework that can serve as a more comprehensive preventative tool to mitigate the risks of misuse of deepfakes. The study employed a Systematic Literature Review (SLR) guided by PRISMA, selecting ten primary sources published between 2018 and 2025 to identify ethical deficiencies, regulatory needs, and appropriate normative solutions. The analysis shows that the integration of the principles of (Maqasid al-Shariah) particularly (hifz al-ird) protecting honor and (hifz al-nafs) protecting the self, provides a strong normative basis for regulating the responsible use of technology. This study yields three strategic recommendations: regulatory changes that recognize the intangible and psychological harm caused by reputational damage; improved technology management through moral scrutiny that upholds the values of justice (adl), trust, and openness; and increased public digital literacy based on the principle of (tabayyun) examination and caution. Overall, this study concludes that the application of Islamic ethics offers a shift in thinking from punitive mechanisms to preventative approaches that focus on protecting human dignity, preventing harm, and strengthening the common good in the digital age.","authors":["Wisnu Uriawan","Imany Fauzy Rahman","Muhamad Zidan","Irma Rohmatillah","Muhammad Arkan Raihan","Irma Dwiyanti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.13168v2","updated":"2025-12-19T03:59:15Z","published":"2025-12-15T10:28:45Z","title":"Finch: Benchmarking Finance & Accounting across Spreadsheet-Centric Enterprise Workflows","summary":"We introduce a finance & accounting benchmark (Finch) for evaluating AI agents on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management.\n  We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain-expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work.\n  We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 48 hours in total yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI agents.","authors":["Haoyu Dong","Pengkun Zhang","Yan Gao","Xuanyu Dong","Yilin Cheng","Mingzhe Lu","Adina Yakefu","Shuxin Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17215v1","updated":"2025-12-19T03:58:02Z","published":"2025-12-19T03:58:02Z","title":"Research on Dead Reckoning Algorithm for Self-Propelled Pipeline Robots in Three-Dimensional Complex Pipelines","summary":"In the field of gas pipeline location, existing pipeline location methods mostly rely on pipeline location instruments. However, when faced with complex and curved pipeline scenarios, these methods often fail due to problems such as cable entanglement and insufficient equipment flexibility. To address this pain point, we designed a self-propelled pipeline robot. This robot can autonomously complete the location work of complex and curved pipelines in complex pipe networks without external dragging. In terms of pipeline mapping technology, traditional visual mapping and laser mapping methods are easily affected by lighting conditions and insufficient features in the confined space of pipelines, resulting in mapping drift and divergence problems. In contrast, the pipeline location method that integrates inertial navigation and wheel odometers is less affected by pipeline environmental factors. Based on this, this paper proposes a pipeline robot location method based on extended Kalman filtering (EKF). Firstly, the body attitude angle is initially obtained through an inertial measurement unit (IMU). Then, the extended Kalman filtering algorithm is used to improve the accuracy of attitude angle estimation. Finally, high-precision pipeline location is achieved by combining wheel odometers. During the testing phase, the roll wheels of the pipeline robot needed to fit tightly against the pipe wall to reduce slippage. However, excessive tightness would reduce the flexibility of motion control due to excessive friction. Therefore, a balance needed to be struck between the robot's motion capability and positioning accuracy. Experiments were conducted using the self-propelled pipeline robot in a rectangular loop pipeline, and the results verified the effectiveness of the proposed dead reckoning algorithm.","authors":["Yan Gao","Jiliang Wang","Minghan Wang","Xiaohua Chen","Demin Chen","Zhiyong Ren","Tian-Yun Huang"],"pdf_url":"","comment":"8 pages, 9 figures"},{"id":"http://arxiv.org/abs/2512.07984v2","updated":"2025-12-19T03:34:12Z","published":"2025-12-08T19:15:08Z","title":"Restrictive Hierarchical Semantic Segmentation for Stratified Tooth Layer Detection","summary":"Accurate understanding of anatomical structures is essential for reliably staging certain dental diseases. A way of introducing this within semantic segmentation models is by utilising hierarchy-aware methodologies. However, existing hierarchy-aware segmentation methods largely encode anatomical structure through the loss functions, providing weak and indirect supervision. We introduce a general framework that embeds an explicit anatomical hierarchy into semantic segmentation by coupling a recurrent, level-wise prediction scheme with restrictive output heads and top-down feature conditioning. At each depth of the class tree, the backbone is re-run on the original image concatenated with logits from the previous level. Child class features are conditioned using Feature-wise Linear Modulation of their parent class probabilities, to modulate child feature spaces for fine grained detection. A probabilistic composition rule enforces consistency between parent and descendant classes. Hierarchical loss combines per-level class weighted Dice and cross entropy loss and a consistency term loss, ensuring parent predictions are the sum of their children. We validate our approach on our proposed dataset, TL-pano, containing 194 panoramic radiographs with dense instance and semantic segmentation annotations, of tooth layers and alveolar bone. Utilising UNet and HRNet as donor models across a 5-fold cross validation scheme, the hierarchical variants consistently increase IoU, Dice, and recall, particularly for fine-grained anatomies, and produce more anatomically coherent masks. However, hierarchical variants also demonstrated increased recall over precision, implying increased false positives. The results demonstrate that explicit hierarchical structuring improves both performance and clinical plausibility, especially in low data dental imaging regimes.","authors":["Ryan Banks","Camila Lindoni Azevedo","Hongying Tang","Yunpeng Li"],"pdf_url":"","comment":"13 pages, 7 figures, 3 tables"},{"id":"http://arxiv.org/abs/2507.17061v4","updated":"2025-12-19T03:33:45Z","published":"2025-07-22T22:42:51Z","title":"Parallelism Meets Adaptiveness: Scalable Documents Understanding in Multi-Agent LLM Systems","summary":"Large language model (LLM) agents have shown increasing promise for collaborative task completion. However, existing multi-agent frameworks often rely on static workflows, fixed roles, and limited inter-agent communication, reducing their effectiveness in open-ended, high-complexity domains. This paper proposes a coordination framework that enables adaptiveness through three core mechanisms: dynamic task routing, bidirectional feedback, and parallel agent evaluation. The framework allows agents to reallocate tasks based on confidence and workload, exchange structured critiques to iteratively improve outputs, and crucially compete on high-ambiguity subtasks with evaluator-driven selection of the most suitable result. We instantiate these principles in a modular architecture and demonstrate substantial improvements in factual coverage, coherence, and efficiency over static and partially adaptive baselines. Our findings highlight the benefits of incorporating both adaptiveness and structured competition in multi-agent LLM systems.","authors":["Chengxuan Xia","Qianye Wu","Sixuan Tian","Yilun Hao"],"pdf_url":"","comment":"Accepted at AAAI 2026 Workshop on WoMAPF, Camera ready version"},{"id":"http://arxiv.org/abs/2512.17202v1","updated":"2025-12-19T03:28:39Z","published":"2025-12-19T03:28:39Z","title":"Fose: Fusion of One-Step Diffusion and End-to-End Network for Pansharpening","summary":"Pansharpening is a significant image fusion task that fuses low-resolution multispectral images (LRMSI) and high-resolution panchromatic images (PAN) to obtain high-resolution multispectral images (HRMSI). The development of the diffusion models (DM) and the end-to-end models (E2E model) has greatly improved the frontier of pansharping. DM takes the multi-step diffusion to obtain an accurate estimation of the residual between LRMSI and HRMSI. However, the multi-step process takes large computational power and is time-consuming. As for E2E models, their performance is still limited by the lack of prior and simple structure. In this paper, we propose a novel four-stage training strategy to obtain a lightweight network Fose, which fuses one-step DM and an E2E model. We perform one-step distillation on an enhanced SOTA DM for pansharping to compress the inference process from 50 steps to only 1 step. Then we fuse the E2E model with one-step DM with lightweight ensemble blocks. Comprehensive experiments are conducted to demonstrate the significant improvement of the proposed Fose on three commonly used benchmarks. Moreover, we achieve a 7.42 speedup ratio compared to the baseline DM while achieving much better performance. The code and model are released at https://github.com/Kai-Liu001/Fose.","authors":["Kai Liu","Zeli Lin","Weibo Wang","Linghe Kong","Yulun Zhang"],"pdf_url":"","comment":"Code link: https://github.com/Kai-Liu001/Fose"},{"id":"http://arxiv.org/abs/2411.15355v3","updated":"2025-12-19T03:24:39Z","published":"2024-11-22T21:59:46Z","title":"UniGaussian: Driving Scene Reconstruction from Multiple Camera Models via Unified Gaussian Representations","summary":"Urban scene reconstruction is crucial for real-world autonomous driving simulators. Although existing methods have achieved photorealistic reconstruction, they mostly focus on pinhole cameras and neglect fisheye cameras. In fact, how to effectively simulate fisheye cameras in driving scene remains an unsolved problem. In this work, we propose UniGaussian, a novel approach that learns a unified 3D Gaussian representation from multiple camera models for urban scene reconstruction in autonomous driving. Our contributions are two-fold. First, we propose a new differentiable rendering method that distorts 3D Gaussians using a series of affine transformations tailored to fisheye camera models. This addresses the compatibility issue of 3D Gaussian splatting with fisheye cameras, which is hindered by light ray distortion caused by lenses or mirrors. Besides, our method maintains real-time rendering while ensuring differentiability. Second, built on the differentiable rendering method, we design a new framework that learns a unified Gaussian representation from multiple camera models. By applying affine transformations to adapt different camera models and regularizing the shared Gaussians with supervision from different modalities, our framework learns a unified 3D Gaussian representation with input data from multiple sources and achieves holistic driving scene understanding. As a result, our approach models multiple sensors (pinhole and fisheye cameras) and modalities (depth, semantic, normal and LiDAR point clouds). Our experiments show that our method achieves superior rendering quality and fast rendering speed for driving scene simulation.","authors":["Yuan Ren","Guile Wu","Runhao Li","Zheyuan Yang","Yibo Liu","Xingxin Chen","Tongtong Cao","Bingbing Liu"],"pdf_url":"","comment":"3DV 2026"},{"id":"http://arxiv.org/abs/2512.17196v1","updated":"2025-12-19T03:20:59Z","published":"2025-12-19T03:20:59Z","title":"UmniBench: Unified Understand and Generation Model Oriented Omni-dimensional Benchmark","summary":"Unifying multimodal understanding and generation has shown impressive capabilities in cutting-edge proprietary systems. However, evaluations of unified multimodal models (UMMs) remain decoupled, assessing their understanding and generation abilities separately with corresponding datasets. To address this, we propose UmniBench, a benchmark tailored for UMMs with omni-dimensional evaluation. First, UmniBench can assess the understanding, generation, and editing ability within a single evaluation process. Based on human-examined prompts and QA pairs, UmniBench leverages UMM itself to evaluate its generation and editing ability with its understanding ability. This simple but effective paradigm allows comprehensive evaluation of UMMs. Second, UmniBench covers 13 major domains and more than 200 concepts, ensuring a thorough inspection of UMMs. Moreover, UmniBench can also decouple and separately evaluate understanding, generation, and editing abilities, providing a fine-grained assessment. Based on UmniBench, we benchmark 24 popular models, including both UMMs and single-ability large models. We hope this benchmark provides a more comprehensive and objective view of unified models and logistical support for improving the performance of the community model.","authors":["Kai Liu","Leyang Chen","Wenbo Li","Zhikai Chen","Zhixin Wang","Renjing Pei","Linghe Kong","Yulun Zhang"],"pdf_url":"","comment":"Project Page: https://umnibench.github.io/"},{"id":"http://arxiv.org/abs/2512.17194v1","updated":"2025-12-19T03:19:54Z","published":"2025-12-19T03:19:54Z","title":"MMRAG-RFT: Two-stage Reinforcement Fine-tuning for Explainable Multi-modal Retrieval-augmented Generation","summary":"Multi-modal Retrieval-Augmented Generation (MMRAG) enables highly credible generation by integrating external multi-modal knowledge, thus demonstrating impressive performance in complex multi-modal scenarios. However, existing MMRAG methods fail to clarify the reasoning logic behind retrieval and response generation, which limits the explainability of the results. To address this gap, we propose to introduce reinforcement learning into multi-modal retrieval-augmented generation, enhancing the reasoning capabilities of multi-modal large language models through a two-stage reinforcement fine-tuning framework to achieve explainable multi-modal retrieval-augmented generation. Specifically, in the first stage, rule-based reinforcement fine-tuning is employed to perform coarse-grained point-wise ranking of multi-modal documents, effectively filtering out those that are significantly irrelevant. In the second stage, reasoning-based reinforcement fine-tuning is utilized to jointly optimize fine-grained list-wise ranking and answer generation, guiding multi-modal large language models to output explainable reasoning logic in the MMRAG process. Our method achieves state-of-the-art results on WebQA and MultimodalQA, two benchmark datasets for multi-modal retrieval-augmented generation, and its effectiveness is validated through comprehensive ablation experiments.","authors":["Shengwei Zhao","Jingwen Yao","Sitong Wei","Linhai Xu","Yuying Liu","Dong Zhang","Zhiqiang Tian","Shaoyi Du"],"pdf_url":"","comment":"This paper was accepted to AAAI2026"},{"id":"http://arxiv.org/abs/2509.07414v3","updated":"2025-12-19T03:05:26Z","published":"2025-09-09T05:51:34Z","title":"Language Self-Play For Data-Free Training","summary":"Large language models (LLMs) have advanced rapidly in recent years, driven by scale, abundant high-quality training data, and reinforcement learning. Yet this progress faces a fundamental bottleneck: the need for ever more data from which models can continue to learn. In this work, we propose a reinforcement learning approach that removes this dependency by enabling models to improve without additional data. Our method leverages a game-theoretic framework of self-play, where a model's capabilities are cast as performance in a competitive game and stronger policies emerge by having the model play against itself-a process we call Language Self-Play (LSP). Experiments with Llama-3.2-3B-Instruct on instruction-following, mathematics, and coding benchmarks show that pretrained models can be effectively improved with self-play alone.","authors":["Jakub Grudzien Kuba","Mengting Gu","Qi Ma","Yuandong Tian","Vijai Mohan","Jason Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17185v1","updated":"2025-12-19T03:00:09Z","published":"2025-12-19T03:00:09Z","title":"Systemic Risk Radar: A Multi-Layer Graph Framework for Early Market Crash Warning","summary":"Financial crises emerge when structural vulnerabilities accumulate across sectors, markets, and investor behavior. Predicting these systemic transitions is challenging because they arise from evolving interactions between market participants, not isolated price movements alone. We present Systemic Risk Radar (SRR), a framework that models financial markets as multi-layer graphs to detect early signs of systemic fragility and crash-regime transitions.\n  We evaluate SRR across three major crises: the Dot-com crash, the Global Financial Crisis, and the COVID-19 shock. Our experiments compare snapshot GNNs, a simplified temporal GNN prototype, and standard baselines (logistic regression and Random Forest). Results show that structural network information provides useful early-warning signals compared to feature-based models alone.\n  This correlation-based instantiation of SRR demonstrates that graph-derived features capture meaningful changes in market structure during stress events. The findings motivate extending SRR with additional graph layers (sector/factor exposure, sentiment) and more expressive temporal architectures (LSTM/GRU or Transformer encoders) to better handle diverse crisis types.","authors":["Sandeep Neela"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2508.20705v2","updated":"2025-12-19T02:47:26Z","published":"2025-08-28T12:23:28Z","title":"EEGDM: Learning EEG Representation with Latent Diffusion Model","summary":"Recent advances in self-supervised learning for EEG representation have largely relied on masked reconstruction, where models are trained to recover randomly masked signal segments. While effective at modeling local dependencies, such objectives are inherently limited in capturing the global dynamics and long-range dependencies essential for characterizing neural activity. To address this limitation, we propose EEGDM, a novel self-supervised framework that leverages latent diffusion models to generate EEG signals as an objective. Unlike masked reconstruction, diffusion-based generation progressively denoises signals from noise to realism, compelling the model to capture holistic temporal patterns and cross-channel relationships. Specifically, EEGDM incorporates an EEG encoder that distills raw signals and their channel augmentations into a compact representation, acting as conditional information to guide the diffusion model for generating EEG signals. This design endows EEGDM with a compact latent space, which not only offers ample control over the generative process but also can be leveraged for downstream tasks. Experimental results show that EEGDM (1) reconstructs high-quality EEG signals, (2) learns robust representations, and (3) achieves competitive performance across diverse downstream tasks, thus exploring a new direction for self-supervised EEG representation learning.","authors":["Shaocong Wang","Tong Liu","Yihan Li","Ming Li","Kairui Wen","Pei Yang","Wenqi Ji","Minjing Yu","Yong-Jin Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17180v1","updated":"2025-12-19T02:38:04Z","published":"2025-12-19T02:38:04Z","title":"Conservative Bias in Multi-Teacher Learning: Why Agents Prefer Low-Reward Advisors","summary":"Interactive reinforcement learning (IRL) has shown promise in enabling autonomous agents and robots to learn complex behaviours from human teachers, yet the dynamics of teacher selection remain poorly understood. This paper reveals an unexpected phenomenon in IRL: when given a choice between teachers with different reward structures, learning agents overwhelmingly prefer conservative, low-reward teachers (93.16% selection rate) over those offering 20x higher rewards. Through 1,250 experimental runs in navigation tasks with multiple expert teachers, we discovered: (1) Conservative bias dominates teacher selection: agents systematically choose the lowest-reward teacher, prioritising consistency over optimality; (2) Critical performance thresholds exist at teacher availability rho >= 0.6 and accuracy omega >= 0.6, below which the framework fails catastrophically; (3) The framework achieves 159% improvement over baseline Q-learning under concept drift. These findings challenge fundamental assumptions about optimal teaching in RL and suggest potential implications for human-robot collaboration, where human preferences for safety and consistency may align with the observed agent selection behaviour, potentially informing training paradigms for safety-critical robotic applications.","authors":["Maher Mesto","Francisco Cruz"],"pdf_url":"","comment":"10 pages, 5 figures. Accepted at ACRA 2025 (Australasian Conference on Robotics and Automation)"},{"id":"http://arxiv.org/abs/2512.17172v1","updated":"2025-12-19T02:19:38Z","published":"2025-12-19T02:19:38Z","title":"PILAR: Personalizing Augmented Reality Interactions with LLM-based Human-Centric and Trustworthy Explanations for Daily Use Cases","summary":"Artificial intelligence (AI)-driven augmented reality (AR) systems are becoming increasingly integrated into daily life, and with this growth comes a greater need for explainability in real-time user interactions. Traditional explainable AI (XAI) methods, which often rely on feature-based or example-based explanations, struggle to deliver dynamic, context-specific, personalized, and human-centric insights for everyday AR users. These methods typically address separate explainability dimensions (e.g., when, what, how) with different explanation techniques, resulting in unrealistic and fragmented experiences for seamless AR interactions. To address this challenge, we propose PILAR, a novel framework that leverages a pre-trained large language model (LLM) to generate context-aware, personalized explanations, offering a more intuitive and trustworthy experience in real-time AI-powered AR systems. Unlike traditional methods, which rely on multiple techniques for different aspects of explanation, PILAR employs a unified LLM-based approach that dynamically adapts explanations to the user's needs, fostering greater trust and engagement. We implement the PILAR concept in a real-world AR application (e.g., personalized recipe recommendations), an open-source prototype that integrates real-time object detection, recipe recommendation, and LLM-based personalized explanations of the recommended recipes based on users' dietary preferences. We evaluate the effectiveness of PILAR through a user study with 16 participants performing AR-based recipe recommendation tasks, comparing an LLM-based explanation interface to a traditional template-based one. Results show that the LLM-based interface significantly enhances user performance and experience, with participants completing tasks 40% faster and reporting greater satisfaction, ease of use, and perceived transparency.","authors":["Ripan Kumar Kundu","Istiak Ahmed","Khaza Anuarul Hoque"],"pdf_url":"","comment":"Published in the 2025 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)"},{"id":"http://arxiv.org/abs/2502.01956v3","updated":"2025-12-19T02:05:30Z","published":"2025-02-04T03:05:55Z","title":"DHP: Discrete Hierarchical Planning for Hierarchical Reinforcement Learning Agents","summary":"Hierarchical Reinforcement Learning (HRL) agents often struggle with long-horizon visual planning due to their reliance on error-prone distance metrics. We propose Discrete Hierarchical Planning (DHP), a method that replaces continuous distance estimates with discrete reachability checks to evaluate subgoal feasibility. DHP recursively constructs tree-structured plans by decomposing long-term goals into sequences of simpler subtasks, using a novel advantage estimation strategy that inherently rewards shorter plans and generalizes beyond training depths. In addition, to address the data efficiency challenge, we introduce an exploration strategy that generates targeted training examples for the planning modules without needing expert data. Experiments in 25-room navigation environments demonstrate a 100% success rate (vs. 90% baseline). We also present an offline variant that achieves state-of-the-art results on OGBench benchmarks, with up to 71% absolute gains on giant HumanoidMaze tasks, demonstrating our core contributions are architecture-agnostic. The method also generalizes to momentum-based control tasks and requires only log N steps for replanning. Theoretical analysis and ablations validate our design choices.","authors":["Shashank Sharma","Janina Hoffmann","Vinay Namboodiri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17145v1","updated":"2025-12-19T00:43:49Z","published":"2025-12-19T00:43:49Z","title":"Solomonoff-Inspired Hypothesis Ranking with LLMs for Prediction Under Uncertainty","summary":"Reasoning under uncertainty is a key challenge in AI, especially for real-world tasks, where problems with sparse data demands systematic generalisation. Existing approaches struggle to balance accuracy and simplicity when evaluating multiple candidate solutions. We propose a Solomonoff-inspired method that weights LLM-generated hypotheses by simplicity and predictive fit. Applied to benchmark (Mini-ARC) tasks, our method produces Solomonoff-weighted mixtures for per-cell predictions, yielding conservative, uncertainty-aware outputs even when hypotheses are noisy or partially incorrect. Compared to Bayesian Model Averaging (BMA), Solomonoff scoring spreads probability more evenly across competing hypotheses, while BMA concentrates weight on the most likely but potentially flawed candidates. Across tasks, this highlights the value of algorithmic information-theoretic priors for interpretable, reliable multi-hypothesis reasoning under uncertainty.","authors":["Josh Barber","Rourke Young","Cameron Coombe","Will Browne"],"pdf_url":"","comment":"10 pages, ACRA 2025, Submitted, Accepted and Presented"},{"id":"http://arxiv.org/abs/2504.20196v2","updated":"2025-12-19T00:21:29Z","published":"2025-04-28T18:59:28Z","title":"Understanding and supporting how developers prompt for LLM-powered code editing in practice","summary":"Large Language Models (LLMs) are rapidly transforming software engineering, with coding assistants embedded in an IDE becoming increasingly prevalent. While research has focused on improving the tools and understanding developer perceptions, a critical gap exists in understanding how developers actually use these tools in their daily workflows, and, crucially, where they struggle. This paper addresses part of this gap through a multi-phased investigation of developer interactions with an LLM-powered code editing feature, Transform Code, in an IDE widely used at Google. First, we analyze telemetry logs of the feature usage, revealing that frequent re-prompting can be an indicator of developer struggles with using Transform Code. Second, we conduct a qualitative analysis of unsatisfactory requests, identifying five key categories of information often missing from developer prompts. Finally, based on these findings, we propose and evaluate a tool, AutoPrompter, for automatically improving prompts by inferring missing information from the surrounding code context, leading to a 27% improvement in edit correctness on our test set.","authors":["Daye Nam","Ahmed Omran","Ambar Murillo","Saksham Thakur","Abner Araujo","Marcel Blistein","Alexander Frömmgen","Vincent Hellendoorn","Satish Chandra"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17137v1","updated":"2025-12-19T00:09:32Z","published":"2025-12-19T00:09:32Z","title":"SDUM: A Scalable Deep Unrolled Model for Universal MRI Reconstruction","summary":"Clinical MRI encompasses diverse imaging protocols--spanning anatomical targets (cardiac, brain, knee), contrasts (T1, T2, mapping), sampling patterns (Cartesian, radial, spiral, kt-space), and acceleration factors--yet current deep learning reconstructions are typically protocol-specific, hindering generalization and deployment. We introduce Scalable Deep Unrolled Model (SDUM), a universal framework combining a Restormer-based reconstructor, a learned coil sensitivity map estimator (CSME), sampling-aware weighted data consistency (SWDC), universal conditioning (UC) on cascade index and protocol metadata, and progressive cascade expansion training. SDUM exhibits foundation-model-like scaling behavior: reconstruction quality follows PSNR ${\\sim}$ log(parameters) with correlation $r{=}0.986$ ($R^2{=}0.973$) up to 18 cascades, demonstrating predictable performance gains with model depth. A single SDUM trained on heterogeneous data achieves state-of-the-art results across all four CMRxRecon2025 challenge tracks--multi-center, multi-disease, 5T, and pediatric--without task-specific fine-tuning, surpassing specialized baselines by up to ${+}1.0$~dB. On CMRxRecon2024, SDUM outperforms the winning method PromptMR+ by ${+}0.55$~dB; on fastMRI brain, it exceeds PC-RNN by ${+}1.8$~dB. Ablations validate each component: SWDC ${+}0.43$~dB over standard DC, per-cascade CSME ${+}0.51$~dB, UC ${+}0.38$~dB. These results establish SDUM as a practical path toward universal, scalable MRI reconstruction.","authors":["Puyang Wang","Pengfei Guo","Keyi Chai","Jinyuan Zhou","Daguang Xu","Shanshan Jiang"],"pdf_url":"","comment":null}]},"2025-12-22T00:00:00Z":{"Distributed, Parallel, and Cluster Computing":[{"id":"http://arxiv.org/abs/2512.19606v1","updated":"2025-12-22T17:42:51Z","published":"2025-12-22T17:42:51Z","title":"RAPID-LLM: Resilience-Aware Performance analysis of Infrastructure for Distributed LLM Training and Inference","summary":"RAPID-LLM is a unified performance modeling framework for large language model (LLM) training and inference on GPU clusters. It couples a DeepFlow-based frontend that generates hardware-aware, operator-level Chakra execution traces from an abstract LLM specification (model shape, batch/sequence settings, training vs. inference, and hybrid parallelism choices) with an extended Astra-Sim backend that executes those traces on explicit multi-dimensional network topologies with congestion-aware routing and support for degraded and faulty links. The frontend assigns per-operator latency using a tile-based model that accounts for SM under-utilization and multi-level memory traffic (SRAM/ L2/ HBM), and prunes memory-infeasible configurations using an activation-liveness traversal under recomputation, parallelism and ZeRO/FDSP sharding policies.\n  Across A100-based validation cases, RAPID-LLM predicts Llama inference step latency and GPT-scale training time per batch within 10.4\\% relative to published measurements, and matches ns-3 packet-level results within 8\\% on representative communication workloads. Case studies demonstrate how RAPID-LLM enables fast, exhaustive sweeps over hybrid-parallel configurations, quantifies sensitivity to soft link faults under realistic routing and congestion, and evaluates hypothetical GPU design variants including HBM bandwidth throttling effects.","authors":["George Karfakis","Faraz Tahmasebi","Binglu Chen","Lime Yao","Saptarshi Mitra","Tianyue Pan","Hyoukjun Kwon","Puneet Gupta"],"pdf_url":"","comment":"11 pages, 12 figures"},{"id":"http://arxiv.org/abs/2504.06408v2","updated":"2025-12-22T15:22:18Z","published":"2025-04-08T20:04:32Z","title":"Parallel GPU-Enabled Algorithms for SpGEMM on Arbitrary Semirings with Hybrid Communication","summary":"Sparse General Matrix Multiply (SpGEMM) is key for various High-Performance Computing (HPC) applications such as genomics and graph analytics. Using the semiring abstraction, many algorithms can be formulated as SpGEMM, allowing redefinition of addition, multiplication, and numeric types. Today large input matrices require distributed memory parallelism to avoid disk I/O, and modern HPC machines with GPUs can greatly accelerate linear algebra computation. In this paper, we implement a GPU-based distributed-memory SpGEMM routine on top of the CombBLAS library. Our implementation achieves a speedup of over 2x compared to the CPU-only CombBLAS implementation and up to 3x compared to PETSc for large input matrices. Furthermore, we note that communication between processes can be optimized by either direct host-to-host or device-to-device communication, depending on the message size. To exploit this, we introduce a hybrid communication scheme that dynamically switches data paths depending on the message size, thus improving runtimes in communication-bound scenarios.","authors":["Thomas McFarland","Julian Bellavita","Giulia Guidi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19342v1","updated":"2025-12-22T12:36:54Z","published":"2025-12-22T12:36:54Z","title":"Faster Distributed Inference-Only Recommender Systems via Bounded Lag Synchronous Collectives","summary":"Recommender systems are enablers of personalized content delivery, and therefore revenue, for many large companies. In the last decade, deep learning recommender models (DLRMs) are the de-facto standard in this field. The main bottleneck in DLRM inference is the lookup of sparse features across huge embedding tables, which are usually partitioned across the aggregate RAM of many nodes. In state-of-the-art recommender systems, the distributed lookup is implemented via irregular all-to-all (alltoallv) communication, and often presents the main bottleneck. Today, most related work sees this operation as a given; in addition, every collective is synchronous in nature. In this work, we propose a novel bounded lag synchronous (BLS) version of the alltoallv operation. The bound can be a parameter allowing slower processes to lag behind entire iterations before the fastest processes block. In special applications such as inference-only DLRM, the accuracy of the application is fully preserved. We implement BLS alltoallv in a new PyTorch Distributed backend and evaluate it with a BLS version of the reference DLRM code. We show that for well balanced, homogeneous-access DLRM runs our BLS technique does not offer notable advantages. But for unbalanced runs, e.g. runs with strongly irregular embedding table accesses or with delays across different processes, our BLS technique improves both the latency and throughput of inference-only DLRM. In the best-case scenario, the proposed reduced synchronisation can mask the delays across processes altogether.","authors":["Kiril Dichev","Filip Pawlowski","Albert-Jan Yzelman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19326v1","updated":"2025-12-22T12:22:03Z","published":"2025-12-22T12:22:03Z","title":"Simulations between Strongly Sublinear MPC and Node-Capacitated Clique","summary":"We study how the strongly sublinear MPC model relates to the classic, graph-centric distributed models, focusing on the Node-Capacitated Clique (NCC), a bandwidth-parametrized generalization of the Congested Clique. In MPC, $M$ machines with per-machine memory $S$ hold a partition of the input graph, in NCC, each node knows its full neighborhood but can send/receive only a bounded number of $C$ words per round. We are particularly interested in the strongly sublinear regime where $S=C=n^δ$ for some constant $0 < δ<1$.\n  Our goal is determine when round-preserving simulations between these models are possible and when they are not, when total memory and total bandwidth $SM=nC$ in both models are matched, for different problem families and graph classes. On the positive side, we provide techniques that allow us to replicate the specific behavior regarding input representation, number of machines and local memory from one model to the other to obtain simulations with only constant overhead. On the negative side, we prove simulation impossibility results, which show that the limitations of our simulations are necessary.","authors":["Philipp Schneider","Julian Werthmann"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.04521v2","updated":"2025-12-22T11:48:52Z","published":"2025-03-06T15:08:31Z","title":"Dynamic Pricing for On-Demand DNN Inference in the Edge-AI Market","summary":"The convergence of edge computing and Artificial Intelligence (AI) gives rise to Edge-AI, which enables the deployment of real-time AI applications at the network edge. A key research challenge in Edge-AI is edge inference acceleration, which aims to realize low-latency high-accuracy Deep Neural Network (DNN) inference by offloading partitioned inference tasks from end devices to edge servers. However, existing research has yet to adopt a practical Edge-AI market perspective, which would explore the personalized inference needs of AI users (e.g., inference accuracy, latency, and task complexity), the revenue incentives for AI service providers that offer edge inference services, and multi-stakeholder governance within a market-oriented context. To bridge this gap, we propose an Auction-based Edge Inference Pricing Mechanism (AERIA) for revenue maximization to tackle the multi-dimensional optimization problem of DNN model partition, edge inference pricing, and resource allocation. We develop a multi-exit device-edge synergistic inference scheme for on-demand DNN inference acceleration, and theoretically analyze the auction dynamics amongst the AI service providers, AI users and edge infrastructure provider. Owing to the strategic mechanism design via randomized consensus estimate and cost sharing techniques, the Edge-AI market attains several desirable properties. These include competitiveness in revenue maximization, incentive compatibility, and envy-freeness, which are crucial to maintain the effectiveness, truthfulness, and fairness in auction outcomes. Extensive simulations based on four representative DNN inference workloads demonstrate that AERIA significantly outperforms several state-of-the-art approaches in revenue maximization. This validates the efficacy of AERIA for on-demand DNN inference in the Edge-AI market.","authors":["Songyuan Li","Jia Hu","Geyong Min","Haojun Huang","Jiwei Huang"],"pdf_url":"","comment":"Accepted for publication in IEEE Transactions on Mobile Computing. Index Terms: Edge-AI, DNN Inference Offloading, Resource Management, Dynamic Pricing, Auction Mechanism"},{"id":"http://arxiv.org/abs/2512.19179v1","updated":"2025-12-22T09:13:40Z","published":"2025-12-22T09:13:40Z","title":"L4: Low-Latency and Load-Balanced LLM Serving via Length-Aware Scheduling","summary":"Efficiently harnessing GPU compute is critical to improving user experience and reducing operational costs in large language model (LLM) services. However, current inference engine schedulers overlook the attention backend's sensitivity to request-length heterogeneity within a batch. As state-of-the-art models now support context windows exceeding 128K tokens, this once-tolerable inefficiency has escalated into a primary system bottleneck, causing severe performance degradation through GPU underutilization and increased latency. We present L4, a runtime system that dynamically reschedules requests across multiple instances serving the same LLM to mitigate per-instance length heterogeneity. L4 partitions these instances into length-specialized groups, each handling requests within a designated length range, naturally forming a pipeline as requests flow through them. L4 devises a dynamic programming algorithm to efficiently find the stage partition with the best QoE, employs runtime range refinement together with decentralized load (re)balance both across and within groups, achieving a balanced and efficient multi-instance service. Our evaluation shows that, under the same configuration, L4 reduces end-to-end latency by up to 67% and tail latency by up to 69%, while improving overall system throughput by up to 2.89 times compared to the state-of-the-art multi-instance scheduling systems.","authors":["Yitao Yuan","Chenqi Zhao","Bohan Zhao","Zane Cao","Yongchao He","Wenfei Wu"],"pdf_url":"","comment":"15 pages, 16 figures"},{"id":"http://arxiv.org/abs/2512.19131v1","updated":"2025-12-22T08:26:54Z","published":"2025-12-22T08:26:54Z","title":"Evidential Trust-Aware Model Personalization in Decentralized Federated Learning for Wearable IoT","summary":"Decentralized federated learning (DFL) enables collaborative model training across edge devices without centralized coordination, offering resilience against single points of failure. However, statistical heterogeneity arising from non-identically distributed local data creates a fundamental challenge: nodes must learn personalized models adapted to their local distributions while selectively collaborating with compatible peers. Existing approaches either enforce a single global model that fits no one well, or rely on heuristic peer selection mechanisms that cannot distinguish between peers with genuinely incompatible data distributions and those with valuable complementary knowledge. We present Murmura, a framework that leverages evidential deep learning to enable trust-aware model personalization in DFL. Our key insight is that epistemic uncertainty from Dirichlet-based evidential models directly indicates peer compatibility: high epistemic uncertainty when a peer's model evaluates local data reveals distributional mismatch, enabling nodes to exclude incompatible influence while maintaining personalized models through selective collaboration. Murmura introduces a trust-aware aggregation mechanism that computes peer compatibility scores through cross-evaluation on local validation samples and personalizes model aggregation based on evidential trust with adaptive thresholds. Evaluation on three wearable IoT datasets (UCI HAR, PAMAP2, PPG-DaLiA) demonstrates that Murmura reduces performance degradation from IID to non-IID conditions compared to baseline (0.9% vs. 19.3%), achieves 7.4$\\times$ faster convergence, and maintains stable accuracy across hyperparameter choices. These results establish evidential uncertainty as a principled foundation for compatibility-aware personalization in decentralized heterogeneous environments.","authors":["Murtaza Rangwala","Richard O. Sinnott","Rajkumar Buyya"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19103v1","updated":"2025-12-22T07:18:13Z","published":"2025-12-22T07:18:13Z","title":"Timely Parameter Updating in Over-the-Air Federated Learning","summary":"Incorporating over-the-air computations (OAC) into the model training process of federated learning (FL) is an effective approach to alleviating the communication bottleneck in FL systems. Under OAC-FL, every client modulates its intermediate parameters, such as gradient, onto the same set of orthogonal waveforms and simultaneously transmits the radio signal to the edge server. By exploiting the superposition property of multiple-access channels, the edge server can obtain an automatically aggregated global gradient from the received signal. However, the limited number of orthogonal waveforms available in practical systems is fundamentally mismatched with the high dimensionality of modern deep learning models. To address this issue, we propose Freshness Freshness-mAgnItude awaRe top-k (FAIR-k), an algorithm that selects, in each communication round, the most impactful subset of gradients to be updated over the air. In essence, FAIR-k combines the complementary strengths of the Round-Robin and Top-k algorithms, striking a delicate balance between timeliness (freshness of parameter updates) and importance (gradient magnitude). Leveraging tools from Markov analysis, we characterize the distribution of parameter staleness under FAIR-k. Building on this, we establish the convergence rate of OAC-FL with FAIR-k, which discloses the joint effect of data heterogeneity, channel noise, and parameter staleness on the training efficiency. Notably, as opposed to conventional analyses that assume a universal Lipschitz constant across all the clients, our framework adopts a finer-grained model of the data heterogeneity. The analysis demonstrates that since FAIR-k promotes fresh (and fair) parameter updates, it not only accelerates convergence but also enhances communication efficiency by enabling an extended period of local training without significantly affecting overall training efficiency.","authors":["Jiaqi Zhu","Zhongyuan Zhao","Xiao Li","Ruihao Du","Shi Jin","Howard H. Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.22714v2","updated":"2025-12-22T05:47:00Z","published":"2025-06-28T01:50:13Z","title":"Libra: Unleashing GPU Heterogeneity for High-Performance Sparse Matrix Multiplication","summary":"Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely used in deep learning and scientific computing. Modern accelerators are commonly equipped with Tensor Core Units (TCUs) and CUDA cores to accelerate sparse operators. The former excels at structured matrix computations, whereas the latter offers greater programming flexibility. However, how to combine these two resources to maximize sparse-operator performance remains unclear. In this work, we first identify the source of performance gains in hybrid computation and systematically analyze their complementary strengths. Motivated by this, we propose Libra, a holistic framework that efficiently leverages heterogeneous computing resources to accelerate both SpMM and SDDMM operators. Specifically, Libra introduces a 2D-aware (locality and utilization) workload distribution method to precisely identify the optimal task mapping, simultaneously leveraging the data reuse capabilities of TCUs and the flexibility of CUDA cores to minimize computational redundancy. Libra further incorporates hybrid load balancing, occupancy-aware task scheduling, and efficient kernel implementations to maximize execution efficiency. Extensive experiments on H100 and RTX 4090 GPUs demonstrate that Libra surpasses all the 12 up-to-date baselines significantly, e.g., on average 1.77x speedup over FlashSparse, 1.73x over RoDe, and 2.9x over DGL for end-to-end GNN applications. Libra opens up a new perspective for sparse operator acceleration by fully unleashing the power of heterogeneous GPU resources.","authors":["Jinliang Shi","Shigang Li","Youxuan Xu","Xueying Wang","Rongtian Fu","Zhi Ma","Tong Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.20068v3","updated":"2025-12-22T01:27:59Z","published":"2025-04-24T05:55:21Z","title":"JITServe: SLO-aware LLM Serving with Imprecise Request Information","summary":"The integration of Large Language Models (LLMs) into applications ranging from interactive chatbots to multi-agent systems has introduced a wide spectrum of service-level objectives (SLOs) for responsiveness. These include latency-sensitive requests emphasizing per-token latency in streaming chat, deadline-sensitive requests requiring rapid full responses to trigger external tools, and compound requests with evolving dependencies across multiple LLM calls. Despite-or perhaps, because of-this workload diversity and unpredictable request information (e.g., response lengths and dependencies), existing request schedulers have focused on aggregate performance, unable to ensure application-level SLO needs.\n  This paper presents JITServe, the first SLO-aware LLM serving system designed to maximize service goodput (e.g., the number of tokens meeting request SLOs) across diverse workloads. JITServe novelly schedules requests using imprecise request information and gradually relaxes this conservatism by refining request information estimates as generation progresses. It applies a grouped margin goodput maximization algorithm to allocate just enough serving bandwidth to satisfy each request's SLO just-in-time (JIT), maximizing residual capacity for others, while deciding the composition of requests in a batch to maximize efficiency and goodput with provable guarantees. Our evaluation across diverse realistic workloads, including chat, deep research, and agentic pipelines, shows that JITServe improves service goodput by 1.4x-6.3x, alternatively achieving 28.5%-83.2% resource savings, compared to state-of-the-art designs.","authors":["Wei Zhang","Zhiyu Wu","Yi Mu","Rui Ning","Banruo Liu","Nikhil Sarda","Myungjin Lee","Fan Lai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19851v1","updated":"2025-12-22T20:08:47Z","published":"2025-12-22T20:08:47Z","title":"An Adaptive Distributed Stencil Abstraction for GPUs","summary":"The scientific computing ecosystem in Python is largely confined to single-node parallelism, creating a gap between high-level prototyping in NumPy and high-performance execution on modern supercomputers. The increasing prevalence of hardware accelerators and the need for energy efficiency have made resource adaptivity a critical requirement, yet traditional HPC abstractions remain rigid. To address these challenges, we present an adaptive, distributed abstraction for stencil computations on multi-node GPUs. This abstraction is built using CharmTyles, a framework based on the adaptive Charm++ runtime, and features a familiar NumPy-like syntax to minimize the porting effort from prototype to production code. We showcase the resource elasticity of our abstraction by dynamically rescaling a running application across a different number of nodes and present a performance analysis of the associated overheads. Furthermore, we demonstrate that our abstraction achieves significant performance improvements over both a specialized, high-performance stencil DSL and a generalized NumPy replacement.","authors":["Aditya Bhosale","Laxmikant Kale"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19849v1","updated":"2025-12-22T20:05:09Z","published":"2025-12-22T20:05:09Z","title":"UCCL-EP: Portable Expert-Parallel Communication","summary":"Mixture-of-Experts (MoE) workloads rely on expert parallelism (EP) to achieve high GPU efficiency. State-of-the-art EP communication systems such as DeepEP demonstrate strong performance but exhibit poor portability across heterogeneous GPU and NIC platforms. The poor portability is rooted in architecture: GPU-initiated token-level RDMA communication requires tight vertical integration between GPUs and NICs, e.g., GPU writes to NIC driver/MMIO interfaces.\n  We present UCCL-EP, a portable EP communication system that delivers DeepEP-level performance across heterogeneous GPU and NIC hardware. UCCL-EP replaces GPU-initiated RDMA with a high-throughput GPU-CPU control channel: compact token-routing commands are transferred to multithreaded CPU proxies, which then issue GPUDirect RDMA operations on behalf of GPUs. UCCL-EP further emulates various ordering semantics required by specialized EP communication modes using RDMA immediate data, enabling correctness on NICs that lack such ordering, e.g., AWS EFA. We implement UCCL-EP on NVIDIA and AMD GPUs with EFA and Broadcom NICs. On EFA, it outperforms the best existing EP solution by up to $2.1\\times$ for dispatch and combine throughput. On NVIDIA-only platform, UCCL-EP achieves comparable performance to the original DeepEP. UCCL-EP also improves token throughput on SGLang by up to 40% on the NVIDIA+EFA platform, and improves DeepSeek-V3 training throughput over the AMD Primus/Megatron-LM framework by up to 45% on a 16-node AMD+Broadcom platform.","authors":["Ziming Mao","Yihan Zhang","Chihan Cui","Kaichao You","Zhongjie Chen","Zhiying Xu","Scott Shenker","Costin Raiciu","Yang Zhou","Ion Stoica"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19842v1","updated":"2025-12-22T19:54:14Z","published":"2025-12-22T19:54:14Z","title":"Holoscope: Open and Lightweight Distributed Telescope & Honeypot Platform","summary":"The complexity and scale of Internet attacks call for distributed, cooperative observatories capable of monitoring malicious traffic across diverse networks. Holoscope is a lightweight, cloud-native platform designed to simplify the deployment and management of distributed telescope (passive) and honeypot (active) sensors, used to collect and analyse attack traffic by exposing or simulating vulnerable systems. Built upon K3s and WireGuard, Holoscope offers secure connectivity, automated node onboarding, and resilient operation even in resource-constrained environments. Through modular design and Infrastructure-as-Code principles, it supports dynamic sensor orchestration, automated recovery and processing. We build, deploy and operate Holoscope across multiple institutions and cloud networks in Europe and Brazil, enabling unified visibility into large-scale attack phenomena while maintaining ease of integration and security compliance.","authors":["Andrea Sordello","Marco Mellia","Idilio Drago","Rodolfo Valentim","Francesco Musumeci","Massimo Tornatore","Federico Cerutti","Martino Trevisan","Alessio Botta","Willen Borges Coelho"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19777v1","updated":"2025-12-22T15:01:41Z","published":"2025-12-22T15:01:41Z","title":"Learned Digital Codes for Over-the-Air Computation in Federated Edge Learning","summary":"Federated edge learning (FEEL) enables wireless devices to collaboratively train a centralised model without sharing raw data, but repeated uplink transmission of model updates makes communication the dominant bottleneck. Over-the-air (OTA) aggregation alleviates this by exploiting the superposition property of the wireless channel, enabling simultaneous transmission and merging communication with computation. Digital OTA schemes extend this principle by incorporating the robustness of conventional digital communication, but current designs remain limited in low signal-to-noise ratio (SNR) regimes. This work proposes a learned digital OTA framework that improves recovery accuracy, convergence behaviour, and robustness to challenging SNR conditions while maintaining the same uplink overhead as state-of-the-art methods. The design integrates an unsourced random access (URA) codebook with vector quantisation and AMP-DA-Net, an unrolled approximate message passing (AMP)-style decoder trained end-to-end with the digital codebook and parameter server local training statistics. The proposed design extends OTA aggregation beyond averaging to a broad class of symmetric functions, including trimmed means and majority-based rules. Experiments on highly heterogeneous device datasets and varying numbers of active devices show that the proposed design extends reliable digital OTA operation by more than 10 dB into low SNR regimes while matching or improving performance across the full SNR range. The learned decoder remains effective under message corruption and nonlinear aggregation, highlighting the broader potential of end-to-end learned design for digital OTA communication in FEEL.","authors":["Antonio Tarizzo","Mohammad Kazemi","Deniz Gündüz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20687v1","updated":"2025-12-22T19:26:59Z","published":"2025-12-22T19:26:59Z","title":"PHOTON: Hierarchical Autoregressive Modeling for Lightspeed and Memory-Efficient Language Generation","summary":"Transformers operate as horizontal token-by-token scanners; at each generation step, the model attends to an ever-growing sequence of token-level states. This access pattern increases prefill latency and makes long-context decoding increasingly memory-bound, as KV-cache reads and writes dominate inference throughput rather than arithmetic computation. We propose Parallel Hierarchical Operation for Top-down Networks (PHOTON), a hierarchical autoregressive model that replaces flat scanning with vertical, multi-resolution context access. PHOTON maintains a hierarchy of latent streams: a bottom-up encoder progressively compresses tokens into low-rate contextual states, while lightweight top-down decoders reconstruct fine-grained token representations. Experimental results show that PHOTON is superior to competitive Transformer-based language models regarding the throughput-quality trade-off, offering significant advantages in long-context and multi-query tasks. This reduces decode-time KV-cache traffic, yielding up to $10^{3}\\times$ higher throughput per unit memory.","authors":["Yuma Ichikawa","Naoya Takagi","Takumi Nakagawa","Yuzi Kanazawa","Akira Sakai"],"pdf_url":"","comment":"12 pages, 5 figures"}],"Computation and Language":[{"id":"http://arxiv.org/abs/2512.19682v1","updated":"2025-12-22T18:57:13Z","published":"2025-12-22T18:57:13Z","title":"GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators","summary":"Training capable Large Language Model (LLM) agents is critically bottlenecked by the high cost and static nature of real-world interaction data. We address this by introducing GenEnv, a framework that establishes a difficulty-aligned co-evolutionary game between an agent and a scalable, generative environment simulator. Unlike traditional methods that evolve models on static datasets, GenEnv instantiates a dataevolving: the simulator acts as a dynamic curriculum policy, continuously generating tasks specifically tailored to the agent's ``zone of proximal development''. This process is guided by a simple but effective $α$-Curriculum Reward, which aligns task difficulty with the agent's current capabilities. We evaluate GenEnv on five benchmarks, including API-Bank, ALFWorld, BFCL, Bamboogle, and TravelPlanner. Across these tasks, GenEnv improves agent performance by up to \\textbf{+40.3\\%} over 7B baselines and matches or exceeds the average performance of larger models. Compared to Gemini 2.5 Pro-based offline data augmentation, GenEnv achieves better performance while using 3.3$\\times$ less data. By shifting from static supervision to adaptive simulation, GenEnv provides a data-efficient pathway for scaling agent capabilities.","authors":["Jiacheng Guo","Ling Yang","Peter Chen","Qixin Xiao","Yinjie Wang","Xinzhe Juan","Jiahao Qiu","Ke Shen","Mengdi Wang"],"pdf_url":"","comment":"Our codes are available at https://github.com/Gen-Verse/GenEnv"},{"id":"http://arxiv.org/abs/2510.09595v2","updated":"2025-12-22T18:56:01Z","published":"2025-10-10T17:54:24Z","title":"LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?","summary":"Competitive programming problems increasingly serve as valuable benchmarks to evaluate the coding capabilities of large language models (LLMs) due to their complexity and ease of verification. Yet, current coding benchmarks face limitations such as lack of exceptionally challenging problems, insufficient test case coverage, reliance on online platform APIs that limit accessibility. To address these issues, we introduce LiveOIBench, a comprehensive benchmark featuring 403 expert-curated Olympiad-level competitive programming problems, each with an average of 60 expert-designed test cases. The problems are sourced directly from 72 official contests of 14 Informatics Olympiads in different regions conducted between 2023 and 2025. LiveOIBench distinguishes itself through four key features: (1) meticulously curated high-quality tasks with detailed subtask rubrics and extensive private test cases; (2) direct integration of elite contestant performance data to enable informative comparison against top-performing humans; (3) planned continuous, contamination-free updates from newly released Olympiad problems; and (4) a self-contained evaluation system facilitating offline and easy-to-reproduce assessments. Benchmarking 34 popular general-purpose and reasoning LLMs, we find that GPT-5 achieves a notable 81.76th percentile, a strong result that nonetheless falls short of top human contestants, who usually place above 90th. In contrast, among open-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile, underscoring significant capability disparities from frontier closed models. Detailed analyses indicate that robust reasoning models prioritize precise problem analysis over excessive exploration, suggesting future models should emphasize structured analysis and minimize unnecessary exploration. All data, code, and leaderboard results are publicly available on our website.","authors":["Kaijian Zou","Aaron Xiong","Yunxiang Zhang","Frederick Zhang","Yueqi Ren","Jirong Yang","Ayoung Lee","Shitanshu Bhushan","Lu Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19673v1","updated":"2025-12-22T18:51:48Z","published":"2025-12-22T18:51:48Z","title":"Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies","summary":"Existing reinforcement learning (RL) approaches treat large language models (LLMs) as a single unified policy, overlooking their internal mechanisms. Understanding how policy evolves across layers and modules is therefore crucial for enabling more targeted optimization and raveling out complex reasoning mechanisms. In this paper, we decompose the language model policy by leveraging the intrinsic split of the Transformer residual stream and the equivalence between the composition of hidden states with the unembedding matrix and the resulting samplable policy. This decomposition reveals Internal Layer Policies, corresponding to contributions from individual layers, and Internal Modular Policies, which align with the self-attention and feed-forward network (FFN) components within each layer. By analyzing the entropy of internal policy, we find that: (a) Early layers keep high entropy for exploration, top layers converge to near-zero entropy for refinement, with convergence patterns varying across model series. (b) LLama's prediction space rapidly converges in the final layer, whereas Qwen-series models, especially Qwen3, exhibit a more human-like, progressively structured reasoning pattern. Motivated by these findings, we propose Bottom-up Policy Optimization (BuPO), a novel RL paradigm that directly optimizes the internal layer policy during early training. By aligning training objective at lower layer, BuPO reconstructs foundational reasoning capabilities and achieves superior performance. Extensive experiments on complex reasoning benchmarks demonstrates the effectiveness of our method. Our code is available at https://github.com/Trae1ounG/BuPO.","authors":["Yuqiao Tan","Minzheng Wang","Shizhu He","Huanxuan Liao","Chengfeng Zhao","Qiunan Lu","Tian Liang","Jun Zhao","Kang Liu"],"pdf_url":"","comment":"Preprint. Our code is available at https://github.com/Trae1ounG/BuPO"},{"id":"http://arxiv.org/abs/2512.19651v1","updated":"2025-12-22T18:23:37Z","published":"2025-12-22T18:23:37Z","title":"Exploring Zero-Shot ACSA with Unified Meaning Representation in Chain-of-Thought Prompting","summary":"Aspect-Category Sentiment Analysis (ACSA) provides granular insights by identifying specific themes within reviews and their associated sentiment. While supervised learning approaches dominate this field, the scarcity and high cost of annotated data for new domains present significant barriers. We argue that leveraging large language models (LLMs) in a zero-shot setting is a practical alternative where resources for data annotation are limited. In this work, we propose a novel Chain-of-Thought (CoT) prompting technique that utilises an intermediate Unified Meaning Representation (UMR) to structure the reasoning process for the ACSA task. We evaluate this UMR-based approach against a standard CoT baseline across three models (Qwen3-4B, Qwen3-8B, and Gemini-2.5-Pro) and four diverse datasets. Our findings suggest that UMR effectiveness may be model-dependent. Whilst preliminary results indicate comparable performance for mid-sized models such as Qwen3-8B, these observations warrant further investigation, particularly regarding the potential applicability to smaller model architectures. Further research is required to establish the generalisability of these findings across different model scales.","authors":["Filippos Ventirozos","Peter Appleby","Matthew Shardlow"],"pdf_url":"","comment":"9 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2512.19630v1","updated":"2025-12-22T18:04:24Z","published":"2025-12-22T18:04:24Z","title":"Diacritic Restoration for Low-Resource Indigenous Languages: Case Study with Bribri and Cook Islands Māori","summary":"We present experiments on diacritic restoration, a form of text normalization essential for natural language processing (NLP) tasks. Our study focuses on two extremely under-resourced languages: Bribri, a Chibchan language spoken in Costa Rica, and Cook Islands Māori, a Polynesian language spoken in the Cook Islands. Specifically, this paper: (i) compares algorithms for diacritics restoration in under-resourced languages, including tonal diacritics, (ii) examines the amount of data required to achieve target performance levels, (iii) contrasts results across varying resource conditions, and (iv) explores the related task of diacritic correction. We find that fine-tuned, character-level LLMs perform best, likely due to their ability to decompose complex characters into their UTF-8 byte representations. In contrast, massively multilingual models perform less effectively given our data constraints. Across all models, reliable performance begins to emerge with data budgets of around 10,000 words. Zero-shot approaches perform poorly in all cases. This study responds both to requests from the language communities and to broader NLP research questions concerning model performance and generalization in under-resourced contexts.","authors":["Rolando Coto-Solano","Daisy Li","Manoela Teleginski Ferraz","Olivia Sasse","Cha Krupka","Sharid Loáiciga","Sally Akevai Tenamu Nicholas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19620v1","updated":"2025-12-22T17:54:49Z","published":"2025-12-22T17:54:49Z","title":"Exploring the features used for summary evaluation by Human and GPT","summary":"Summary assessment involves evaluating how well a generated summary reflects the key ideas and meaning of the source text, requiring a deep understanding of the content. Large Language Models (LLMs) have been used to automate this process, acting as judges to evaluate summaries with respect to the original text. While previous research investigated the alignment between LLMs and Human responses, it is not yet well understood what properties or features are exploited by them when asked to evaluate based on a particular quality dimension, and there has not been much attention towards mapping between evaluation scores and metrics. In this paper, we address this issue and discover features aligned with Human and Generative Pre-trained Transformers (GPTs) responses by studying statistical and machine learning metrics. Furthermore, we show that instructing GPTs to employ metrics used by Human can improve their judgment and conforming them better with human responses.","authors":["Zahra Sadeghi","Evangelos Milios","Frank Rudzicz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19612v1","updated":"2025-12-22T17:47:49Z","published":"2025-12-22T17:47:49Z","title":"MauBERT: Universal Phonetic Inductive Biases for Few-Shot Acoustic Units Discovery","summary":"This paper introduces MauBERT, a multilingual extension of HuBERT that leverages articulatory features for robust cross-lingual phonetic representation learning. We continue HuBERT pre-training with supervision based on a phonetic-to-articulatory feature mapping in 55 languages. Our models learn from multilingual data to predict articulatory features or phones, resulting in language-independent representations that capture multilingual phonetic properties. Through comprehensive ABX discriminability testing, we show MauBERT models produce more context-invariant representations than state-of-the-art multilingual self-supervised learning models. Additionally, the models effectively adapt to unseen languages and casual speech with minimal self-supervised fine-tuning (10 hours of speech). This establishes an effective approach for instilling linguistic inductive biases in self-supervised speech models.","authors":["Angelo Ortiz Tandazo","Manel Khentout","Youssef Benchekroun","Thomas Hueber","Emmanuel Dupoux"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.05594v2","updated":"2025-12-22T17:37:53Z","published":"2025-06-05T21:12:51Z","title":"SoK: Are Watermarks in LLMs Ready for Deployment?","summary":"Large Language Models (LLMs) have transformed natural language processing, demonstrating impressive capabilities across diverse tasks. However, deploying these models introduces critical risks related to intellectual property violations and potential misuse, particularly as adversaries can imitate these models to steal services or generate misleading outputs. We specifically focus on model stealing attacks, as they are highly relevant to proprietary LLMs and pose a serious threat to their security, revenue, and ethical deployment. While various watermarking techniques have emerged to mitigate these risks, it remains unclear how far the community and industry have progressed in developing and deploying watermarks in LLMs.\n  To bridge this gap, we aim to develop a comprehensive systematization for watermarks in LLMs by 1) presenting a detailed taxonomy for watermarks in LLMs, 2) proposing a novel intellectual property classifier to explore the effectiveness and impacts of watermarks on LLMs under both attack and attack-free environments, 3) analyzing the limitations of existing watermarks in LLMs, and 4) discussing practical challenges and potential future directions for watermarks in LLMs. Through extensive experiments, we show that despite promising research outcomes and significant attention from leading companies and community to deploy watermarks, these techniques have yet to reach their full potential in real-world applications due to their unfavorable impacts on model utility of LLMs and downstream tasks. Our findings provide an insightful understanding of watermarks in LLMs, highlighting the need for practical watermarks solutions tailored to LLM deployment.","authors":["Kieu Dang","Phung Lai","NhatHai Phan","Yelong Shen","Ruoming Jin","Abdallah Khreishah","My T. Thai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19585v1","updated":"2025-12-22T17:12:04Z","published":"2025-12-22T17:12:04Z","title":"Increasing the Thinking Budget is Not All You Need","summary":"Recently, a new wave of thinking-capable Large Language Models has emerged, demonstrating exceptional capabilities across a wide range of reasoning benchmarks. Early studies have begun to explore how the amount of compute in terms of the length of the reasoning process, the so-called thinking budget, impacts model performance. In this work, we propose a systematic investigation of the thinking budget as a key parameter, examining its interaction with various configurations such as self-consistency, reflection, and others. Our goal is to provide an informative, balanced comparison framework that considers both performance outcomes and computational cost. Among our findings, we discovered that simply increasing the thinking budget is not the most effective use of compute. More accurate responses can instead be achieved through alternative configurations, such as self-consistency and self-reflection.","authors":["Ignacio Iacobacci","Zhaozhi Qian","Faroq AL-Tam","Muhammad AL-Qurishi","Riad Souissi"],"pdf_url":"","comment":"4 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2509.20490v3","updated":"2025-12-22T17:02:44Z","published":"2025-09-24T19:08:01Z","title":"RadAgents: Multimodal Agentic Reasoning for Chest X-ray Interpretation with Radiologist-like Workflows","summary":"Agentic systems offer a potential path to solve complex clinical tasks through collaboration among specialized agents, augmented by tool use and external knowledge bases. Nevertheless, for chest X-ray (CXR) interpretation, prevailing methods remain limited: (i) reasoning is frequently neither clinically interpretable nor aligned with guidelines, reflecting mere aggregation of tool outputs; (ii) multimodal evidence is insufficiently fused, yielding text-only rationales that are not visually grounded; and (iii) systems rarely detect or resolve cross-tool inconsistencies and provide no principled verification mechanisms. To bridge the above gaps, we present RadAgents, a multi-agent framework that couples clinical priors with task-aware multimodal reasoning and encodes a radiologist-style workflow into a modular, auditable pipeline. In addition, we integrate grounding and multimodal retrieval-augmentation to verify and resolve context conflicts, resulting in outputs that are more reliable, transparent, and consistent with clinical practice.","authors":["Kai Zhang","Corey D Barrett","Jangwon Kim","Lichao Sun","Tara Taghavi","Krishnaram Kenthapadi"],"pdf_url":"","comment":"ML4H'25; Work in progress"},{"id":"http://arxiv.org/abs/2409.20302v6","updated":"2025-12-22T16:29:48Z","published":"2024-09-30T14:00:04Z","title":"OM4OV: Leveraging Ontology Matching for Ontology Versioning","summary":"Due to the dynamic nature of the Semantic Web, version control is necessary to capture time-varying information for widely used ontologies. Despite the long-standing recognition of ontology versioning (OV) as a crucial component of efficient ontology management, many approaches treat OV as similar to ontology matching (OM) and directly reuse OM systems for OV tasks. In this study, we systematically analyse the similarities and differences between OM and OV and formalise the OM4OV pipeline. The pipeline is implemented and evaluated in the state-of-the-art OM system Agent-OM. The experimental results indicate that OM systems can be reused for OV tasks, but without necessary extensions, the current OM4OV pipeline can produce skewed measurements, poor performance in detecting update entities, and limited explainability for false mappings. To tackle these issues, we propose an optimisation method called the cross-reference (CR) mechanism, building upon the existing alignments from OM to reduce the number of matching candidates and improve overall OV performance.","authors":["Zhangcheng Qiang","Kerry Taylor","Weiqing Wang"],"pdf_url":"","comment":"16 pages, 8 figures, 1 table"},{"id":"http://arxiv.org/abs/2512.19543v1","updated":"2025-12-22T16:26:15Z","published":"2025-12-22T16:26:15Z","title":"Algerian Dialect","summary":"We present Algerian Dialect, a large-scale sentiment-annotated dataset consisting of 45,000 YouTube comments written in Algerian Arabic dialect. The comments were collected from more than 30 Algerian press and media channels using the YouTube Data API. Each comment is manually annotated into one of five sentiment categories: very negative, negative, neutral, positive, and very positive. In addition to sentiment labels, the dataset includes rich metadata such as collection timestamps, like counts, video URLs, and annotation dates. This dataset addresses the scarcity of publicly available resources for Algerian dialect and aims to support research in sentiment analysis, dialectal Arabic NLP, and social media analytics. The dataset is publicly available on Mendeley Data under a CC BY 4.0 license at https://doi.org/10.17632/zzwg3nnhsz.2.","authors":["Zakaria Benmounah","Abdennour Boulesnane"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16401v2","updated":"2025-12-22T16:22:23Z","published":"2025-12-18T10:56:27Z","title":"Navigating the Reality Gap: Privacy-Preserving Adaptation of ASR for Challenging Low-Resource Domains","summary":"Automatic Speech Recognition (ASR) holds immense potential to assist in clinical documentation and patient report generation, particularly in resource-constrained regions. However, deployment is currently hindered by a technical deadlock: a severe \"Reality Gap\" between laboratory performance and noisy, real-world clinical audio, coupled with strict privacy and resource constraints. We quantify this gap, showing that a robust multilingual model (IndicWav2Vec) degrades to a 40.94% WER on rural clinical data from India, rendering it unusable. To address this, we explore a zero-data-exfiltration framework enabling localized, continual adaptation via Low-Rank Adaptation (LoRA). We conduct a rigorous investigative study of continual learning strategies, characterizing the trade-offs between data-driven and parameter-driven stability. Our results demonstrate that multi-domain Experience Replay (ER) yields the primary performance gains, achieving a 17.1% relative improvement in target WER and reducing catastrophic forgetting by 55% compared to naive adaptation. Furthermore, we observed that standard Elastic Weight Consolidation (EWC) faced numerical stability challenges when applied to LoRA in noisy environments. Our experiments show that a stabilized, linearized formulation effectively controls gradient magnitudes and enables stable convergence. Finally, we verify via a domain-specific spot check that acoustic adaptation is a fundamental prerequisite for usability which cannot be bypassed by language models alone.","authors":["Darshil Chauhan","Adityasinh Solanki","Vansh Patel","Kanav Kapoor","Ritvik Jain","Aditya Bansal","Pratik Narang","Dhruv Kumar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19537v1","updated":"2025-12-22T16:22:14Z","published":"2025-12-22T16:22:14Z","title":"Event Extraction in Large Language Model","summary":"Large language models (LLMs) and multimodal LLMs are changing event extraction (EE): prompting and generation can often produce structured outputs in zero shot or few shot settings. Yet LLM based pipelines face deployment gaps, including hallucinations under weak constraints, fragile temporal and causal linking over long contexts and across documents, and limited long horizon knowledge management within a bounded context window. We argue that EE should be viewed as a system component that provides a cognitive scaffold for LLM centered solutions. Event schemas and slot constraints create interfaces for grounding and verification; event centric structures act as controlled intermediate representations for stepwise reasoning; event links support relation aware retrieval with graph based RAG; and event stores offer updatable episodic and agent memory beyond the context window. This survey covers EE in text and multimodal settings, organizing tasks and taxonomy, tracing method evolution from rule based and neural models to instruction driven and generative frameworks, and summarizing formulations, decoding strategies, architectures, representations, datasets, and evaluation. We also review cross lingual, low resource, and domain specific settings, and highlight open challenges and future directions for reliable event centric systems. Finally, we outline open challenges and future directions that are central to the LLM era, aiming to evolve EE from static extraction into a structurally reliable, agent ready perception and memory layer for open world systems.","authors":["Bobo Li","Xudong Han","Jiang Liu","Yuzhe Ding","Liqiang Jing","Zhaoqi Zhang","Jinheng Li","Xinya Du","Fei Li","Meishan Zhang","Min Zhang","Aixin Sun","Philip S. Yu","Hao Fei"],"pdf_url":"","comment":"38 pages, 9 Figures, 5 Tables"},{"id":"http://arxiv.org/abs/2402.08971v3","updated":"2025-12-22T16:15:22Z","published":"2024-02-14T06:33:22Z","title":"Structured Language Generation Model: Loss Calibration and Formatted Decoding for Robust Structure Prediction and Knowledge Retrieval","summary":"Modern generative pre-trained language models excel at open-ended text generation, yet continue to underperform on structure-related tasks such as NER, relation extraction, and semantic role labeling, especially when compared to encoder-only models of similar sizes. While this gap has been attributed to limited structure knowledge, we hypothesize this is also due to the missing connection between the model's internal representations of linguistic structure and the output space used during supervised fine-tuning. We propose the Structured Language Generation Model (SLGM), a model- and task-agnostic framework that reformulates structured prediction as a classification problem through three components: (1) reinforced input formatting with structural cues, (2) loss design, and (3) format-aware decoding that constrains generation to task-valid outputs. Across 5 tasks and 13 datasets, SLGM substantially improves structure prediction without relying on dataset-specific engineering or additional model parameters, strengthening alignment between the model's internal structure representation and output. It outperforms baseline fine-tuning on models of the same size, achieves comparable performance to much larger models when used with <1B parameter models, and acts as a zero-weight adapter that reproduces the benefits of dataset-specific fine-tuning in low-resource settings.","authors":["Minho Lee","Junghyun Min","Yerang Kim","Woochul Lee","Yeonsoo Lee"],"pdf_url":"","comment":"20 pages, 4 figures. FrontierIR at AAAI 2026"},{"id":"http://arxiv.org/abs/2509.23863v2","updated":"2025-12-22T16:06:03Z","published":"2025-09-28T13:08:10Z","title":"SPELL: Self-Play Reinforcement Learning for evolving Long-Context Language Models","summary":"Progress in long-context reasoning for large language models (LLMs) has lagged behind other recent advances. This gap arises not only from the intrinsic difficulty of processing long texts, but also from the scarcity of reliable human annotations and programmatically verifiable reward signals. In this paper, we propose SPELL, a multi-role self-play reinforcement learning framework that enables scalable, label-free optimization for long-context reasoning. SPELL integrates three cyclical roles-questioner, responder, and verifier-within a single model to enable continual self-improvement. The questioner generates questions from raw documents paired with reference answers; the responder learns to solve these questions based on the documents; and the verifier evaluates semantic equivalence between the responder's output and the questioner's reference answer, producing reward signals to guide continual training. To stabilize training, we introduce an automated curriculum that gradually increases document length and a reward function that adapts question difficulty to the model's evolving capabilities. Extensive experiments on six long-context benchmarks show that SPELL consistently improves performance across diverse LLMs and outperforms equally sized models fine-tuned on large-scale annotated data. Notably, SPELL achieves an average 7.6-point gain in pass@8 on the strong reasoning model Qwen3-30B-A3B-Thinking, raising its performance ceiling and showing promise for scaling to even more capable models.","authors":["Ziyi Yang","Weizhou Shen","Chenliang Li","Ruijun Chen","Fanqi Wan","Ming Yan","Xiaojun Quan","Fei Huang"],"pdf_url":"","comment":"Preprint under review"},{"id":"http://arxiv.org/abs/2505.20063v2","updated":"2025-12-22T15:49:59Z","published":"2025-05-26T14:47:59Z","title":"SAEs Are Good for Steering -- If You Select the Right Features","summary":"Sparse Autoencoders (SAEs) have been proposed as an unsupervised approach to learn a decomposition of a model's latent space. This enables useful applications such as steering - influencing the output of a model towards a desired concept - without requiring labeled data. Current methods identify SAE features to steer by analyzing the input tokens that activate them. However, recent work has highlighted that activations alone do not fully describe the effect of a feature on the model's output. In this work, we draw a distinction between two types of features: input features, which mainly capture patterns in the model's input, and output features, which have a human-understandable effect on the model's output. We propose input and output scores to characterize and locate these types of features, and show that high values for both scores rarely co-occur in the same features. These findings have practical implications: after filtering out features with low output scores, we obtain 2-3x improvements when steering with SAEs, making them competitive with supervised methods.","authors":["Dana Arad","Aaron Mueller","Yonatan Belinkov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19475v1","updated":"2025-12-22T15:28:55Z","published":"2025-12-22T15:28:55Z","title":"A Large-Language-Model Framework for Automated Humanitarian Situation Reporting","summary":"Timely and accurate situational reports are essential for humanitarian decision-making, yet current workflows remain largely manual, resource intensive, and inconsistent. We present a fully automated framework that uses large language models (LLMs) to transform heterogeneous humanitarian documents into structured and evidence-grounded reports. The system integrates semantic text clustering, automatic question generation, retrieval augmented answer extraction with citations, multi-level summarization, and executive summary generation, supported by internal evaluation metrics that emulate expert reasoning. We evaluated the framework across 13 humanitarian events, including natural disasters and conflicts, using more than 1,100 documents from verified sources such as ReliefWeb. The generated questions achieved 84.7 percent relevance, 84.0 percent importance, and 76.4 percent urgency. The extracted answers reached 86.3 percent relevance, with citation precision and recall both exceeding 76 percent. Agreement between human and LLM based evaluations surpassed an F1 score of 0.80. Comparative analysis shows that the proposed framework produces reports that are more structured, interpretable, and actionable than existing baselines. By combining LLM reasoning with transparent citation linking and multi-level evaluation, this study demonstrates that generative AI can autonomously produce accurate, verifiable, and operationally useful humanitarian situation reports.","authors":["Ivan Decostanzi","Yelena Mejova","Kyriaki Kalimeri"],"pdf_url":"","comment":"18 pages, 3 figures"},{"id":"http://arxiv.org/abs/2512.19466v1","updated":"2025-12-22T15:20:21Z","published":"2025-12-22T15:20:21Z","title":"Epistemological Fault Lines Between Human and Artificial Intelligence","summary":"Large language models (LLMs) are widely described as artificial intelligence, yet their epistemic profile diverges sharply from human cognition. Here we show that the apparent alignment between human and machine outputs conceals a deeper structural mismatch in how judgments are produced. Tracing the historical shift from symbolic AI and information filtering systems to large-scale generative transformers, we argue that LLMs are not epistemic agents but stochastic pattern-completion systems, formally describable as walks on high-dimensional graphs of linguistic transitions rather than as systems that form beliefs or models of the world. By systematically mapping human and artificial epistemic pipelines, we identify seven epistemic fault lines, divergences in grounding, parsing, experience, motivation, causal reasoning, metacognition, and value. We call the resulting condition Epistemia: a structural situation in which linguistic plausibility substitutes for epistemic evaluation, producing the feeling of knowing without the labor of judgment. We conclude by outlining consequences for evaluation, governance, and epistemic literacy in societies increasingly organized around generative AI.","authors":["Walter Quattrociocchi","Valerio Capraro","Matjaž Perc"],"pdf_url":"","comment":"16 pages, 1 figure"},{"id":"http://arxiv.org/abs/2512.19456v1","updated":"2025-12-22T15:01:07Z","published":"2025-12-22T15:01:07Z","title":"Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations","summary":"Automated essay scoring (AES) is a challenging task in cross-prompt settings due to the diversity of scoring criteria. While previous studies have focused on the output of large language models (LLMs) to improve scoring accuracy, we believe activations from intermediate layers may also provide valuable information. To explore this possibility, we evaluated the discriminative power of LLMs' activations in cross-prompt essay scoring task. Specifically, we used activations to fit probes and further analyzed the effects of different models and input content of LLMs on this discriminative power. By computing the directions of essays across various trait dimensions under different prompts, we analyzed the variation in evaluation perspectives of large language models concerning essay types and traits. Results show that the activations possess strong discriminative power in evaluating essay quality and that LLMs can adapt their evaluation perspectives to different traits and essay types, effectively handling the diversity of scoring criteria in cross-prompt settings.","authors":["Jinwei Chi","Ke Wang","Yu Chen","Xuanye Lin","Qiang Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19455v1","updated":"2025-12-22T15:00:25Z","published":"2025-12-22T15:00:25Z","title":"SiamGPT: Quality-First Fine-Tuning for Stable Thai Text Generation","summary":"Open-weights large language models remain difficult to deploy for Thai due to unstable generation under complex instructions, despite strong English performance. To mitigate these limitations, We present SiamGPT-32B, an open-weights model based on Qwen3-32B, fine-tuned with a Quality-First strategy emphasizing curated supervision over data scale. The fine-tuning pipeline combines translated high-complexity English instruction data with a Thai-adapted AutoIF framework for instruction and linguistic constraints. Using supervised fine-tuning only, without continual pretraining or corpus expansion, SiamGPT-32B improves instruction adherence, multi-turn robustness, and linguistic stability. Evaluations on the SEA-HELM benchmark show that SiamGPT-32B achieves the strongest overall performance among similar-scale open-weights Thai models, with consistent gains in instruction following, multi-turn dialogue, and natural language understanding.","authors":["Thittipat Pairatsuppawat","Abhibhu Tachaapornchai","Paweekorn Kusolsomboon","Chutikan Chaiwong","Thodsaporn Chay-intr","Kobkrit Viriyayudhakorn","Nongnuch Ketui","Aslan B. Wong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19432v1","updated":"2025-12-22T14:31:28Z","published":"2025-12-22T14:31:28Z","title":"MobileWorld: Benchmarking Autonomous Mobile Agents in Agent-User Interactive, and MCP-Augmented Environments","summary":"Among existing online mobile-use benchmarks, AndroidWorld has emerged as the dominant benchmark due to its reproducible environment and deterministic evaluation; however, recent agents achieving over 90% success rates indicate its saturation and motivate the need for a more challenging benchmark. In addition, its environment lacks key application categories, such as e-commerce and enterprise communication, and does not reflect realistic mobile-use scenarios characterized by vague user instructions and hybrid tool usage. To bridge this gap, we introduce MobileWorld, a substantially more challenging benchmark designed to better reflect real-world mobile usage, comprising 201 tasks across 20 applications, while maintaining the same level of reproducible evaluation as AndroidWorld. The difficulty of MobileWorld is twofold. First, it emphasizes long-horizon tasks with cross-application interactions: MobileWorld requires nearly twice as many task-completion steps on average (27.8 vs. 14.3) and includes far more multi-application tasks (62.2% vs. 9.5%) compared to AndroidWorld. Second, MobileWorld extends beyond standard GUI manipulation by introducing novel task categories, including agent-user interaction and MCP-augmented tasks. To ensure robust evaluation, we provide snapshot-based container environment and precise functional verifications, including backend database inspection and task callback APIs. We further develop a planner-executor agentic framework with extended action spaces to support user interactions and MCP calls. Our results reveal a sharp performance drop compared to AndroidWorld, with the best agentic framework and end-to-end model achieving 51.7% and 20.9% success rates, respectively. Our analysis shows that current models struggle significantly with user interaction and MCP calls, offering a strategic roadmap toward more robust, next-generation mobile intelligence.","authors":["Quyu Kong","Xu Zhang","Zhenyu Yang","Nolan Gao","Chen Liu","Panrong Tong","Chenglin Cai","Hanzhang Zhou","Jianan Zhang","Liangyu Chen","Zhidan Liu","Steven Hoi","Yue Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.18822v2","updated":"2025-12-22T14:30:53Z","published":"2025-05-24T18:46:50Z","title":"AdaCtrl: Towards Adaptive and Controllable Reasoning via Difficulty-Aware Budgeting","summary":"Modern large reasoning models demonstrate impressive problem-solving capabilities by employing sophisticated reasoning strategies. However, they often struggle to balance efficiency and effectiveness, frequently generating unnecessarily lengthy reasoning chains for simple problems. In this work, we propose AdaCtrl, a novel framework to support both difficulty-aware adaptive reasoning budget allocation and explicit user control over reasoning depth. AdaCtrl dynamically adjusts its reasoning length based on self-assessed problem difficulty, while also allowing users to manually control the budget to prioritize either efficiency or effectiveness. This is achieved through a two-stage training pipeline: an initial cold-start fine-tuning phase to instill the ability to self-aware difficulty and adjust reasoning budget, followed by a difficulty-aware reinforcement learning (RL) stage that refines the model's adaptive reasoning strategies and calibrates its difficulty assessments based on its evolving capabilities during online training. To enable intuitive user interaction, we design explicit length-triggered tags that function as a natural interface for budget control. Empirical results show that AdaCtrl adapts reasoning length based on estimated difficulty, compared to the standard training baseline that also incorporates fine-tuning and RL, it yields performance improvements and simultaneously reduces response length by 10.06% and 12.14% on the more challenging AIME2024 and AIME2025 datasets, which require elaborate reasoning, and by 62.05% and 91.04% on the MATH500 and GSM8K datasets, where more concise responses are sufficient. Furthermore, AdaCtrl enables precise user control over the reasoning budget, allowing for tailored responses to meet specific needs.","authors":["Shijue Huang","Hongru Wang","Wanjun Zhong","Zhaochen Su","Jiazhan Feng","Bowen Cao","Yi R. Fung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19424v1","updated":"2025-12-22T14:27:17Z","published":"2025-12-22T14:27:17Z","title":"CodeSimpleQA: Scaling Factuality in Code Large Language Models","summary":"Large language models (LLMs) have made significant strides in code generation, achieving impressive capabilities in synthesizing code snippets from natural language instructions. However, a critical challenge remains in ensuring LLMs generate factually accurate responses about programming concepts, technical implementations, etc. Most previous code-related benchmarks focus on code execution correctness, overlooking the factual accuracy of programming knowledge. To address this gap, we present CodeSimpleQA, a comprehensive bilingual benchmark designed to evaluate the factual accuracy of code LLMs in answering code-related questions, which contains carefully curated question-answer pairs in both English and Chinese, covering diverse programming languages and major computer science domains. Further, we create CodeSimpleQA-Instruct, a large-scale instruction corpus with 66M samples, and develop a post-training framework combining supervised fine-tuning and reinforcement learning. Our comprehensive evaluation of diverse LLMs reveals that even frontier LLMs struggle with code factuality. Our proposed framework demonstrates substantial improvements over the base model, underscoring the critical importance of factuality-aware alignment in developing reliable code LLMs.","authors":["Jian Yang","Wei Zhang","Yizhi Li","Shawn Guo","Haowen Wang","Aishan Liu","Ge Zhang","Zili Wang","Zhoujun Li","Xianglong Liu","Weifeng Lv"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19414v1","updated":"2025-12-22T14:13:01Z","published":"2025-12-22T14:13:01Z","title":"From Retrieval to Reasoning: A Framework for Cyber Threat Intelligence NER with Explicit and Adaptive Instructions","summary":"The automation of Cyber Threat Intelligence (CTI) relies heavily on Named Entity Recognition (NER) to extract critical entities from unstructured text. Currently, Large Language Models (LLMs) primarily address this task through retrieval-based In-Context Learning (ICL). This paper analyzes this mainstream paradigm, revealing a fundamental flaw: its success stems not from global semantic similarity but largely from the incidental overlap of entity types within retrieved examples. This exposes the limitations of relying on unreliable implicit induction. To address this, we propose TTPrompt, a framework shifting from implicit induction to explicit instruction. TTPrompt maps the core concepts of CTI's Tactics, Techniques, and Procedures (TTPs) into an instruction hierarchy: formulating task definitions as Tactics, guiding strategies as Techniques, and annotation guidelines as Procedures. Furthermore, to handle the adaptability challenge of static guidelines, we introduce Feedback-driven Instruction Refinement (FIR). FIR enables LLMs to self-refine guidelines by learning from errors on minimal labeled data, adapting to distinct annotation dialects. Experiments on five CTI NER benchmarks demonstrate that TTPrompt consistently surpasses retrieval-based baselines. Notably, with refinement on just 1% of training data, it rivals models fine-tuned on the full dataset. For instance, on LADDER, its Micro F1 of 71.96% approaches the fine-tuned baseline, and on the complex CTINexus, its Macro F1 exceeds the fine-tuned ACLM model by 10.91%.","authors":["Jiaren Peng","Hongda Sun","Xuan Tian","Cheng Huang","Zeqing Li","Rui Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.08398v2","updated":"2025-12-22T13:57:26Z","published":"2025-12-09T09:26:37Z","title":"Ontology-Based Knowledge Graph Framework for Industrial Standard Documents via Hierarchical and Propositional Structuring","summary":"Ontology-based knowledge graph (KG) construction is a core technology that enables multidimensional understanding and advanced reasoning over domain knowledge. Industrial standards, in particular, contain extensive technical information and complex rules presented in highly structured formats that combine tables, scopes of application, constraints, exceptions, and numerical calculations, making KG construction especially challenging. In this study, we propose a method that organizes such documents into a hierarchical semantic structure, decomposes sentences and tables into atomic propositions derived from conditional and numerical rules, and integrates them into an ontology-knowledge graph through LLM-based triple extraction. Our approach captures both the hierarchical and logical structures of documents, effectively representing domain-specific semantics that conventional methods fail to reflect. To verify its effectiveness, we constructed rule, table, and multi-hop QA datasets, as well as a toxic clause detection dataset, from industrial standards, and implemented an ontology-aware KG-RAG framework for comparative evaluation. Experimental results show that our method achieves significant performance improvements across all QA types compared to existing KG-RAG approaches. This study demonstrates that reliable and scalable knowledge representation is feasible even for industrial documents with intertwined conditions, constraints, and scopes, contributing to future domain-specific RAG development and intelligent document management.","authors":["Jiin Park","Hyuna Jeon","Yoonseo Lee","Jisu Hong","Misuk Kim"],"pdf_url":"","comment":"The authors have identified significant technical errors in the paper that invalidate the current findings"},{"id":"http://arxiv.org/abs/2512.19400v1","updated":"2025-12-22T13:52:33Z","published":"2025-12-22T13:52:33Z","title":"Kunnafonidilaw ka Cadeau: an ASR dataset of present-day Bambara","summary":"We present Kunkado, a 160-hour Bambara ASR dataset compiled from Malian radio archives to capture present-day spontaneous speech across a wide range of topics. It includes code-switching, disfluencies, background noise, and overlapping speakers that practical ASR systems encounter in real-world use. We finetuned Parakeet-based models on a 33.47-hour human-reviewed subset and apply pragmatic transcript normalization to reduce variability in number formatting, tags, and code-switching annotations. Evaluated on two real-world test sets, finetuning with Kunkado reduces WER from 44.47\\% to 37.12\\% on one and from 36.07\\% to 32.33\\% on the other. In human evaluation, the resulting model also outperforms a comparable system with the same architecture trained on 98 hours of cleaner, less realistic speech. We release the data and models to support robust ASR for predominantly oral languages.","authors":["Yacouba Diarra","Panga Azazia Kamate","Nouhoum Souleymane Coulibaly","Michael Leventhal"],"pdf_url":"","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2512.16229v2","updated":"2025-12-22T13:29:11Z","published":"2025-12-18T06:22:01Z","title":"LoPA: Scaling dLLM Inference via Lookahead Parallel Decoding","summary":"Diffusion Large Language Models (dLLMs) have demonstrated significant potential for high-speed inference. However, current confidence-driven decoding strategies are constrained by limited parallelism, typically achieving only 1--3 tokens per forward pass (TPF). In this work, we identify that the degree of parallelism during dLLM inference is highly sensitive to the Token Filling Order (TFO). Then, we introduce Lookahead PArallel Decoding LoPA, a training-free, plug-and-play algorithm, to identify a superior TFO and hence accelerate inference. LoPA concurrently explores distinct candidate TFOs via parallel branches, and selects the one with the highest potential for future parallelism based on branch confidence. We apply LoPA to the state-of-the-art D2F model and observe a substantial enhancement in decoding efficiency. Notably, LoPA increases the TPF of D2F-Dream to 10.1 on the GSM8K while maintaining performance superior to the Dream baseline. Furthermore, to facilitate this unprecedented degree of parallelism, we develop a specialized multi-device inference system featuring Branch Parallelism (BP), which achieves a single-sample throughput of 1073.9 tokens per second under multi-GPU deployment. The code is available at https://github.com/zhijie-group/LoPA.","authors":["Chenkai Xu","Yijie Jin","Jiajun Li","Yi Tu","Guoping Long","Dandan Tu","Mingcong Song","Hongjie Si","Tianqi Hou","Junchi Yan","Zhijie Deng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19378v1","updated":"2025-12-22T13:23:29Z","published":"2025-12-22T13:23:29Z","title":"HATS: High-Accuracy Triple-Set Watermarking for Large Language Models","summary":"Misuse of LLM-generated text can be curbed by watermarking techniques that embed implicit signals into the output. We propose a watermark that partitions the vocabulary at each decoding step into three sets (Green/Yellow/Red) with fixed ratios and restricts sampling to the Green and Yellow sets. At detection time, we replay the same partitions, compute Green-enrichment and Red-depletion statistics, convert them to one-sided z-scores, and aggregate their p-values via Fisher's method to decide whether a passage is watermarked. We implement generation, detection, and testing on Llama 2 7B, and evaluate true-positive rate, false-positive rate, and text quality. Results show that the triple-partition scheme achieves high detection accuracy at fixed FPR while preserving readability.","authors":["Zhiqing Hu","Chenxu Zhao","Jiazhong Lu","Xiaolei Liu"],"pdf_url":"","comment":"Camera-ready version of the paper accepted for oral presentation at the 11th International Conference on Computer and Communications (ICCC 2025)"},{"id":"http://arxiv.org/abs/2506.17231v2","updated":"2025-12-22T13:04:30Z","published":"2025-05-26T08:27:51Z","title":"Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs","summary":"As the scale and complexity of jailbreaking attacks on large language models (LLMs) continue to escalate, their efficiency and practical applicability are constrained, posing a profound challenge to LLM security. Jailbreaking techniques have advanced from manual prompt engineering to automated methodologies. Recent advances have automated jailbreaking approaches that harness LLMs to generate jailbreak instructions and adversarial examples, delivering encouraging results. Nevertheless, these methods universally include an LLM generation phase, which, due to the complexities of deploying and reasoning with LLMs, impedes effective implementation and broader adoption. To mitigate this issue, we introduce \\textbf{Adversarial Prompt Distillation}, an innovative framework that integrates masked language modeling, reinforcement learning, and dynamic temperature control to distill LLM jailbreaking prowess into smaller language models (SLMs). This methodology enables efficient, robust jailbreak attacks while maintaining high success rates and accommodating a broader range of application contexts. Empirical evaluations affirm the approach's superiority in attack efficacy, resource optimization, and cross-model versatility. Our research underscores the practicality of transferring jailbreak capabilities to SLMs, reveals inherent vulnerabilities in LLMs, and provides novel insights to advance LLM security investigations. Our code is available at: https://github.com/lxgem/Efficient_and_Stealthy_Jailbreak_Attacks_via_Adversarial_Prompt.","authors":["Xiang Li","Chong Zhang","Jia Wang","Fangyu Wu","Yushi Li","Xiaobo Jin"],"pdf_url":"","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2506.18998v3","updated":"2025-12-22T12:50:45Z","published":"2025-06-23T18:01:16Z","title":"Mirage of Mastery: Memorization Tricks LLMs into Artificially Inflated Self-Knowledge","summary":"When artificial intelligence mistakes memorization for intelligence, it creates a dangerous mirage of reasoning. Existing studies treat memorization and self-knowledge deficits in LLMs as separate issues and do not recognize an intertwining link that degrades the trustworthiness of LLM responses. In our study, we utilize a novel framework to ascertain if LLMs genuinely learn reasoning patterns from training data or merely memorize them to assume competence across problems of similar complexity focused on STEM domains. Our analysis shows a noteworthy problem in generalization: LLMs draw confidence from memorized solutions to infer a higher self-knowledge about their reasoning ability, which manifests as an over 45% inconsistency in feasibility assessments when faced with self-validated, logically coherent task perturbations. This effect is most pronounced in science and medicine domains, which tend to have maximal standardized jargon and problems, further confirming our approach. Significant wavering within the self-knowledge of LLMs also shows flaws in current architectures and training patterns, highlighting the need for techniques that ensure a balanced, consistent stance on models' perceptions of their own knowledge for maximum AI explainability and trustworthiness. Our code and results are available publicly at https://github.com/Sahil-R-Kale/mirage_of_mastery","authors":["Sahil Kale"],"pdf_url":"","comment":"12 pages, 9 figures"},{"id":"http://arxiv.org/abs/2510.02025v2","updated":"2025-12-22T12:27:15Z","published":"2025-10-02T13:57:14Z","title":"Style Over Story: A Process-Oriented Study of Authorial Creativity in Large Language Models","summary":"Evaluations of large language models (LLMs)' creativity have focused primarily on the quality of their outputs rather than the processes that shape them. This study takes a process-oriented approach, drawing on narratology to examine LLMs as computational authors. We introduce constraint-based decision-making as a lens for authorial creativity. Using controlled prompting to assign authorial personas, we analyze the creative preferences of the models. Our findings show that LLMs consistently emphasize Style over other elements, including Character, Event, and Setting. By also probing the reasoning the models provide for their choices, we show that distinctive profiles emerge across models and argue that our approach provides a novel systematic tool for analyzing AI's authorial creativity.","authors":["Donghoon Jung","Jiwoo Choi","Songeun Chae","Seohyon Jung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19320v1","updated":"2025-12-22T12:13:17Z","published":"2025-12-22T12:13:17Z","title":"MAGIC: Achieving Superior Model Merging via Magnitude Calibration","summary":"The proliferation of pre-trained models has given rise to a wide array of specialised, fine-tuned models. Model merging aims to merge the distinct capabilities of these specialised models into a unified model, requiring minimal or even no additional training. A core objective of model merging is to ensure the merged model retains the behavioural characteristics of the specialised models, typically achieved through feature alignment. We identify that features consist of two critical components: direction and magnitude. Prior research has predominantly focused on directional alignment, while the influence of magnitude remains largely neglected, despite its pronounced vulnerability to perturbations introduced by common merging operations (e.g., parameter fusion and sparsification). Such perturbations to magnitude inevitably lead to feature deviations in the merged model from the specialised models, resulting in subsequent performance degradation. To address this, we propose MAGnItude Calibration (MAGIC), a plug-and-play framework that rectifies layer-wise magnitudes in feature and weight spaces, with three variants. Specifically, our Feature Space Calibration (FSC) realigns the merged model's features using a small set of unlabelled data, while Weight Space Calibration (WSC) extends this calibration to the weight space without requiring additional data. Combining these yields Dual Space Calibration (DSC). Comprehensive experiments demonstrate that MAGIC consistently boosts performance across diverse Computer Vision tasks (+4.3% on eight datasets) and NLP tasks (+8.0% on Llama) without additional training. Our code is available at: https://github.com/lyymuwu/MAGIC","authors":["Yayuan Li","Jian Zhang","Jintao Guo","Zihan Cheng","Lei Qi","Yinghuan Shi","Yang Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19305v1","updated":"2025-12-22T11:53:01Z","published":"2025-12-22T11:53:01Z","title":"CienaLLM: Generative Climate-Impact Extraction from News Articles with Autoregressive LLMs","summary":"Understanding and monitoring the socio-economic impacts of climate hazards requires extracting structured information from heterogeneous news articles on a large scale. To that end, we have developed CienaLLM, a modular framework based on schema-guided Generative Information Extraction. CienaLLM uses open-weight Large Language Models for zero-shot information extraction from news articles, and supports configurable prompts and output schemas, multi-step pipelines, and cloud or on-premise inference. To systematically assess how the choice of LLM family, size, precision regime, and prompting strategy affect performance, we run a large factorial study in models, precisions, and prompt engineering techniques. An additional response parsing step nearly eliminates format errors while preserving accuracy; larger models deliver the strongest and most stable performance, while quantization offers substantial efficiency gains with modest accuracy trade-offs; and prompt strategies show heterogeneous, model-specific effects. CienaLLM matches or outperforms the supervised baseline in accuracy for extracting drought impacts from Spanish news, although at a higher inference cost. While evaluated in droughts, the schema-driven and model-agnostic design is suitable for adapting to related information extraction tasks (e.g., other hazards, sectors, or languages) by editing prompts and schemas rather than retraining. We release code, configurations, and schemas to support reproducible use.","authors":["Javier Vela-Tambo","Jorge Gracia","Fernando Dominguez-Castro"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16301v2","updated":"2025-12-22T11:05:54Z","published":"2025-12-18T08:38:51Z","title":"Adaptation of Agentic AI","summary":"Cutting-edge agentic AI systems are built on foundation models that can be adapted to plan, reason, and interact with external tools to perform increasingly complex and specialized tasks. As these systems grow in capability and scope, adaptation becomes a central mechanism for improving performance, reliability, and generalization. In this paper, we unify the rapidly expanding research landscape into a systematic framework that spans both agent adaptations and tool adaptations. We further decompose these into tool-execution-signaled and agent-output-signaled forms of agent adaptation, as well as agent-agnostic and agent-supervised forms of tool adaptation. We demonstrate that this framework helps clarify the design space of adaptation strategies in agentic AI, makes their trade-offs explicit, and provides practical guidance for selecting or switching among strategies during system design. We then review the representative approaches in each category, analyze their strengths and limitations, and highlight key open challenges and future opportunities. Overall, this paper aims to offer a conceptual foundation and practical roadmap for researchers and practitioners seeking to build more capable, efficient, and reliable agentic AI systems.","authors":["Pengcheng Jiang","Jiacheng Lin","Zhiyi Shi","Zifeng Wang","Luxi He","Yichen Wu","Ming Zhong","Peiyang Song","Qizheng Zhang","Heng Wang","Xueqiang Xu","Hanwen Xu","Pengrui Han","Dylan Zhang","Jiashuo Sun","Chaoqi Yang","Kun Qian","Tian Wang","Changran Hu","Manling Li","Quanzheng Li","Hao Peng","Sheng Wang","Jingbo Shang","Chao Zhang","Jiaxuan You","Liyuan Liu","Pan Lu","Yu Zhang","Heng Ji","Yejin Choi","Dawn Song","Jimeng Sun","Jiawei Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19247v1","updated":"2025-12-22T10:29:51Z","published":"2025-12-22T10:29:51Z","title":"Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics","summary":"Prompt engineering plays a critical role in adapting large language models (LLMs) to complex reasoning and labeling tasks without the need for extensive fine-tuning. In this paper, we propose a novel prompt optimization pipeline for frame detection in logistics texts, combining retrieval-augmented generation (RAG), few-shot prompting, chain-of-thought (CoT) reasoning, and automatic CoT synthesis (Auto-CoT) to generate highly effective task-specific prompts. Central to our approach is an LLM-based prompt optimizer agent that iteratively refines the prompts using retrieved examples, performance feedback, and internal self-evaluation. Our framework is evaluated on a real-world logistics text annotation task, where reasoning accuracy and labeling efficiency are critical. Experimental results show that the optimized prompts - particularly those enhanced via Auto-CoT and RAG - improve real-world inference accuracy by up to 15% compared to baseline zero-shot or static prompts. The system demonstrates consistent improvements across multiple LLMs, including GPT-4o, Qwen 2.5 (72B), and LLaMA 3.1 (70B), validating its generalizability and practical value. These findings suggest that structured prompt optimization is a viable alternative to full fine-tuning, offering scalable solutions for deploying LLMs in domain-specific NLP applications such as logistics.","authors":["Do Minh Duc","Quan Xuan Truong","Nguyen Tat Dat","Nguyen Van Vinh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19240v1","updated":"2025-12-22T10:21:40Z","published":"2025-12-22T10:21:40Z","title":"ChemATP: A Training-Free Chemical Reasoning Framework for Large Language Models","summary":"Large Language Models (LLMs) exhibit strong general reasoning but struggle in molecular science due to the lack of explicit chemical priors in standard string representations. Current solutions face a fundamental dilemma. Training-based methods inject priors into parameters, but this static coupling hinders rapid knowledge updates and often compromises the model's general reasoning capabilities. Conversely, existing training-free methods avoid these issues but rely on surface-level prompting, failing to provide the fine-grained atom-level priors essential for precise chemical reasoning. To address this issue, we introduce ChemATP, a framework that decouples chemical knowledge from the reasoning engine. By constructing the first atom-level textual knowledge base, ChemATP enables frozen LLMs to explicitly retrieve and reason over this information dynamically. This architecture ensures interpretability and adaptability while preserving the LLM's intrinsic general intelligence. Experiments show that ChemATP significantly outperforms training-free baselines and rivals state-of-the-art training-based models, demonstrating that explicit prior injection is a competitive alternative to implicit parameter updates.","authors":["Mingxu Zhang","Dazhong Shen","Qi Zhang","Ying Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19238v1","updated":"2025-12-22T10:20:20Z","published":"2025-12-22T10:20:20Z","title":"Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation","summary":"Large language models (LLMs) have been shown to exhibit social bias, however, bias towards non-protected stigmatized identities remain understudied. Furthermore, what social features of stigmas are associated with bias in LLM outputs is unknown. From psychology literature, it has been shown that stigmas contain six shared social features: aesthetics, concealability, course, disruptiveness, origin, and peril. In this study, we investigate if human and LLM ratings of the features of stigmas, along with prompt style and type of stigma, have effect on bias towards stigmatized groups in LLM outputs. We measure bias against 93 stigmatized groups across three widely used LLMs (Granite 3.0-8B, Llama-3.1-8B, Mistral-7B) using SocialStigmaQA, a benchmark that includes 37 social scenarios about stigmatized identities; for example deciding wether to recommend them for an internship. We find that stigmas rated by humans to be highly perilous (e.g., being a gang member or having HIV) have the most biased outputs from SocialStigmaQA prompts (60% of outputs from all models) while sociodemographic stigmas (e.g. Asian-American or old age) have the least amount of biased outputs (11%). We test if the amount of biased outputs could be decreased by using guardrail models, models meant to identify harmful input, using each LLM's respective guardrail model (Granite Guardian 3.0, Llama Guard 3.0, Mistral Moderation API). We find that bias decreases significantly by 10.4%, 1.4%, and 7.8%, respectively. However, we show that features with significant effect on bias remain unchanged post-mitigation and that guardrail models often fail to recognize the intent of bias in prompts. This work has implications for using LLMs in scenarios involving stigmatized groups and we suggest future work towards improving guardrail models for bias mitigation.","authors":["Anna-Maria Gueorguieva","Aylin Caliskan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.20647v2","updated":"2025-12-22T09:52:15Z","published":"2025-10-23T15:22:00Z","title":"The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI","summary":"Large Reasoning Models (LRMs) achieve strong performance on mathematical, scientific, and other question-answering tasks, but their multilingual reasoning abilities remain underexplored. When presented with non-English questions, LRMs often default to reasoning in English, raising concerns about interpretability and the handling of linguistic and cultural nuances. We systematically compare an LRM's reasoning in English versus the language of the question. Our evaluation spans two tasks: MGSM and GPQA Diamond. Beyond measuring answer accuracy, we also analyze cognitive attributes in the reasoning traces. We find that English reasoning traces exhibit a substantially higher presence of these cognitive behaviors, and that reasoning in English generally yields higher final-answer accuracy, with the performance gap increasing as tasks become more complex. However, this English-centric strategy is susceptible to a key failure mode - getting \"Lost in Translation,\" where translation steps lead to errors that would have been avoided by question's language reasoning.","authors":["Alan Saji","Raj Dabre","Anoop Kunchukuttan","Ratish Puduppully"],"pdf_url":"","comment":"14 pages, 13 figures, 5 tables"},{"id":"http://arxiv.org/abs/2512.19173v1","updated":"2025-12-22T09:07:34Z","published":"2025-12-22T09:07:34Z","title":"CycleChart: A Unified Consistency-Based Learning Framework for Bidirectional Chart Understanding and Generation","summary":"Current chart-specific tasks, such as chart question answering, chart parsing, and chart generation, are typically studied in isolation, preventing models from learning the shared semantics that link chart generation and interpretation. We introduce CycleChart, a consistency-based learning framework for bidirectional chart understanding and generation. CycleChart adopts a schema-centric formulation as a common interface across tasks. We construct a consistent multi-task dataset, where each chart sample includes aligned annotations for schema prediction, data parsing, and question answering. To learn cross-directional chart semantics, CycleChart introduces a generate-parse consistency objective: the model generates a chart schema from a table and a textual query, then learns to recover the schema and data from the generated chart, enforcing semantic alignment across directions. CycleChart achieves strong results on chart generation, chart parsing, and chart question answering, demonstrating improved cross-task generalization and marking a step toward more general chart understanding models.","authors":["Dazhen Deng","Sen Yang","Yuchen He","Yuan Tian","Yingcai Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19171v1","updated":"2025-12-22T09:05:06Z","published":"2025-12-22T09:05:06Z","title":"JEPA-Reasoner: Decoupling Latent Reasoning from Token Generation","summary":"While Joint-Embedding Predictive Architecture (JEPA) has emerged as a powerful architecture for learning rich latent representations, it fundamentally lacks generative abilities. Meanwhile, latent space reasoning attempts for Transformer models like COCONUT do improve performance, but they ultimately rely on token-by-token generation, which still accumulates compounding error and relies on context information to gain reasoning insights. To address these limitations, we propose JEPA-Reasoner, a novel JEPA model enhanced with generative ability that reasons in latent space. We augment it with a separate action-taker model, Talker, to produce human-readable sentences. Our approach demonstrates that decoupling latent space reasoning and token generation enables JEPA-Reasoner to produce mixed latent vectors that might lay the foundation for multi-threaded reasoning, while performing autoregressive generation with superior robustness to compounding error.","authors":["Bingyang Kelvin Liu","Ziyu Patrick Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19161v1","updated":"2025-12-22T08:57:16Z","published":"2025-12-22T08:57:16Z","title":"From Speech to Subtitles: Evaluating ASR Models in Subtitling Italian Television Programs","summary":"Subtitles are essential for video accessibility and audience engagement. Modern Automatic Speech Recognition (ASR) systems, built upon Encoder-Decoder neural network architectures and trained on massive amounts of data, have progressively reduced transcription errors on standard benchmark datasets. However, their performance in real-world production environments, particularly for non-English content like long-form Italian videos, remains largely unexplored. This paper presents a case study on developing a professional subtitling system for an Italian media company. To inform our system design, we evaluated four state-of-the-art ASR models (Whisper Large v2, AssemblyAI Universal, Parakeet TDT v3 0.6b, and WhisperX) on a 50-hour dataset of Italian television programs. The study highlights their strengths and limitations, benchmarking their performance against the work of professional human subtitlers. The findings indicate that, while current models cannot meet the media industry's accuracy needs for full autonomy, they can serve as highly effective tools for enhancing human productivity. We conclude that a human-in-the-loop (HITL) approach is crucial and present the production-grade, cloud-based infrastructure we designed to support this workflow.","authors":["Alessandro Lucca","Francesco Pierri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.09566v3","updated":"2025-12-22T08:34:18Z","published":"2025-04-13T13:35:41Z","title":"Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution","summary":"Chain-of-Thought (CoT) prompting enhances the reasoning of large language models (LLMs) by decomposing problems into sequential steps, mimicking human logic and reducing errors. However, complex tasks with vast solution spaces and vague constraints often exceed the capacity of a single reasoning chain. Inspired by Minimal Free Resolution (MFR) in commutative algebra and algebraic geometry, we propose Syzygy of Thoughts (SoT)-a novel framework that extends CoT by introducing auxiliary, interrelated reasoning paths. SoT captures deeper logical dependencies, enabling more robust and structured problem-solving. MFR decomposes a module into a sequence of free modules with minimal rank, providing a structured analytical approach to complex systems. This method introduces the concepts of \"Module\", \"Betti numbers\",\"Freeness\", \"Mapping\", \"Exactness\" and \"Minimality\", enabling the systematic decomposition of the original complex problem into logically complete minimal subproblems while preserving key problem features and reducing reasoning length. We tested SoT across diverse datasets (e.g., GSM8K, MATH) and models (e.g., GPT-4o-mini, Qwen2.5), achieving inference accuracy that matches or surpasses mainstream CoTs standards. Additionally, by aligning the sampling process with algebraic constraints, our approach enhances the scalability of inference time in LLMs, ensuring both transparent reasoning and high performance. Our code will be publicly available at https://github.com/dlMARiA/Syzygy-of-thoughts.","authors":["Chenghao Li","Chaoning Zhang","Yi Lu","Jiaquan Zhang","Qigan Sun","Xudong Wang","Jiwei Wei","Guoqing Wang","Yang Yang","Heng Tao Shen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19134v1","updated":"2025-12-22T08:28:05Z","published":"2025-12-22T08:28:05Z","title":"QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation","summary":"Dynamic Retrieval-Augmented Generation adaptively determines when to retrieve during generation to mitigate hallucinations in large language models (LLMs). However, existing methods rely on model-internal signals (e.g., logits, entropy), which are fundamentally unreliable because LLMs are typically ill-calibrated and often exhibit high confidence in erroneous outputs. We propose QuCo-RAG, which shifts from subjective confidence to objective statistics computed from pre-training data. Our method quantifies uncertainty through two stages: (1) before generation, we identify low-frequency entities indicating long-tail knowledge gaps; (2) during generation, we verify entity co-occurrence in the pre-training corpus, where zero co-occurrence often signals hallucination risk. Both stages leverage Infini-gram for millisecond-latency queries over 4 trillion tokens, triggering retrieval when uncertainty is high. Experiments on multi-hop QA benchmarks show QuCo-RAG achieves EM gains of 5--12 points over state-of-the-art baselines with OLMo-2 models, and transfers effectively to models with undisclosed pre-training data (Llama, Qwen, GPT), improving EM by up to 14 points. Domain generalization on biomedical QA further validates the robustness of our paradigm. These results establish corpus-grounded verification as a principled, practically model-agnostic paradigm for dynamic RAG. Our code is publicly available at https://github.com/ZhishanQ/QuCo-RAG.","authors":["Dehai Min","Kailin Zhang","Tongtong Wu","Lu Cheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19126v1","updated":"2025-12-22T08:07:00Z","published":"2025-12-22T08:07:00Z","title":"AWPO: Enhancing Tool-Use of Large Language Models through Explicit Integration of Reasoning Rewards","summary":"While reinforcement learning (RL) shows promise in training tool-use large language models (LLMs) using verifiable outcome rewards, existing methods largely overlook the potential of explicit reasoning rewards to bolster reasoning and tool utilization. Furthermore, natively combining reasoning and outcome rewards may yield suboptimal performance or conflict with the primary optimization objective. To address this, we propose advantage-weighted policy optimization (AWPO) -- a principled RL framework that effectively integrates explicit reasoning rewards to enhance tool-use capability. AWPO incorporates variance-aware gating and difficulty-aware weighting to adaptively modulate advantages from reasoning signals based on group-relative statistics, alongside a tailored clipping mechanism for stable optimization. Extensive experiments demonstrate that AWPO achieves state-of-the-art performance across standard tool-use benchmarks, significantly outperforming strong baselines and leading closed-source models in challenging multi-turn scenarios. Notably, with exceptional parameter efficiency, our 4B model surpasses Grok-4 by 16.0 percent in multi-turn accuracy while preserving generalization capability on the out-of-distribution MMLU-Pro benchmark.","authors":["Zihan Lin","Xiaohan Wang","Hexiong Yang","Jiajun Chai","Jie Cao","Guojun Yin","Wei Lin","Ran He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19125v1","updated":"2025-12-22T08:05:01Z","published":"2025-12-22T08:05:01Z","title":"SAP: Syntactic Attention Pruning for Transformer-based Language Models","summary":"This paper introduces Syntactic Attention Pruning (SAP), a novel method for effectively pruning attention heads in Transformer models. Unlike conventional approaches that rely solely on mathematical analysis of model weights and activations, SAP incorporates both the syntactic structure and attention patterns of sentences to guide the pruning process. By leveraging these linguistic features, SAP not only achieves performance comparable to state-of-the-art methods but also enhances the interpretability of model behavior. To further improve robustness, we propose Candidate Filtering (CF), a mechanism that prioritizes heads based on their contribution to model performance, mitigating degradation during pruning. Experimental results indicate that SAP effectively preserves critical heads of a high density of strong attention values, outperforming existing head pruning strategies in retrain-free settings. These findings position SAP as a promising foundation for a new direction in model compression research, offering high flexibility for pruning across all transformer-based language models.","authors":["Tzu-Yun Lee","Ding-Yong Hong","Jan-Jan Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19122v1","updated":"2025-12-22T07:53:16Z","published":"2025-12-22T07:53:16Z","title":"BanglaForge: LLM Collaboration with Self-Refinement for Bangla Code Generation","summary":"Bangla is a low-resource language for code generation, lacking large-scale annotated datasets and tools to transform natural language specifications into executable programs. This makes Bangla-to-code generation a challenging task requiring innovative solutions. To address this, we introduce BanglaForge, a novel framework for generating code from Bangla function descriptions. BanglaForge leverages a retrieval-augmented dual-model collaboration paradigm with self-refinement, combining in-context learning, llm-based translation, systematic prompt engineering, and iterative self-refinement based on execution feedback, where a coder generates initial solutions and a reviewer enhances them for robustness. On the BLP-2025 Bangla Code Generation benchmark, BanglaForge achieves a competitive Pass@1 accuracy of 84.00%, demonstrating the effectiveness of retrieval, model collaboration, and self-refinement for low-resource Bangla code generation.","authors":["Mahir Labib Dihan","Sadif Ahmed","Md Nafiu Rahman"],"pdf_url":"","comment":"Accepted at BLP Workshop @ IJCNLP-AACL 2025. Code is available at https://github.com/mahirlabibdihan/BanglaForge"},{"id":"http://arxiv.org/abs/2512.19117v1","updated":"2025-12-22T07:43:43Z","published":"2025-12-22T07:43:43Z","title":"Stop saying LLM: Large Discourse Models (LDM) and Artificial Discursive Agent (ADA)?","summary":"This paper proposes an epistemological shift in the analysis of large generative models, replacing the category ''Large Language Models'' (LLM) with that of ''Large Discourse Models'' (LDM), and then with that of Artificial Discursive Agent (ADA). The theoretical framework is based on an ontological triad distinguishing three regulatory instances: the apprehension of the phenomenal regularities of the referential world, the structuring of embodied cognition, and the structural-linguistic sedimentation of the utterance within a socio-historical context. LDMs, operating on the product of these three instances (the document), model the discursive projection of a portion of human experience reified by the learning corpus. The proposed program aims to replace the ''fascination/fear'' dichotomy with public trials and procedures that make the place, uses, and limits of artificial discursive agents in contemporary social space decipherable, situating this approach within a perspective of governance and co-regulation involving the State, industry, civil society, and academia.","authors":["Amar Lakel"],"pdf_url":"","comment":"in French language"},{"id":"http://arxiv.org/abs/2512.19092v1","updated":"2025-12-22T07:01:05Z","published":"2025-12-22T07:01:05Z","title":"A Large Language Model Based Method for Complex Logical Reasoning over Knowledge Graphs","summary":"Reasoning over knowledge graphs (KGs) with first-order logic (FOL) queries is challenging due to the inherent incompleteness of real-world KGs and the compositional complexity of logical query structures. Most existing methods rely on embedding entities and relations into continuous geometric spaces and answer queries via differentiable set operations. While effective for simple query patterns, these approaches often struggle to generalize to complex queries involving multiple operators, deeper reasoning chains, or heterogeneous KG schemas. We propose ROG (Reasoning Over knowledge Graphs with large language models), an ensemble-style framework that combines query-aware KG neighborhood retrieval with large language model (LLM)-based chain-of-thought reasoning. ROG decomposes complex FOL queries into sequences of simpler sub-queries, retrieves compact, query-relevant subgraphs as contextual evidence, and performs step-by-step logical inference using an LLM, avoiding the need for task-specific embedding optimization. Experiments on standard KG reasoning benchmarks demonstrate that ROG consistently outperforms strong embedding-based baselines in terms of mean reciprocal rank (MRR), with particularly notable gains on high-complexity query types. These results suggest that integrating structured KG retrieval with LLM-driven logical reasoning offers a robust and effective alternative for complex KG reasoning tasks.","authors":["Ziyan Zhang","Chao Wang","Zhuo Chen","Lei Chen","Chiyi Li","Kai Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.22255v3","updated":"2025-12-22T06:48:29Z","published":"2025-05-28T11:41:11Z","title":"Kronecker Factorization Improves Efficiency and Interpretability of Sparse Autoencoders","summary":"Sparse Autoencoders (SAEs) have demonstrated significant promise in interpreting the hidden states of language models by decomposing them into interpretable latent directions. However, training and interpreting SAEs at scale remains challenging, especially when large dictionary sizes are used. While decoders can leverage sparse-aware kernels for efficiency, encoders still require computationally intensive linear operations with large output dimensions. To address this, we propose KronSAE, a novel architecture that factorizes the latent representation via Kronecker product decomposition, drastically reducing memory and computational overhead. Furthermore, we introduce mAND, a differentiable activation function approximating the binary AND operation, which improves interpretability and performance in our factorized framework.","authors":["Vadim Kurochkin","Yaroslav Aksenov","Daniil Laptev","Daniil Gavrilov","Nikita Balagansky"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19070v1","updated":"2025-12-22T06:20:53Z","published":"2025-12-22T06:20:53Z","title":"Watch Closely: Mitigating Object Hallucinations in Large Vision-Language Models with Disentangled Decoding","summary":"Large Vision-Language Models (LVLMs) bridge the gap between visual and linguistic modalities, demonstrating strong potential across a variety of domains. However, despite significant progress, LVLMs still suffer from severe hallucination issues in object recognition tasks. These models often fail to accurately identify certain objects, leading to text generation that appears fluent but does not correspond to the visual content, which can have serious consequences in real-world applications. Recently, several methods have been proposed to alleviate LVLM hallucinations, but most focus solely on reducing hallucinations in the language modality. To mitigate hallucinations in both the language and visual modalities, we introduce Hallucination Disentangled Decoding (HDD) method that requires no training. HDD enhances the original image by segmenting it and selecting images that augment the original, while also utilizing a blank image to eliminate language prior hallucinations in both the original and segmented images. This design not only reduces the model's dependence on language priors but also enhances its visual performance. (Code: https://github.com/rickeyhhh/Hallucination-Disentangled-Decoding)","authors":["Ruiqi Ma","Yu Yan","Chunhong Zhang","Minghao Yin","XinChao Liu","Zhihong Jin","Zheng Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.07019v7","updated":"2025-12-22T05:48:26Z","published":"2024-11-11T14:22:42Z","title":"UniHR: Hierarchical Representation Learning for Unified Knowledge Graph Link Prediction","summary":"Real-world knowledge graphs (KGs) contain not only standard triple-based facts, but also more complex, heterogeneous types of facts, such as hyper-relational facts with auxiliary key-value pairs, temporal facts with additional timestamps, and nested facts that imply relationships between facts. These richer forms of representation have attracted significant attention due to their enhanced expressiveness and capacity to model complex semantics in real-world scenarios. However, most existing studies suffer from two main limitations: (1) they typically focus on modeling only specific types of facts, thus making it difficult to generalize to real-world scenarios with multiple fact types; and (2) they struggle to achieve generalizable hierarchical (inter-fact and intra-fact) modeling due to the complexity of these representations. To overcome these limitations, we propose UniHR, a Unified Hierarchical Representation learning framework, which consists of a learning-optimized Hierarchical Data Representation (HiDR) module and a unified Hierarchical Structure Learning (HiSL) module. The HiDR module unifies hyper-relational KGs, temporal KGs, and nested factual KGs into triple-based representations. Then HiSL incorporates intra-fact and inter-fact message passing, focusing on enhancing both semantic information within individual facts and enriching the structural information between facts. To go beyond the unified method itself, we further explore the potential of unified representation in complex real-world scenarios. Extensive experiments on 9 datasets across 5 types of KGs demonstrate the effectiveness of UniHR and highlight the strong potential of unified representations. Code and data are available at https://github.com/zjukg/UniHR.","authors":["Zhiqiang Liu","Yin Hua","Mingyang Chen","Yichi Zhang","Zhuo Chen","Lei Liang","Wen Zhang"],"pdf_url":"","comment":"AAAI 2026 (oral)"},{"id":"http://arxiv.org/abs/2512.19012v1","updated":"2025-12-22T04:03:01Z","published":"2025-12-22T04:03:01Z","title":"DramaBench: A Six-Dimensional Evaluation Framework for Drama Script Continuation","summary":"Drama script continuation requires models to maintain character consistency, advance plot coherently, and preserve dramatic structurecapabilities that existing benchmarks fail to evaluate comprehensively. We present DramaBench, the first large-scale benchmark for evaluating drama script continuation across six independent dimensions: Format Standards, Narrative Efficiency, Character Consistency, Emotional Depth, Logic Consistency, and Conflict Handling. Our framework combines rulebased analysis with LLM-based labeling and statistical metrics, ensuring objective and reproducible evaluation. We conduct comprehensive evaluation of 8 state-of-the-art language models on 1,103 scripts (8,824 evaluations total), with rigorous statistical significance testing (252 pairwise comparisons, 65.9% significant) and human validation (188 scripts, substantial agreement on 3/5 dimensions). Our ablation studies confirm all six dimensions capture independent quality aspects (mean | r | = 0.020). DramaBench provides actionable, dimensionspecific feedback for model improvement and establishes a rigorous standard for creative writing evaluation.","authors":["Shijian Ma","Yunqi Huang","Yan Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19011v1","updated":"2025-12-22T04:00:35Z","published":"2025-12-22T04:00:35Z","title":"Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline","summary":"Prompt injection and jailbreaking attacks pose persistent security challenges to large language model (LLM)-based systems. We present an efficient and systematically evaluated defense architecture that mitigates these threats through a lightweight, multi-stage pipeline. Its core component is a semantic filter based on text normalization, TF-IDF representations, and a Linear SVM classifier. Despite its simplicity, this module achieves 93.4% accuracy and 96.5% specificity on held-out data, substantially reducing attack throughput while incurring negligible computational overhead.\n  Building on this efficient foundation, the full pipeline integrates complementary detection and mitigation mechanisms that operate at successive stages, providing strong robustness with minimal latency. In comparative experiments, our SVM-based configuration improves overall accuracy from 35.1% to 93.4% while reducing average time to completion from approximately 450s to 47s, yielding over 10 times lower latency than ShieldGemma. These results demonstrate that the proposed design simultaneously advances defensive precision and efficiency, addressing a core limitation of current model-based moderators.\n  Evaluation across a curated corpus of over 30,000 labeled prompts, including benign, jailbreak, and application-layer injections, confirms that staged, resource-efficient defenses can robustly secure modern LLM-driven applications.","authors":["Akshaj Prashanth Rao","Advait Singh","Saumya Kumaar Saksena","Dhruv Kumar"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2512.19004v1","updated":"2025-12-22T03:45:04Z","published":"2025-12-22T03:45:04Z","title":"Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models","summary":"Diffusion Large Language Models (DLLMs) enable fully parallel token decoding but often remain impractical at inference time due to the many denoising iterations required to refine an information-free, fully masked initialization into coherent text. Most existing acceleration methods focus on traversing this generative trajectory more efficiently via improved solvers or sampling strategies. We advance a complementary perspective: shorten the trajectory itself by starting closer to the target distribution through context-aware initialization.\n  We propose a training-free interface that injects prompt-conditioned priors from a lightweight auxiliary model into the diffusion initialization, and instantiate it with two mechanisms: discrete token injection and representation-level embedding interpolation. Because injected priors can be imperfect and unmask-only decoding can over-commit early, we also introduce a simple confidence-based remasking mechanism as a form of prior skepticism. Preliminary evidence on GSM8K suggests that context-aware initialization can substantially reduce denoising iterations (about 35\\% fewer function evaluations in our setting), while also exposing a key open challenge: naive warm-starting can degrade final accuracy relative to strong diffusion baselines. We use these findings to motivate a research agenda around calibration, revision mechanisms, and representation alignment for reliable warm-started diffusion decoding.","authors":["Tongyuan Miao","Gary Huang","Kai Jun Han","Annie Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.14554v3","updated":"2025-12-22T03:45:03Z","published":"2025-12-16T16:28:32Z","title":"VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models","summary":"The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.","authors":["Nguyen Tien Dong","Minh-Anh Nguyen","Thanh Dat Hoang","Nguyen Tuan Ngoc","Dao Xuan Quang Minh","Phan Phi Hai","Nguyen Thi Ngoc Anh","Dang Van Tu","Binh Vu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18999v1","updated":"2025-12-22T03:33:43Z","published":"2025-12-22T03:33:43Z","title":"Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative Study and An Optimized Framework","summary":"When applied directly in an end-to-end manner to medical follow-up tasks, Large Language Models (LLMs) often suffer from uncontrolled dialog flow and inaccurate information extraction due to the complexity of follow-up forms. To address this limitation, we designed and compared two follow-up chatbot systems: an end-to-end LLM-based system (control group) and a modular pipeline with structured process control (experimental group). Experimental results show that while the end-to-end approach frequently fails on lengthy and complex forms, our modular method-built on task decomposition, semantic clustering, and flow management-substantially improves dialog stability and extraction accuracy. Moreover, it reduces the number of dialogue turns by 46.73% and lowers token consumption by 80% to 87.5%. These findings highlight the necessity of integrating external control mechanisms when deploying LLMs in high-stakes medical follow-up scenarios.","authors":["Jinyan Liu","Zikang Chen","Qinchuan Wang","Tan Xie","Heming Zheng","Xudong Lv"],"pdf_url":"","comment":"10 pages,3 figures,conference ICCBB2025"},{"id":"http://arxiv.org/abs/2512.12608v2","updated":"2025-12-22T03:19:42Z","published":"2025-12-14T09:12:09Z","title":"Human-Inspired Learning for Large Language Models via Obvious Record and Maximum-Entropy Method Discovery","summary":"Large Language Models (LLMs) excel at extracting common patterns from large-scale corpora, yet they struggle with rare, low-resource, or previously unseen scenarios-such as niche hardware deployment issues or irregular IoT device behaviors-because such cases are sparsely represented in training data. Moreover, LLMs rely primarily on implicit parametric memory, which limits their ability to explicitly acquire, recall, and refine methods, causing them to behave predominantly as intuition-driven predictors rather than deliberate, method-oriented learners. Inspired by how humans learn from rare experiences, this paper proposes a human-inspired learning framework that integrates two complementary mechanisms. The first, Obvious Record, explicitly stores cause--result (or question--solution) relationships as symbolic memory, enabling persistent learning even from single or infrequent encounters. The second, Maximum-Entropy Method Discovery, prioritizes and preserves methods with high semantic dissimilarity, allowing the system to capture diverse and underrepresented strategies that are typically overlooked by next-token prediction. Verification on a benchmark of 60 semantically diverse question--solution pairs demonstrates that the proposed entropy-guided approach achieves stronger coverage of unseen questions and significantly greater internal diversity than a random baseline, confirming its effectiveness in discovering more generalizable and human-inspired methods.","authors":["Hong Su"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18987v1","updated":"2025-12-22T02:55:25Z","published":"2025-12-22T02:55:25Z","title":"Affordance RAG: Hierarchical Multimodal Retrieval with Affordance-Aware Embodied Memory for Mobile Manipulation","summary":"In this study, we address the problem of open-vocabulary mobile manipulation, where a robot is required to carry a wide range of objects to receptacles based on free-form natural language instructions. This task is challenging, as it involves understanding visual semantics and the affordance of manipulation actions. To tackle these challenges, we propose Affordance RAG, a zero-shot hierarchical multimodal retrieval framework that constructs Affordance-Aware Embodied Memory from pre-explored images. The model retrieves candidate targets based on regional and visual semantics and reranks them with affordance scores, allowing the robot to identify manipulation options that are likely to be executable in real-world environments. Our method outperformed existing approaches in retrieval performance for mobile manipulation instruction in large-scale indoor environments. Furthermore, in real-world experiments where the robot performed mobile manipulation in indoor environments based on free-form instructions, the proposed method achieved a task success rate of 85%, outperforming existing methods in both retrieval performance and overall task success.","authors":["Ryosuke Korekata","Quanting Xie","Yonatan Bisk","Komei Sugiura"],"pdf_url":"","comment":"Accepted to IEEE RA-L, with presentation at ICRA 2026"},{"id":"http://arxiv.org/abs/2403.15676v5","updated":"2025-12-22T02:52:50Z","published":"2024-03-23T01:44:57Z","title":"AC4: Algebraic Computation Checker for Circuit Constraints in ZKPs","summary":"Zero-knowledge proof (ZKP) systems have surged attention and held a fundamental role in contemporary cryptography. Zero-knowledge succinct non-interactive argument of knowledge (zk-SNARK) protocols dominate the ZKP usage, implemented through arithmetic circuit programming paradigm. However, underconstrained or overconstrained circuits may lead to bugs. The former refers to circuits that lack the necessary constraints, resulting in unexpected solutions and causing the verifier to accept a bogus witness, and the latter refers to circuits that are constrained excessively, resulting in lacking necessary solutions and causing the verifier to accept no witness. This paper introduces a novel approach for pinpointing two distinct types of bugs in ZKP circuits. The method involves encoding the arithmetic circuit constraints to polynomial equation systems and solving them over finite fields by the computer algebra system. The classification of verification results is refined, greatly enhancing the expressive power of the system. A tool, AC4, is proposed to represent the implementation of the method. Experiments show that AC4 demonstrates a increase in the solved rate, showing a 29% improvement over Picus and CIVER, and a slight improvement over halo2-analyzer, a checker for halo2 circuits. Within a solvable range, the checking time has also exhibited noticeable improvement, demonstrating a magnitude increase compared to previous efforts.","authors":["Qizhe Yang","Boxuan Liang","Hao Chen","Guoqiang Li"],"pdf_url":"","comment":"26 pages, 5 figures"},{"id":"http://arxiv.org/abs/2512.01457v3","updated":"2025-12-22T02:26:36Z","published":"2025-12-01T09:44:31Z","title":"Zero-Overhead Introspection for Adaptive Test-Time Compute","summary":"Large language models excel at reasoning but lack key aspects of introspection, including anticipating their own success and the computation required to achieve it. Humans use real-time introspection to decide how much effort to invest, when to make multiple attempts, when to stop, and when to signal success or failure. Without this, LLMs struggle to make intelligent meta-cognition decisions. Test-time scaling methods like Best-of-N drive up cost and latency by using a fixed budget of samples regardless of the marginal benefit of each one at any point in generation, and the absence of confidence signals can mislead people, prevent appropriate escalation to better tools, and undermine trustworthiness. Learned verifiers or reward models can provide confidence estimates, but do not enable adaptive inference and add substantial cost by requiring extra models or forward passes. We present ZIP-RC, an adaptive inference method that equips models with zero-overhead inference-time predictions of reward and cost. At every token, ZIP-RC reuses reserved or unused logits in the same forward pass as next-token prediction to output a joint distribution over final reward and remaining length -- no extra models, architecture change, or inference overhead. This full joint distribution is used to compute a sampling utility which is the linear combination of the expected maximum reward, total compute, and latency of set of samples if generated to completion. During inference, we maximize this utility with meta-actions that determine which prefix of tokens to continue or initiate sampling from. On mixed-difficulty mathematical benchmarks, ZIP-RC improves accuracy by up to 12% over majority voting at equal or lower average cost, and traces smooth Pareto frontiers between quality, compute, and latency. By providing real-time reward-cost introspection, ZIP-RC enables adaptive, efficient reasoning.","authors":["Rohin Manvi","Joey Hong","Tim Seyde","Maxime Labonne","Mathias Lechner","Sergey Levine"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.15210v3","updated":"2025-12-22T02:26:22Z","published":"2025-05-21T07:38:45Z","title":"Deliberation on Priors: Trustworthy Reasoning of Large Language Models on Knowledge Graphs","summary":"Knowledge graph-based retrieval-augmented generation seeks to mitigate hallucinations in Large Language Models (LLMs) caused by insufficient or outdated knowledge. However, existing methods often fail to fully exploit the prior knowledge embedded in knowledge graphs (KGs), particularly their structural information and explicit or implicit constraints. The former can enhance the faithfulness of LLMs' reasoning, while the latter can improve the reliability of response generation. Motivated by these, we propose a trustworthy reasoning framework, termed Deliberation over Priors (DP), which sufficiently utilizes the priors contained in KGs. Specifically, DP adopts a progressive knowledge distillation strategy that integrates structural priors into LLMs through a combination of supervised fine-tuning and Kahneman-Tversky optimization, thereby improving the faithfulness of relation path generation. Furthermore, our framework employs a reasoning-introspection strategy, which guides LLMs to perform refined reasoning verification based on extracted constraint priors, ensuring the reliability of response generation. Extensive experiments on three benchmark datasets demonstrate that DP achieves new state-of-the-art performance, especially a Hit@1 improvement of 13% on the ComplexWebQuestions dataset, and generates highly trustworthy responses. We also conduct various analyses to verify its flexibility and practicality. The code is available at https://github.com/reml-group/Deliberation-on-Priors.","authors":["Jie Ma","Ning Qu","Zhitao Gao","Rui Xing","Jun Liu","Hongbin Pei","Jiang Xie","Linyun Song","Pinghui Wang","Jing Tao","Zhou Su"],"pdf_url":"","comment":"Accepted by NeurIPS 2025"},{"id":"http://arxiv.org/abs/2408.15510v5","updated":"2025-12-22T02:12:55Z","published":"2024-08-28T03:45:49Z","title":"How Reliable are Causal Probing Interventions?","summary":"Causal probing aims to analyze foundation models by examining how intervening on their representation of various latent properties impacts their outputs. Recent works have cast doubt on the theoretical basis of several leading causal probing methods, but it has been unclear how to systematically evaluate the effectiveness of these methods in practice. To address this, we define two key causal probing desiderata: completeness (how thoroughly the representation of the target property has been transformed) and selectivity (how little non-targeted properties have been impacted). We find that there is an inherent tradeoff between the two, which we define as reliability, their harmonic mean. We introduce an empirical analysis framework to measure and evaluate these quantities, allowing us to make the first direct comparisons between different families of leading causal probing methods (e.g., linear vs. nonlinear, or concept removal vs. counterfactual interventions). We find that: (1) all methods show a clear tradeoff between completeness and selectivity; (2) more complete and reliable methods have a greater impact on LLM behavior; and (3) nonlinear interventions are almost always more reliable than linear interventions.\n  Our project webpage is available at: https://ahdavies6.github.io/causal_probing_reliability/","authors":["Marc Canby","Adam Davies","Chirag Rastogi","Julia Hockenmaier"],"pdf_url":"","comment":"In Proceedings of IJCNLP-AACL, 2025"},{"id":"http://arxiv.org/abs/2512.18940v1","updated":"2025-12-22T01:19:50Z","published":"2025-12-22T01:19:50Z","title":"FASTRIC: Prompt Specification Language for Verifiable LLM Interactions","summary":"Large Language Models (LLMs) execute complex multi-turn interaction protocols but lack formal specifications to verify execution against designer intent. We introduce FASTRIC, a Prompt Specification Language that makes implicit Finite State Machines (FSMs) explicit in natural language prompts, enabling conformance verification through execution trace analysis. The LLM serves as intelligent execution agent: interpreting designer-encoded FSMs to execute specified behavioral roles. Unlike symbolic specification languages requiring parsers and compilers, FASTRIC leverages LLMs as unified infrastructure-simultaneously parser, interpreter, runtime environment, and development assistant. FASTRIC guides designers to articulate seven FSM elements (Final States, Agents, States, Triggers, Roles, Initial State, Constraints) structuring multi-turn interactions. Specification formality-ranging from implicit descriptions that frontier models infer to explicit step-by-step instructions for weaker models-serves as a design parameter. We introduce procedural conformance as verification metric measuring execution adherence to FSM specifications. Testing a 3-state kindergarten tutoring FSM across four formality levels and three model scales (14.7B, 685B, 1T+ parameters) reveals optimal specification formality is a function of model capacity. DeepSeek-V3.2 (685B) achieves perfect conformance (1.00) at L2-L4; ChatGPT-5 (~1T) peaks at L3 (0.90) before collapsing at L4 (0.39); Phi4 (14.7B) shows no stable optimum with high variance (SD=0.16-0.36). These findings reveal model-specific formality ranges-\"Goldilocks zones\"-where specifications provide sufficient structure without over-constraint, establishing Prompt Specification Engineering for creating verifiable interaction protocols, transforming multi-turn interaction design from heuristic art to systematic engineering with measurable procedural guarantees.","authors":["Wen-Long Jin"],"pdf_url":"","comment":"13 pages, 3 figures. Supplementary materials at https://doi.org/10.17605/OSF.IO/PV6R3"},{"id":"http://arxiv.org/abs/2512.19933v1","updated":"2025-12-22T23:31:49Z","published":"2025-12-22T23:31:49Z","title":"PRISM: A Personality-Driven Multi-Agent Framework for Social Media Simulation","summary":"Traditional agent-based models (ABMs) of opinion dynamics often fail to capture the psychological heterogeneity driving online polarization due to simplistic homogeneity assumptions. This limitation obscures the critical interplay between individual cognitive biases and information propagation, thereby hindering a mechanistic understanding of how ideological divides are amplified. To address this challenge, we introduce the Personality-Refracted Intelligent Simulation Model (PRISM), a hybrid framework coupling stochastic differential equations (SDE) for continuous emotional evolution with a personality-conditional partially observable Markov decision process (PC-POMDP) for discrete decision-making. In contrast to continuous trait approaches, PRISM assigns distinct Myers-Briggs Type Indicator (MBTI) based cognitive policies to multimodal large language model (MLLM) agents, initialized via data-driven priors from large-scale social media datasets. PRISM achieves superior personality consistency aligned with human ground truth, significantly outperforming standard homogeneous and Big Five benchmarks. This framework effectively replicates emergent phenomena such as rational suppression and affective resonance, offering a robust tool for analyzing complex social media ecosystems.","authors":["Zhixiang Lu","Xueyuan Deng","Yiran Liu","Yulong Li","Qiang Yan","Imran Razzak","Jionglong Su"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19908v1","updated":"2025-12-22T22:22:46Z","published":"2025-12-22T22:22:46Z","title":"Counterfactual LLM-based Framework for Measuring Rhetorical Style","summary":"The rise of AI has fueled growing concerns about ``hype'' in machine learning papers, yet a reliable way to quantify rhetorical style independently of substantive content has remained elusive. Because bold language can stem from either strong empirical results or mere rhetorical style, it is often difficult to distinguish between the two. To disentangle rhetorical style from substantive content, we introduce a counterfactual, LLM-based framework: multiple LLM rhetorical personas generate counterfactual writings from the same substantive content, an LLM judge compares them through pairwise evaluations, and the outcomes are aggregated using a Bradley--Terry model. Applying this method to 8,485 ICLR submissions sampled from 2017 to 2025, we generate more than 250,000 counterfactual writings and provide a large-scale quantification of rhetorical style in ML papers. We find that visionary framing significantly predicts downstream attention, including citations and media attention, even after controlling for peer-review evaluations. We also observe a sharp rise in rhetorical strength after 2023, and provide empirical evidence showing that this increase is largely driven by the adoption of LLM-based writing assistance. The reliability of our framework is validated by its robustness to the choice of personas and the high correlation between LLM judgments and human annotations. Our work demonstrates that LLMs can serve as instruments to measure and improve scientific evaluation.","authors":["Jingyi Qiu","Hong Chen","Zongyi Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19903v1","updated":"2025-12-22T22:08:32Z","published":"2025-12-22T22:08:32Z","title":"How well do Large Language Models Recognize Instructional Moves? Establishing Baselines for Foundation Models in Educational Discourse","summary":"Large language models (LLMs) are increasingly adopted in educational technologies for a variety of tasks, from generating instructional materials and assisting with assessment design to tutoring. While prior work has investigated how models can be adapted or optimized for specific tasks, far less is known about how well LLMs perform at interpreting authentic educational scenarios without significant customization. As LLM-based systems become widely adopted by learners and educators in everyday academic contexts, understanding their out-of-the-box capabilities is increasingly important for setting expectations and benchmarking. We compared six LLMs to estimate their baseline performance on a simple but important task: classifying instructional moves in authentic classroom transcripts. We evaluated typical prompting methods: zero-shot, one-shot, and few-shot prompting. We found that while zero-shot performance was moderate, providing comprehensive examples (few-shot prompting) significantly improved performance for state-of-the-art models, with the strongest configuration reaching Cohen's Kappa = 0.58 against expert-coded annotations. At the same time, improvements were neither uniform nor complete: performance varied considerably by instructional move, and higher recall frequently came at the cost of increased false positives. Overall, these findings indicate that foundation models demonstrate meaningful yet limited capacity to interpret instructional discourse, with prompt design helping to surface capability but not eliminating fundamental reliability constraints.","authors":["Kirk Vanacore","Rene F. Kizilcec"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19864v1","updated":"2025-12-22T20:38:30Z","published":"2025-12-22T20:38:30Z","title":"HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data","summary":"Unstructured notes within the electronic health record (EHR) contain rich clinical information vital for cancer treatment decision making and research, yet reliably extracting structured oncology data remains challenging due to extensive variability, specialized terminology, and inconsistent document formats. Manual abstraction, although accurate, is prohibitively costly and unscalable. Existing automated approaches typically address narrow scenarios - either using synthetic datasets, restricting focus to document-level extraction, or isolating specific clinical variables (e.g., staging, biomarkers, histology) - and do not adequately handle patient-level synthesis across the large number of clinical documents containing contradictory information. In this study, we propose an agentic framework that systematically decomposes complex oncology data extraction into modular, adaptive tasks. Specifically, we use large language models (LLMs) as reasoning agents, equipped with context-sensitive retrieval and iterative synthesis capabilities, to exhaustively and comprehensively extract structured clinical variables from real-world oncology notes. Evaluated on a large-scale dataset of over 400,000 unstructured clinical notes and scanned PDF reports spanning 2,250 cancer patients, our method achieves an average F1-score of 0.93, with 100 out of 103 oncology-specific clinical variables exceeding 0.85, and critical variables (e.g., biomarkers and medications) surpassing 0.95. Moreover, integration of the agentic system into a data curation workflow resulted in 0.94 direct manual approval rate, significantly reducing annotation costs. To our knowledge, this constitutes the first exhaustive, end-to-end application of LLM-based agents for structured oncology data extraction at scale","authors":["Shashi Kant Gupta","Arijeet Pramanik","Jerrin John Thomas","Regina Schwind","Lauren Wiener","Avi Raju","Jeremy Kornbluth","Yanshan Wang","Zhaohui Su","Hrituraj Singh"],"pdf_url":"","comment":"39 Pages, Supplementary Included"},{"id":"http://arxiv.org/abs/2509.10534v2","updated":"2025-12-22T20:13:10Z","published":"2025-09-05T14:22:27Z","title":"Decoupling the \"What\" and \"Where\" With Polar Coordinate Positional Embeddings","summary":"The attention mechanism in a Transformer architecture matches key to query based on both content -- the what -- and position in a sequence -- the where. We present an analysis indicating that what and where are entangled in the popular RoPE rotary position embedding. This entanglement can impair performance particularly when decisions require independent matches on these two factors. We propose an improvement to RoPE, which we call Polar Coordinate Position Embeddings or PoPE, that eliminates the what-where confound. PoPE is far superior on a diagnostic task requiring indexing solely by position or by content. On autoregressive sequence modeling in music, genomic, and natural language domains, Transformers using PoPE as the positional encoding scheme outperform baselines using RoPE with respect to evaluation loss (perplexity) and downstream task performance. On language modeling, these gains persist across model scale, from 124M to 774M parameters. Crucially, PoPE shows strong zero-shot length extrapolation capabilities compared not only to RoPE but even a method designed for extrapolation, YaRN, which requires additional fine tuning and frequency interpolation.","authors":["Anand Gopalakrishnan","Robert Csordás","Jürgen Schmidhuber","Michael C. Mozer"],"pdf_url":"","comment":"Comparison to YaRN added + additional bias visualization + model ablation"},{"id":"http://arxiv.org/abs/2506.00920v2","updated":"2025-12-22T19:46:45Z","published":"2025-06-01T09:20:44Z","title":"Position as Probability: Self-Supervised Transformers that Think Past Their Training for Length Extrapolation","summary":"Deep sequence models typically degrade in accuracy when test sequences significantly exceed their training lengths, yet many critical tasks--such as algorithmic reasoning, multi-step arithmetic, and compositional generalization--require robust length extrapolation. We introduce PRISM, a Probabilistic Relative-position Implicit Superposition Model, a novel positional encoding mechanism that enables Transformers to extrapolate accurately up to 10x beyond their training length. PRISM learns continuous relative positions through a differentiable histogram-filter update, preserving position uncertainty via a probabilistic superposition rather than conventional deterministic embeddings. Empirically, PRISM achieves state-of-the-art length extrapolation, successfully generalizing to previously intractable sequence lengths across algorithmic benchmarks--including arithmetic (addition, multiplication), SCAN compositionality tasks, and complex copy variants derived from DeepMind's recent datasets. Our analysis demonstrates that PRISM's stochastic positional encoding maintains sharp and interpretable internal states, providing a theoretical basis for reliable length generalization. These results advance the goal of neural sequence models that remain algorithmically robust at lengths far exceeding their training horizon.","authors":["Philip Heejun Lee"],"pdf_url":"","comment":"Note: v2: working paper; code, additional baselines, ablations, will follow in v3"},{"id":"http://arxiv.org/abs/2507.16003v3","updated":"2025-12-22T19:30:19Z","published":"2025-07-21T18:44:35Z","title":"Learning without training: The implicit dynamics of in-context learning","summary":"One of the most striking features of Large Language Models (LLMs) is their ability to learn in-context. Namely at inference time an LLM is able to learn new patterns without any additional weight update when these patterns are presented in the form of examples in the prompt, even if these patterns were not seen during training. The mechanisms through which this can happen are still largely unknown. In this work, we show that the stacking of a self-attention layer with an MLP, allows the transformer block to implicitly modify the weights of the MLP layer according to the context. We argue through theory and experimentation that this simple mechanism may be the reason why LLMs can learn in-context and not only during training. Specifically, we show how a transformer block implicitly transforms a context into a low-rank weight-update of its MLP layer.","authors":["Benoit Dherin","Michael Munn","Hanna Mazzawi","Michael Wunder","Javier Gonzalvo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.19916v5","updated":"2025-12-22T18:59:31Z","published":"2024-09-30T03:37:10Z","title":"Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Object-Oriented Programming","summary":"Object-Oriented Programming (OOP) has become a crucial paradigm for managing the growing complexity of modern software systems, particularly in fields like machine learning, deep learning, large language models (LLM), and data analytics. This work provides a comprehensive introduction to the integration of OOP techniques within these domains, with a focus on improving code modularity, maintainability, and scalability. We begin by outlining the evolution of computing and the rise of OOP, followed by an in-depth discussion of key OOP principles such as encapsulation, inheritance, polymorphism, and abstraction. The practical application of these principles is demonstrated using Python, a widely adopted language in AI and data science. Furthermore, we examine how design patterns and modular programming can be employed to enhance the structure and efficiency of machine learning systems. In subsequent sections, we apply these OOP concepts to real-world AI tasks, including the encapsulation of preprocessing workflows, machine learning model training, and evaluation. Detailed examples illustrate how OOP can be used to build reusable, scalable machine learning systems while maintaining code clarity and reducing redundancy.This work is intended to serve as a bridge for both beginners and experienced developers, equipping them with the necessary knowledge to apply OOP methodologies in AI-driven projects, ultimately fostering the development of more robust and maintainable systems.","authors":["Tianyang Wang","Ziqian Bi","Keyu Chen","Jiawei Xu","Qian Niu","Junyu Liu","Benji Peng","Ming Li","Sen Zhang","Xuanhe Pan","Jinlang Wang","Pohsun Feng","Yizhu Wen","Xinyuan Song","Ming Liu"],"pdf_url":"","comment":"49pages"},{"id":"http://arxiv.org/abs/2512.19399v1","updated":"2025-12-22T13:51:03Z","published":"2025-12-22T13:51:03Z","title":"Brain-Grounded Axes for Reading and Steering LLM States","summary":"Interpretability methods for large language models (LLMs) typically derive directions from textual supervision, which can lack external grounding. We propose using human brain activity not as a training signal but as a coordinate system for reading and steering LLM states. Using the SMN4Lang MEG dataset, we construct a word-level brain atlas of phase-locking value (PLV) patterns and extract latent axes via ICA. We validate axes with independent lexica and NER-based labels (POS/log-frequency used as sanity checks), then train lightweight adapters that map LLM hidden states to these brain axes without fine-tuning the LLM. Steering along the resulting brain-derived directions yields a robust lexical (frequency-linked) axis in a mid TinyLlama layer, surviving perplexity-matched controls, and a brain-vs-text probe comparison shows larger log-frequency shifts (relative to the text probe) with lower perplexity for the brain axis. A function/content axis (axis 13) shows consistent steering in TinyLlama, Qwen2-0.5B, and GPT-2, with PPL-matched text-level corroboration. Layer-4 effects in TinyLlama are large but inconsistent, so we treat them as secondary (Appendix). Axis structure is stable when the atlas is rebuilt without GPT embedding-change features or with word2vec embeddings (|r|=0.64-0.95 across matched axes), reducing circularity concerns. Exploratory fMRI anchoring suggests potential alignment for embedding change and log frequency, but effects are sensitive to hemodynamic modeling assumptions and are treated as population-level evidence only. These results support a new interface: neurophysiology-grounded axes provide interpretable and controllable handles for LLM behavior.","authors":["Sandro Andric"],"pdf_url":"","comment":"10 pages, 4 figures. Code: https://github.com/sandroandric/Brain-Grounded-Axes-for-Reading-and-Steering-LLM-States"},{"id":"http://arxiv.org/abs/2512.20687v1","updated":"2025-12-22T19:26:59Z","published":"2025-12-22T19:26:59Z","title":"PHOTON: Hierarchical Autoregressive Modeling for Lightspeed and Memory-Efficient Language Generation","summary":"Transformers operate as horizontal token-by-token scanners; at each generation step, the model attends to an ever-growing sequence of token-level states. This access pattern increases prefill latency and makes long-context decoding increasingly memory-bound, as KV-cache reads and writes dominate inference throughput rather than arithmetic computation. We propose Parallel Hierarchical Operation for Top-down Networks (PHOTON), a hierarchical autoregressive model that replaces flat scanning with vertical, multi-resolution context access. PHOTON maintains a hierarchy of latent streams: a bottom-up encoder progressively compresses tokens into low-rate contextual states, while lightweight top-down decoders reconstruct fine-grained token representations. Experimental results show that PHOTON is superior to competitive Transformer-based language models regarding the throughput-quality trade-off, offering significant advantages in long-context and multi-query tasks. This reduces decode-time KV-cache traffic, yielding up to $10^{3}\\times$ higher throughput per unit memory.","authors":["Yuma Ichikawa","Naoya Takagi","Takumi Nakagawa","Yuzi Kanazawa","Akira Sakai"],"pdf_url":"","comment":"12 pages, 5 figures"}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2512.19671v1","updated":"2025-12-22T18:51:06Z","published":"2025-12-22T18:51:06Z","title":"CORE: Compensable Reward as a Catalyst for Improving Offline RL in Wireless Networks","summary":"Real-world wireless data are expensive to collect and often lack sufficient expert demonstrations, causing existing offline RL methods to overfit suboptimal behaviors and exhibit unstable performance. To address this issue, we propose CORE, an offline RL framework specifically designed for wireless environments. CORE identifies latent expert trajectories from noisy datasets via behavior embedding clustering, and trains a conditional variational autoencoder with a contrastive objective to separate expert and non-expert behaviors in latent space. Based on the learned representations, CORE constructs compensable rewards that reflect expert-likelihood, effectively guiding policy learning under limited or imperfect supervision. More broadly, this work represents one of the early systematic explorations of offline RL in wireless networking, where prior adoption remains limited. Beyond introducing offline RL techniques to this domain, we further examine intrinsic wireless data characteristics and develop a domain-aligned algorithm that explicitly accounts for their structural properties. While offline RL has not yet been fully established as a standard methodology in the wireless community, our study aims to provide foundational insights and empirical evidence to support its broader acceptance.","authors":["Lipeng Zu","Hansong Zhou","Yu Qian","Shayok Chakraborty","Yukun Yuan","Linke Guo","Xiaonan Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.23740v2","updated":"2025-12-22T18:25:28Z","published":"2025-06-30T11:27:57Z","title":"Campus5G: A Campus Scale Private 5G Open RAN Testbed","summary":"Mobile networks are embracing disaggregation, reflected by the industry trend towards Open RAN. Private 5G networks are viewed as particularly suitable contenders as early adopters of Open RAN, owing to their setting, high degree of control, and opportunity for innovation they present. Motivated by this, we have recently deployed Campus5G, the first of its kind campus-wide, O-RAN-compliant private 5G testbed across the central campus of the University of Edinburgh. We present in detail our process developing the testbed, from planning, to architecting, to deployment, and measuring the testbed performance. We then discuss the lessons learned from building the testbed, and highlight some research opportunities that emerged from our deployment experience.","authors":["Andrew E. Ferguson","Ujjwal Pawar","Tianxin Wang","Mahesh K. Marina"],"pdf_url":"","comment":"To appear in ACM SIGCOMM Computer Communication Review (CCR), July 2025"},{"id":"http://arxiv.org/abs/2512.19563v1","updated":"2025-12-22T16:44:32Z","published":"2025-12-22T16:44:32Z","title":"On Network-Aware Semantic Communication and Edge-Cloud Collaborative Intelligence Systems","summary":"Semantic communication and edge-cloud collaborative intelligence are increasingly recognized as foundational enablers for next-generation intelligent services operating under stringent bandwidth, latency, and resource constraints. By shifting the communication objective from bit-perfect delivery toward the transmission of task-relevant semantic representations, semantic communication enables adaptive tradeoffs among communication overhead, inference accuracy, computational load, and end-to-end latency. This survey provides a comprehensive and system-level synthesis of recent advances in semantic communication at the edge-cloud interface, encompassing architectural models for collaborative intelligence, representation learning and semantic abstraction techniques, network-aware and resource-adaptive semantic encoding strategies, and learning-driven optimization and orchestration mechanisms. Beyond efficiency considerations, the survey situates semantic communication within practical operational contexts, including security, trust, resilience, and scalability, drawing connections to zero-trust networking, physical-layer security, and emerging edge-cloud control paradigms. Finally, open challenges and research directions are identified, highlighting the role of semantic communication as a key building block for AI-native networking and 6G-ready intelligent systems.","authors":["Murdadha Nasif","Ahmed Refaey Hussein"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19488v1","updated":"2025-12-22T15:43:39Z","published":"2025-12-22T15:43:39Z","title":"Lightweight Intrusion Detection in IoT via SHAP-Guided Feature Pruning and Knowledge-Distilled Kronecker Networks","summary":"The widespread deployment of Internet of Things (IoT) devices requires intrusion detection systems (IDS) with high accuracy while operating under strict resource constraints. Conventional deep learning IDS are often too large and computationally intensive for edge deployment. We propose a lightweight IDS that combines SHAP-guided feature pruning with knowledge-distilled Kronecker networks. A high-capacity teacher model identifies the most relevant features through SHAP explanations, and a compressed student leverages Kronecker-structured layers to minimize parameters while preserving discriminative inputs. Knowledge distillation transfers softened decision boundaries from teacher to student, improving generalization under compression. Experiments on the TON\\_IoT dataset show that the student is nearly three orders of magnitude smaller than the teacher yet sustains macro-F1 above 0.986 with millisecond-level inference latency. The results demonstrate that explainability-driven pruning and structured compression can jointly enable scalable, low-latency, and energy-efficient IDS for heterogeneous IoT environments.","authors":["Hafsa Benaddi","Mohammed Jouhari","Nouha Laamech","Anas Motii","Khalil Ibrahimi"],"pdf_url":"","comment":"This work has been published in the proceedings of the 2025 8th International Conference on Advanced Communication Technologies and Networking (CommNet)"},{"id":"http://arxiv.org/abs/2512.14323v2","updated":"2025-12-22T14:39:18Z","published":"2025-12-16T11:41:39Z","title":"FUSION: Forecast-Embedded Agent Scheduling with Service Incentive Optimization over Distributed Air-Ground Edge Networks","summary":"In this paper, we introduce a first-of-its-kind forecasting-driven, incentive-inherent service provisioning framework for distributed air-ground integrated networks that explicitly accounts for human-machine coexistence. In our framework, vehicular-UAV agent pairs (APs) are proactively dispatched to overloaded hotspots to augment the computing capacity of edge servers (ESs), which in turn gives rise to a set of challenges that we jointly address: highly uncertain spatio-temporal workloads, spatio-temporal coupling between road traffic and UAV capacity, forecast-driven contracting risks, and heterogeneous quality-of-service (QoS) requirements of human users (HUs) and machine users (MUs). To address these challenges, we propose FUSION, a two-stage optimization framework, consisting of an offline stage and an online stage. In the offline stage, a liquid neural network-powered module performs multi-step spatio-temporal demand forecasting at distributed ESs, whose outputs are exploited by an enhanced ant colony optimization-based routing scheme and an auction-based incentive-compatible contracting mechanism, to jointly determine ES-AP contracts and pre-planned service routes. In the online stage, we formulate the congestion-aware task scheduling as a potential game among HUs, MUs, and heterogeneous ES/UAVs, and devise a potential-guided best-response dynamics algorithm that provably converges to a pure-strategy Nash equilibrium. Experiments on both synthetic and real-world datasets show that FUSION consistently achieves higher social welfare and improved resource utilization, while maintaining latency and energy costs comparable to state-of-the-art baselines and preserving individual rationality, budget balance, and near-truthfulness.","authors":["Houyi Qi","Minghui Liwang","Seyyedali Hosseinalipour","Liqun Fu","Sai Zou","Xianbin Wang","Wei Ni","Yiguang Hong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19177v1","updated":"2025-12-22T09:11:57Z","published":"2025-12-22T09:11:57Z","title":"Semantic Communication for Rate-Limited Closed-Loop Distributed Communication-Sensing-Control Systems","summary":"The growing integration of distributed integrated sensing and communication (ISAC) with closed-loop control in intelligent networks demands efficient information transmission under stringent bandwidth constraints. To address this challenge, this paper proposes a unified framework for goal-oriented semantic communication in distributed SCC systems. Building upon Weaver's three-level model, we establish a hierarchical semantic formulation with three error levels (L1: observation reconstruction, L2: state estimation, and L3: control) to jointly optimize their corresponding objectives. Based on this formulation, we propose a unified goal-oriented semantic compression and rate adaptation framework that is applicable to different semantic error levels and optimization goals across the SCC loop. A rate-limited multi-sensor LQR system is used as a case study to validate the proposed framework. We employ a GRU-based AE for semantic compression and a PPO-based rate adaptation algorithm that dynamically allocates transmission rates across sensors. Results show that the proposed framework effectively captures task-relevant semantics and adapts its resource allocation strategies across different semantic levels, thereby achieving level-specific performance gains under bandwidth constraints.","authors":["Guangjin Pan","Zhixing Li","Ayça Özçelikkale","Christian Häger","Musa Furkan Keskin","Henk Wymeersch"],"pdf_url":"","comment":"13 pages, 18 figures. This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2504.04027v3","updated":"2025-12-22T09:04:13Z","published":"2025-04-05T02:43:37Z","title":"A Fast Solver-Free Algorithm for Traffic Engineering in Large-Scale Data Center Network","summary":"Rapid growth of data center networks (DCNs) poses significant challenges for large-scale traffic engineering (TE). Existing acceleration strategies, which rely on commercial solvers or deep learning, face scalability issues and struggle with degrading performance or long computational time. Unlike existing algorithms adopting parallel strategies, we propose Sequential Source-Destination Optimization (SSDO), a sequential solver-free algorithm for TE. SSDO decomposes the problem into subproblems, each focused on adjusting the split ratios for a specific source-destination (SD) demand while keeping others fixed. To enhance the efficiency of subproblem optimization, we design a Balanced Binary Search Method (BBSM), which identifies the most balanced split ratios among multiple solutions that minimize Maximum Link Utilization (MLU). SSDO dynamically updates the sequence of SDs based on real-time utilization, which accelerates convergence and enhances solution quality. We evaluate SSDO on Meta DCNs and two wide-area networks. In a Meta topology, SSDO achieves a 65\\% and 60\\% reduction in normalized MLU compared to TEAL and POP, two state-of-the-art TE acceleration methods, while delivering a $12\\times$ speedup over POP. These results demonstrate the superior performance of SSDO in large-scale TE.","authors":["Yingming Mao","Qiaozhu Zhai","Ximeng Liu","Zhen Yao","Xia Zhu","Yuzhou Zhou"],"pdf_url":"","comment":"Accepted by 23rd USENIX Symposium on Network Systems Design and Implementation (NSDI '26), to be held in Seattle on May 4-6, 2026"},{"id":"http://arxiv.org/abs/2512.19082v1","updated":"2025-12-22T06:45:30Z","published":"2025-12-22T06:45:30Z","title":"BEVCooper: Accurate and Communication-Efficient Bird's-Eye-View Perception in Vehicular Networks","summary":"Bird's-Eye-View (BEV) is critical to connected and automated vehicles (CAVs) as it can provide unified and precise representation of vehicular surroundings. However, quality of the raw sensing data may degrade in occluded or distant regions, undermining the fidelity of constructed BEV map. In this paper, we propose BEVCooper, a novel collaborative perception framework that can guarantee accurate and low-latency BEV map construction. We first define an effective metric to evaluate the utility of BEV features from neighboring CAVs. Then, based on this, we develop an online learning-based collaborative CAV selection strategy that captures the ever-changing BEV feature utility of neighboring vehicles, enabling the ego CAV to prioritize the most valuable sources under bandwidth-constrained vehicle-to-vehicle (V2V) links. Furthermore, we design an adaptive fusion mechanism that optimizes BEV feature compression based on the environment dynamics and real-time V2V channel quality, effectively balancing feature transmission latency and accuracy of the constructed BEV map. Theoretical analysis demonstrates that, BEVCooper achieves asymptotically optimal CAV selection and adaptive feature fusion under dynamic vehicular topology and V2V channel conditions. Extensive experiments on real-world testbed show that, compared with state-of-the-art benchmarks, the proposed BEVCooper enhances BEV perception accuracy by up to $63.18\\%$ and reduces end-to-end latency by $67.9\\%$, with only $1.8\\%$ additional computational overhead.","authors":["Jiawei Hou","Peng Yang","Xiangxiang Dai","Mingliu Liu","Conghao Zhou"],"pdf_url":"","comment":"10 pages, 11 figures, accepted by IEEE INFOCOM 2026"},{"id":"http://arxiv.org/abs/2512.19075v1","updated":"2025-12-22T06:36:37Z","published":"2025-12-22T06:36:37Z","title":"Optimal 3D Directional WPT Charging via UAV for 3D Wireless Rechargeable Sensor Networks","summary":"The high mobility and flexible deployment capability of UAVs make them an impressive option for charging nodes in Wireless Rechargeable Sensor Networks (WRSNs) using Directional Wireless Power Transfer (WPT) technology. However, existing studies largely focus on 2D-WRSNs, lacking designs catering to real 3D-WRSNs. The spatial distribution characteristics of nodes in a 3D-WRSN further increase the complexity of the charging scheduling task, thus requiring a systematic framework to solve this problem. In this paper, we investigated the Directional UAV Charging Scheduling problem for 3D-WRSNs (DCS-3D) and established its NP-hard property, and then proposed a three-step framework named as directional charging scheduling algorithm using Functional Equivalent (FuncEqv) direction set and Lin-Kernighan heuristic (LKH) for 3D-WRSNs (FELKH-3D) to solve it. In FELKH-3D, the challenge of infinite charging direction space is solved by designing an algorithm generating a minimum-size direction set guaranteed to be FuncEqv to the infinite set of whole sphere surface, and the optimaility of the method was proved.To determine the optimal charging tour for the UAV, the LKH algorithm is employed.Simulation experiments demonstrated the superiority of FELKH-3D over other classical algorithms.","authors":["Zhenguo Gao","Hui Li","Yiqin Chen","Qingyu Gao","Zhufang Kuang","Shih-Hau Fang","Hsiao-Chun Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.11291v2","updated":"2025-12-22T00:24:46Z","published":"2025-10-13T11:28:28Z","title":"Network-Optimised Spiking Neural Network (NOS) Scheduling for 6G O-RAN: Spectral Margin and Delay-Tail Control","summary":"This work presents a Network-Optimised Spiking (NOS) delay-aware scheduler for 6G radio access. The scheme couples a bounded two-state kernel to a clique-feasible proportional-fair (PF) grant head: the excitability state acts as a finite-buffer proxy, the recovery state suppresses repeated grants, and neighbour pressure is injected along the interference graph via delayed spikes. A small-signal analysis yields a delay-dependent threshold $k_\\star(Δ)$ and a spectral margin $δ= k_\\star(Δ) - gHρ(W)$ that compress topology, controller gain, and delay into a single design parameter. Under light assumptions on arrivals, we prove geometric ergodicity for $δ>0$ and derive sub-Gaussian backlog and delay tail bounds with exponents proportional to $δ$. A numerical study, aligned with the analysis and a DU compute budget, compares NOS with PF and delayed backpressure (BP) across interference topologies over a $5$--$20$\\,ms delay sweep. With a single gain fixed at the worst spectral radius, NOS sustains higher utilisation and a smaller 99.9th-percentile delay while remaining clique-feasible on integer PRBs.","authors":["Muhammad Bilal","Xiaolong Xu"],"pdf_url":"","comment":"6 pages, 5 figures, 1 table"},{"id":"http://arxiv.org/abs/2512.15503v2","updated":"2025-12-22T23:04:16Z","published":"2025-12-17T14:45:33Z","title":"Attention in Motion: Secure Platooning via Transformer-based Misbehavior Detection","summary":"Vehicular platooning promises transformative improvements in transportation efficiency and safety through the coordination of multi-vehicle formations enabled by Vehicle-to-Everything (V2X) communication. However, the distributed nature of platoon coordination creates security vulnerabilities, allowing authenticated vehicles to inject falsified kinematic data, compromise operational stability, and pose a threat to passenger safety. Traditional misbehaviour detection approaches, which rely on plausibility checks and statistical methods, suffer from high False Positive (FP) rates and cannot capture the complex temporal dependencies inherent in multi-vehicle coordination dynamics. We present Attention In Motion (AIMformer), a transformer-based framework specifically tailored for real-time misbehaviour detection in vehicular platoons with edge deployment capabilities. AIMformer leverages multi-head self-attention mechanisms to simultaneously capture intra-vehicle temporal dynamics and inter-vehicle spatial correlations. It incorporates global positional encoding with vehicle-specific temporal offsets to handle join/exit maneuvers. We propose a Precision-Focused Binary Cross-Entropy (PFBCE) loss function that penalizes FPs to meet the requirements of safety-critical vehicular systems. Extensive evaluation across 4 platoon controllers, multiple attack vectors, and diverse mobility scenarios demonstrates superior performance ($\\geq$ 0.93) compared to state-of-the-art baseline architectures. A comprehensive deployment analysis utilizing TensorFlow Lite (TFLite), Open Neural Network Exchange (ONNX), and TensorRT achieves sub-millisecond inference latency, making it suitable for real-time operation on resource-constrained edge platforms. Hence, validating AIMformer is viable for both in-vehicle and roadside infrastructure deployment.","authors":["Konstantinos Kalogiannis","Ahmed Mohamed Hussain","Hexu Li","Panos Papadimitratos"],"pdf_url":"","comment":"16 pages and 10 figures"},{"id":"http://arxiv.org/abs/2512.19849v1","updated":"2025-12-22T20:05:09Z","published":"2025-12-22T20:05:09Z","title":"UCCL-EP: Portable Expert-Parallel Communication","summary":"Mixture-of-Experts (MoE) workloads rely on expert parallelism (EP) to achieve high GPU efficiency. State-of-the-art EP communication systems such as DeepEP demonstrate strong performance but exhibit poor portability across heterogeneous GPU and NIC platforms. The poor portability is rooted in architecture: GPU-initiated token-level RDMA communication requires tight vertical integration between GPUs and NICs, e.g., GPU writes to NIC driver/MMIO interfaces.\n  We present UCCL-EP, a portable EP communication system that delivers DeepEP-level performance across heterogeneous GPU and NIC hardware. UCCL-EP replaces GPU-initiated RDMA with a high-throughput GPU-CPU control channel: compact token-routing commands are transferred to multithreaded CPU proxies, which then issue GPUDirect RDMA operations on behalf of GPUs. UCCL-EP further emulates various ordering semantics required by specialized EP communication modes using RDMA immediate data, enabling correctness on NICs that lack such ordering, e.g., AWS EFA. We implement UCCL-EP on NVIDIA and AMD GPUs with EFA and Broadcom NICs. On EFA, it outperforms the best existing EP solution by up to $2.1\\times$ for dispatch and combine throughput. On NVIDIA-only platform, UCCL-EP achieves comparable performance to the original DeepEP. UCCL-EP also improves token throughput on SGLang by up to 40% on the NVIDIA+EFA platform, and improves DeepSeek-V3 training throughput over the AMD Primus/Megatron-LM framework by up to 45% on a 16-node AMD+Broadcom platform.","authors":["Ziming Mao","Yihan Zhang","Chihan Cui","Kaichao You","Zhongjie Chen","Zhiying Xu","Scott Shenker","Costin Raiciu","Yang Zhou","Ion Stoica"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19177v1","updated":"2025-12-22T09:11:57Z","published":"2025-12-22T09:11:57Z","title":"Semantic Communication for Rate-Limited Closed-Loop Distributed Communication-Sensing-Control Systems","summary":"The growing integration of distributed integrated sensing and communication (ISAC) with closed-loop control in intelligent networks demands efficient information transmission under stringent bandwidth constraints. To address this challenge, this paper proposes a unified framework for goal-oriented semantic communication in distributed SCC systems. Building upon Weaver's three-level model, we establish a hierarchical semantic formulation with three error levels (L1: observation reconstruction, L2: state estimation, and L3: control) to jointly optimize their corresponding objectives. Based on this formulation, we propose a unified goal-oriented semantic compression and rate adaptation framework that is applicable to different semantic error levels and optimization goals across the SCC loop. A rate-limited multi-sensor LQR system is used as a case study to validate the proposed framework. We employ a GRU-based AE for semantic compression and a PPO-based rate adaptation algorithm that dynamically allocates transmission rates across sensors. Results show that the proposed framework effectively captures task-relevant semantics and adapts its resource allocation strategies across different semantic levels, thereby achieving level-specific performance gains under bandwidth constraints.","authors":["Guangjin Pan","Ayça Özçelikkale","Christian Häger","Musa Furkan Keskin","Henk Wymeersch"],"pdf_url":"","comment":"13 pages, 18 figures. This work has been submitted to the IEEE for possible publication"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2512.19687v1","updated":"2025-12-22T18:59:07Z","published":"2025-12-22T18:59:07Z","title":"Pushing the Frontier of Audiovisual Perception with Large-Scale Multimodal Correspondence Learning","summary":"We introduce Perception Encoder Audiovisual, PE-AV, a new family of encoders for audio and video understanding trained with scaled contrastive learning. Built on PE, PE-AV makes several key contributions to extend representations to audio, and natively support joint embeddings across audio-video, audio-text, and video-text modalities. PE-AV's unified cross-modal embeddings enable novel tasks such as speech retrieval, and set a new state of the art across standard audio and video benchmarks. We unlock this by building a strong audiovisual data engine that synthesizes high-quality captions for O(100M) audio-video pairs, enabling large-scale supervision consistent across modalities. Our audio data includes speech, music, and general sound effects-avoiding single-domain limitations common in prior work. We exploit ten pairwise contrastive objectives, showing that scaling cross-modality and caption-type pairs strengthens alignment and improves zero-shot performance. We further develop PE-A-Frame by fine-tuning PE-AV with frame-level contrastive objectives, enabling fine-grained audio-frame-to-text alignment for tasks such as sound event detection.","authors":["Apoorv Vyas","Heng-Jui Chang","Cheng-Fu Yang","Po-Yao Huang","Luya Gao","Julius Richter","Sanyuan Chen","Matt Le","Piotr Dollár","Christoph Feichtenhofer","Ann Lee","Wei-Ning Hsu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.20072v3","updated":"2025-12-22T18:57:39Z","published":"2025-08-27T17:39:11Z","title":"Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies","summary":"Vision-Language-Action (VLA) models adapt large vision-language backbones to map images and instructions into robot actions. However, prevailing VLAs either generate actions auto-regressively in a fixed left-to-right order or attach separate MLP or diffusion heads outside the backbone, leading to fragmented information pathways and specialized training requirements that hinder a unified, scalable architecture. We present Discrete Diffusion VLA, a unified-transformer policy that models discretized action chunks with discrete diffusion. The design retains diffusion's progressive refinement paradigm while remaining natively compatible with the discrete token interface of VLMs. Our method achieves an adaptive decoding order that resolves easy action elements before harder ones and uses secondary re-masking to revisit uncertain predictions across refinement rounds, which improves consistency and enables robust error correction. This unified decoder preserves pre-trained vision-language priors, supports parallel decoding, breaks the autoregressive bottleneck, and reduces the number of function evaluations. Discrete Diffusion VLA achieves 96.3% avg. success rates on LIBERO, 71.2% visual matching on SimplerEnv-Fractal and 54.2% overall on SimplerEnv-Bridge. We also provide ablation study on vision-language ability retention on LIBERO-OOD (Out-of-Distribution) benchmark, with our method improving over autoregressive, MLP decoder and continuous diffusion baselines. These findings indicate that discrete-diffusion VLA supports precise action modeling and consistent training, laying groundwork for scaling VLA to larger models and datasets. Our code is available at https://github.com/Liang-ZX/DiscreteDiffusionVLA/tree/libero.","authors":["Zhixuan Liang","Yizhuo Li","Tianshuo Yang","Chengyue Wu","Sitong Mao","Tian Nian","Liuao Pei","Shunbo Zhou","Xiaokang Yang","Jiangmiao Pang","Yao Mu","Ping Luo"],"pdf_url":"","comment":"New experiments on VL retention and new ablations. 18 pages"},{"id":"http://arxiv.org/abs/2510.09595v2","updated":"2025-12-22T18:56:01Z","published":"2025-10-10T17:54:24Z","title":"LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?","summary":"Competitive programming problems increasingly serve as valuable benchmarks to evaluate the coding capabilities of large language models (LLMs) due to their complexity and ease of verification. Yet, current coding benchmarks face limitations such as lack of exceptionally challenging problems, insufficient test case coverage, reliance on online platform APIs that limit accessibility. To address these issues, we introduce LiveOIBench, a comprehensive benchmark featuring 403 expert-curated Olympiad-level competitive programming problems, each with an average of 60 expert-designed test cases. The problems are sourced directly from 72 official contests of 14 Informatics Olympiads in different regions conducted between 2023 and 2025. LiveOIBench distinguishes itself through four key features: (1) meticulously curated high-quality tasks with detailed subtask rubrics and extensive private test cases; (2) direct integration of elite contestant performance data to enable informative comparison against top-performing humans; (3) planned continuous, contamination-free updates from newly released Olympiad problems; and (4) a self-contained evaluation system facilitating offline and easy-to-reproduce assessments. Benchmarking 34 popular general-purpose and reasoning LLMs, we find that GPT-5 achieves a notable 81.76th percentile, a strong result that nonetheless falls short of top human contestants, who usually place above 90th. In contrast, among open-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile, underscoring significant capability disparities from frontier closed models. Detailed analyses indicate that robust reasoning models prioritize precise problem analysis over excessive exploration, suggesting future models should emphasize structured analysis and minimize unnecessary exploration. All data, code, and leaderboard results are publicly available on our website.","authors":["Kaijian Zou","Aaron Xiong","Yunxiang Zhang","Frederick Zhang","Yueqi Ren","Jirong Yang","Ayoung Lee","Shitanshu Bhushan","Lu Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19673v1","updated":"2025-12-22T18:51:48Z","published":"2025-12-22T18:51:48Z","title":"Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies","summary":"Existing reinforcement learning (RL) approaches treat large language models (LLMs) as a single unified policy, overlooking their internal mechanisms. Understanding how policy evolves across layers and modules is therefore crucial for enabling more targeted optimization and raveling out complex reasoning mechanisms. In this paper, we decompose the language model policy by leveraging the intrinsic split of the Transformer residual stream and the equivalence between the composition of hidden states with the unembedding matrix and the resulting samplable policy. This decomposition reveals Internal Layer Policies, corresponding to contributions from individual layers, and Internal Modular Policies, which align with the self-attention and feed-forward network (FFN) components within each layer. By analyzing the entropy of internal policy, we find that: (a) Early layers keep high entropy for exploration, top layers converge to near-zero entropy for refinement, with convergence patterns varying across model series. (b) LLama's prediction space rapidly converges in the final layer, whereas Qwen-series models, especially Qwen3, exhibit a more human-like, progressively structured reasoning pattern. Motivated by these findings, we propose Bottom-up Policy Optimization (BuPO), a novel RL paradigm that directly optimizes the internal layer policy during early training. By aligning training objective at lower layer, BuPO reconstructs foundational reasoning capabilities and achieves superior performance. Extensive experiments on complex reasoning benchmarks demonstrates the effectiveness of our method. Our code is available at https://github.com/Trae1ounG/BuPO.","authors":["Yuqiao Tan","Minzheng Wang","Shizhu He","Huanxuan Liao","Chengfeng Zhao","Qiunan Lu","Tian Liang","Jun Zhao","Kang Liu"],"pdf_url":"","comment":"Preprint. Our code is available at https://github.com/Trae1ounG/BuPO"},{"id":"http://arxiv.org/abs/2506.22552v7","updated":"2025-12-22T18:48:57Z","published":"2025-06-27T18:04:36Z","title":"Probing forced responses and causality in data-driven climate emulators: conceptual limitations and the role of reduced-order models","summary":"A central challenge in climate science and applied mathematics is developing data-driven models of multiscale systems that capture both stationary statistics and responses to external perturbations. Current neural climate emulators aim to resolve the atmosphere-ocean system in all its complexity but often struggle to reproduce forced responses, limiting their use in causal studies such as Green's function experiments. To explore the origin of these limitations, we first examine a simplified dynamical system that retains key features of climate variability. We interpret the results through linear response theory, providing a rigorous framework to evaluate neural models beyond stationary statistics and to probe causal mechanisms. We argue that the ability of emulators of multiscale systems to reproduce perturbed statistics depends critically on (i) the choice of an appropriate coarse-grained representation and (ii) careful parameterizations of unresolved processes. These insights highlight reduced-order models, tailored to specific goals, processes, and scales, as valuable alternatives to general-purpose emulators. We next consider a real-world application by developing a neural model to investigate the joint variability of the surface temperature field and radiative fluxes. The model infers a multiplicative noise process directly from data, largely reproduces the system's probability distribution, and enables causal studies through forced responses. We discuss its limitations and outline directions for future work. Overall, these results expose key challenges in data-driven modeling of multiscale physical systems and underscore the value of coarse-grained, stochastic approaches, with response theory providing a principled framework to guide model design and enhance causal understanding.","authors":["Fabrizio Falasca"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.01353v2","updated":"2025-12-22T18:27:42Z","published":"2025-05-02T15:43:37Z","title":"Differentiable Nonlinear Model Predictive Control","summary":"The efficient computation of parametric solution sensitivities is a key challenge in the integration of learning-enhanced methods with nonlinear model predictive control (MPC), as their availability is crucial for many learning algorithms. This paper discusses the computation of solution sensitivities of general nonlinear programs (NLPs) using the implicit function theorem (IFT) and smoothed optimality conditions treated in interior-point methods (IPM). We detail sensitivity computation within a sequential quadratic programming (SQP) method which employs an IPM for the quadratic subproblems. Previous works presented in the machine learning community are limited to convex or unconstrained formulations, or lack an implementation for efficient sensitivity evaluation. The publication is accompanied by an efficient open-source implementation within the acados framework, providing both forward and adjoint sensitivities for general optimal control problems, achieving speedups exceeding 3x over the state-of-the-art solvers mpc.pytorch and cvxpygen.","authors":["Jonathan Frey","Katrin Baumgärtner","Gianluca Frison","Dirk Reinhardt","Jasper Hoffmann","Leonard Fichtner","Sebastien Gros","Moritz Diehl"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19649v1","updated":"2025-12-22T18:22:11Z","published":"2025-12-22T18:22:11Z","title":"Deep Legendre Transform","summary":"We introduce a novel deep learning algorithm for computing convex conjugates of differentiable convex functions, a fundamental operation in convex analysis with various applications in different fields such as optimization, control theory, physics and economics. While traditional numerical methods suffer from the curse of dimensionality and become computationally intractable in high dimensions, more recent neural network-based approaches scale better, but have mostly been studied with the aim of solving optimal transport problems and require the solution of complicated optimization or max-min problems. Using an implicit Fenchel formulation of convex conjugation, our approach facilitates an efficient gradient-based framework for the minimization of approximation errors and, as a byproduct, also provides a posteriori error estimates for the approximation quality. Numerical experiments demonstrate our method's ability to deliver accurate results across different high-dimensional examples. Moreover, by employing symbolic regression with Kolmogorov--Arnold networks, it is able to obtain the exact convex conjugates of specific convex functions.","authors":["Aleksey Minabutdinov","Patrick Cheridito"],"pdf_url":"","comment":"Accepted at NeurIPS 2025 (poster). NeurIPS page: https://neurips.cc/virtual/2025/loc/san-diego/poster/120307"},{"id":"http://arxiv.org/abs/2510.12085v2","updated":"2025-12-22T18:20:12Z","published":"2025-10-14T02:48:50Z","title":"GraphShaper: Geometry-aware Alignment for Improving Transfer Learning in Text-Attributed Graphs","summary":"Graph foundation models represent a transformative paradigm for learning transferable representations across diverse graph domains. Recent methods leverage large language models to unify graph and text modalities into a shared representation space using contrastive learning. However, systematic evaluations reveal significant performance degradation at structural boundaries where distinct topological patterns converge, with accuracy losses exceeding 20 percentage points. This issue arises from a key limitation: current methods assume all graph structures can be encoded within a single Euclidean space. In reality, tree structures require hyperbolic geometry to preserve hierarchical branching, while cyclic patterns depend on spherical geometry for closure properties. At structural boundaries, nodes experience conflicting geometric constraints that uniform encoding spaces cannot resolve. This raises a crucial challenge: \\textbf{Can alignment frameworks be designed to respect the intrinsic geometric diversity of graph structures?} We introduce \\textbf{GraphShaper}, a geometry-aware framework that enhances graph encoding through multi-geometric specialization. Our approach employs expert networks tailored to different geometric spaces, dynamically computing fusion weights to adaptively integrate geometric properties based on local structural characteristics. This adaptive fusion preserves structural integrity before alignment with text embeddings. Extensive experiments demonstrate that GraphShaper achieves 9.47\\% accuracy improvements on citation networks and 7.63\\% on social networks in zero-shot settings.","authors":["Heng Zhang","Tianyi Zhang","Yuling Shi","Xiaodong Gu","Yaomin Shen","Haochen You","Zijian Zhang","Yilei Yuan","Jin Huang"],"pdf_url":"","comment":"This submission has been withdrawn by the authors due to a fundamental error in the methodology that affects the validity of the main results"},{"id":"http://arxiv.org/abs/2512.19643v1","updated":"2025-12-22T18:17:28Z","published":"2025-12-22T18:17:28Z","title":"The Best of Both Worlds: Hybridizing Neural Operators and Solvers for Stable Long-Horizon Inference","summary":"Numerical simulation of time-dependent partial differential equations (PDEs) is central to scientific and engineering applications, but high-fidelity solvers are often prohibitively expensive for long-horizon or time-critical settings. Neural operator (NO) surrogates offer fast inference across parametric and functional inputs; however, most autoregressive NO frameworks remain vulnerable to compounding errors, and ensemble-averaged metrics provide limited guarantees for individual inference trajectories. In practice, error accumulation can become unacceptable beyond the training horizon, and existing methods lack mechanisms for online monitoring or correction. To address this gap, we propose ANCHOR (Adaptive Numerical Correction for High-fidelity Operator Rollouts), an online, instance-aware hybrid inference framework for stable long-horizon prediction of nonlinear, time-dependent PDEs. ANCHOR treats a pretrained NO as the primary inference engine and adaptively couples it with a classical numerical solver using a physics-informed, residual-based error estimator. Inspired by adaptive time-stepping in numerical analysis, ANCHOR monitors an exponential moving average (EMA) of the normalized PDE residual to detect accumulating error and trigger corrective solver interventions without requiring access to ground-truth solutions. We show that the EMA-based estimator correlates strongly with the true relative L2 error, enabling data-free, instance-aware error control during inference. Evaluations on four canonical PDEs: 1D and 2D Burgers', 2D Allen-Cahn, and 3D heat conduction, demonstrate that ANCHOR reliably bounds long-horizon error growth, stabilizes extrapolative rollouts, and significantly improves robustness over standalone neural operators, while remaining substantially more efficient than high-fidelity numerical solvers.","authors":["Rajyasri Roy","Dibyajyoti Nayak","Somdatta Goswami"],"pdf_url":"","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.08401v3","updated":"2025-12-22T17:58:14Z","published":"2025-11-11T16:16:10Z","title":"Source-Optimal Training is Transfer-Suboptimal","summary":"We prove that training a source model optimally for its own task is generically suboptimal when the objective is downstream transfer. We study the source-side optimization problem in L2-SP ridge regression and show a fundamental mismatch between the source-optimal and transfer-optimal source regularization: outside of a measure-zero set, $τ_0^* \\neq τ_S^*$. We characterize the transfer-optimal source penalty $τ_0^*$ as a function of task alignment and identify an alignment-dependent reversal: with imperfect alignment ($0<ρ<1$), transfer benefits from stronger source regularization, while in super-aligned regimes ($ρ>1$), transfer benefits from weaker regularization. In isotropic settings, the decision of whether transfer helps is independent of the target sample size and noise, depending only on task alignment and source characteristics. We verify the linear predictions in a synthetic ridge regression experiment, and we present CIFAR-10 experiments as evidence that the source-optimal versus transfer-optimal mismatch can persist in nonlinear networks.","authors":["C. Evans Hedges"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19605v1","updated":"2025-12-22T17:41:26Z","published":"2025-12-22T17:41:26Z","title":"KerJEPA: Kernel Discrepancies for Euclidean Self-Supervised Learning","summary":"Recent breakthroughs in self-supervised Joint-Embedding Predictive Architectures (JEPAs) have established that regularizing Euclidean representations toward isotropic Gaussian priors yields provable gains in training stability and downstream generalization. We introduce a new, flexible family of KerJEPAs, self-supervised learning algorithms with kernel-based regularizers. One instance of this family corresponds to the recently-introduced LeJEPA Epps-Pulley regularizer which approximates a sliced maximum mean discrepancy (MMD) with a Gaussian prior and Gaussian kernel. By expanding the class of viable kernels and priors and computing the closed-form high-dimensional limit of sliced MMDs, we develop alternative KerJEPAs with a number of favorable properties including improved training stability and design flexibility.","authors":["Eric Zimmermann","Harley Wiltzer","Justin Szeto","David Alvarez-Melis","Lester Mackey"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.17196v3","updated":"2025-12-22T17:30:15Z","published":"2025-05-22T18:05:16Z","title":"Shape it Up! Restoring LLM Safety during Finetuning","summary":"Finetuning large language models (LLMs) enables user-specific customization but introduces critical safety risks: even a few harmful examples can compromise safety alignment. A common mitigation strategy is to update the model more strongly on examples deemed safe, while downweighting or excluding those flagged as unsafe. However, because safety context can shift within a single example, updating the model equally on both harmful and harmless parts of a response is suboptimal-a coarse treatment we term static safety shaping. In contrast, we propose dynamic safety shaping (DSS), a framework that uses fine-grained safety signals to reinforce learning from safe segments of a response while suppressing unsafe content. To enable such fine-grained control during finetuning, we introduce a key insight: guardrail models, traditionally used for filtering, can be repurposed to evaluate partial responses, tracking how safety risk evolves throughout the response, segment by segment. This leads to the Safety Trajectory Assessment of Response (STAR), a token-level signal that enables shaping to operate dynamically over the training sequence. Building on this, we present STAR-DSS, guided by STAR scores, that robustly mitigates finetuning risks and delivers substantial safety improvements across diverse threats, datasets, and model families-all without compromising capability on intended tasks. We encourage future safety research to build on dynamic shaping principles for stronger mitigation against evolving finetuning risks. Our code is publicly available at https://github.com/poloclub/star-dss.","authors":["ShengYun Peng","Pin-Yu Chen","Jianfeng Chi","Seongmin Lee","Duen Horng Chau"],"pdf_url":"","comment":"NeurIPS'25"},{"id":"http://arxiv.org/abs/2507.22782v3","updated":"2025-12-22T17:22:59Z","published":"2025-07-30T15:48:38Z","title":"Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies","summary":"This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement learning algorithm designed to enhance multi-agent collaboration in cooperative environments. TAAC employs a Centralized Training/Centralized Execution scheme incorporating multi-headed attention mechanisms in both the actor and critic. This design facilitates dynamic, inter-agent communication, allowing agents to explicitly query teammates, thereby efficiently managing the exponential growth of joint-action spaces while ensuring a high degree of collaboration. We further introduce a penalized loss function which promotes diverse yet complementary roles among agents. We evaluate TAAC in a simulated soccer environment against benchmark algorithms representing other multi-agent paradigms, including Proximal Policy Optimization and Multi-Agent Actor-Attention-Critic. We find that TAAC exhibits superior performance and enhanced collaborative behaviors across a variety of metrics (win rates, goal differentials, Elo ratings, inter-agent connectivity, balanced spatial distributions, and frequent tactical interactions such as ball possession swaps).","authors":["Hugo Garrido-Lestache Belinchon","Jeremy Kedziora"],"pdf_url":"","comment":"11 pages"},{"id":"http://arxiv.org/abs/2512.19576v1","updated":"2025-12-22T17:00:25Z","published":"2025-12-22T17:00:25Z","title":"LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller","summary":"Attitude control is essential for many satellite missions. Classical controllers, however, are time-consuming to design and sensitive to model uncertainties and variations in operational boundary conditions. Deep Reinforcement Learning (DRL) offers a promising alternative by learning adaptive control strategies through autonomous interaction with a simulation environment. Overcoming the Sim2Real gap, which involves deploying an agent trained in simulation onto the real physical satellite, remains a significant challenge. In this work, we present the first successful in-orbit demonstration of an AI-based attitude controller for inertial pointing maneuvers. The controller was trained entirely in simulation and deployed to the InnoCube 3U nanosatellite, which was developed by the Julius-Maximilians-Universität Würzburg in cooperation with the Technische Universität Berlin, and launched in January 2025. We present the AI agent design, the methodology of the training procedure, the discrepancies between the simulation and the observed behavior of the real satellite, and a comparison of the AI-based attitude controller with the classical PD controller of InnoCube. Steady-state metrics confirm the robust performance of the AI-based controller during repeated in-orbit maneuvers.","authors":["Kirill Djebko","Tom Baumann","Erik Dilger","Frank Puppe","Sergio Montenegro"],"pdf_url":"","comment":"55 pages, 27 figures, 29 tables. The maneuver telemetry datasets generated and analyzed during this work are available in the GitHub repository https://github.com/kdjebko/lelar-in-orbit-data"},{"id":"http://arxiv.org/abs/2512.19554v1","updated":"2025-12-22T16:34:21Z","published":"2025-12-22T16:34:21Z","title":"CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal","summary":"Group-relative reinforcement learning with verifiable rewards (RLVR) often wastes the most informative data it already has the failures. When all rollouts are wrong, gradients stall; when one happens to be correct, the update usually ignores why the others are close-but-wrong, and credit can be misassigned to spurious chains. We present CARE (Contrastive Anchored REflection), a failure-centric post-training framework for multimodal reasoning that turns errors into supervision. CARE combines: (i) an anchored-contrastive objective that forms a compact subgroup around the best rollout and a set of semantically proximate hard negatives, performs within-subgroup z-score normalization with negative-only scaling, and includes an all-negative rescue to prevent zero-signal batches; and (ii) Reflection-Guided Resampling (RGR), a one-shot structured self-repair that rewrites a representative failure and re-scores it with the same verifier, converting near-misses into usable positives without any test-time reflection. CARE improves accuracy and training smoothness while explicitly increasing the share of learning signal that comes from failures. On Qwen2.5-VL-7B, CARE lifts macro-averaged accuracy by 4.6 points over GRPO across six verifiable visual-reasoning benchmarks; with Qwen3-VL-8B it reaches competitive or state-of-the-art results on MathVista and MMMU-Pro under an identical evaluation protocol.","authors":["Yongxin Wang","Zhicheng Yang","Meng Cao","Mingfei Han","Haokun Lin","Yingying Zhu","Xiaojun Chang","Xiaodan Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19550v1","updated":"2025-12-22T16:31:14Z","published":"2025-12-22T16:31:14Z","title":"DFORD: Directional Feedback based Online Ordinal Regression Learning","summary":"In this paper, we introduce directional feedback in the ordinal regression setting, in which the learner receives feedback on whether the predicted label is on the left or the right side of the actual label. This is a weak supervision setting for ordinal regression compared to the full information setting, where the learner can access the labels. We propose an online algorithm for ordinal regression using directional feedback. The proposed algorithm uses an exploration-exploitation scheme to learn from directional feedback efficiently. Furthermore, we introduce its kernel-based variant to learn non-linear ordinal regression models in an online setting. We use a truncation trick to make the kernel implementation more memory efficient. The proposed algorithm maintains the ordering of the thresholds in the expected sense. Moreover, it achieves the expected regret of $\\mathcal{O}(\\log T)$. We compare our approach with a full information and a weakly supervised algorithm for ordinal regression on synthetic and real-world datasets. The proposed approach, which learns using directional feedback, performs comparably (sometimes better) to its full information counterpart.","authors":["Naresh Manwani","M Elamparithy","Tanish Taneja"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.24116v2","updated":"2025-12-22T16:25:04Z","published":"2024-10-31T16:46:23Z","title":"AIDOVECL: AI-generated Dataset of Outpainted Vehicles for Eye-level Classification and Localization","summary":"Image labeling is a critical bottleneck in the development of computer vision technologies, often constraining the potential of machine learning models due to the time-intensive nature of manual annotations. This work introduces a novel approach that leverages outpainting to mitigate the problem of annotated data scarcity by generating artificial contexts and annotations, significantly reducing manual labeling efforts. We apply this technique to a particularly acute challenge in autonomous driving, urban planning, and environmental monitoring: the lack of diverse, eye-level vehicle images in desired classes. Our dataset comprises AI-generated vehicle images obtained by detecting and cropping vehicles from manually selected seed images, which are then outpainted onto larger canvases to simulate varied real-world conditions. The outpainted images include detailed annotations, providing high-quality ground truth data. Advanced outpainting techniques and image quality assessments ensure visual fidelity and contextual relevance. Ablation results show that incorporating AIDOVECL improves overall detection performance by up to 10%, and delivers gains of up to 40% in settings with greater diversity of context, object scale, and placement, with underrepresented classes achieving up to 50% higher true positives. AIDOVECL enhances vehicle detection by augmenting real training data and supporting evaluation across diverse scenarios. By demonstrating outpainting as an automatic annotation paradigm, it offers a practical and versatile solution for building fine-grained datasets with reduced labeling effort across multiple machine learning domains. The code and links to datasets used in this study are available for further research and replication at https://github.com/amir-kazemi/aidovecl .","authors":["Amir Kazemi","Qurat ul ain Fatima","Volodymyr Kindratenko","Christopher Tessum"],"pdf_url":"","comment":"34 pages, 10 figures, 5 tables"},{"id":"http://arxiv.org/abs/2512.19540v1","updated":"2025-12-22T16:24:12Z","published":"2025-12-22T16:24:12Z","title":"Active Convolved Illumination with Deep Transfer Learning for Complex Beam Transmission through Atmospheric Turbulence","summary":"Atmospheric turbulence imposes a fundamental limitation across a broad range of applications, including optical imaging, remote sensing, and free-space optical communication. Recent advances in adaptive optics, wavefront shaping, and machine learning, driven by synergistic progress in fundamental theories, optoelectronic hardware, and computational algorithms, have demonstrated substantial potential in mitigating turbulence-induced distortions. Recently, active convolved illumination (ACI) was proposed as a versatile and physics-driven technique for transmitting structured light beams with minimal distortion through highly challenging turbulent regimes. While distinct in its formulation, ACI shares conceptual similarities with other physics-driven distortion correction approaches and stands to benefit from complementary integration with data-driven deep learning (DL) models. Inspired by recent work coupling deep learning with traditional turbulence mitigation strategies, the present work investigates the feasibility of integrating ACI with neural network-based methods. We outline a conceptual framework for coupling ACI with data-driven models and identify conditions under which learned representations can meaningfully support ACI's correlation-injection mechanism. As a representative example, we employ a convolutional neural network (CNN) together with a transfer-learning approach to examine how a learned model may operate in tandem with ACI. This exploratory study demonstrates feasible implementation pathways and establishes an early foundation for assessing the potential of future ACI-DL hybrid architectures, representing a step toward evaluating broader synergistic interactions between ACI and modern DL models.","authors":["Adrian A. Moazzam","Anindya Ghoshroy","Breeanne Heusdens","Durdu O. Guney","Roohollah Askari"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19530v1","updated":"2025-12-22T16:19:01Z","published":"2025-12-22T16:19:01Z","title":"Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement","summary":"Predicting reaction outcomes across continuous solvent composition ranges remains a critical challenge in organic synthesis and process chemistry. Traditional machine learning approaches often treat solvent identity as a discrete categorical variable, which prevents systematic interpolation and extrapolation across the solvent space. This work introduces the \\textbf{Catechol Benchmark}, a high-throughput transient flow chemistry dataset comprising 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures, parameterized by continuous volume fractions ($\\% B$). We evaluate various architectures under rigorous leave-one-solvent-out and leave-one-mixture-out protocols to test generalization to unseen chemical environments.\n  Our results demonstrate that classical tabular methods (e.g., Gradient-Boosted Decision Trees) and large language model embeddings (e.g., Qwen-7B) struggle with quantitative precision, yielding Mean Squared Errors (MSE) of 0.099 and 0.129, respectively. In contrast, we propose a hybrid GNN-based architecture that integrates Graph Attention Networks (GATs) with Differential Reaction Fingerprints (DRFP) and learned mixture-aware solvent encodings. This approach achieves an \\textbf{MSE of 0.0039} ($\\pm$ 0.0003), representing a 60\\% error reduction over competitive baselines and a $>25\\times$ improvement over tabular ensembles. Ablation studies confirm that explicit molecular graph message-passing and continuous mixture encoding are essential for robust generalization. The complete dataset, evaluation protocols, and reference implementations are released to facilitate data-efficient reaction prediction and continuous solvent representation learning.","authors":["Hongsheng Xing","Qiuxin Si"],"pdf_url":"","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2512.19527v1","updated":"2025-12-22T16:18:29Z","published":"2025-12-22T16:18:29Z","title":"Deep Learning for Unrelated-Machines Scheduling: Handling Variable Dimensions","summary":"Deep learning has been effectively applied to many discrete optimization problems. However, learning-based scheduling on unrelated parallel machines remains particularly difficult to design. Not only do the numbers of jobs and machines vary, but each job-machine pair has a unique processing time, dynamically altering feature dimensions. We propose a novel approach with a neural network tailored for offline deterministic scheduling of arbitrary sizes on unrelated machines. The goal is to minimize a complex objective function that includes the makespan and the weighted tardiness of jobs and machines. Unlike existing online approaches, which process jobs sequentially, our method generates a complete schedule considering the entire input at once. The key contribution of this work lies in the sophisticated architecture of our model. By leveraging various NLP-inspired architectures, it effectively processes any number of jobs and machines with varying feature dimensions imposed by unrelated processing times. Our approach enables supervised training on small problem instances while demonstrating strong generalization to much larger scheduling environments. Trained and tested on instances with 8 jobs and 4 machines, costs were only 2.51% above optimal. Across all tested configurations of up to 100 jobs and 10 machines, our network consistently outperformed an advanced dispatching rule, which incurred 22.22% higher costs on average. As our method allows fast retraining with simulated data and adaptation to various scheduling conditions, we believe it has the potential to become a standard approach for learning-based scheduling on unrelated machines and similar problem environments.","authors":["Diego Hitzges","Guillaume Sagnol"],"pdf_url":"","comment":"24th IEEE International Conference on Machine Learning and Applications (ICMLA 2025) in Boca Raton, USA. Project page: https://github.com/DiegoHitzges/Deep-Learning-for-Unrelated-Machines-Scheduling . 8 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2512.19524v1","updated":"2025-12-22T16:17:37Z","published":"2025-12-22T16:17:37Z","title":"Initialization of a Polyharmonic Cascade, Launch and Testing","summary":"This paper concludes a series of studies on the polyharmonic cascade, a deep machine learning architecture theoretically derived from indifference principles and the theory of random functions. A universal initialization procedure is proposed, based on symmetric constellations in the form of hyperoctahedra with a central point. This initialization not only ensures stable training of cascades with tens and hundreds of layers (up to 500 layers without skip connections), but also radically simplifies the computations. Scalability and robustness are demonstrated on MNIST (98.3% without convolutions or augmentations), HIGGS (AUC approximately 0.885 on 11M examples), and Epsilon (AUC approximately 0.963 with 2000 features). All linear algebra is reduced to 2D operations and is efficiently executed on GPUs. A public repository and an archived snapshot are provided for full reproducibility.","authors":["Yuriy N. Bakhvalov"],"pdf_url":"","comment":"Part 4 of 4 in the \"Polyharmonic Cascade\" cycle. Contains initialization algorithms and experimental results (MNIST, HIGGS, Epsilon). Previous papers: arXiv:2512.12731, arXiv:2512.16718, arXiv:2512.17671. Source code: https://github.com/xolod7/polyharmonic-cascade"},{"id":"http://arxiv.org/abs/2512.17654v2","updated":"2025-12-22T16:13:25Z","published":"2025-12-19T14:52:04Z","title":"Estimating Spatially Resolved Radiation Fields Using Neural Networks","summary":"We present an in-depth analysis on how to build and train neural networks to estimate the spatial distribution of scattered radiation fields for radiation protection dosimetry in medical radiation fields, such as those found in interventional radiology and cardiology. We present three different synthetically generated datasets with increasing complexity for training, using a Monte-Carlo Simulation application based on Geant4. On those datasets, we evaluate convolutional and fully connected architectures of neural networks to demonstrate which design decisions work well for reconstructing the fluence and spectra distributions over the spatial domain of such radiation fields. All our datasets, as well as our training pipeline, are published as open source in separate repositories.","authors":["Felix Lehner","Pasquale Lombardo","Susana Castillo","Oliver Hupe","Marcus Magnor"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19516v1","updated":"2025-12-22T16:08:03Z","published":"2025-12-22T16:08:03Z","title":"LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning","summary":"Multiobjective reinforcement learning (MORL) poses significant challenges due to the inherent conflicts between objectives and the difficulty of adapting to dynamic environments. Traditional methods often struggle to generalize effectively, particularly in large and complex state-action spaces. To address these limitations, we introduce the Latent Causal Diffusion Model (LacaDM), a novel approach designed to enhance the adaptability of MORL in discrete and continuous environments. Unlike existing methods that primarily address conflicts between objectives, LacaDM learns latent temporal causal relationships between environmental states and policies, enabling efficient knowledge transfer across diverse MORL scenarios. By embedding these causal structures within a diffusion model-based framework, LacaDM achieves a balance between conflicting objectives while maintaining strong generalization capabilities in previously unseen environments. Empirical evaluations on various tasks from the MOGymnasium framework demonstrate that LacaDM consistently outperforms the state-of-art baselines in terms of hypervolume, sparsity, and expected utility maximization, showcasing its effectiveness in complex multiobjective tasks.","authors":["Xueming Yan","Bo Yin","Yaochu Jin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.11076v3","updated":"2025-12-22T16:05:29Z","published":"2025-05-16T10:07:36Z","title":"Addition is almost all you need: Compressing neural networks with double binary factorization","summary":"Binary quantization approaches, which replace weight matrices with binary matrices and substitute costly multiplications with cheaper additions, offer a computationally efficient approach to address the increasing computational and storage requirements of Large Language Models (LLMs). However, the severe quantization constraint ($\\pm1$) can lead to significant accuracy degradation. In this paper, we propose Double Binary Factorization (DBF), a novel method that factorizes dense weight matrices into products of two binary (sign) matrices, each accompanied by scaling vectors. DBF preserves the efficiency advantages of binary representations while achieving compression rates that are competitive with or superior to state-of-the-art methods. Specifically, in a 1-bit per weight range, DBF is better than existing binarization approaches. In a 2-bit per weight range, DBF is competitive with the best quantization methods like QuIP\\# and QTIP. Unlike most existing compression techniques, which offer limited compression level choices, DBF allows fine-grained control over compression ratios by adjusting the factorization's intermediate dimension. Based on this advantage, we further introduce an algorithm for estimating non-uniform layer-wise compression ratios for DBF, based on previously developed channel pruning criteria.\n  Code available at: https://github.com/usamec/double_binary","authors":["Vladimír Boža","Vladimír Macko"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19510v1","updated":"2025-12-22T16:05:18Z","published":"2025-12-22T16:05:18Z","title":"Toward Scalable and Valid Conditional Independence Testing with Spectral Representations","summary":"Conditional independence (CI) is central to causal inference, feature selection, and graphical modeling, yet it is untestable in many settings without additional assumptions. Existing CI tests often rely on restrictive structural conditions, limiting their validity on real-world data. Kernel methods using the partial covariance operator offer a more principled approach but suffer from limited adaptivity, slow convergence, and poor scalability. In this work, we explore whether representation learning can help address these limitations. Specifically, we focus on representations derived from the singular value decomposition of the partial covariance operator and use them to construct a simple test statistic, reminiscent of the Hilbert-Schmidt Independence Criterion (HSIC). We also introduce a practical bi-level contrastive algorithm to learn these representations. Our theory links representation learning error to test performance and establishes asymptotic validity and power guarantees. Preliminary experiments suggest that this approach offers a practical and statistically grounded path toward scalable CI testing, bridging kernel-based theory with modern representation learning.","authors":["Alek Frohlich","Vladimir Kostic","Karim Lounici","Daniel Perazzo","Massimiliano Pontil"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19506v1","updated":"2025-12-22T16:00:55Z","published":"2025-12-22T16:00:55Z","title":"DK-STN: A Domain Knowledge Embedded Spatio-Temporal Network Model for MJO Forecast","summary":"Understanding and predicting the Madden-Julian Oscillation (MJO) is fundamental for precipitation forecasting and disaster prevention. To date, long-term and accurate MJO prediction has remained a challenge for researchers. Conventional MJO prediction methods using Numerical Weather Prediction (NWP) are resource-intensive, time-consuming, and highly unstable (most NWP methods are sensitive to seasons, with better MJO forecast results in winter). While existing Artificial Neural Network (ANN) methods save resources and speed forecasting, their accuracy never reaches the 28 days predicted by the state-of-the-art NWP method, i.e., the operational forecasts from ECMWF, since neural networks cannot handle climate data effectively. In this paper, we present a Domain Knowledge Embedded Spatio-Temporal Network (DK-STN), a stable neural network model for accurate and efficient MJO forecasting. It combines the benefits of NWP and ANN methods and successfully improves the forecast accuracy of ANN methods while maintaining a high level of efficiency and stability. We begin with a spatial-temporal network (STN) and embed domain knowledge in it using two key methods: (i) applying a domain knowledge enhancement method and (ii) integrating a domain knowledge processing method into network training. We evaluated DK-STN with the 5th generation of ECMWF reanalysis (ERA5) data and compared it with ECMWF. Given 7 days of climate data as input, DK-STN can generate reliable forecasts for the following 28 days in 1-2 seconds, with an error of only 2-3 days in different seasons. DK-STN significantly exceeds ECMWF in that its forecast accuracy is equivalent to ECMWF's, while its efficiency and stability are significantly superior.","authors":["Hongliang Li","Nong Zhang","Zhewen Xu","Xiang Li","Changzheng Liu","Chongbo Zhao","Jie Wu"],"pdf_url":"","comment":"18 pages, 10 figures"},{"id":"http://arxiv.org/abs/2511.14455v3","updated":"2025-12-22T16:00:38Z","published":"2025-11-18T12:59:20Z","title":"Nonparametric estimation of conditional probability distributions using a generative approach based on conditional push-forward neural networks","summary":"We introduce conditional push-forward neural networks (CPFN), a generative framework for conditional distribution estimation. Instead of directly modeling the conditional density $f_{Y|X}$, CPFN learns a stochastic map $\\varphi=\\varphi(x,u)$ such that $\\varphi(x,U)$ and $Y|X=x$ follow approximately the same law, with $U$ a suitable random vector of pre-defined latent variables. This enables efficient conditional sampling and straightforward estimation of conditional statistics through Monte Carlo methods. The model is trained via an objective function derived from a Kullback-Leibler formulation, without requiring invertibility or adversarial training. We establish a near-asymptotic consistency result and demonstrate experimentally that CPFN can achieve performance competitive with, or even superior to, state-of-the-art methods, including kernel estimators, tree-based algorithms, and popular deep learning techniques, all while remaining lightweight and easy to train.","authors":["Nicola Rares Franco","Lorenzo Tedesco"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2306.05300v3","updated":"2025-12-22T15:54:45Z","published":"2023-06-08T15:45:57Z","title":"Anti-Correlated Noise in Epoch-Based Stochastic Gradient Descent: Implications for Weight Variances in Flat Directions","summary":"Stochastic Gradient Descent (SGD) has become a cornerstone of neural network optimization due to its computational efficiency and generalization capabilities. However, the gradient noise introduced by SGD is often assumed to be uncorrelated over time, despite the common practice of epoch-based training where data is sampled without replacement. In this work, we challenge this assumption and investigate the effects of epoch-based noise correlations on the stationary distribution of discrete-time SGD with momentum. Our main contributions are twofold: First, we calculate the exact autocorrelation of the noise during epoch-based training under the assumption that the noise is independent of small fluctuations in the weight vector, revealing that SGD noise is inherently anti-correlated over time. Second, we explore the influence of these anti-correlations on the variance of weight fluctuations. We find that for directions with curvature of the loss greater than a hyperparameter-dependent crossover value, the conventional predictions of isotropic weight variance under stationarity, based on uncorrelated and curvature-proportional noise, are recovered. Anti-correlations have negligible effect here. However, for relatively flat directions, the weight variance is significantly reduced, leading to a considerable decrease in loss fluctuations compared to the constant weight variance assumption. Furthermore, we present a numerical experiment where training with these anti-correlations enhances test performance, suggesting that the inherent noise structure induced by epoch-based training may play a role in finding flatter minima that generalize better.","authors":["Marcel Kühn","Bernd Rosenow"],"pdf_url":"","comment":"55 pages, 16 figures, Machine Learning: Science and Technology 2025"},{"id":"http://arxiv.org/abs/2505.20063v2","updated":"2025-12-22T15:49:59Z","published":"2025-05-26T14:47:59Z","title":"SAEs Are Good for Steering -- If You Select the Right Features","summary":"Sparse Autoencoders (SAEs) have been proposed as an unsupervised approach to learn a decomposition of a model's latent space. This enables useful applications such as steering - influencing the output of a model towards a desired concept - without requiring labeled data. Current methods identify SAE features to steer by analyzing the input tokens that activate them. However, recent work has highlighted that activations alone do not fully describe the effect of a feature on the model's output. In this work, we draw a distinction between two types of features: input features, which mainly capture patterns in the model's input, and output features, which have a human-understandable effect on the model's output. We propose input and output scores to characterize and locate these types of features, and show that high values for both scores rarely co-occur in the same features. These findings have practical implications: after filtering out features with low output scores, we obtain 2-3x improvements when steering with SAEs, making them competitive with supervised methods.","authors":["Dana Arad","Aaron Mueller","Yonatan Belinkov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19494v1","updated":"2025-12-22T15:49:24Z","published":"2025-12-22T15:49:24Z","title":"Kolmogorov-Arnold Graph Neural Networks Applied to Inorganic Nanomaterials Dataset","summary":"The recent development of Kolmogorov-Arnold Networks (KANs) introduced new discoveries in the field of Graph Neural Networks (GNNs), expanding the existing set of models with KAN-based versions of GNNs, which often surpass the accuracy of MultiLayer Perceptron (MLP)-based GNNs. These models were widely tested on the graph datasets consisting of organic molecules; however, those studies disregarded the inorganic nanomaterials datasets. In this work, we close this gap by applying Kolmogorov-Arnold Graph Neural Networks (KAGNNs) to a recently published large inorganic nanomaterials dataset called CHILI. For this, we adapt and test KAGNNs appropriate for this dataset. Our experiments reveal that on the CHILI datasets, particularly on the CHILI-3K, KAGNNs substantially surpass conventional GNNs in classification, achieving state-of-the-art results.","authors":["Nikita Volzhin","Soowhan Yoon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.24936v2","updated":"2025-12-22T15:45:08Z","published":"2025-09-29T15:36:27Z","title":"OAT-FM: Optimal Acceleration Transport for Improved Flow Matching","summary":"As a powerful technique in generative modeling, Flow Matching (FM) aims to learn velocity fields from noise to data, which is often explained and implemented as solving Optimal Transport (OT) problems. In this study, we bridge FM and the recent theory of Optimal Acceleration Transport (OAT), developing an improved FM method called OAT-FM and exploring its benefits in both theory and practice. In particular, we demonstrate that the straightening objective hidden in existing OT-based FM methods is mathematically equivalent to minimizing the physical action associated with acceleration defined by OAT. Accordingly, instead of enforcing constant velocity, OAT-FM optimizes the acceleration transport in the product space of sample and velocity, whose objective corresponds to a necessary and sufficient condition of flow straightness. An efficient algorithm is designed to achieve OAT-FM with low complexity. OAT-FM motivates a new two-phase FM paradigm: Given a generative model trained by an arbitrary FM method, whose velocity information has been relatively reliable, we can fine-tune and improve it via OAT-FM. This paradigm eliminates the risk of data distribution drift and the need to generate a large number of noise data pairs, which consistently improves model performance in various generative tasks. Code is available at: https://github.com/AngxiaoYue/OAT-FM","authors":["Angxiao Yue","Anqi Dong","Hongteng Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19491v1","updated":"2025-12-22T15:44:47Z","published":"2025-12-22T15:44:47Z","title":"Learning from sanctioned government suppliers: A machine learning and network science approach to detecting fraud and corruption in Mexico","summary":"Detecting fraud and corruption in public procurement remains a major challenge for governments worldwide. Most research to-date builds on domain-knowledge-based corruption risk indicators of individual contract-level features and some also analyzes contracting network patterns. A critical barrier for supervised machine learning is the absence of confirmed non-corrupt, negative, examples, which makes conventional machine learning inappropriate for this task. Using publicly available data on federally funded procurement in Mexico and company sanction records, this study implements positive-unlabeled (PU) learning algorithms that integrate domain-knowledge-based red flags with network-derived features to identify likely corrupt and fraudulent contracts. The best-performing PU model on average captures 32 percent more known positives and performs on average 2.3 times better than random guessing, substantially outperforming approaches based solely on traditional red flags. The analysis of the Shapley Additive Explanations reveals that network-derived features, particularly those associated with contracts in the network core or suppliers with high eigenvector centrality, are the most important. Traditional red flags further enhance model performance in line with expectations, albeit mainly for contracts awarded through competitive tenders. This methodology can support law enforcement in Mexico, and it can be adapted to other national contexts too.","authors":["Martí Medina-Hern ández","Janos Kertész","Mihály Fazekas"],"pdf_url":"","comment":"15 pages of main text with 6 figures and 31 pages of supplementary information"},{"id":"http://arxiv.org/abs/2512.19488v1","updated":"2025-12-22T15:43:39Z","published":"2025-12-22T15:43:39Z","title":"Lightweight Intrusion Detection in IoT via SHAP-Guided Feature Pruning and Knowledge-Distilled Kronecker Networks","summary":"The widespread deployment of Internet of Things (IoT) devices requires intrusion detection systems (IDS) with high accuracy while operating under strict resource constraints. Conventional deep learning IDS are often too large and computationally intensive for edge deployment. We propose a lightweight IDS that combines SHAP-guided feature pruning with knowledge-distilled Kronecker networks. A high-capacity teacher model identifies the most relevant features through SHAP explanations, and a compressed student leverages Kronecker-structured layers to minimize parameters while preserving discriminative inputs. Knowledge distillation transfers softened decision boundaries from teacher to student, improving generalization under compression. Experiments on the TON\\_IoT dataset show that the student is nearly three orders of magnitude smaller than the teacher yet sustains macro-F1 above 0.986 with millisecond-level inference latency. The results demonstrate that explainability-driven pruning and structured compression can jointly enable scalable, low-latency, and energy-efficient IDS for heterogeneous IoT environments.","authors":["Hafsa Benaddi","Mohammed Jouhari","Nouha Laamech","Anas Motii","Khalil Ibrahimi"],"pdf_url":"","comment":"This work has been published in the proceedings of the 2025 8th International Conference on Advanced Communication Technologies and Networking (CommNet)"},{"id":"http://arxiv.org/abs/2512.19472v1","updated":"2025-12-22T15:25:10Z","published":"2025-12-22T15:25:10Z","title":"Multi-Layer Confidence Scoring for Detection of Out-of-Distribution Samples, Adversarial Attacks, and In-Distribution Misclassifications","summary":"The recent explosive growth in Deep Neural Networks applications raises concerns about the black-box usage of such models, with limited trasparency and trustworthiness in high-stakes domains, which have been crystallized as regulatory requirements such as the European Union Artificial Intelligence Act. While models with embedded confidence metrics have been proposed, such approaches cannot be applied to already existing models without retraining, limiting their broad application. On the other hand, post-hoc methods, which evaluate pre-trained models, focus on solving problems related to improving the confidence in the model's predictions, and detecting Out-Of-Distribution or Adversarial Attacks samples as independent applications. To tackle the limited applicability of already existing methods, we introduce Multi-Layer Analysis for Confidence Scoring (MACS), a unified post-hoc framework that analyzes intermediate activations to produce classification-maps. From the classification-maps, we derive a score applicable for confidence estimation, detecting distributional shifts and adversarial attacks, unifying the three problems in a common framework, and achieving performances that surpass the state-of-the-art approaches in our experiments with the VGG16 and ViTb16 models with a fraction of their computational overhead.","authors":["Lorenzo Capelli","Leandro de Souza Rosa","Gianluca Setti","Mauro Mangia","Riccardo Rovatti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19469v1","updated":"2025-12-22T15:23:19Z","published":"2025-12-22T15:23:19Z","title":"GLUE: Generative Latent Unification of Expertise-Informed Engineering Models","summary":"Engineering complex systems (aircraft, buildings, vehicles) requires accounting for geometric and performance couplings across subsystems. As generative models proliferate for specialized domains (wings, structures, engines), a key research gap is how to coordinate frozen, pre-trained submodels to generate full-system designs that are feasible, diverse, and high-performing. We introduce Generative Latent Unification of Expertise-Informed Engineering Models (GLUE), which orchestrates pre-trained, frozen subsystem generators while enforcing system-level feasibility, optimality, and diversity. We propose and benchmark (i) data-driven GLUE models trained on pre-generated system-level designs and (ii) a data-free GLUE model trained online on a differentiable geometry layer. On a UAV design problem with five coupling constraints, we find that data-driven approaches yield diverse, high-performing designs but require large datasets to satisfy constraints reliably. The data-free approach is competitive with Bayesian optimization and gradient-based optimization in performance and feasibility while training a full generative model in only 10 min on a RTX 4090 GPU, requiring more than two orders of magnitude fewer geometry evaluations and FLOPs than the data-driven method. Ablations focused on data-free training show that subsystem output continuity affects coordination, and equality constraints can trigger mode collapse unless mitigated. By integrating unmodified, domain-informed submodels into a modular generative workflow, this work provides a viable path for scaling generative design to complex, real-world engineering systems.","authors":["Tim Aebersold","Soheyl Massoudi","Mark D. Fuge"],"pdf_url":"","comment":"11 pages, 10 figures. Preprint. Submitted to Computer-Aided Engineering (Elsevier)"},{"id":"http://arxiv.org/abs/2512.17593v2","updated":"2025-12-22T15:11:58Z","published":"2025-12-19T14:01:50Z","title":"A Unified Representation of Neural Networks Architectures","summary":"In this paper we consider the limiting case of neural networks (NNs) architectures when the number of neurons in each hidden layer and the number of hidden layers tend to infinity thus forming a continuum, and we derive approximation errors as a function of the number of neurons and/or hidden layers. Firstly, we consider the case of neural networks with a single hidden layer and we derive an integral infinite width neural representation that generalizes existing continuous neural networks (CNNs) representations. Then we extend this to deep residual CNNs that have a finite number of integral hidden layers and residual connections. Secondly, we revisit the relation between neural ODEs and deep residual NNs and we formalize approximation errors via discretization techniques. Then, we merge these two approaches into a unified homogeneous representation of NNs as a Distributed Parameter neural Network (DiPaNet) and we show that most of the existing finite and infinite-dimensional NNs architectures are related via homogenization/discretization with the DiPaNet representation. Our approach is purely deterministic and applies to general, uniformly continuous matrix weight functions. Relations with neural fields and other neural integro-differential equations are discussed along with further possible generalizations and applications of the DiPaNet framework.","authors":["Christophe Prieur","Mircea Lazar","Bogdan Robu"],"pdf_url":"","comment":"Minor typographical corrections and clarifications; results unchanged"},{"id":"http://arxiv.org/abs/2507.18540v2","updated":"2025-12-22T14:56:25Z","published":"2025-07-24T16:07:13Z","title":"Deep Variational Free Energy Calculation of Hydrogen Hugoniot","summary":"We develop a deep variational free energy framework to compute the equation of state of hydrogen in the warm dense matter region. This method parameterizes the variational density matrix of hydrogen nuclei and electrons at finite temperature using three deep generative models: a normalizing flow model for the Boltzmann distribution of the classical nuclei, an autoregressive transformer for the distribution of electrons in excited states, and a permutational equivariant flow model for the unitary backflow transformation of electron coordinates in Hartree-Fock states. By jointly optimizing the three neural networks to minimize the variational free energy, we obtain the equation of state and related thermodynamic properties of dense hydrogen for the temperature range where electrons occupy excited states. We compare our results with other theoretical and experimental results on the deuterium Hugoniot curve, aiming to resolve existing discrepancies. Our results bridge the gap between the results obtained by path-integral Monte Carlo calculations at high temperature and ground-state electronic methods at low temperature, thus providing a valuable benchmark for hydrogen in the warm dense matter region.","authors":["Zihang Li","Hao Xie","Xinyang Dong","Lei Wang"],"pdf_url":"","comment":"8+18 pages, 4+12 figures, for source code and raw data, see https://github.com/fermiflow/Hugoniot, https://github.com/ZihangL/hqc, https://huggingface.co/datasets/Kelvin2025q/hugoniot"},{"id":"http://arxiv.org/abs/2505.14081v2","updated":"2025-12-22T14:49:44Z","published":"2025-05-20T08:39:16Z","title":"Personalized and Resilient Distributed Learning Through Opinion Dynamics","summary":"In this paper, we address two practical challenges of distributed learning in multi-agent network systems, namely personalization and resilience. Personalization is the need of heterogeneous agents to learn local models tailored to their own data and tasks, while still generalizing well; on the other hand, the learning process must be resilient to cyberattacks or anomalous training data to avoid disruption. Motivated by a conceptual affinity between these two requirements, we devise a distributed learning algorithm that combines distributed gradient descent and the Friedkin-Johnsen model of opinion dynamics to fulfill both of them. We quantify its convergence speed and the neighborhood that contains the final learned models, which can be easily controlled by tuning the algorithm parameters to enforce a more personalized/resilient behavior. We numerically showcase the effectiveness of our algorithm on synthetic and real-world distributed learning tasks, where it achieves high global accuracy both for personalized models and with malicious agents compared to standard strategies.","authors":["Luca Ballotta","Nicola Bastianello","Riccardo M. G. Ferrari","Karl H. Johansson"],"pdf_url":"","comment":"Published on IEEE Transactions on Control of Network Systems. Final accepted version"},{"id":"http://arxiv.org/abs/2408.10566v5","updated":"2025-12-22T14:46:47Z","published":"2024-08-20T06:05:52Z","title":"Overcoming Growth-Induced Forgetting in Task-Agnostic Continual Learning","summary":"In continual learning (CL), model growth enhances adaptability to new data. However, when model growth is applied improperly, especially in task-agnostic CL, where the entire grown model is used for inference, it can lead to severe degradation of learned knowledge, a problem we term growth-induced forgetting. Most existing methods that adopt model growth to improve adaptability often overlook the forgetting issue, resulting in compromised knowledge retention, making them unsuitable for task-agnostic settings. To promote both adaptability and knowledge retention with model growth, we identify the key: gradient and parameter sparsity. Introducing SparseGrow, which increases gradient sparsity through layer expansion and gradient gating to enable focused updates on parameters while preserving critical parameters, thus inhibiting forgetting. Moreover, it promotes parameter sparsity with sparse initialization and training, aiming at better control of model plasticity, improving adaptability over new data. Extensive experiments across diverse datasets, task-agnostic settings, and a large number of tasks demonstrate the necessity of controlled layer expansion and validate the effectiveness of SparseGrow in achieving high adaptability while minimizing forgetting in continual learning. By enabling model growth with sparsified gradients and parameters, SparseGrow paves the way for building scalable lifelong learning systems capable of continual adaptation with better knowledge retention.","authors":["Yuqing Zhao","Jiannong Cao","Divya Saxena","Xiaoyun Liu","Changlin Song","Bo Yuan","Julie McCann"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19442v1","updated":"2025-12-22T14:41:17Z","published":"2025-12-22T14:41:17Z","title":"Real-Time Streamable Generative Speech Restoration with Flow Matching","summary":"Diffusion-based generative models have greatly impacted the speech processing field in recent years, exhibiting high speech naturalness and spawning a new research direction. Their application in real-time communication is, however, still lagging behind due to their computation-heavy nature involving multiple calls of large DNNs.\n  Here, we present Stream.FM, a frame-causal flow-based generative model with an algorithmic latency of 32 milliseconds (ms) and a total latency of 48 ms, paving the way for generative speech processing in real-time communication. We propose a buffered streaming inference scheme and an optimized DNN architecture, show how learned few-step numerical solvers can boost output quality at a fixed compute budget, explore model weight compression to find favorable points along a compute/quality tradeoff, and contribute a model variant with 24 ms total latency for the speech enhancement task.\n  Our work looks beyond theoretical latencies, showing that high-quality streaming generative speech processing can be realized on consumer GPUs available today. Stream.FM can solve a variety of speech processing tasks in a streaming fashion: speech enhancement, dereverberation, codec post-filtering, bandwidth extension, STFT phase retrieval, and Mel vocoding. As we verify through comprehensive evaluations and a MUSHRA listening test, Stream.FM establishes a state-of-the-art for generative streaming speech restoration, exhibits only a reasonable reduction in quality compared to a non-streaming variant, and outperforms our recent work (Diffusion Buffer) on generative streaming speech enhancement while operating at a lower latency.","authors":["Simon Welker","Bunlong Lay","Maris Hillemann","Tal Peer","Timo Gerkmann"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2512.19440v1","updated":"2025-12-22T14:40:30Z","published":"2025-12-22T14:40:30Z","title":"Binary Kernel Logistic Regression: a sparsity-inducing formulation and a convergent decomposition training algorithm","summary":"Kernel logistic regression (KLR) is a widely used supervised learning method for binary and multi-class classification, which provides estimates of the conditional probabilities of class membership for the data points. Unlike other kernel methods such as Support Vector Machines (SVMs), KLRs are generally not sparse. Previous attempts to deal with sparsity in KLR include a heuristic method referred to as the Import Vector Machine (IVM) and ad hoc regularizations such as the $\\ell_{1/2}$-based one. Achieving a good trade-off between prediction accuracy and sparsity is still a challenging issue with a potential significant impact from the application point of view. In this work, we revisit binary KLR and propose an extension of the training formulation proposed by Keerthi et al., which is able to induce sparsity in the trained model, while maintaining good testing accuracy. To efficiently solve the dual of this formulation, we devise a decomposition algorithm of Sequential Minimal Optimization type which exploits second-order information, and for which we establish global convergence. Numerical experiments conducted on 12 datasets from the literature show that the proposed binary KLR approach achieves a competitive trade-off between accuracy and sparsity with respect to IVM, $\\ell_{1/2}$-based regularization for KLR, and SVM while retaining the advantages of providing informative estimates of the class membership probabilities.","authors":["Antonio Consolo","Andrea Manno","Edoardo Amaldi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19439v1","updated":"2025-12-22T14:40:13Z","published":"2025-12-22T14:40:13Z","title":"An Inverse Scattering Inspired Fourier Neural Operator for Time-Dependent PDE Learning","summary":"Learning accurate and stable time-advancement operators for nonlinear partial differential equations (PDEs) remains challenging, particularly for chaotic, stiff, and long-horizon dynamical systems. While neural operator methods such as the Fourier Neural Operator (FNO) and Koopman-inspired extensions achieve good short-term accuracy, their long-term stability is often limited by unconstrained latent representations and cumulative rollout errors. In this work, we introduce an inverse scattering inspired Fourier Neural Operator(IS-FNO), motivated by the reversibility and spectral evolution structure underlying the classical inverse scattering transform. The proposed architecture enforces a near-reversible pairing between lifting and projection maps through an explicitly invertible neural transformation, and models latent temporal evolution using exponential Fourier layers that naturally encode linear and nonlinear spectral dynamics. We systematically evaluate IS-FNO against baseline FNO and Koopman-based models on a range of benchmark PDEs, including the Michelson-Sivashinsky and Kuramoto-Sivashinsky equations (in one and two dimensions), as well as the integrable Korteweg-de Vries and Kadomtsev-Petviashvili equations. The results demonstrate that IS-FNO achieves lower short-term errors and substantially improved long-horizon stability in non-stiff regimes. For integrable systems, reduced IS-FNO variants that embed analytical scattering structure retain competitive long-term accuracy despite limited model capacity. Overall, this work shows that incorporating physical structure -- particularly reversibility and spectral evolution -- into neural operator design significantly enhances robustness and long-term predictive fidelity for nonlinear PDE dynamics.","authors":["Rixin Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.04453v3","updated":"2025-12-22T14:35:03Z","published":"2025-07-06T16:23:07Z","title":"ESSA: Evolutionary Strategies for Scalable Alignment","summary":"Alignment of Large Language Models (LLMs) typically relies on Reinforcement Learning from Human Feedback (RLHF) with gradient-based optimizers such as Proximal Policy Optimization (PPO) or Group Relative Policy Optimization (GRPO). While effective, these methods require complex distributed training, large memory budgets, and careful hyperparameter tuning, all of which become increasingly difficult at billion-parameter scale. We present ESSA, Evolutionary Strategies for Scalable Alignment, a gradient-free framework that aligns LLMs using only forward inference and black-box optimization. ESSA focuses optimization on Low-Rank Adapters (LoRA) and further compresses their parameter space by optimizing only the singular values from an singular value decomposition (SVD) of each adapter matrix. This dimensionality reduction makes evolutionary search practical even for very large models and allows efficient operation in quantized INT4 and INT8 inference mode. Across these benchmarks ESSA improves the test accuracy of Qwen2.5-Math-7B by 12.6% on GSM8K and 14.8% on PRM800K, and raises the accuracy of LLaMA3.1-8B on IFEval by 22.5%, all compared with GRPO. In large-scale settings ESSA shows stronger scaling than gradient-based methods: on Qwen2.5-32B for PRM800K it reaches near-optimal accuracy twice as fast on 16 GPUs and six times as fast on 128 GPUs compared with GRPO. These results position evolutionary strategies as a compelling, hardware-friendly alternative to gradient-based LLM alignment, combining competitive quality with substantially reduced wall-clock time and engineering overhead.","authors":["Daria Korotyshova","Boris Shaposhnikov","Alexey Malakhov","Alexey Khokhulin","Nikita Surnachev","Kirill Ovcharenko","George Bredis","Alexey Gorbatovski","Viacheslav Sinii","Daniil Gavrilov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2311.11871v4","updated":"2025-12-22T14:29:58Z","published":"2023-11-20T16:06:35Z","title":"Training robust and generalizable quantum models","summary":"Adversarial robustness and generalization are both crucial properties of reliable machine learning models. In this paper, we study these properties in the context of quantum machine learning based on Lipschitz bounds. We derive parameter-dependent Lipschitz bounds for quantum models with trainable encoding, showing that the norm of the data encoding has a crucial impact on the robustness against data perturbations. Further, we derive a bound on the generalization error which explicitly involves the parameters of the data encoding. Our theoretical findings give rise to a practical strategy for training robust and generalizable quantum models by regularizing the Lipschitz bound in the cost. Further, we show that, for fixed and non-trainable encodings, as those frequently employed in quantum machine learning, the Lipschitz bound cannot be influenced by tuning the parameters. Thus, trainable encodings are crucial for systematically adapting robustness and generalization during training. The practical implications of our theoretical findings are illustrated with numerical results.","authors":["Julian Berberich","Daniel Fink","Daniel Pranjić","Christian Tutschku","Christian Holm"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19428v1","updated":"2025-12-22T14:29:18Z","published":"2025-12-22T14:29:18Z","title":"Attention Is Not What You Need","summary":"We revisit a basic question in sequence modeling: is explicit self-attention actually necessary for strong performance and reasoning? We argue that standard multi-head attention is best seen as a form of tensor lifting: hidden vectors are mapped into a high-dimensional space of pairwise interactions, and learning proceeds by constraining this lifted tensor through gradient descent. This mechanism is extremely expressive but mathematically opaque, because after many layers it becomes very hard to describe the model with a small family of explicit invariants.\n  To explore an alternative, we propose an attention-free architecture based on Grassmann flows. Instead of forming an L by L attention matrix, our Causal Grassmann layer (i) linearly reduces token states, (ii) encodes local token pairs as two-dimensional subspaces on a Grassmann manifold via Plucker coordinates, and (iii) fuses these geometric features back into the hidden states through gated mixing. Information therefore propagates by controlled deformations of low-rank subspaces over multi-scale local windows, so the core computation lives on a finite-dimensional manifold rather than in an unstructured tensor space.\n  On the Wikitext-2 language modeling benchmark, purely Grassmann-based models with 13 to 18 million parameters achieve validation perplexities within about 10 to 15 percent of size-matched Transformers. On the SNLI natural language inference task, a Grassmann-Plucker head on top of DistilBERT slightly outperforms a Transformer head, with best validation and test accuracies of 0.8550 and 0.8538 compared to 0.8545 and 0.8511. We analyze the complexity of Grassmann mixing, show linear scaling in sequence length for fixed rank, and argue that such manifold-based designs offer a more structured route toward geometric and invariant-based interpretations of neural reasoning.","authors":["Zhang Chong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.07329v2","updated":"2025-12-22T14:21:27Z","published":"2025-11-10T17:31:39Z","title":"Preparation of Fractal-Inspired Computational Architectures for Advanced Large Language Model Analysis","summary":"It introduces FractalNet, a fractal-inspired computational architectures for advanced large language model analysis that mainly challenges model diversity on a large scale in an efficient manner. The new set-up involves a template-driven generator, runner, and evaluation framework that, through systematic permutations of convolutional, normalization, activation, and dropout layers, can create more than 1,200 variants of neural networks. Fractal templates allow for structural recursion and multi-column pathways, thus, models become deeper and wider in a balanced way. Training utilizes PyTorch, Automatic Mixed Precision (AMP), and gradient checkpointing and is carried out on the CIFAR-10 dataset for five epochs. The outcomes show that fractal-based architectures are capable of strong performance and are computationally efficient. The paper positions fractal design as a feasible and resource-efficient method of automated architecture exploration.","authors":["Yash Mittal","Dmitry Ignatov","Radu Timofte"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17473v2","updated":"2025-12-22T14:13:49Z","published":"2025-12-19T11:40:06Z","title":"Alternating Direction Method of Multipliers for Nonlinear Matrix Decompositions","summary":"We present an algorithm based on the alternating direction method of multipliers (ADMM) for solving nonlinear matrix decompositions (NMD). Given an input matrix $X \\in \\mathbb{R}^{m \\times n}$ and a factorization rank $r \\ll \\min(m, n)$, NMD seeks matrices $W \\in \\mathbb{R}^{m \\times r}$ and $H \\in \\mathbb{R}^{r \\times n}$ such that $X \\approx f(WH)$, where $f$ is an element-wise nonlinear function. We evaluate our method on several representative nonlinear models: the rectified linear unit activation $f(x) = \\max(0, x)$, suitable for nonnegative sparse data approximation, the component-wise square $f(x) = x^2$, applicable to probabilistic circuit representation, and the MinMax transform $f(x) = \\min(b, \\max(a, x))$, relevant for recommender systems. The proposed framework flexibly supports diverse loss functions, including least squares, $\\ell_1$ norm, and the Kullback-Leibler divergence, and can be readily extended to other nonlinearities and metrics. We illustrate the applicability, efficiency, and adaptability of the approach on real-world datasets, highlighting its potential for a broad range of applications.","authors":["Atharva Awari","Nicolas Gillis","Arnaud Vandaele"],"pdf_url":"","comment":"14 pages, 6 figures. v2: Added a forgotten acknowledgement. Code available from https://gitlab.com/Atharva05/admm-for-nmd"},{"id":"http://arxiv.org/abs/2512.19410v1","updated":"2025-12-22T14:05:31Z","published":"2025-12-22T14:05:31Z","title":"Research Program: Theory of Learning in Dynamical Systems","summary":"Modern learning systems increasingly interact with data that evolve over time and depend on hidden internal state. We ask a basic question: when is such a dynamical system learnable from observations alone? This paper proposes a research program for understanding learnability in dynamical systems through the lens of next-token prediction. We argue that learnability in dynamical systems should be studied as a finite-sample question, and be based on the properties of the underlying dynamics rather than the statistical properties of the resulting sequence. To this end, we give a formulation of learnability for stochastic processes induced by dynamical systems, focusing on guarantees that hold uniformly at every time step after a finite burn-in period. This leads to a notion of dynamic learnability which captures how the structure of a system, such as stability, mixing, observability, and spectral properties, governs the number of observations required before reliable prediction becomes possible. We illustrate the framework in the case of linear dynamical systems, showing that accurate prediction can be achieved after finite observation without system identification, by leveraging improper methods based on spectral filtering. We survey the relationship between learning in dynamical systems and classical PAC, online, and universal prediction theories, and suggest directions for studying nonlinear and controlled systems.","authors":["Elad Hazan","Shai Shalev Shwartz","Nathan Srebro"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19409v1","updated":"2025-12-22T14:04:13Z","published":"2025-12-22T14:04:13Z","title":"Symplectic Reservoir Representation of Legendre Dynamics","summary":"Modern learning systems act on internal representations of data, yet how these representations encode underlying physical or statistical structure is often left implicit. In physics, conservation laws of Hamiltonian systems such as symplecticity guarantee long-term stability, and recent work has begun to hard-wire such constraints into learning models at the loss or output level. Here we ask a different question: what would it mean for the representation itself to obey a symplectic conservation law in the sense of Hamiltonian mechanics?\n  We express this symplectic constraint through Legendre duality: the pairing between primal and dual parameters, which becomes the structure that the representation must preserve. We formalize Legendre dynamics as stochastic processes whose trajectories remain on Legendre graphs, so that the evolving primal-dual parameters stay Legendre dual. We show that this class includes linear time-invariant Gaussian process regression and Ornstein-Uhlenbeck dynamics.\n  Geometrically, we prove that the maps that preserve all Legendre graphs are exactly symplectomorphisms of cotangent bundles of the form \"cotangent lift of a base diffeomorphism followed by an exact fibre translation\". Dynamically, this characterization leads to the design of a Symplectic Reservoir (SR), a reservoir-computing architecture that is a special case of recurrent neural network and whose recurrent core is generated by Hamiltonian systems that are at most linear in the momentum.\n  Our main theorem shows that every SR update has this normal form and therefore transports Legendre graphs to Legendre graphs, preserving Legendre duality at each time step. Overall, SR implements a geometrically constrained, Legendre-preserving representation map, injecting symplectic geometry and Hamiltonian mechanics directly at the representational level.","authors":["Robert Simon Fong","Gouhei Tanaka","Kazuyuki Aihara"],"pdf_url":"","comment":"39 pages"},{"id":"http://arxiv.org/abs/2512.19399v1","updated":"2025-12-22T13:51:03Z","published":"2025-12-22T13:51:03Z","title":"Brain-Grounded Axes for Reading and Steering LLM States","summary":"Interpretability methods for large language models (LLMs) typically derive directions from textual supervision, which can lack external grounding. We propose using human brain activity not as a training signal but as a coordinate system for reading and steering LLM states. Using the SMN4Lang MEG dataset, we construct a word-level brain atlas of phase-locking value (PLV) patterns and extract latent axes via ICA. We validate axes with independent lexica and NER-based labels (POS/log-frequency used as sanity checks), then train lightweight adapters that map LLM hidden states to these brain axes without fine-tuning the LLM. Steering along the resulting brain-derived directions yields a robust lexical (frequency-linked) axis in a mid TinyLlama layer, surviving perplexity-matched controls, and a brain-vs-text probe comparison shows larger log-frequency shifts (relative to the text probe) with lower perplexity for the brain axis. A function/content axis (axis 13) shows consistent steering in TinyLlama, Qwen2-0.5B, and GPT-2, with PPL-matched text-level corroboration. Layer-4 effects in TinyLlama are large but inconsistent, so we treat them as secondary (Appendix). Axis structure is stable when the atlas is rebuilt without GPT embedding-change features or with word2vec embeddings (|r|=0.64-0.95 across matched axes), reducing circularity concerns. Exploratory fMRI anchoring suggests potential alignment for embedding change and log frequency, but effects are sensitive to hemodynamic modeling assumptions and are treated as population-level evidence only. These results support a new interface: neurophysiology-grounded axes provide interpretable and controllable handles for LLM behavior.","authors":["Sandro Andric"],"pdf_url":"","comment":"10 pages, 4 figures. Code: https://github.com/sandroandric/Brain-Grounded-Axes-for-Reading-and-Steering-LLM-States"},{"id":"http://arxiv.org/abs/2412.14031v5","updated":"2025-12-22T13:49:48Z","published":"2024-12-18T16:51:47Z","title":"A Riemannian Optimization Perspective of the Gauss-Newton Method for Feedforward Neural Networks","summary":"In this work, we establish non-asymptotic convergence bounds for the Gauss-Newton method in training neural networks with smooth activations. In the underparameterized regime, the Gauss-Newton gradient flow in parameter space induces a Riemannian gradient flow on a low-dimensional embedded submanifold of the function space. Using tools from Riemannian optimization, we establish geodesic Polyak-Lojasiewicz and Lipschitz-smoothness conditions for the loss under appropriately chosen output scaling, yielding geometric convergence to the optimal in-class predictor at an explicit rate independent of the conditioning of the Gram matrix. In the overparameterized regime, we propose adaptive, curvature-aware regularization schedules that ensure fast geometric convergence to a global optimum at a rate independent of the minimum eigenvalue of the neural tangent kernel and, locally, of the modulus of strong convexity of the loss. These results demonstrate that Gauss-Newton achieves accelerated convergence rates in settings where first-order methods exhibit slow convergence due to ill-conditioned kernel matrices and loss landscapes.","authors":["Semih Cayci"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.17383v2","updated":"2025-12-22T13:33:33Z","published":"2025-07-23T10:26:10Z","title":"Confidence Calibration in Vision-Language-Action Models","summary":"Trustworthy robot behavior requires not only high levels of task success but also that the robot can reliably quantify how likely it is to succeed. To this end, we present a first-of-its-kind study of confidence calibration in vision-language-action (VLA) foundation models, which map visual observations and natural language instructions to low-level robot motor commands. We establish a confidence baseline for VLAs, examine how task success relates to calibration error and how calibration evolves over time, and introduce two lightweight techniques to remedy the miscalibration we observe: prompt ensembles and action-wise Platt scaling. Our aim in this study is to begin to develop the tools and conceptual understanding necessary to render VLAs both highly performant and highly trustworthy via reliable uncertainty quantification.","authors":["Thomas P Zollo","Richard Zemel"],"pdf_url":"","comment":"38 pages, 19 figures; additional experiments with VLA variants"},{"id":"http://arxiv.org/abs/2408.11607v3","updated":"2025-12-22T13:33:03Z","published":"2024-08-21T13:32:46Z","title":"Networked Communication for Mean-Field Games with Function Approximation and Empirical Mean-Field Estimation","summary":"Recent algorithms allow decentralised agents, possibly connected via a communication network, to learn equilibria in mean-field games from a non-episodic run of the empirical system. However, these algorithms are for tabular settings: this computationally limits the size of agents' observation space, meaning the algorithms cannot handle anything but small state spaces, nor generalise beyond policies depending only on the agent's local state to so-called 'population-dependent' policies. We address this limitation by introducing function approximation to the existing setting, drawing on the Munchausen Online Mirror Descent method that has previously been employed only in finite-horizon, episodic, centralised settings. While this permits us to include the mean field in the observation for players' policies, it is unrealistic to assume decentralised agents have access to this global information: we therefore also provide new algorithms allowing agents to locally estimate the global empirical distribution, and to improve this estimate via inter-agent communication. We prove theoretically that exchanging policy information helps networked agents outperform both independent and even centralised agents in function-approximation settings. Our experiments demonstrate this happening empirically, and show that the communication network allows decentralised agents to estimate the mean field for population-dependent policies.","authors":["Patrick Benjamin","Alessandro Abate"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19383v1","updated":"2025-12-22T13:27:23Z","published":"2025-12-22T13:27:23Z","title":"Real-Time Machine Learning for Embedded Anomaly Detection","summary":"The spread of a resource-constrained Internet of Things (IoT) environment and embedded devices has put pressure on the real-time detection of anomalies occurring at the edge. This survey presents an overview of machine-learning methods aimed specifically at on-device anomaly detection with extremely strict constraints for latency, memory, and power consumption. Lightweight algorithms such as Isolation Forest, One-Class SVM, recurrent architectures, and statistical techniques are compared here according to the realities of embedded implementation. Our survey brings out significant trade-offs of accuracy and computational efficiency of detection, as well as how hardware constraints end up fundamentally redefining algorithm choice. The survey is completed with a set of practical recommendations on the choice of the algorithm depending on the equipment profiles and new trends in TinyML, which can help close the gap between detection capabilities and embedded reality. The paper serves as a strategic roadmap for engineers deploying anomaly detection in edge environments that are constrained by bandwidth and may be safety-critical.","authors":["Abdelmadjid Benmachiche","Khadija Rais","Hamda Slimi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2306.02766v6","updated":"2025-12-22T13:25:46Z","published":"2023-06-05T10:45:39Z","title":"Networked Communication for Decentralised Agents in Mean-Field Games","summary":"Methods like multi-agent reinforcement learning struggle to scale with growing population size. Mean-field games (MFGs) are a game-theoretic approach that can circumvent this by finding a solution for an abstract infinite population, which can then be used as an approximate solution for the $N$-agent problem. However, classical mean-field algorithms usually only work under restrictive conditions. We take steps to address this by introducing networked communication to MFGs, in particular to settings that use a single, non-episodic run of $N$ decentralised agents to simulate the infinite population, as is likely to be most reasonable in real-world deployments. We prove that our architecture's sample guarantees lie between those of earlier theoretical algorithms for the centralised- and independent-learning architectures, varying dependent on network structure and the number of communication rounds. However, the sample guarantees of the three theoretical algorithms do not actually result in practical convergence times. We thus contribute practical enhancements to all three algorithms allowing us to present their first empirical demonstrations. We then show that in practical settings where the theoretical hyperparameters are not observed, giving fewer loops but poorer estimation of the Q-function, our communication scheme still respects the earlier theoretical analysis: it considerably accelerates learning over the independent case, which hardly seems to learn at all, and often performs similarly to the centralised case, while removing the restrictive assumption of the latter. We provide ablations and additional studies showing that our networked approach also has advantages over both alternatives in terms of robustness to update failures and to changes in population size.","authors":["Patrick Benjamin","Alessandro Abate"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19379v1","updated":"2025-12-22T13:23:55Z","published":"2025-12-22T13:23:55Z","title":"OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation","summary":"Indonesian, spoken by over 200 million people, remains underserved in multimodal emotion recognition research despite its dominant presence on Southeast Asian social media platforms. We introduce IndoMER, the first multimodal emotion recognition benchmark for Indonesian, comprising 1,944 video segments from 203 speakers with temporally aligned text, audio, and visual annotations across seven emotion categories. The dataset exhibits realistic challenges including cross-modal inconsistency and long-tailed class distributions shaped by Indonesian cultural communication norms. To address these challenges, we propose OmniMER, a multimodal adaptation framework built upon Qwen2.5-Omni that enhances emotion recognition through three auxiliary modality-specific perception tasks: emotion keyword extraction for text, facial expression analysis for video, and prosody analysis for audio. These auxiliary tasks help the model identify emotion-relevant cues in each modality before fusion, reducing reliance on spurious correlations in low-resource settings. Experiments on IndoMER show that OmniMER achieves 0.582 Macro-F1 on sentiment classification and 0.454 on emotion recognition, outperforming the base model by 7.6 and 22.1 absolute points respectively. Cross-lingual evaluation on the Chinese CH-SIMS dataset further demonstrates the generalizability of the proposed framework. The dataset and code are publicly available. https://github.com/yanxm01/INDOMER","authors":["Xueming Yan","Boyan Xu","Yaochu Jin","Lixian Xiao","Wenlong Ye","Runyang Cai","Zeqi Zheng","Jingfa Liu","Aimin Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19376v1","updated":"2025-12-22T13:21:11Z","published":"2025-12-22T13:21:11Z","title":"A Critical Assessment of Pattern Comparisons Between POD and Autoencoders in Intraventricular Flows","summary":"Understanding intraventricular hemodynamics requires compact and physically interpretable representations of the underlying flow structures, as characteristic flow patterns are closely associated with cardiovascular conditions and can support early detection of cardiac deterioration. Conventional visualization of velocity or pressure fields, however, provides limited insight into the coherent mechanisms driving these dynamics. Reduced-order modeling techniques, like Proper Orthogonal Decomposition (POD) and Autoencoder (AE) architectures, offer powerful alternatives to extract dominant flow features from complex datasets. This study systematically compares POD with several AE variants (Linear, Nonlinear, Convolutional, and Variational) using left ventricular flow fields obtained from computational fluid dynamics simulations. We show that, for a suitably chosen latent dimension, AEs produce modes that become nearly orthogonal and qualitatively resemble POD modes that capture a given percentage of kinetic energy. As the number of latent modes increases, AE modes progressively lose orthogonality, leading to linear dependence, spatial redundancy, and the appearance of repeated modes with substantial high-frequency content. This degradation reduces interpretability and introduces noise-like components into AE-based reduced-order models, potentially complicating their integration with physics-based formulations or neural-network surrogates. The extent of interpretability loss varies across the AEs, with nonlinear, convolutional, and variational models exhibiting distinct behaviors in orthogonality preservation and feature localization. Overall, the results indicate that AEs can reproduce POD-like coherent structures under specific latent-space configurations, while highlighting the need for careful mode selection to ensure physically meaningful representations of cardiac flow dynamics.","authors":["Eneko Lazpita","Andrés Bell-Navas","Jesús Garicano-Mena","Petros Koumoutsakos","Soledad Le Clainche"],"pdf_url":"","comment":"27 pages, 9 figures"},{"id":"http://arxiv.org/abs/2512.19373v1","updated":"2025-12-22T13:15:52Z","published":"2025-12-22T13:15:52Z","title":"Cluster-Based Generalized Additive Models Informed by Random Fourier Features","summary":"Explainable machine learning aims to strike a balance between prediction accuracy and model transparency, particularly in settings where black-box predictive models, such as deep neural networks or kernel-based methods, achieve strong empirical performance but remain difficult to interpret. This work introduces a mixture of generalized additive models (GAMs) in which random Fourier feature (RFF) representations are leveraged to uncover locally adaptive structure in the data. In the proposed method, an RFF-based embedding is first learned and then compressed via principal component analysis. The resulting low-dimensional representations are used to perform soft clustering of the data through a Gaussian mixture model. These cluster assignments are then applied to construct a mixture-of-GAMs framework, where each local GAM captures nonlinear effects through interpretable univariate smooth functions. Numerical experiments on real-world regression benchmarks, including the California Housing, NASA Airfoil Self-Noise, and Bike Sharing datasets, demonstrate improved predictive performance relative to classical interpretable models. Overall, this construction provides a principled approach for integrating representation learning with transparent statistical modeling.","authors":["Xin Huang","Jia Li","Jun Yu"],"pdf_url":"","comment":"25 pages, 13 figures, 4 tables"},{"id":"http://arxiv.org/abs/2512.19367v1","updated":"2025-12-22T13:09:45Z","published":"2025-12-22T13:09:45Z","title":"Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture","summary":"We present Sprecher Networks (SNs), a family of trainable neural architectures inspired by the classical Kolmogorov-Arnold-Sprecher (KAS) construction for approximating multivariate continuous functions. Distinct from Multi-Layer Perceptrons (MLPs) with fixed node activations and Kolmogorov-Arnold Networks (KANs) featuring learnable edge activations, SNs utilize shared, learnable splines (monotonic and general) within structured blocks incorporating explicit shift parameters and mixing weights. Our approach directly realizes Sprecher's specific 1965 sum of shifted splines formula in its single-layer variant and extends it to deeper, multi-layer compositions. We further enhance the architecture with optional lateral mixing connections that enable intra-block communication between output dimensions, providing a parameter-efficient alternative to full attention mechanisms. Beyond parameter efficiency with $O(LN + LG)$ scaling (where $G$ is the knot count of the shared splines) versus MLPs' $O(LN^2)$, SNs admit a sequential evaluation strategy that reduces peak forward-intermediate memory from $O(N^2)$ to $O(N)$ (treating batch size as constant), making much wider architectures feasible under memory constraints. We demonstrate empirically that composing these blocks into deep networks leads to highly parameter and memory-efficient models, discuss theoretical motivations, and compare SNs with related architectures (MLPs, KANs, and networks with learnable node activations).","authors":["Christian Hägg","Kathlén Kohn","Giovanni Luca Marchetti","Boris Shapiro"],"pdf_url":"","comment":"37 pages"},{"id":"http://arxiv.org/abs/2512.19366v1","updated":"2025-12-22T13:08:58Z","published":"2025-12-22T13:08:58Z","title":"Learning General Policies with Policy Gradient Methods","summary":"While reinforcement learning methods have delivered remarkable results in a number of settings, generalization, i.e., the ability to produce policies that generalize in a reliable and systematic way, has remained a challenge. The problem of generalization has been addressed formally in classical planning where provable correct policies that generalize over all instances of a given domain have been learned using combinatorial methods. The aim of this work is to bring these two research threads together to illuminate the conditions under which (deep) reinforcement learning approaches, and in particular, policy optimization methods, can be used to learn policies that generalize like combinatorial methods do. We draw on lessons learned from previous combinatorial and deep learning approaches, and extend them in a convenient way. From the former, we model policies as state transition classifiers, as (ground) actions are not general and change from instance to instance. From the latter, we use graph neural networks (GNNs) adapted to deal with relational structures for representing value functions over planning states, and in our case, policies. With these ingredients in place, we find that actor-critic methods can be used to learn policies that generalize almost as well as those obtained using combinatorial approaches while avoiding the scalability bottleneck and the use of feature pools. Moreover, the limitations of the DRL methods on the benchmarks considered have little to do with deep learning or reinforcement learning algorithms, and result from the well-understood expressive limitations of GNNs, and the tradeoff between optimality and generalization (general policies cannot be optimal in some domains). Both of these limitations are addressed without changing the basic DRL methods by adding derived predicates and an alternative cost structure to optimize.","authors":["Simon Ståhlberg","Blai Bonet","Hector Geffner"],"pdf_url":"","comment":"In Proceedings of the 20th International Conference on Principles of Knowledge Representation and Reasoning (KR 2023)"},{"id":"http://arxiv.org/abs/2512.19363v1","updated":"2025-12-22T13:04:16Z","published":"2025-12-22T13:04:16Z","title":"From Points to Coalitions: Hierarchical Contrastive Shapley Values for Prioritizing Data Samples","summary":"How should we quantify the value of each training example when datasets are large, heterogeneous, and geometrically structured? Classical Data-Shapley answers in principle, but its O(n!) complexity and point-wise perspective are ill-suited to modern scales. We propose Hierarchical Contrastive Data Valuation (HCDV), a three-stage framework that (i) learns a contrastive, geometry-preserving representation, (ii) organizes the data into a balanced coarse-to-fine hierarchy of clusters, and (iii) assigns Shapley-style payoffs to coalitions via local Monte-Carlo games whose budgets are propagated downward. HCDV collapses the factorial burden to O(T sum_{l} K_{l}) = O(T K_max log n), rewards examples that sharpen decision boundaries, and regularizes outliers through curvature-based smoothness. We prove that HCDV approximately satisfies the four Shapley axioms with surplus loss O(eta log n), enjoys sub-Gaussian coalition deviation tilde O(1/sqrt{T}), and incurs at most k epsilon_infty regret for top-k selection. Experiments on four benchmarks--tabular, vision, streaming, and a 45M-sample CTR task--plus the OpenDataVal suite show that HCDV lifts accuracy by up to +5 pp, slashes valuation time by up to 100x, and directly supports tasks such as augmentation filtering, low-latency streaming updates, and fair marketplace payouts.","authors":["Canran Xiao","Jiabao Dou","Zhiming Lin","Zong Ke","Liwei Hou"],"pdf_url":"","comment":"AAAI'26 Oral"},{"id":"http://arxiv.org/abs/2512.19361v1","updated":"2025-12-22T12:59:48Z","published":"2025-12-22T12:59:48Z","title":"Interpretable Hybrid Deep Q-Learning Framework for IoT-Based Food Spoilage Prediction with Synthetic Data Generation and Hardware Validation","summary":"The need for an intelligent, real-time spoilage prediction system has become critical in modern IoT-driven food supply chains, where perishable goods are highly susceptible to environmental conditions. Existing methods often lack adaptability to dynamic conditions and fail to optimize decision making in real time. To address these challenges, we propose a hybrid reinforcement learning framework integrating Long Short-Term Memory (LSTM) and Recurrent Neural Networks (RNN) for enhanced spoilage prediction. This hybrid architecture captures temporal dependencies within sensor data, enabling robust and adaptive decision making. In alignment with interpretable artificial intelligence principles, a rule-based classifier environment is employed to provide transparent ground truth labeling of spoilage levels based on domain-specific thresholds. This structured design allows the agent to operate within clearly defined semantic boundaries, supporting traceable and interpretable decisions. Model behavior is monitored using interpretability-driven metrics, including spoilage accuracy, reward-to-step ratio, loss reduction rate, and exploration decay. These metrics provide both quantitative performance evaluation and insights into learning dynamics. A class-wise spoilage distribution visualization is used to analyze the agents decision profile and policy behavior. Extensive evaluations on simulated and real-time hardware data demonstrate that the LSTM and RNN based agent outperforms alternative reinforcement learning approaches in prediction accuracy and decision efficiency while maintaining interpretability. The results highlight the potential of hybrid deep reinforcement learning with integrated interpretability for scalable IoT-based food monitoring systems.","authors":["Isshaan Singh","Divyansh Chawla","Anshu Garg","Shivin Mangal","Pallavi Gupta","Khushi Agarwal","Nimrat Singh Khalsa","Nandan Patel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19349v1","updated":"2025-12-22T12:48:29Z","published":"2025-12-22T12:48:29Z","title":"VIGOR+: Iterative Confounder Generation and Validation via LLM-CEVAE Feedback Loop","summary":"Hidden confounding remains a fundamental challenge in causal inference from observational data. Recent advances leverage Large Language Models (LLMs) to generate plausible hidden confounders based on domain knowledge, yet a critical gap exists: LLM-generated confounders often exhibit semantic plausibility without statistical utility. We propose VIGOR+ (Variational Information Gain for iterative cOnfounder Refinement), a novel framework that closes the loop between LLM-based confounder generation and CEVAE-based statistical validation. Unlike prior approaches that treat generation and validation as separate stages, VIGOR+ establishes an iterative feedback mechanism: validation signals from CEVAE (including information gain, latent consistency metrics, and diagnostic messages) are transformed into natural language feedback that guides subsequent LLM generation rounds. This iterative refinement continues until convergence criteria are met. We formalize the feedback mechanism, prove convergence properties under mild assumptions, and provide a complete algorithmic framework.","authors":["JiaWei Zhu","ZiHeng Liu"],"pdf_url":"","comment":"7 pages,1 figure,4 tables"},{"id":"http://arxiv.org/abs/2512.19342v1","updated":"2025-12-22T12:36:54Z","published":"2025-12-22T12:36:54Z","title":"Faster Distributed Inference-Only Recommender Systems via Bounded Lag Synchronous Collectives","summary":"Recommender systems are enablers of personalized content delivery, and therefore revenue, for many large companies. In the last decade, deep learning recommender models (DLRMs) are the de-facto standard in this field. The main bottleneck in DLRM inference is the lookup of sparse features across huge embedding tables, which are usually partitioned across the aggregate RAM of many nodes. In state-of-the-art recommender systems, the distributed lookup is implemented via irregular all-to-all (alltoallv) communication, and often presents the main bottleneck. Today, most related work sees this operation as a given; in addition, every collective is synchronous in nature. In this work, we propose a novel bounded lag synchronous (BLS) version of the alltoallv operation. The bound can be a parameter allowing slower processes to lag behind entire iterations before the fastest processes block. In special applications such as inference-only DLRM, the accuracy of the application is fully preserved. We implement BLS alltoallv in a new PyTorch Distributed backend and evaluate it with a BLS version of the reference DLRM code. We show that for well balanced, homogeneous-access DLRM runs our BLS technique does not offer notable advantages. But for unbalanced runs, e.g. runs with strongly irregular embedding table accesses or with delays across different processes, our BLS technique improves both the latency and throughput of inference-only DLRM. In the best-case scenario, the proposed reduced synchronisation can mask the delays across processes altogether.","authors":["Kiril Dichev","Filip Pawlowski","Albert-Jan Yzelman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20944v3","updated":"2025-12-22T12:31:00Z","published":"2025-11-26T00:34:46Z","title":"Semantic Superiority vs. Forensic Efficiency: A Comparative Analysis of Deep Learning and Psycholinguistics for Business Email Compromise Detection","summary":"Business Email Compromise (BEC) is a sophisticated social engineering threat that manipulates organizational hierarchies, leading to significant financial damage. According to the 2024 FBI Internet Crime Report, BEC accounts for over $2.9 billion in annual losses, presenting a massive economic asymmetry: the financial cost of a False Negative (fraud loss) exceeds the operational cost of a False Positive (manual review) by a ratio of approximately 5,480:1. This paper contrasts two detection paradigms: a Forensic Psycholinguistic Stream (CatBoost), which analyzes linguistic cues like urgency and authority with high interpretability, and a Semantic Stream (DistilBERT), which utilizes deep learning for contextual understanding. We evaluated both streams on a hybrid dataset (N=7,990) containing human-legitimate and AI-synthesized adversarial fraud. Benchmarked on Tesla T4 infrastructure, DistilBERT achieved near-perfect detection on synthetic threats (AUC >0.99, F1 =0.998) with acceptable real-time latency (7.4 ms). CatBoost achieved competitive detection (AUC =0.991, F1 =0.949) at 8.4x lower latency (0.8 ms) with negligible resource consumption. We conclude that while DistilBERT offers maximum accuracy for GPU-equipped organizations, CatBoost provides a viable, cost-effective alternative for edge deployments. Both approaches demonstrate a theoretical ROI exceeding 99.9% when optimized via cost-sensitive learning.","authors":["Yaw Osei Adjei","Frederick Ayivor","Davis Opoku"],"pdf_url":"","comment":"8 pages, 12 figures, 7 tables"},{"id":"http://arxiv.org/abs/2512.19334v1","updated":"2025-12-22T12:28:53Z","published":"2025-12-22T12:28:53Z","title":"Orthogonal Approximate Message Passing with Optimal Spectral Initializations for Rectangular Spiked Matrix Models","summary":"We propose an orthogonal approximate message passing (OAMP) algorithm for signal estimation in the rectangular spiked matrix model with general rotationally invariant (RI) noise. We establish a rigorous state evolution that precisely characterizes the algorithm's high-dimensional dynamics and enables the construction of iteration-wise optimal denoisers. Within this framework, we accommodate spectral initializations under minimal assumptions on the empirical noise spectrum. In the rectangular setting, where a single rank-one component typically generates multiple informative outliers, we further propose a procedure for combining these outliers under mild non-Gaussian signal assumptions. For general RI noise models, the predicted performance of the proposed optimal OAMP algorithm agrees with replica-symmetric predictions for the associated Bayes-optimal estimator, and we conjecture that it is statistically optimal within a broad class of iterative estimation methods.","authors":["Haohua Chen","Songbin Liu","Junjie Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19332v1","updated":"2025-12-22T12:27:36Z","published":"2025-12-22T12:27:36Z","title":"A Logical View of GNN-Style Computation and the Role of Activation Functions","summary":"We study the numerical and Boolean expressiveness of MPLang, a declarative language that captures the computation of graph neural networks (GNNs) through linear message passing and activation functions. We begin with A-MPLang, the fragment without activation functions, and give a characterization of its expressive power in terms of walk-summed features. For bounded activation functions, we show that (under mild conditions) all eventually constant activations yield the same expressive power - numerical and Boolean - and that it subsumes previously established logics for GNNs with eventually constant activation functions but without linear layers. Finally, we prove the first expressive separation between unbounded and bounded activations in the presence of linear layers: MPLang with ReLU is strictly more powerful for numerical queries than MPLang with eventually constant activation functions, e.g., truncated ReLU. This hinges on subtle interactions between linear aggregation and eventually constant non-linearities, and it establishes that GNNs using ReLU are more expressive than those restricted to eventually constant activations and linear layers.","authors":["Pablo Barceló","Floris Geerts","Matthias Lanzinger","Klara Pakhomenko","Jan Van den Bussche"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19323v1","updated":"2025-12-22T12:17:47Z","published":"2025-12-22T12:17:47Z","title":"Alternative positional encoding functions for neural transformers","summary":"A key module in neural transformer-based deep architectures is positional encoding. This module enables a suitable way to encode positional information as input for transformer neural layers. This success has been rooted in the use of sinusoidal functions of various frequencies, in order to capture recurrent patterns of differing typical periods. In this work, an alternative set of periodic functions is proposed for positional encoding. These functions preserve some key properties of sinusoidal ones, while they depart from them in fundamental ways. Some tentative experiments are reported, where the original sinusoidal version is substantially outperformed. This strongly suggests that the alternative functions may have a wider use in other transformer architectures.","authors":["Ezequiel Lopez-Rubio","Macoris Decena-Gimenez","Rafael Marcos Luque-Baena"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19320v1","updated":"2025-12-22T12:13:17Z","published":"2025-12-22T12:13:17Z","title":"MAGIC: Achieving Superior Model Merging via Magnitude Calibration","summary":"The proliferation of pre-trained models has given rise to a wide array of specialised, fine-tuned models. Model merging aims to merge the distinct capabilities of these specialised models into a unified model, requiring minimal or even no additional training. A core objective of model merging is to ensure the merged model retains the behavioural characteristics of the specialised models, typically achieved through feature alignment. We identify that features consist of two critical components: direction and magnitude. Prior research has predominantly focused on directional alignment, while the influence of magnitude remains largely neglected, despite its pronounced vulnerability to perturbations introduced by common merging operations (e.g., parameter fusion and sparsification). Such perturbations to magnitude inevitably lead to feature deviations in the merged model from the specialised models, resulting in subsequent performance degradation. To address this, we propose MAGnItude Calibration (MAGIC), a plug-and-play framework that rectifies layer-wise magnitudes in feature and weight spaces, with three variants. Specifically, our Feature Space Calibration (FSC) realigns the merged model's features using a small set of unlabelled data, while Weight Space Calibration (WSC) extends this calibration to the weight space without requiring additional data. Combining these yields Dual Space Calibration (DSC). Comprehensive experiments demonstrate that MAGIC consistently boosts performance across diverse Computer Vision tasks (+4.3% on eight datasets) and NLP tasks (+8.0% on Llama) without additional training. Our code is available at: https://github.com/lyymuwu/MAGIC","authors":["Yayuan Li","Jian Zhang","Jintao Guo","Zihan Cheng","Lei Qi","Yinghuan Shi","Yang Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19309v1","updated":"2025-12-22T11:59:47Z","published":"2025-12-22T11:59:47Z","title":"Time-Vertex Machine Learning for Optimal Sensor Placement in Temporal Graph Signals: Applications in Structural Health Monitoring","summary":"Structural Health Monitoring (SHM) plays a crucial role in maintaining the safety and resilience of infrastructure. As sensor networks grow in scale and complexity, identifying the most informative sensors becomes essential to reduce deployment costs without compromising monitoring quality. While Graph Signal Processing (GSP) has shown promise by leveraging spatial correlations among sensor nodes, conventional approaches often overlook the temporal dynamics of structural behavior. To overcome this limitation, we propose Time-Vertex Machine Learning (TVML), a novel framework that integrates GSP, time-domain analysis, and machine learning to enable interpretable and efficient sensor placement by identifying representative nodes that minimize redundancy while preserving critical information. We evaluate the proposed approach on two bridge datasets for damage detection and time-varying graph signal reconstruction tasks. The results demonstrate the effectiveness of our approach in enhancing SHM systems by providing a robust, adaptive, and efficient solution for sensor placement.","authors":["Keivan Faghih Niresi","Jun Qing","Mengjie Zhao","Olga Fink"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17531v2","updated":"2025-12-22T11:36:59Z","published":"2025-12-19T12:54:03Z","title":"NetworkFF: Unified Layer Optimization in Forward-Only Neural Networks","summary":"The Forward-Forward algorithm eliminates backpropagation's memory constraints and biological implausibility through dual forward passes with positive and negative data. However, conventional implementations suffer from critical inter-layer isolation, where layers optimize goodness functions independently without leveraging collective learning dynamics. This isolation constrains representational coordination and limits convergence efficiency in deeper architectures. This paper introduces Collaborative Forward-Forward (CFF) learning, extending the original algorithm through inter-layer cooperation mechanisms that preserve forward-only computation while enabling global context integration. Our framework implements two collaborative paradigms: Fixed CFF (F-CFF) with constant inter-layer coupling and Adaptive CFF (A-CFF) with learnable collaboration parameters that evolve during training. The collaborative goodness function incorporates weighted contributions from all layers, enabling coordinated feature learning while maintaining memory efficiency and biological plausibility. Comprehensive evaluation on MNIST and Fashion-MNIST demonstrates significant performance improvements over baseline Forward-Forward implementations. These findings establish inter-layer collaboration as a fundamental enhancement to Forward-Forward learning, with immediate applicability to neuromorphic computing architectures and energy-constrained AI systems.","authors":["Salar Beigzad"],"pdf_url":"","comment":"Conference paper, IEEE, 2025"},{"id":"http://arxiv.org/abs/2509.23941v2","updated":"2025-12-22T11:33:19Z","published":"2025-09-28T15:35:25Z","title":"Brain-language fusion enables interactive neural readout and in-silico experimentation","summary":"Large language models (LLMs) have revolutionized human-machine interaction, and have been extended by embedding diverse modalities such as images into a shared language space. Yet, neural decoding has remained constrained by static, non-interactive methods. We introduce CorText, a framework that integrates neural activity directly into the latent space of an LLM, enabling open-ended, natural language interaction with brain data. Trained on fMRI data recorded during viewing of natural scenes, CorText generates accurate image captions and can answer more detailed questions better than controls, while having access to neural data only. We showcase that CorText achieves zero-shot generalization beyond semantic categories seen during training. In-silico microstimulation experiments, which enable counterfactual prompts on brain activity, reveal a consistent, and graded mapping between brain-state and language output. These advances mark a shift from passive decoding toward generative, flexible interfaces between brain activity and language.","authors":["Victoria Bosch","Daniel Anthes","Adrien Doerig","Sushrut Thorat","Peter König","Tim Christian Kietzmann"],"pdf_url":"","comment":"v2"},{"id":"http://arxiv.org/abs/2512.19286v1","updated":"2025-12-22T11:29:28Z","published":"2025-12-22T11:29:28Z","title":"GShield: Mitigating Poisoning Attacks in Federated Learning","summary":"Federated Learning (FL) has recently emerged as a revolutionary approach to collaborative training Machine Learning models. In particular, it enables decentralized model training while preserving data privacy, but its distributed nature makes it highly vulnerable to a severe attack known as Data Poisoning. In such scenarios, malicious clients inject manipulated data into the training process, thereby degrading global model performance or causing targeted misclassification. In this paper, we present a novel defense mechanism called GShield, designed to detect and mitigate malicious and low-quality updates, especially under non-independent and identically distributed (non-IID) data scenarios. GShield operates by learning the distribution of benign gradients through clustering and Gaussian modeling during an initial round, enabling it to establish a reliable baseline of trusted client behavior. With this benign profile, GShield selectively aggregates only those updates that align with the expected gradient patterns, effectively isolating adversarial clients and preserving the integrity of the global model. An extensive experimental campaign demonstrates that our proposed defense significantly improves model robustness compared to the state-of-the-art methods while maintaining a high accuracy of performance across both tabular and image datasets. Furthermore, GShield improves the accuracy of the targeted class by 43\\% to 65\\% after detecting malicious and low-quality clients.","authors":["Sameera K. M.","Serena Nicolazzo","Antonino Nocera","Vinod P.","Rafidha Rehiman K. A"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19280v1","updated":"2025-12-22T11:24:42Z","published":"2025-12-22T11:24:42Z","title":"Digital Twin-Driven Zero-Shot Fault Diagnosis of Axial Piston Pumps Using Fluid-Borne Noise Signals","summary":"Axial piston pumps are crucial components in fluid power systems, where reliable fault diagnosis is essential for ensuring operational safety and efficiency. Traditional data-driven methods require extensive labeled fault data, which is often impractical to obtain, while model-based approaches suffer from parameter uncertainties. This paper proposes a digital twin (DT)-driven zero-shot fault diagnosis framework utilizing fluid-borne noise (FBN) signals. The framework calibrates a high-fidelity DT model using only healthy-state data, generates synthetic fault signals for training deep learning classifiers, and employs a physics-informed neural network (PINN) as a virtual sensor for flow ripple estimation. Gradient-weighted class activation mapping (Grad-CAM) is integrated to visualize the decision-making process of neural networks, revealing that large kernels matching the subsequence length in time-domain inputs and small kernels in time-frequency domain inputs enable higher diagnostic accuracy by focusing on physically meaningful features. Experimental validations demonstrate that training on signals from the calibrated DT model yields diagnostic accuracies exceeding 95\\% on real-world benchmarks, while uncalibrated models result in significantly lower performance, highlighting the framework's effectiveness in data-scarce scenarios.","authors":["Chang Dong","Jianfeng Tao","Chengliang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19269v1","updated":"2025-12-22T11:06:06Z","published":"2025-12-22T11:06:06Z","title":"Translating Flow to Policy via Hindsight Online Imitation","summary":"Recent advances in hierarchical robot systems leverage a high-level planner to propose task plans and a low-level policy to generate robot actions. This design allows training the planner on action-free or even non-robot data sources (e.g., videos), providing transferable high-level guidance. Nevertheless, grounding these high-level plans into executable actions remains challenging, especially with the limited availability of high-quality robot data. To this end, we propose to improve the low-level policy through online interactions. Specifically, our approach collects online rollouts, retrospectively annotates the corresponding high-level goals from achieved outcomes, and aggregates these hindsight-relabeled experiences to update a goal-conditioned imitation policy. Our method, Hindsight Flow-conditioned Online Imitation (HinFlow), instantiates this idea with 2D point flows as the high-level planner. Across diverse manipulation tasks in both simulation and physical world, our method achieves more than $2\\times$ performance improvement over the base policy, significantly outperforming the existing methods. Moreover, our framework enables policy acquisition from planners trained on cross-embodiment video data, demonstrating its potential for scalable and transferable robot learning.","authors":["Yitian Zheng","Zhangchen Ye","Weijun Dong","Shengjie Wang","Yuyang Liu","Chongjie Zhang","Chuan Wen","Yang Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.17860v4","updated":"2025-12-22T10:41:08Z","published":"2025-07-23T18:33:27Z","title":"Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis","summary":"Recent advances in deep learning and on-device inference could transform routine screening for skin cancers. Along with the anticipated benefits of this technology, potential dangers arise from unforeseen and inherent biases. A significant obstacle is building evaluation datasets that accurately reflect key demographics, including sex, age, and race, as well as other underrepresented groups. To address this, we train a state-of-the-art generative model to generate synthetic data in a controllable manner to assess the fairness of publicly available skin cancer classifiers. To evaluate whether synthetic images can be used as a fairness testing dataset, we prepare a real-image dataset (MILK10K) as a benchmark and compare the True Positive Rate result of three models (DeepGuide, MelaNet, and SkinLesionDensnet). As a result, the classification tendencies observed in each model when tested on real and generated images showed similar patterns across different attribute data sets. We confirm that highly realistic synthetic images facilitate model fairness verification.","authors":["Ko Watanabe","Stanislav Frolov","Aya Hassan","David Dembinsky","Adriano Lucieri","Andreas Dengel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19253v1","updated":"2025-12-22T10:40:03Z","published":"2025-12-22T10:40:03Z","title":"Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study","summary":"We present the first comprehensive empirical study of machine unlearning (MU) in hybrid quantum-classical neural networks. While MU has been extensively explored in classical deep learning, its behavior within variational quantum circuits (VQCs) and quantum-augmented architectures remains largely unexplored. First, we adapt a broad suite of unlearning methods to quantum settings, including gradient-based, distillation-based, regularization-based and certified techniques. Second, we introduce two new unlearning strategies tailored to hybrid models. Experiments across Iris, MNIST, and Fashion-MNIST, under both subset removal and full-class deletion, reveal that quantum models can support effective unlearning, but outcomes depend strongly on circuit depth, entanglement structure, and task complexity. Shallow VQCs display high intrinsic stability with minimal memorization, whereas deeper hybrid models exhibit stronger trade-offs between utility, forgetting strength, and alignment with retrain oracle. We find that certain methods, e.g. EU-k, LCA, and Certified Unlearning, consistently provide the best balance across metrics. These findings establish baseline empirical insights into quantum machine unlearning and highlight the need for quantum-aware algorithms and theoretical guarantees, as quantum machine learning systems continue to expand in scale and capability. We publicly release our code at: https://github.com/CrivoiCarla/HQML.","authors":["Carla Crivoi","Radu Tudor Ionescu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19250v1","updated":"2025-12-22T10:34:45Z","published":"2025-12-22T10:34:45Z","title":"Small Language Models as Compiler Experts: Auto-Parallelization for Heterogeneous Systems","summary":"Traditional auto-parallelizing compilers, reliant on rigid heuristics, struggle with the complexity of modern heterogeneous systems. This paper presents a comprehensive evaluation of small (approximately 1B parameter) language-model-driven compiler auto-parallelization. We evaluate three models: gemma3, llama3.2, and qwen2.5, using six reasoning strategies across 11 real-world kernels drawn from scientific computing, graph algorithms, and machine learning. Our system is benchmarked against strong compiler baselines, including LLVM Polly, TVM, and Triton. Across 376 total evaluations, the proposed approach achieves an average speedup of 6.81x and a peak performance of 43.25x on convolution operations. We analyze scalability, verify correctness using multiple sanitizers, and confirm robustness across diverse compilers and hardware platforms. Our results demonstrate that small, efficient language models can serve as powerful reasoning engines for complex compiler optimization tasks.","authors":["Prathamesh Devadiga"],"pdf_url":"","comment":"Accepted at NeurIPS 2025 ML for Systems Workshop"},{"id":"http://arxiv.org/abs/2512.19246v1","updated":"2025-12-22T10:28:22Z","published":"2025-12-22T10:28:22Z","title":"From Black-Box Tuning to Guided Optimization via Hyperparameters Interaction Analysis","summary":"Hyperparameters tuning is a fundamental, yet computationally expensive, step in optimizing machine learning models. Beyond optimization, understanding the relative importance and interaction of hyperparameters is critical to efficient model development. In this paper, we introduce MetaSHAP, a scalable semi-automated eXplainable AI (XAI) method, that uses meta-learning and Shapley values analysis to provide actionable and dataset-aware tuning insights. MetaSHAP operates over a vast benchmark of over 09 millions evaluated machine learning pipelines, allowing it to produce interpretable importance scores and actionable tuning insights that reveal how much each hyperparameter matters, how it interacts with others and in which value ranges its influence is concentrated. For a given algorithm and dataset, MetaSHAP learns a surrogate performance model from historical configurations, computes hyperparameters interactions using SHAP-based analysis, and derives interpretable tuning ranges from the most influential hyperparameters. This allows practitioners not only to prioritize which hyperparameters to tune, but also to understand their directionality and interactions. We empirically validate MetaSHAP on a diverse benchmark of 164 classification datasets and 14 classifiers, demonstrating that it produces reliable importance rankings and competitive performance when used to guide Bayesian optimization.","authors":["Moncef Garouani","Ayah Barhrhouj"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17452v2","updated":"2025-12-22T10:23:36Z","published":"2025-12-19T11:08:58Z","title":"Learning What to Write: Write-Gated KV for Efficient Long-Context Inference","summary":"Long-context LLM inference is bottlenecked by the quadratic attention complexity and linear KV cache growth. Prior approaches mitigate this via post-hoc selection or eviction but overlook the root inefficiency: indiscriminate writing to persistent memory. In this paper, we formalize KV cache management as a causal system of three primitives: KV Admission, Selection, and Eviction. We instantiate KV Admission via Write-Gated KV, a lightweight mechanism that learns to predict token utility before it enters the cache. By filtering out low-utility states early to maintain a compact global cache alongside a sliding local cache, Write-Gated KV reduces memory usage by 46-57% and delivers 3.03-3.45$\\times$ prefill and 1.89-2.56$\\times$ decode speedups on Llama model with negligible accuracy loss, all while remaining compatible with FlashAttention and paged-KV systems. These results demonstrate that learning what to write, is a principled and practical recipe for efficient long-context inference. Code is available at https://github.com/EMCLab-Sinica/WG-KV .","authors":["Yen-Chieh Huang","Pi-Cheng Hsiu","Rui Fang","Ming-Syan Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.11646v2","updated":"2025-12-22T10:22:37Z","published":"2025-11-10T08:50:03Z","title":"What-If Decision Support for Product Line Extension Using Conditional Deep Generative Models","summary":"Product line extension is a strategically important managerial decision that requires anticipating how consumer segments and purchasing contexts may respond to hypothetical product designs that do not yet exist in the market. Such decisions are inherently uncertain because managers must infer future outcomes from historical purchase data without direct market observations. This study addresses this challenge by proposing a data-driven decision support framework that enables forward-looking what-if analysis based on historical transaction data. We introduce a Conditional Tabular Variational Autoencoder (CTVAE) that learns the conditional joint distribution of product attributes and consumer characteristics from large-scale tabular data. By conditioning the generative process on controllable design variables such as container type, volume, flavor, and calorie content, the proposed model generates synthetic consumer attribute distributions for hypothetical line-extended products. This enables systematic exploration of alternative design scenarios without costly market pretests. The framework is evaluated using home-scan panel data covering more than 20,000 consumers and 700 soft drink products. Empirical results show that the CTVAE outperforms existing tabular generative models in capturing conditional consumer attribute distributions. Simulation-based analyses further demonstrate that the generated synthetic data support knowledge-driven reasoning for assessing cannibalization risks and identifying potential target segments. These findings highlight the value of conditional deep generative models as core components of decision support systems for product line extension planning.","authors":["Yinxing Li","Tsukasa Ishigaki"],"pdf_url":"","comment":"25 pages"},{"id":"http://arxiv.org/abs/2512.19238v1","updated":"2025-12-22T10:20:20Z","published":"2025-12-22T10:20:20Z","title":"Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation","summary":"Large language models (LLMs) have been shown to exhibit social bias, however, bias towards non-protected stigmatized identities remain understudied. Furthermore, what social features of stigmas are associated with bias in LLM outputs is unknown. From psychology literature, it has been shown that stigmas contain six shared social features: aesthetics, concealability, course, disruptiveness, origin, and peril. In this study, we investigate if human and LLM ratings of the features of stigmas, along with prompt style and type of stigma, have effect on bias towards stigmatized groups in LLM outputs. We measure bias against 93 stigmatized groups across three widely used LLMs (Granite 3.0-8B, Llama-3.1-8B, Mistral-7B) using SocialStigmaQA, a benchmark that includes 37 social scenarios about stigmatized identities; for example deciding wether to recommend them for an internship. We find that stigmas rated by humans to be highly perilous (e.g., being a gang member or having HIV) have the most biased outputs from SocialStigmaQA prompts (60% of outputs from all models) while sociodemographic stigmas (e.g. Asian-American or old age) have the least amount of biased outputs (11%). We test if the amount of biased outputs could be decreased by using guardrail models, models meant to identify harmful input, using each LLM's respective guardrail model (Granite Guardian 3.0, Llama Guard 3.0, Mistral Moderation API). We find that bias decreases significantly by 10.4%, 1.4%, and 7.8%, respectively. However, we show that features with significant effect on bias remain unchanged post-mitigation and that guardrail models often fail to recognize the intent of bias in prompts. This work has implications for using LLMs in scenarios involving stigmatized groups and we suggest future work towards improving guardrail models for bias mitigation.","authors":["Anna-Maria Gueorguieva","Aylin Caliskan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19232v1","updated":"2025-12-22T10:14:00Z","published":"2025-12-22T10:14:00Z","title":"Regression generation adversarial network based on dual data evaluation strategy for industrial application","summary":"Soft sensing infers hard-to-measure data through a large number of easily obtainable variables. However, in complex industrial scenarios, the issue of insufficient data volume persists, which diminishes the reliability of soft sensing. Generative Adversarial Networks (GAN) are one of the effective solutions for addressing insufficient samples. Nevertheless, traditional GAN fail to account for the mapping relationship between labels and features, which limits further performance improvement. Although some studies have proposed solutions, none have considered both performance and efficiency simultaneously. To address these problems, this paper proposes the multi-task learning-based regression GAN framework that integrates regression information into both the discriminator and generator, and implements a shallow sharing mechanism between the discriminator and regressor. This approach significantly enhances the quality of generated samples while improving the algorithm's operational efficiency. Moreover, considering the importance of training samples and generated samples, a dual data evaluation strategy is designed to make GAN generate more diverse samples, thereby increasing the generalization of subsequent modeling. The superiority of method is validated through four classic industrial soft sensing cases: wastewater treatment plants, surface water, $CO_2$ absorption towers, and industrial gas turbines.","authors":["Zesen Wang","Yonggang Li","Lijuan Lan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19223v1","updated":"2025-12-22T10:03:51Z","published":"2025-12-22T10:03:51Z","title":"Phase-space entropy at acquisition reflects downstream learnability","summary":"Modern learning systems work with data that vary widely across domains, but they all ultimately depend on how much structure is already present in the measurements before any model is trained. This raises a basic question: is there a general, modality-agnostic way to quantify how acquisition itself preserves or destroys the information that downstream learners could use? Here we propose an acquisition-level scalar $ΔS_{\\mathcal B}$ based on instrument-resolved phase space. Unlike pixelwise distortion or purely spectral errors that often saturate under aggressive undersampling, $ΔS_{\\mathcal B}$ directly quantifies how acquisition mixes or removes joint space--frequency structure at the instrument scale. We show theoretically that \\(ΔS_{\\mathcal B}\\) correctly identifies the phase-space coherence of periodic sampling as the physical source of aliasing, recovering classical sampling-theorem consequences. Empirically, across masked image classification, accelerated MRI, and massive MIMO (including over-the-air measurements), $|ΔS_{\\mathcal B}|$ consistently ranks sampling geometries and predicts downstream reconstruction/recognition difficulty \\emph{without training}. In particular, minimizing $|ΔS_{\\mathcal B}|$ enables zero-training selection of variable-density MRI mask parameters that matches designs tuned by conventional pre-reconstruction criteria. These results suggest that phase-space entropy at acquisition reflects downstream learnability, enabling pre-training selection of candidate sampling policies and as a shared notion of information preservation across modalities.","authors":["Xiu-Cheng Wang","Jun-Jie Zhanga","Nan Cheng","Long-Gang Pang","Taijiao Du","Deyu Meng"],"pdf_url":"","comment":"22 pages 6 figures"},{"id":"http://arxiv.org/abs/2512.19206v1","updated":"2025-12-22T09:44:26Z","published":"2025-12-22T09:44:26Z","title":"MixKVQ: Query-Aware Mixed-Precision KV Cache Quantization for Long-Context Reasoning","summary":"Long Chain-of-Thought (CoT) reasoning has significantly advanced the capabilities of Large Language Models (LLMs), but this progress is accompanied by substantial memory and latency overhead from the extensive Key-Value (KV) cache. Although KV cache quantization is a promising compression technique, existing low-bit quantization methods often exhibit severe performance degradation on complex reasoning tasks. Fixed-precision quantization struggles to handle outlier channels in the key cache, while current mixed-precision strategies fail to accurately identify components requiring high-precision representation. We find that an effective low-bit KV cache quantization strategy must consider two factors: a key channel's intrinsic quantization difficulty and its relevance to the query. Based on this insight, we propose MixKVQ, a novel plug-and-play method that introduces a lightweight, query-aware algorithm to identify and preserve critical key channels that need higher precision, while applying per-token quantization for value cache. Experiments on complex reasoning datasets demonstrate that our approach significantly outperforms existing low-bit methods, achieving performance comparable to a full-precision baseline at a substantially reduced memory footprint.","authors":["Tao Zhang","Ziqian Zeng","Hao Peng","Huiping Zhuang","Cen Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.13081v2","updated":"2025-12-22T09:39:40Z","published":"2024-02-20T15:25:56Z","title":"IT Intrusion Detection Using Statistical Learning and Testbed Measurements","summary":"We study automated intrusion detection in an IT infrastructure, specifically the problem of identifying the start of an attack, the type of attack, and the sequence of actions an attacker takes, based on continuous measurements from the infrastructure. We apply statistical learning methods, including Hidden Markov Model (HMM), Long Short-Term Memory (LSTM), and Random Forest Classifier (RFC) to map sequences of observations to sequences of predicted attack actions. In contrast to most related research, we have abundant data to train the models and evaluate their predictive power. The data comes from traces we generate on an in-house testbed where we run attacks against an emulated IT infrastructure. Central to our work is a machine-learning pipeline that maps measurements from a high-dimensional observation space to a space of low dimensionality or to a small set of observation symbols. Investigating intrusions in offline as well as online scenarios, we find that both HMM and LSTM can be effective in predicting attack start time, attack type, and attack actions. If sufficient training data is available, LSTM achieves higher prediction accuracy than HMM. HMM, on the other hand, requires less computational resources and less training data for effective prediction. Also, we find that the methods we study benefit from data produced by traditional intrusion detection systems like SNORT.","authors":["Xiaoxuan Wang","Rolf Stadler"],"pdf_url":"","comment":"A version of this paper appeared in the conference proceedings of NOMS 2024 (IEEE/IFIP Network Operations and Management Symposium)"},{"id":"http://arxiv.org/abs/2512.19199v1","updated":"2025-12-22T09:36:24Z","published":"2025-12-22T09:36:24Z","title":"On the Koopman-Based Generalization Bounds for Multi-Task Deep Learning","summary":"The paper establishes generalization bounds for multitask deep neural networks using operator-theoretic techniques. The authors propose a tighter bound than those derived from conventional norm based methods by leveraging small condition numbers in the weight matrices and introducing a tailored Sobolev space as an expanded hypothesis space. This enhanced bound remains valid even in single output settings, outperforming existing Koopman based bounds. The resulting framework maintains key advantages such as flexibility and independence from network width, offering a more precise theoretical understanding of multitask deep learning in the context of kernel methods.","authors":["Mahdi Mohammadigohari","Giuseppe Di Fatta","Giuseppe Nicosia","Panos M. Pardalos"],"pdf_url":"","comment":"Accepted for publication in Lecture Notes in Computer Science (LNCS). Final version forthcoming"},{"id":"http://arxiv.org/abs/2512.15661v2","updated":"2025-12-22T09:34:23Z","published":"2025-12-17T18:14:59Z","title":"Prospects for quantum advantage in machine learning from the representability of functions","summary":"Demonstrating quantum advantage in machine learning tasks requires navigating a complex landscape of proposed models and algorithms. To bring clarity to this search, we introduce a framework that connects the structure of parametrized quantum circuits to the mathematical nature of the functions they can actually learn. Within this framework, we show how fundamental properties, like circuit depth and non-Clifford gate count, directly determine whether a model's output leads to efficient classical simulation or surrogation. We argue that this analysis uncovers common pathways to dequantization that underlie many existing simulation methods. More importantly, it reveals critical distinctions between models that are fully simulatable, those whose function space is classically tractable, and those that remain robustly quantum. This perspective provides a conceptual map of this landscape, clarifying how different models relate to classical simulability and pointing to where opportunities for quantum advantage may lie.","authors":["Sergi Masot-Llima","Elies Gil-Fuster","Carlos Bravo-Prieto","Jens Eisert","Tommaso Guaita"],"pdf_url":"","comment":"21 pages, 6 figures, comments welcome"},{"id":"http://arxiv.org/abs/2512.19196v1","updated":"2025-12-22T09:31:31Z","published":"2025-12-22T09:31:31Z","title":"Self-Consistent Probability Flow for High-Dimensional Fokker-Planck Equations","summary":"Solving high-dimensional Fokker-Planck (FP) equations is a challenge in computational physics and stochastic dynamics, due to the curse of dimensionality (CoD) and the bottleneck of evaluating second-order diffusion terms. Existing deep learning approaches, such as Physics-Informed Neural Networks (PINNs), face computational challenges as dimensionality increases, driven by the $O(D^2)$ complexity of automatic differentiation for second-order derivatives. While recent probability flow approaches bypass this by learning score functions or matching velocity fields, they often involve serial computational operations or depend on sampling efficiency in complex distributions. To address these issues, we propose the Self-Consistent Probability Flow (SCPF) method. We reformulate the second-order FP equation into an equivalent first-order deterministic Probability Flow ODE (PF-ODE) constraint. Unlike score matching or velocity matching, SCPF solves this problem by minimizing the residual of the PF-ODE continuity equation, which avoids explicit Hessian computation. We leverage Continuous Normalizing Flows (CNF) combined with the Hutchinson Trace Estimator (HTE) to reduce the training complexity to linear scale $O(D)$, achieving an effective $O(1)$ wall-clock time on GPUs. To address data sparsity in high dimensions, we apply a generative adaptive sampling strategy and theoretically prove that dynamically aligning collocation points with the evolving probability mass is a necessary condition to bound the approximation error. Experiments on diverse benchmarks -- ranging from anisotropic Ornstein-Uhlenbeck (OU) processes and high-dimensional Brownian motions with time-varying diffusion terms, to Geometric OU processes featuring non-Gaussian solutions -- demonstrate that SCPF effectively mitigates the CoD, maintaining high accuracy and constant computational cost for problems up to 100 dimensions.","authors":["Xiaolong Wu","Qifeng Liao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19194v1","updated":"2025-12-22T09:30:25Z","published":"2025-12-22T09:30:25Z","title":"Causal Heterogeneous Graph Learning Method for Chronic Obstructive Pulmonary Disease Prediction","summary":"Due to the insufficient diagnosis and treatment capabilities at the grassroots level, there are still deficiencies in the early identification and early warning of acute exacerbation of Chronic obstructive pulmonary disease (COPD), often resulting in a high prevalence rate and high burden, but the screening rate is relatively low. In order to gradually improve this situation. In this paper, this study develop a Causal Heterogeneous Graph Representation Learning (CHGRL) method for COPD comorbidity risk prediction method that: a) constructing a heterogeneous Our dataset includes the interaction between patients and diseases; b) A cause-aware heterogeneous graph learning architecture has been constructed, combining causal inference mechanisms with heterogeneous graph learning, which can support heterogeneous graph causal learning for different types of relationships; and c) Incorporate the causal loss function in the model design, and add counterfactual reasoning learning loss and causal regularization loss on the basis of the cross-entropy classification loss. We evaluate our method and compare its performance with strong GNN baselines. Following experimental evaluation, the proposed model demonstrates high detection accuracy.","authors":["Leming Zhou","Zuo Wang","Zhigang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19190v1","updated":"2025-12-22T09:28:23Z","published":"2025-12-22T09:28:23Z","title":"PEDESTRIAN: An Egocentric Vision Dataset for Obstacle Detection on Pavements","summary":"Walking has always been a primary mode of transportation and is recognized as an essential activity for maintaining good health. Despite the need for safe walking conditions in urban environments, sidewalks are frequently obstructed by various obstacles that hinder free pedestrian movement. Any object obstructing a pedestrian's path can pose a safety hazard. The advancement of pervasive computing and egocentric vision techniques offers the potential to design systems that can automatically detect such obstacles in real time, thereby enhancing pedestrian safety. The development of effective and efficient identification algorithms relies on the availability of comprehensive and well-balanced datasets of egocentric data. In this work, we introduce the PEDESTRIAN dataset, comprising egocentric data for 29 different obstacles commonly found on urban sidewalks. A total of 340 videos were collected using mobile phone cameras, capturing a pedestrian's point of view. Additionally, we present the results of a series of experiments that involved training several state-of-the-art deep learning algorithms using the proposed dataset, which can be used as a benchmark for obstacle detection and recognition tasks. The dataset can be used for training pavement obstacle detectors to enhance the safety of pedestrians in urban areas.","authors":["Marios Thoma","Zenonas Theodosiou","Harris Partaourides","Vassilis Vassiliades","Loizos Michael","Andreas Lanitis"],"pdf_url":"","comment":"24 pages, 7 figures, 9 tables, Dataset: https://doi.org/10.5281/zenodo.10907945, Code: https://github.com/CYENS/PEDESTRIAN"},{"id":"http://arxiv.org/abs/2506.09574v2","updated":"2025-12-22T09:20:25Z","published":"2025-06-11T10:12:50Z","title":"MOORL: A Framework for Integrating Offline-Online Reinforcement Learning","summary":"Sample efficiency and exploration remain critical challenges in Deep Reinforcement Learning (DRL), particularly in complex domains. Offline RL, which enables agents to learn optimal policies from static, pre-collected datasets, has emerged as a promising alternative. However, offline RL is constrained by issues such as out-of-distribution (OOD) actions that limit policy performance and generalization. To overcome these limitations, we propose Meta Offline-Online Reinforcement Learning (MOORL), a hybrid framework that unifies offline and online RL for efficient and scalable learning. While previous hybrid methods rely on extensive design components and added computational complexity to utilize offline data effectively, MOORL introduces a meta-policy that seamlessly adapts across offline and online trajectories. This enables the agent to leverage offline data for robust initialization while utilizing online interactions to drive efficient exploration. Our theoretical analysis demonstrates that the hybrid approach enhances exploration by effectively combining the complementary strengths of offline and online data. Furthermore, we demonstrate that MOORL learns a stable Q-function without added complexity. Extensive experiments on 28 tasks from the D4RL and V-D4RL benchmarks validate its effectiveness, showing consistent improvements over state-of-the-art offline and hybrid RL baselines. With minimal computational overhead, MOORL achieves strong performance, underscoring its potential for practical applications in real-world scenarios.","authors":["Gaurav Chaudhary","Wassim Uddin Mondal","Laxmidhar Behera"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19184v1","updated":"2025-12-22T09:18:30Z","published":"2025-12-22T09:18:30Z","title":"Operator-Based Generalization Bound for Deep Learning: Insights on Multi-Task Learning","summary":"This paper presents novel generalization bounds for vector-valued neural networks and deep kernel methods, focusing on multi-task learning through an operator-theoretic framework. Our key development lies in strategically combining a Koopman based approach with existing techniques, achieving tighter generalization guarantees compared to traditional norm-based bounds. To mitigate computational challenges associated with Koopman-based methods, we introduce sketching techniques applicable to vector valued neural networks. These techniques yield excess risk bounds under generic Lipschitz losses, providing performance guarantees for applications including robust and multiple quantile regression. Furthermore, we propose a novel deep learning framework, deep vector-valued reproducing kernel Hilbert spaces (vvRKHS), leveraging Perron Frobenius (PF) operators to enhance deep kernel methods. We derive a new Rademacher generalization bound for this framework, explicitly addressing underfitting and overfitting through kernel refinement strategies. This work offers novel insights into the generalization properties of multitask learning with deep learning architectures, an area that has been relatively unexplored until recent developments.","authors":["Mahdi Mohammadigohari","Giuseppe Di Fatta","Giuseppe Nicosia","Panos M. Pardalos"],"pdf_url":"","comment":"Accepted for publication in Lecture Notes in Computer Science (LNCS). Final version forthcoming"},{"id":"http://arxiv.org/abs/2512.17629v2","updated":"2025-12-22T09:18:11Z","published":"2025-12-19T14:33:02Z","title":"SCOPE: Sequential Causal Optimization of Process Interventions","summary":"Prescriptive Process Monitoring (PresPM) recommends interventions during business processes to optimize key performance indicators (KPIs). In realistic settings, interventions are rarely isolated: organizations need to align sequences of interventions to jointly steer the outcome of a case. Existing PresPM approaches fall short in this respect. Many focus on a single intervention decision, while others treat multiple interventions independently, ignoring how they interact over time. Methods that do address these dependencies depend either on simulation or data augmentation to approximate the process to train a Reinforcement Learning (RL) agent, which can create a reality gap and introduce bias. We introduce SCOPE, a PresPM approach that learns aligned sequential intervention recommendations. SCOPE employs backward induction to estimate the effect of each candidate intervention action, propagating its impact from the final decision point back to the first. By leveraging causal learners, our method can utilize observational data directly, unlike methods that require constructing process approximations for reinforcement learning. Experiments on both an existing synthetic dataset and a new semi-synthetic dataset show that SCOPE consistently outperforms state-of-the-art PresPM techniques in optimizing the KPI. The novel semi-synthetic setup, based on a real-life event log, is provided as a reusable benchmark for future work on sequential PresPM.","authors":["Jakob De Moor","Hans Weytjens","Johannes De Smedt","Jochen De Weerdt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.12815v2","updated":"2025-12-22T09:16:29Z","published":"2025-07-17T06:16:06Z","title":"From Novelty to Imitation: Self-Distilled Rewards for Offline Reinforcement Learning","summary":"Offline Reinforcement Learning (RL) aims to learn effective policies from a static dataset without requiring further agent-environment interactions. However, its practical adoption is often hindered by the need for explicit reward annotations, which can be costly to engineer or difficult to obtain retrospectively. To address this, we propose ReLOAD (Reinforcement Learning with Offline Reward Annotation via Distillation), a novel reward annotation framework for offline RL. Unlike existing methods that depend on complex alignment procedures, our approach adapts Random Network Distillation (RND) to generate intrinsic rewards from expert demonstrations using a simple yet effective embedding discrepancy measure. First, we train a predictor network to mimic a fixed target network's embeddings based on expert state transitions. Later, the prediction error between these networks serves as a reward signal for each transition in the static dataset. This mechanism provides a structured reward signal without requiring handcrafted reward annotations. We provide a formal theoretical construct that offers insights into how RND prediction errors effectively serve as intrinsic rewards by distinguishing expert-like transitions. Experiments on the D4RL benchmark demonstrate that ReLOAD enables robust offline policy learning and achieves performance competitive with traditional reward-annotated methods.","authors":["Gaurav Chaudhary","Laxmidhar Behera"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19180v1","updated":"2025-12-22T09:16:08Z","published":"2025-12-22T09:16:08Z","title":"Practical Quantum-Classical Feature Fusion for complex data Classification","summary":"Hybrid quantum and classical learning aims to couple quantum feature maps with the robustness of classical neural networks, yet most architectures treat the quantum circuit as an isolated feature extractor and merge its measurements with classical representations by direct concatenation. This neglects that the quantum and classical branches constitute distinct computational modalities and limits reliable performance on complex, high dimensional tabular and semi structured data, including remote sensing, environmental monitoring, and medical diagnostics. We present a multimodal formulation of hybrid learning and propose a cross attention mid fusion architecture in which a classical representation queries quantum derived feature tokens through an attention block with residual connectivity. The quantum branch is kept within practical NISQ budgets and uses up to nine qubits. We evaluate on Wine, Breast Cancer, Forest CoverType, FashionMNIST, and SteelPlatesFaults, comparing a quantum only model, a classical baseline, residual hybrid models, and the proposed mid fusion model under a consistent protocol. Pure quantum and standard hybrid designs underperform due to measurement induced information loss, while cross attention mid fusion is consistently competitive and improves performance on the more complex datasets in most cases. These findings suggest that quantum derived information becomes most valuable when integrated through principled multimodal fusion rather than used in isolation or loosely appended to classical features.","authors":["Azadeh Alavi","Fatemeh Kouchmeshki","Abdolrahman Alavi"],"pdf_url":"","comment":"16 pages, 3 figues"},{"id":"http://arxiv.org/abs/2512.19172v1","updated":"2025-12-22T09:07:09Z","published":"2025-12-22T09:07:09Z","title":"Finite-sample guarantees for data-driven forward-backward operator methods","summary":"We establish finite sample certificates on the quality of solutions produced by data-based forward-backward (FB) operator splitting schemes. As frequently happens in stochastic regimes, we consider the problem of finding a zero of the sum of two operators, where one is either unavailable in closed form or computationally expensive to evaluate, and shall therefore be approximated using a finite number of noisy oracle samples. Under the lens of algorithmic stability, we then derive probabilistic bounds on the distance between a true zero and the FB output without making specific assumptions about the underlying data distribution. We show that under weaker conditions ensuring the convergence of FB schemes, stability bounds grow proportionally to the number of iterations. Conversely, stronger assumptions yield stability guarantees that are independent of the iteration count. We then specialize our results to a popular FB stochastic Nash equilibrium seeking algorithm and validate our theoretical bounds on a control problem for smart grids, where the energy price uncertainty is approximated by means of historical data.","authors":["Filippo Fabiani","Barbara Franci"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19154v1","updated":"2025-12-22T08:50:30Z","published":"2025-12-22T08:50:30Z","title":"Beyond Sliding Windows: Learning to Manage Memory in Non-Markovian Environments","summary":"Recent success in developing increasingly general purpose agents based on sequence models has led to increased focus on the problem of deploying computationally limited agents within the vastly more complex real-world. A key challenge experienced in these more realistic domains is highly non-Markovian dependencies with respect to the agent's observations, which are less common in small controlled domains. The predominant approach for dealing with this in the literature is to stack together a window of the most recent observations (Frame Stacking), but this window size must grow with the degree of non-Markovian dependencies, which results in prohibitive computational and memory requirements for both action inference and learning. In this paper, we are motivated by the insight that in many environments that are highly non-Markovian with respect to time, the environment only causally depends on a relatively small number of observations over that time-scale. A natural direction would then be to consider meta-algorithms that maintain relatively small adaptive stacks of memories such that it is possible to express highly non-Markovian dependencies with respect to time while considering fewer observations at each step and thus experience substantial savings in both compute and memory requirements. Hence, we propose a meta-algorithm (Adaptive Stacking) for achieving exactly that with convergence guarantees and quantify the reduced computation and memory constraints for MLP, LSTM, and Transformer-based agents. Our experiments utilize popular memory tasks, which give us control over the degree of non-Markovian dependencies. This allows us to demonstrate that an appropriate meta-algorithm can learn the removal of memories not predictive of future rewards without excessive removal of important experiences. Code: https://github.com/geraudnt/adaptive-stacking","authors":["Geraud Nangue Tasse","Matthew Riemer","Benjamin Rosman","Tim Klinger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.13123v3","updated":"2025-12-22T08:50:20Z","published":"2025-12-15T09:26:45Z","title":"Stopping Rules for Stochastic Gradient Descent via Anytime-Valid Confidence Sequences","summary":"We study stopping rules for stochastic gradient descent (SGD) for convex optimization from the perspective of anytime-valid confidence sequences. Classical analyses of SGD provide convergence guarantees in expectation or at a fixed horizon, but offer no statistically valid way to assess, at an arbitrary time, how close the current iterate is to the optimum. We develop an anytime-valid, data-dependent upper confidence sequence for the weighted average suboptimality of projected SGD, constructed via nonnegative supermartingales and requiring no smoothness or strong convexity. This confidence sequence yields a simple stopping rule that is provably $\\varepsilon$-optimal with probability at least $1-α$, with explicit bounds on the stopping time under standard stochastic approximation stepsizes. To the best of our knowledge, these are the first rigorous, time-uniform performance guarantees and finite-time $\\varepsilon$-optimality certificates for projected SGD with general convex objectives, based solely on observable trajectory quantities.","authors":["Liviu Aolaritei","Michael I. Jordan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.00066v2","updated":"2025-12-22T08:49:46Z","published":"2025-10-29T08:07:47Z","title":"Sharpness-Controlled Group Relative Policy Optimization with Token-Level Probability Shaping","summary":"Reinforcement learning with verifiable rewards (RLVR) has become a practical route to improve large language model reasoning, and Group Relative Policy Optimization (GRPO) is a widely used optimizer in this setting. This paper revisits GRPO from a generalization perspective. Recent analysis shows that population performance can be controlled by a robust empirical objective that decomposes into the training loss plus a sharpness term measured by the gradient norm. We develop a token-level view of this sharpness term and show that GRPO can be dominated by a small subset of tokens with disproportionately large per-token gradients, which increases sharpness and can harm generalization. Motivated by this view, we propose Token-Regulated GRPO (TR-GRPO), which introduces a monotone probability shaping function to assign token weights based on the model's own token probabilities, and integrates these weights into the standard GRPO. Our analysis yields a bound that isolates a probability dependent multiplicative factor in token-gradient magnitudes, explaining how probability-aware weighting suppresses sharp directions while preserving learning signal on semantically critical tokens. Experiments on logic puzzles, mathematical reasoning, and tool-augmented question answering show consistent improvements over GRPO, along with smoother gradient-norm trajectories, supporting TR-GRPO as a simple and effective generalization-oriented upgrade to GRPO for RLVR.","authors":["Tue Le","Nghi D. Q. Bui","Linh Ngo Van","Trung Le"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.16750v3","updated":"2025-12-22T08:46:43Z","published":"2024-10-22T07:12:38Z","title":"Theoretical Convergence Guarantees for Variational Autoencoders","summary":"Variational Autoencoders (VAE) are popular generative models used to sample from complex data distributions. Despite their empirical success in various machine learning tasks, significant gaps remain in understanding their theoretical properties, particularly regarding convergence guarantees. This paper aims to bridge that gap by providing non-asymptotic convergence guarantees for VAE trained using both Stochastic Gradient Descent and Adam algorithms. We derive a convergence rate of $\\mathcal{O}(\\log n / \\sqrt{n})$, where $n$ is the number of iterations of the optimization algorithm, with explicit dependencies on the batch size, the number of variational samples, and other key hyperparameters. Our theoretical analysis applies to both Linear VAE and Deep Gaussian VAE, as well as several VAE variants, including $β$-VAE and IWAE. Additionally, we empirically illustrate the impact of hyperparameters on convergence, offering new insights into the theoretical understanding of VAE training.","authors":["Sobihan Surendran","Antoine Godichon-Baggioni","Sylvain Le Corff"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19147v1","updated":"2025-12-22T08:44:58Z","published":"2025-12-22T08:44:58Z","title":"RP-CATE: Recurrent Perceptron-based Channel Attention Transformer Encoder for Industrial Hybrid Modeling","summary":"Nowadays, industrial hybrid modeling which integrates both mechanistic modeling and machine learning-based modeling techniques has attracted increasing interest from scholars due to its high accuracy, low computational cost, and satisfactory interpretability. Nevertheless, the existing industrial hybrid modeling methods still face two main limitations. First, current research has mainly focused on applying a single machine learning method to one specific task, failing to develop a comprehensive machine learning architecture suitable for modeling tasks, which limits their ability to effectively represent complex industrial scenarios. Second, industrial datasets often contain underlying associations (e.g., monotonicity or periodicity) that are not adequately exploited by current research, which can degrade model's predictive performance. To address these limitations, this paper proposes the Recurrent Perceptron-based Channel Attention Transformer Encoder (RP-CATE), with three distinctive characteristics: 1: We developed a novel architecture by replacing the self-attention mechanism with channel attention and incorporating our proposed Recurrent Perceptron (RP) Module into Transformer, achieving enhanced effectiveness for industrial modeling tasks compared to the original Transformer. 2: We proposed a new data type called Pseudo-Image Data (PID) tailored for channel attention requirements and developed a cyclic sliding window method for generating PID. 3: We introduced the concept of Pseudo-Sequential Data (PSD) and a method for converting industrial datasets into PSD, which enables the RP Module to capture the underlying associations within industrial dataset more effectively. An experiment aimed at hybrid modeling in chemical engineering was conducted by using RP-CATE and the experimental results demonstrate that RP-CATE achieves the best performance compared to other baseline models.","authors":["Haoran Yang","Yinan Zhang","Wenjie Zhang","Dongxia Wang","Peiyu Liu","Yuqi Ye","Kexin Chen","Wenhai Wang"],"pdf_url":"","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.09392v4","updated":"2025-12-22T08:42:42Z","published":"2025-11-12T15:00:52Z","title":"Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm","summary":"Sequential Recommenders, which exploit dynamic user intents through interaction sequences, is vulnerable to adversarial attacks. While existing attacks primarily rely on data poisoning, they require large-scale user access or fake profiles thus lacking practicality. In this paper, we focus on the Profile Pollution Attack that subtly contaminates partial user interactions to induce targeted mispredictions. Previous PPA methods suffer from two limitations, i.e., i) over-reliance on sequence horizon impact restricts fine-grained perturbations on item transitions, and ii) holistic modifications cause detectable distribution shifts. To address these challenges, we propose a constrained reinforcement driven attack CREAT that synergizes a bi-level optimization framework with multi-reward reinforcement learning to balance adversarial efficacy and stealthiness. We first develop a Pattern Balanced Rewarding Policy, which integrates pattern inversion rewards to invert critical patterns and distribution consistency rewards to minimize detectable shifts via unbalanced co-optimal transport. Then we employ a Constrained Group Relative Reinforcement Learning paradigm, enabling step-wise perturbations through dynamic barrier constraints and group-shared experience replay, achieving targeted pollution with minimal detectability. Extensive experiments demonstrate the effectiveness of CREAT.","authors":["Jiajie Su","Zihan Nan","Yunshan Ma","Xiaobo Xia","Xiaohua Feng","Weiming Liu","Xiang Chen","Xiaolin Zheng","Chaochao Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19142v1","updated":"2025-12-22T08:41:31Z","published":"2025-12-22T08:41:31Z","title":"A Convex Loss Function for Set Prediction with Optimal Trade-offs Between Size and Conditional Coverage","summary":"We consider supervised learning problems in which set predictions provide explicit uncertainty estimates. Using Choquet integrals (a.k.a. Lov{á}sz extensions), we propose a convex loss function for nondecreasing subset-valued functions obtained as level sets of a real-valued function. This loss function allows optimal trade-offs between conditional probabilistic coverage and the ''size'' of the set, measured by a non-decreasing submodular function. We also propose several extensions that mimic loss functions and criteria for binary classification with asymmetric losses, and show how to naturally obtain sets with optimized conditional coverage. We derive efficient optimization algorithms, either based on stochastic gradient descent or reweighted least-squares formulations, and illustrate our findings with a series of experiments on synthetic datasets for classification and regression tasks, showing improvements over approaches that aim for marginal coverage.","authors":["Francis Bach"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19131v1","updated":"2025-12-22T08:26:54Z","published":"2025-12-22T08:26:54Z","title":"Evidential Trust-Aware Model Personalization in Decentralized Federated Learning for Wearable IoT","summary":"Decentralized federated learning (DFL) enables collaborative model training across edge devices without centralized coordination, offering resilience against single points of failure. However, statistical heterogeneity arising from non-identically distributed local data creates a fundamental challenge: nodes must learn personalized models adapted to their local distributions while selectively collaborating with compatible peers. Existing approaches either enforce a single global model that fits no one well, or rely on heuristic peer selection mechanisms that cannot distinguish between peers with genuinely incompatible data distributions and those with valuable complementary knowledge. We present Murmura, a framework that leverages evidential deep learning to enable trust-aware model personalization in DFL. Our key insight is that epistemic uncertainty from Dirichlet-based evidential models directly indicates peer compatibility: high epistemic uncertainty when a peer's model evaluates local data reveals distributional mismatch, enabling nodes to exclude incompatible influence while maintaining personalized models through selective collaboration. Murmura introduces a trust-aware aggregation mechanism that computes peer compatibility scores through cross-evaluation on local validation samples and personalizes model aggregation based on evidential trust with adaptive thresholds. Evaluation on three wearable IoT datasets (UCI HAR, PAMAP2, PPG-DaLiA) demonstrates that Murmura reduces performance degradation from IID to non-IID conditions compared to baseline (0.9% vs. 19.3%), achieves 7.4$\\times$ faster convergence, and maintains stable accuracy across hyperparameter choices. These results establish evidential uncertainty as a principled foundation for compatibility-aware personalization in decentralized heterogeneous environments.","authors":["Murtaza Rangwala","Richard O. Sinnott","Rajkumar Buyya"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19125v1","updated":"2025-12-22T08:05:01Z","published":"2025-12-22T08:05:01Z","title":"SAP: Syntactic Attention Pruning for Transformer-based Language Models","summary":"This paper introduces Syntactic Attention Pruning (SAP), a novel method for effectively pruning attention heads in Transformer models. Unlike conventional approaches that rely solely on mathematical analysis of model weights and activations, SAP incorporates both the syntactic structure and attention patterns of sentences to guide the pruning process. By leveraging these linguistic features, SAP not only achieves performance comparable to state-of-the-art methods but also enhances the interpretability of model behavior. To further improve robustness, we propose Candidate Filtering (CF), a mechanism that prioritizes heads based on their contribution to model performance, mitigating degradation during pruning. Experimental results indicate that SAP effectively preserves critical heads of a high density of strong attention values, outperforming existing head pruning strategies in retrain-free settings. These findings position SAP as a promising foundation for a new direction in model compression research, offering high flexibility for pruning across all transformer-based language models.","authors":["Tzu-Yun Lee","Ding-Yong Hong","Jan-Jan Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19123v1","updated":"2025-12-22T07:57:20Z","published":"2025-12-22T07:57:20Z","title":"A Composable Channel-Adaptive Architecture for Seizure Classification","summary":"Objective: We develop a channel-adaptive (CA) architecture that seamlessly processes multi-variate time-series with an arbitrary number of channels, and in particular intracranial electroencephalography (iEEG) recordings. Methods: Our CA architecture first processes the iEEG signal using state-of-the-art models applied to each single channel independently. The resulting features are then fused using a vector-symbolic algorithm which reconstructs the spatial relationship using a trainable scalar per channel. Finally, the fused features are accumulated in a long-term memory of up to 2 minutes to perform the classification. Each CA-model can then be pre-trained on a large corpus of iEEG recordings from multiple heterogeneous subjects. The pre-trained model is personalized to each subject via a quick fine-tuning routine, which uses equal or lower amounts of data compared to existing state-of-the-art models, but requiring only 1/5 of the time. Results: We evaluate our CA-models on a seizure detection task both on a short-term (~20 hours) and a long-term (~2500 hours) dataset. In particular, our CA-EEGWaveNet is trained on a single seizure of the tested subject, while the baseline EEGWaveNet is trained on all but one. Even in this challenging scenario, our CA-EEGWaveNet surpasses the baseline in median F1-score (0.78 vs 0.76). Similarly, CA-EEGNet based on EEGNet, also surpasses its baseline in median F1-score (0.79 vs 0.74). Conclusion and significance: Our CA-model addresses two issues: first, it is channel-adaptive and can therefore be trained across heterogeneous subjects without loss of performance; second, it increases the effective temporal context size to a clinically-relevant length. Therefore, our model is a drop-in replacement for existing models, bringing better characteristics and performance across the board.","authors":["Francesco Carzaniga","Michael Hersche","Kaspar Schindler","Abbas Rahimi"],"pdf_url":"","comment":"2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works"},{"id":"http://arxiv.org/abs/2512.19114v1","updated":"2025-12-22T07:35:16Z","published":"2025-12-22T07:35:16Z","title":"HyperLoad: A Cross-Modality Enhanced Large Language Model-Based Framework for Green Data Center Cooling Load Prediction","summary":"The rapid growth of artificial intelligence is exponentially escalating computational demand, inflating data center energy use and carbon emissions, and spurring rapid deployment of green data centers to relieve resource and environmental stress. Achieving sub-minute orchestration of renewables, storage, and loads, while minimizing PUE and lifecycle carbon intensity, hinges on accurate load forecasting. However, existing methods struggle to address small-sample scenarios caused by cold start, load distortion, multi-source data fragmentation, and distribution shifts in green data centers. We introduce HyperLoad, a cross-modality framework that exploits pre-trained large language models (LLMs) to overcome data scarcity. In the Cross-Modality Knowledge Alignment phase, textual priors and time-series data are mapped to a common latent space, maximizing the utility of prior knowledge. In the Multi-Scale Feature Modeling phase, domain-aligned priors are injected through adaptive prefix-tuning, enabling rapid scenario adaptation, while an Enhanced Global Interaction Attention mechanism captures cross-device temporal dependencies. The public DCData dataset is released for benchmarking. Under both data sufficient and data scarce settings, HyperLoad consistently surpasses state-of-the-art (SOTA) baselines, demonstrating its practicality for sustainable green data center management.","authors":["Haoyu Jiang","Boan Qu","Junjie Zhu","Fanjie Zeng","Xiaojie Lin","Wei Zhong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.08985v3","updated":"2025-12-22T07:34:52Z","published":"2025-08-12T14:53:54Z","title":"Low-Regret and Low-Complexity Learning for Hierarchical Inference","summary":"This work focuses on Hierarchical Inference (HI) in edge intelligence systems, where a compact Local-ML model on an end-device works in conjunction with a high-accuracy Remote-ML model on an edge-server. HI aims to reduce latency, improve accuracy, and lower bandwidth usage by first using the Local-ML model for inference and offloading to the Remote-ML only when the local inference is likely incorrect. A critical challenge in HI is estimating the likelihood of the local inference being incorrect, especially when data distributions and offloading costs change over time -- a problem we term Hierarchical Inference Learning (HIL). We introduce a novel approach to HIL by modeling the probability of correct inference by the Local-ML as an increasing function of the model's confidence measure, a structure motivated by empirical observations but previously unexploited. We propose two policies, HI-LCB and HI-LCB-lite, based on the Upper Confidence Bound (UCB) framework. We demonstrate that both policies achieve order-optimal regret of $O(\\log T)$, a significant improvement over existing HIL policies with $O(T^{2/3})$ regret guarantees. Notably, HI-LCB-lite has an $O(1)$ per-sample computational complexity, making it well-suited for deployment on devices with severe resource limitations. Simulations using real-world datasets confirm that our policies outperform existing state-of-the-art HIL methods.","authors":["Sameep Chattopadhyay","Vinay Sutar","Jaya Prakash Champati","Sharayu Moharir"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.25300v3","updated":"2025-12-22T07:20:59Z","published":"2025-09-29T17:10:35Z","title":"Scaling Behaviors of LLM Reinforcement Learning Post-Training: An Empirical Study in Mathematical Reasoning","summary":"While scaling laws for large language models (LLMs) during pre-training have been extensively studied, their behavior under reinforcement learning (RL) post-training remains largely unexplored. This paper presents a systematic empirical investigation of scaling behaviors in RL-based post-training, with a particular focus on mathematical reasoning. Based on a set of experiments across the full Qwen2.5 dense model series (0.5B to 72B), we characterize how model scale, data volume, and computational budget interact to shape performance. Our analysis leads to four key findings: 1. Larger models consistently exhibit superior learning efficiency on both compute and data metrics. 2. The relationship between test loss, compute, and data can be modeled by a predictive power-law which is robust across both base and instruction-tuned models. 3. Although larger models exhibit higher learning efficiency, the analytical learning efficiency term k(N) in the power-law reveals a latent saturation trend in learning efficiency as model size continues to increase. 4. In data-constrained regimes, repeated reuse of high-quality data proves highly effective, as final performance is primarily governed by the total number of optimization steps rather than the uniqueness of samples. Collectively, these results provide a principled foundation and practical guidelines for efficiently scaling the reasoning capabilities of LLMs through RL post-training.","authors":["Zelin Tan","Hejia Geng","Xiaohang Yu","Mulei Zhang","Guancheng Wan","Yifan Zhou","Qiang He","Xiangyuan Xue","Heng Zhou","Yutao Fan","Zhongzhi Li","Zaibin Zhang","Guibin Zhang","Chen Zhang","Zhenfei Yin","Philip Torr","Lei Bai"],"pdf_url":"","comment":"V3 version:27 pages, 14 figures, add code and dataset url"},{"id":"http://arxiv.org/abs/2512.19104v1","updated":"2025-12-22T07:18:57Z","published":"2025-12-22T07:18:57Z","title":"Explicit and Non-asymptotic Query Complexities of Rank-Based Zeroth-order Algorithm on Stochastic Smooth Functions","summary":"Zeroth-order (ZO) optimization with ordinal feedback has emerged as a fundamental problem in modern machine learning systems, particularly in human-in-the-loop settings such as reinforcement learning from human feedback, preference learning, and evolutionary strategies. While rank-based ZO algorithms enjoy strong empirical success and robustness properties, their theoretical understanding, especially under stochastic objectives and standard smoothness assumptions, remains limited. In this paper, we study rank-based zeroth-order optimization for stochastic functions where only ordinal feedback of the stochastic function is available. We propose a simple and computationally efficient rank-based ZO algorithm. Under standard assumptions including smoothness, strong convexity, and bounded second moments of stochastic gradients, we establish explicit non-asymptotic query complexity bounds for both convex and nonconvex objectives. Notably, our results match the best-known query complexities of value-based ZO algorithms, demonstrating that ordinal information alone is sufficient for optimal query efficiency in stochastic settings. Our analysis departs from existing drift-based and information-geometric techniques, offering new tools for the study of rank-based optimization under noise. These findings narrow the gap between theory and practice and provide a principled foundation for optimization driven by human preferences.","authors":["Haishan Ye"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19103v1","updated":"2025-12-22T07:18:13Z","published":"2025-12-22T07:18:13Z","title":"Timely Parameter Updating in Over-the-Air Federated Learning","summary":"Incorporating over-the-air computations (OAC) into the model training process of federated learning (FL) is an effective approach to alleviating the communication bottleneck in FL systems. Under OAC-FL, every client modulates its intermediate parameters, such as gradient, onto the same set of orthogonal waveforms and simultaneously transmits the radio signal to the edge server. By exploiting the superposition property of multiple-access channels, the edge server can obtain an automatically aggregated global gradient from the received signal. However, the limited number of orthogonal waveforms available in practical systems is fundamentally mismatched with the high dimensionality of modern deep learning models. To address this issue, we propose Freshness Freshness-mAgnItude awaRe top-k (FAIR-k), an algorithm that selects, in each communication round, the most impactful subset of gradients to be updated over the air. In essence, FAIR-k combines the complementary strengths of the Round-Robin and Top-k algorithms, striking a delicate balance between timeliness (freshness of parameter updates) and importance (gradient magnitude). Leveraging tools from Markov analysis, we characterize the distribution of parameter staleness under FAIR-k. Building on this, we establish the convergence rate of OAC-FL with FAIR-k, which discloses the joint effect of data heterogeneity, channel noise, and parameter staleness on the training efficiency. Notably, as opposed to conventional analyses that assume a universal Lipschitz constant across all the clients, our framework adopts a finer-grained model of the data heterogeneity. The analysis demonstrates that since FAIR-k promotes fresh (and fair) parameter updates, it not only accelerates convergence but also enhances communication efficiency by enabling an extended period of local training without significantly affecting overall training efficiency.","authors":["Jiaqi Zhu","Zhongyuan Zhao","Xiao Li","Ruihao Du","Shi Jin","Howard H. Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19099v1","updated":"2025-12-22T07:08:20Z","published":"2025-12-22T07:08:20Z","title":"Dual Model Deep Learning for Alzheimer Prognostication","summary":"Disease modifying therapies for Alzheimer's disease demand precise timing decisions, yet current predictive models require longitudinal observations and provide no uncertainty quantification, rendering them impractical at the critical first visit when treatment decisions must be made. We developed PROGRESS (PRognostic Generalization from REsting Static Signatures), a dual-model deep learning framework that transforms a single baseline cerebrospinal fluid biomarker assessment into actionable prognostic estimates without requiring prior clinical history. The framework addresses two complementary clinical questions: a probabilistic trajectory network predicts individualized cognitive decline with calibrated uncertainty bounds achieving near-nominal coverage, enabling honest prognostic communication; and a deep survival model estimates time to conversion from mild cognitive impairment to dementia. Using data from over 3,000 participants across 43 Alzheimer's Disease Research Centers in the National Alzheimer's Coordinating Center database, PROGRESS substantially outperforms Cox proportional hazards, Random Survival Forests, and gradient boosting methods for survival prediction. Risk stratification identifies patient groups with seven-fold differences in conversion rates, enabling clinically meaningful treatment prioritization. Leave-one-center-out validation demonstrates robust generalizability, with survival discrimination remaining strong across held-out sites despite heterogeneous measurement conditions spanning four decades of assay technologies. By combining superior survival prediction with trustworthy trajectory uncertainty quantification, PROGRESS bridges the gap between biomarker measurement and personalized clinical decision-making.","authors":["Alireza Moayedikia","Sara Fin","Uffe Kock Wiil"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19097v1","updated":"2025-12-22T07:07:43Z","published":"2025-12-22T07:07:43Z","title":"DIVER-1 : Deep Integration of Vast Electrophysiological Recordings at Scale","summary":"Electrophysiology signals such as EEG and iEEG are central to neuroscience, brain-computer interfaces, and clinical applications, yet existing foundation models remain limited in scale despite clear evidence that scaling improves performance. We introduce DIVER-1, a family of EEG and iEEG foundation models trained on the largest and most diverse corpus to date-5.3k hours of iEEG and 54k hours of EEG (1.6M channel-hours from over 17.7k subjects)-and scaled up to 1.82B parameters. We present the first systematic scaling law analysis for this domain, showing that they follow data-constrained scaling laws: for a given amount of data and compute, smaller models trained for extended epochs consistently outperform larger models trained briefly. This behavior contrasts with prior electrophysiology foundation models that emphasized model size over training duration. To achieve strong performance, we also design architectural innovations including any-variate attention, sliding temporal conditional positional encoding, and multi-domain reconstruction. DIVER-1 iEEG and EEG models each achieve state-of-the-art performance on their respective benchmarks, establishing a concrete guidelines for efficient scaling and resource allocation in electrophysiology foundation model development.","authors":["Danny Dongyeop Han","Yonghyeon Gwon","Ahhyun Lucy Lee","Taeyang Lee","Seong Jin Lee","Jubin Choi","Sebin Lee","Jihyun Bang","Seungju Lee","David Keetae Park","Shinjae Yoo","Chun Kee Chung","Jiook Cha"],"pdf_url":"","comment":"47 pages, 13 figures, 26 tables"},{"id":"http://arxiv.org/abs/2511.04659v3","updated":"2025-12-22T07:04:01Z","published":"2025-11-06T18:44:35Z","title":"Nowcast3D: Reliable precipitation nowcasting via gray-box learning","summary":"Extreme-precipitation nowcasting requires high spatial and temporal resolution together with extended lead times, yet current approaches remain constrained. Numerical weather prediction systems and their deep-learning emulators operate at relatively coarse space-time resolution and struggle to capture rapidly evolving convective systems. Radar extrapolation methods, which advect recent fields using estimated motion, have difficulty capturing the complex evolution of precipitation. Purely data-driven models often produce overly smoothed reflectivity fields and underestimate intensity. Hybrid 2D radar-based methods discard crucial vertical information, preventing accurate reconstruction of height-dependent dynamics. We introduce Nowcast3D, a gray-box, fully three-dimensional nowcasting framework that operates directly on volumetric radar reflectivity and couples physically constrained neural operators with data-driven learning. The model learns three fields that govern reflectivity evolution: a three-dimensional flow field for advective transport, a spatially varying diffusion field for local dispersive spreading, and a residual source term for unresolved microphysical effects. These learned operators advance the forecast in time under explicit physical constraints, while a conditional diffusion model, conditioned on both the observations and the physics-based forecast, generates ensembles of future radar volumes that quantify forecast uncertainty. In a blind evaluation by 160 meteorologists, Nowcast3D is preferred in 57% of post-hoc and 51% of prior assessments. By explicitly embedding three-dimensional dynamics and uncertainty into a single framework, Nowcast3D offers a scalable and robust approach for reliable nowcasting of extreme precipitation.","authors":["Huaguan Chen","Wei Han","Haofei Sun","Ning Lin","Xingtao Song","Yunfan Yang","Jie Tian","Yang Liu","Ji-Rong Wen","Xiaoye Zhang","Xueshun Shen","Hao Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19091v1","updated":"2025-12-22T07:00:49Z","published":"2025-12-22T07:00:49Z","title":"Auditing Significance, Metric Choice, and Demographic Fairness in Medical AI Challenges","summary":"Open challenges have become the de facto standard for comparative ranking of medical AI methods. Despite their importance, medical AI leaderboards exhibit three persistent limitations: (1) score gaps are rarely tested for statistical significance, so rank stability is unknown; (2) single averaged metrics are applied to every organ, hiding clinically important boundary errors; (3) performance across intersecting demographics is seldom reported, masking fairness and equity gaps. We introduce RankInsight, an open-source toolkit that seeks to address these limitations. RankInsight (1) computes pair-wise significance maps that show the nnU-Net family outperforms Vision-Language and MONAI submissions with high statistical certainty; (2) recomputes leaderboards with organ-appropriate metrics, reversing the order of the top four models when Dice is replaced by NSD for tubular structures; and (3) audits intersectional fairness, revealing that more than half of the MONAI-based entries have the largest gender-race discrepancy on our proprietary Johns Hopkins Hospital dataset. The RankInsight toolkit is publicly released and can be directly applied to past, ongoing, and future challenges. It enables organizers and participants to publish rankings that are statistically sound, clinically meaningful, and demographically fair.","authors":["Ariel Lubonja","Pedro R. A. S. Bassi","Wenxuan Li","Hualin Qiao","Randal Burns","Alan L. Yuille","Zongwei Zhou"],"pdf_url":"","comment":"MICCAI 2025 Workshop on Machine Learning in Medical Imaging"},{"id":"http://arxiv.org/abs/2511.17582v3","updated":"2025-12-22T06:51:54Z","published":"2025-11-15T17:55:47Z","title":"GateRA: Token-Aware Modulation for Parameter-Efficient Fine-Tuning","summary":"Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, DoRA, and HiRA, enable lightweight adaptation of large pre-trained models via low-rank updates. However, existing PEFT approaches apply static, input-agnostic updates to all tokens, disregarding the varying importance and difficulty of different inputs. This uniform treatment can lead to overfitting on trivial content or under-adaptation on more informative regions, especially in autoregressive settings with distinct prefill and decoding dynamics. In this paper, we propose GateRA, a unified framework that introduces token-aware modulation to dynamically adjust the strength of PEFT updates. By incorporating adaptive gating into standard PEFT branches, GateRA enables selective, token-level adaptation, preserving pre-trained knowledge for well-modeled inputs while focusing capacity on challenging cases. Empirical visualizations reveal phase-sensitive behaviors, where GateRA automatically suppresses updates for redundant prefill tokens while emphasizing adaptation during decoding. To promote confident and efficient modulation, we further introduce an entropy-based regularization that encourages near-binary gating decisions. This regularization prevents diffuse update patterns and leads to interpretable, sparse adaptation without hard thresholding. Finally, we present a theoretical analysis showing that GateRA induces a soft gradient-masking effect over the PEFT path, enabling continuous and differentiable control over adaptation. Experiments on multiple commonsense reasoning benchmarks demonstrate that GateRA consistently outperforms or matches prior PEFT methods.","authors":["Jie Ou","Shuaihong Jiang","Yingjun Du","Cees G. M. Snoek"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2505.22255v3","updated":"2025-12-22T06:48:29Z","published":"2025-05-28T11:41:11Z","title":"Kronecker Factorization Improves Efficiency and Interpretability of Sparse Autoencoders","summary":"Sparse Autoencoders (SAEs) have demonstrated significant promise in interpreting the hidden states of language models by decomposing them into interpretable latent directions. However, training and interpreting SAEs at scale remains challenging, especially when large dictionary sizes are used. While decoders can leverage sparse-aware kernels for efficiency, encoders still require computationally intensive linear operations with large output dimensions. To address this, we propose KronSAE, a novel architecture that factorizes the latent representation via Kronecker product decomposition, drastically reducing memory and computational overhead. Furthermore, we introduce mAND, a differentiable activation function approximating the binary AND operation, which improves interpretability and performance in our factorized framework.","authors":["Vadim Kurochkin","Yaroslav Aksenov","Daniil Laptev","Daniil Gavrilov","Nikita Balagansky"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.15178v4","updated":"2025-12-22T06:16:10Z","published":"2024-10-19T18:46:17Z","title":"GUIDEd Agents: Enhancing Navigation Policies through Task-Specific Uncertainty Abstraction in Localization-Limited Environments","summary":"Autonomous vehicles performing navigation tasks in complex environments face significant challenges due to uncertainty in state estimation. In many scenarios, such as stealth operations or resource-constrained settings, accessing high-precision localization comes at a significant cost, forcing robots to rely primarily on less precise state estimates. Our key observation is that different tasks require varying levels of precision in different regions: a robot navigating a crowded space might need precise localization near obstacles but can operate effectively with less precision elsewhere. In this paper, we present a planning method for integrating task-specific uncertainty requirements directly into navigation policies. We introduce Task-Specific Uncertainty Maps (TSUMs), which abstract the acceptable levels of state estimation uncertainty across different regions. TSUMs align task requirements and environmental features using a shared representation space, generated via a domain-adapted encoder. Using TSUMs, we propose Generalized Uncertainty Integration for Decision-Making and Execution (GUIDE), a policy conditioning framework that incorporates these uncertainty requirements into robot decision-making. We find that TSUMs provide an effective way to abstract task-specific uncertainty requirements, and conditioning policies on TSUMs enables the robot to reason about the context-dependent value of certainty and adapt its behavior accordingly. We show how integrating GUIDE into reinforcement learning frameworks allows the agent to learn navigation policies that effectively balance task completion and uncertainty management without explicit reward engineering. We evaluate GUIDE on various real-world robotic navigation tasks and find that it demonstrates significant improvement in task completion rates compared to baseline methods that do not explicitly consider task-specific uncertainty.","authors":["Gokul Puthumanaillam","Paulo Padrao","Jose Fuentes","Leonardo Bobadilla","Melkior Ornik"],"pdf_url":"","comment":"Accepted for publication at RAL (Robotics and automation letters). Updated with the final version"},{"id":"http://arxiv.org/abs/2512.19067v1","updated":"2025-12-22T06:14:17Z","published":"2025-12-22T06:14:17Z","title":"On Cost-Aware Sequential Hypothesis Testing with Random Costs and Action Cancellation","summary":"We study a variant of cost-aware sequential hypothesis testing in which a single active Decision Maker (DM) selects actions with positive, random costs to identify the true hypothesis under an average error constraint, while minimizing the expected total cost. The DM may abort an in-progress action, yielding no sample, by truncating its realized cost at a smaller, tunable deterministic limit, which we term a per-action deadline. We analyze how this cancellation option can be exploited under two cost-revelation models: ex-post, where the cost is revealed only after the sample is obtained, and ex-ante, where the cost accrues before sample acquisition.\n  In the ex-post model, per-action deadlines do not affect the expected total cost, and the cost-error tradeoffs coincide with the baseline obtained by replacing deterministic costs with cost means. In the ex-ante model, we show how per-action deadlines inflate the expected number of times actions are applied, and that the resulting expected total cost can be reduced to the constant-cost setting by introducing an effective per-action cost. We characterize when deadlines are beneficial and study several families in detail.","authors":["George Vershinin","Asaf Cohen","Omer Gurewitz"],"pdf_url":"","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2508.14075v2","updated":"2025-12-22T06:08:18Z","published":"2025-08-12T11:20:27Z","title":"Explainable Graph Spectral Clustering For GloVe-like Text Embeddings","summary":"In a previous paper, we proposed an introduction to the explainability of Graph Spectral Clustering results for textual documents, given that document similarity is computed as cosine similarity in term vector space.\n  In this paper, we generalize this idea by considering other embeddings of documents, in particular, based on the GloVe embedding idea.","authors":["Mieczysław A. Kłopotek","Sławomir T. Wierzchoń","Bartłomiej Starosta","Piotr Borkowski","Dariusz Czerski","Eryk Laskowski"],"pdf_url":"","comment":"47 pages, 19 tables, 11 figures"},{"id":"http://arxiv.org/abs/2504.03560v2","updated":"2025-12-22T06:01:20Z","published":"2025-04-04T16:10:18Z","title":"Stochastic Optimization with Optimal Importance Sampling","summary":"Importance Sampling (IS) is a widely used variance reduction technique for enhancing the efficiency of Monte Carlo methods, particularly in rare-event simulation and related applications. Despite its effectiveness, the performance of IS is highly sensitive to the choice of the proposal distribution and often requires stochastic calibration. While the design and analysis of IS have been extensively studied in estimation settings, applying IS within stochastic optimization introduces a fundamental challenge: the decision variable and the importance sampling distribution are mutually dependent, creating a circular optimization structure. This interdependence complicates both convergence analysis and variance control. We consider convex stochastic optimization problems with linear constraints and propose a single-loop stochastic approximation algorithm, based on a joint variant of Nesterov's dual averaging, that jointly updates the decision variable and the importance sampling distribution, without time-scale separation or nested optimization. The method is globally convergent and achieves minimal asymptotic variance among stochastic gradient schemes, matching the performance of an oracle sampler adapted to the optimal solution.","authors":["Liviu Aolaritei","Bart P. G. Van Parys","Henry Lam","Michael I. Jordan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19061v1","updated":"2025-12-22T05:59:13Z","published":"2025-12-22T05:59:13Z","title":"Fraud Detection Through Large-Scale Graph Clustering with Heterogeneous Link Transformation","summary":"Collaborative fraud, where multiple fraudulent accounts coordinate to exploit online payment systems, poses significant challenges due to the formation of complex network structures. Traditional detection methods that rely solely on high-confidence identity links suffer from limited coverage, while approaches using all available linkages often result in fragmented graphs with reduced clustering effectiveness. In this paper, we propose a novel graph-based fraud detection framework that addresses the challenge of large-scale heterogeneous graph clustering through a principled link transformation approach. Our method distinguishes between \\emph{hard links} (high-confidence identity relationships such as phone numbers, credit cards, and national IDs) and \\emph{soft links} (behavioral associations including device fingerprints, cookies, and IP addresses). We introduce a graph transformation technique that first identifies connected components via hard links, merges them into super-nodes, and then reconstructs a weighted soft-link graph amenable to efficient embedding and clustering. The transformed graph is processed using LINE (Large-scale Information Network Embedding) for representation learning, followed by HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise) for density-based cluster discovery. Experiments on a real-world payment platform dataset demonstrate that our approach achieves significant graph size reduction (from 25 million to 7.7 million nodes), doubles the detection coverage compared to hard-link-only baselines, and maintains high precision across identified fraud clusters. Our framework provides a scalable and practical solution for industrial-scale fraud detection systems.","authors":["Chi Liu"],"pdf_url":"","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2512.16963v2","updated":"2025-12-22T05:58:51Z","published":"2025-12-18T09:02:03Z","title":"Compression is Routing: Reconstruction Error as an Intrinsic Signal for Modular Language Models","summary":"Current Large Language Models (LLMs) face three major challenges: context length limitations, high inference costs, and catastrophic forgetting during continual learning. While Mixture-of-Experts (MoE) architectures mitigate some of these conflicts, their routing mechanisms typically rely on explicitly trained auxiliary classifiers. This not only increases system complexity but also often lacks interpretability when handling mixed-domain inputs.\n  Building upon the premise that ``Compression is Intelligence,'' this paper proposes a novel architectural philosophy: Compression is Routing. We trained an 87M-parameter end-to-end Transformer Autoencoder, achieving a 64x sequence length compression (compressing 512 tokens into 8 latent vectors). Experimental results demonstrate that this compressor possesses extreme domain discriminative capability: it achieves a reconstruction accuracy of 99.47% on the in-domain (code) validation set; accuracy drops sharply to 47.76% on a semi-out-of-distribution domain (Wiki text); and further plummets to just 0.57% on a fully out-of-distribution domain (random sequences).\n  This extreme and systematic performance discrepancy establishes the validity of reconstruction error as an Intrinsic Distribution Fingerprint. Based on this, we propose that expert modules can be automatically scheduled using reconstruction residuals directly, without the need for explicit gating networks. This mechanism offers excellent scalability. Furthermore, this architecture provides a new perspective on ``VRAM compression'' for handling ultra-long contexts. This report aims to verify the physical validity of this foundational architecture, offering a new research perspective for the next generation of scalable modular neural networks.","authors":["Zhongpan Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19057v1","updated":"2025-12-22T05:47:25Z","published":"2025-12-22T05:47:25Z","title":"Efficient Personalization of Generative Models via Optimal Experimental Design","summary":"Preference learning from human feedback has the ability to align generative models with the needs of end-users. Human feedback is costly and time-consuming to obtain, which creates demand for data-efficient query selection methods. This work presents a novel approach that leverages optimal experimental design to ask humans the most informative preference queries, from which we can elucidate the latent reward function modeling user preferences efficiently. We formulate the problem of preference query selection as the one that maximizes the information about the underlying latent preference model. We show that this problem has a convex optimization formulation, and introduce a statistically and computationally efficient algorithm ED-PBRL that is supported by theoretical guarantees and can efficiently construct structured queries such as images or text. We empirically present the proposed framework by personalizing a text-to-image generative model to user-specific styles, showing that it requires less preference queries compared to random query selection.","authors":["Guy Schacht","Ziyad Sheebaelhamd","Riccardo De Santi","Mojmír Mutný","Andreas Krause"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.22714v2","updated":"2025-12-22T05:47:00Z","published":"2025-06-28T01:50:13Z","title":"Libra: Unleashing GPU Heterogeneity for High-Performance Sparse Matrix Multiplication","summary":"Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely used in deep learning and scientific computing. Modern accelerators are commonly equipped with Tensor Core Units (TCUs) and CUDA cores to accelerate sparse operators. The former excels at structured matrix computations, whereas the latter offers greater programming flexibility. However, how to combine these two resources to maximize sparse-operator performance remains unclear. In this work, we first identify the source of performance gains in hybrid computation and systematically analyze their complementary strengths. Motivated by this, we propose Libra, a holistic framework that efficiently leverages heterogeneous computing resources to accelerate both SpMM and SDDMM operators. Specifically, Libra introduces a 2D-aware (locality and utilization) workload distribution method to precisely identify the optimal task mapping, simultaneously leveraging the data reuse capabilities of TCUs and the flexibility of CUDA cores to minimize computational redundancy. Libra further incorporates hybrid load balancing, occupancy-aware task scheduling, and efficient kernel implementations to maximize execution efficiency. Extensive experiments on H100 and RTX 4090 GPUs demonstrate that Libra surpasses all the 12 up-to-date baselines significantly, e.g., on average 1.77x speedup over FlashSparse, 1.73x over RoDe, and 2.9x over DGL for end-to-end GNN applications. Libra opens up a new perspective for sparse operator acceleration by fully unleashing the power of heterogeneous GPU resources.","authors":["Jinliang Shi","Shigang Li","Youxuan Xu","Xueying Wang","Rongtian Fu","Zhi Ma","Tong Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19038v1","updated":"2025-12-22T05:19:05Z","published":"2025-12-22T05:19:05Z","title":"Time-series Forecast for Indoor Zone Air Temperature with Long Horizons: A Case Study with Sensor-based Data from a Smart Building","summary":"With the press of global climate change, extreme weather and sudden weather changes are becoming increasingly common. To maintain a comfortable indoor environment and minimize the contribution of the building to climate change as much as possible, higher requirements are placed on the operation and control of HVAC systems, e.g., more energy-efficient and flexible to response to the rapid change of weather. This places demands on the rapid modeling and prediction of zone air temperatures of buildings. Compared to the traditional simulation-based approach such as EnergyPlus and DOE2, a hybrid approach combined physics and data-driven is more suitable. Recently, the availability of high-quality datasets and algorithmic breakthroughs have driven a considerable amount of work in this field. However, in the niche of short- and long-term predictions, there are still some gaps in existing research. This paper aims to develop a time series forecast model to predict the zone air temperature in a building located in America on a 2-week horizon. The findings could be further improved to support intelligent control and operation of HVAC systems (i.e. demand flexibility) and could also be used as hybrid building energy modeling.","authors":["Liping Sun","Yucheng Guo","Siliang Lu","Zhenzhen Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19037v1","updated":"2025-12-22T05:14:26Z","published":"2025-12-22T05:14:26Z","title":"Elevating Intrusion Detection and Security Fortification in Intelligent Networks through Cutting-Edge Machine Learning Paradigms","summary":"The proliferation of IoT devices and their reliance on Wi-Fi networks have introduced significant security vulnerabilities, particularly the KRACK and Kr00k attacks, which exploit weaknesses in WPA2 encryption to intercept and manipulate sensitive data. Traditional IDS using classifiers face challenges such as model overfitting, incomplete feature extraction, and high false positive rates, limiting their effectiveness in real-world deployments. To address these challenges, this study proposes a robust multiclass machine learning based intrusion detection framework. The methodology integrates advanced feature selection techniques to identify critical attributes, mitigating redundancy and enhancing detection accuracy. Two distinct ML architectures are implemented: a baseline classifier pipeline and a stacked ensemble model combining noise injection, Principal Component Analysis (PCA), and meta learning to improve generalization and reduce false positives. Evaluated on the AWID3 data set, the proposed ensemble architecture achieves superior performance, with an accuracy of 98%, precision of 98%, recall of 98%, and a false positive rate of just 2%, outperforming existing state-of-the-art methods. This work demonstrates the efficacy of combining preprocessing strategies with ensemble learning to fortify network security against sophisticated Wi-Fi attacks, offering a scalable and reliable solution for IoT environments. Future directions include real-time deployment and adversarial resilience testing to further enhance the model's adaptability.","authors":["Md Minhazul Islam Munna","Md Mahbubur Rahman","Jaroslav Frnda","Muhammad Shahid Anwar","Alpamis Kutlimuratov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19031v1","updated":"2025-12-22T05:04:09Z","published":"2025-12-22T05:04:09Z","title":"A Surrogate-Augmented Symbolic CFD-Driven Training Framework for Accelerating Multi-objective Physical Model Development","summary":"Computational Fluid Dynamics (CFD)-driven training combines machine learning (ML) with CFD solvers to develop physically consistent closure models with improved predictive accuracy. In the original framework, each ML-generated candidate model is embedded in a CFD solver and evaluated against reference data, requiring hundreds to thousands of high-fidelity simulations and resulting in prohibitive computational cost for complex flows. To overcome this limitation, we propose an extended framework that integrates surrogate modeling into symbolic CFD-driven training in real time to reduce training cost. The surrogate model learns to approximate the errors of ML-generated models based on previous CFD evaluations and is continuously refined during training. Newly generated models are first assessed using the surrogate, and only those predicted to yield small errors or high uncertainty are subsequently evaluated with full CFD simulations. Discrete expressions generated by symbolic regression are mapped into a continuous space using averaged input-symbol values as inputs to a probabilistic surrogate model. To support multi-objective model training, particularly when fixed weighting of competing quantities is challenging, the surrogate is extended to a multi-output formulation by generalizing the kernel to a matrix form, providing one mean and variance prediction per training objective. Selection metrics based on these probabilistic outputs are used to identify an optimal training setup. The proposed surrogate-augmented CFD-driven training framework is demonstrated across a range of statistically one- and two-dimensional flows, including both single- and multi-expression model optimization. In all cases, the framework substantially reduces training cost while maintaining predictive accuracy comparable to that of the original CFD-driven approach.","authors":["Yuan Fang","Fabian Waschkowski","Maximilian Reissmann","Richard D. Sandberg","Takuo Oda","Koichi Tanimoto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2311.02757v3","updated":"2025-12-22T04:53:58Z","published":"2023-11-05T20:29:40Z","title":"Certified Defense on the Fairness of Graph Neural Networks","summary":"Graph Neural Networks (GNNs) have emerged as a prominent graph learning model in various graph-based tasks over the years. Nevertheless, due to the vulnerabilities of GNNs, it has been empirically shown that malicious attackers could easily corrupt the fairness level of their predictions by adding perturbations to the input graph data. In this paper, we take crucial steps to study a novel problem of certifiable defense on the fairness level of GNNs. Specifically, we propose a principled framework named ELEGANT and present a detailed theoretical certification analysis for the fairness of GNNs. ELEGANT takes {\\em any} GNN as its backbone, and the fairness level of such a backbone is theoretically impossible to be corrupted under certain perturbation budgets for attackers. Notably, ELEGANT does not make any assumptions over the GNN structure or parameters, and does not require re-training the GNNs to realize certification. Hence it can serve as a plug-and-play framework for any optimized GNNs ready to be deployed. We verify the satisfactory effectiveness of ELEGANT in practice through extensive experiments on real-world datasets across different backbones of GNNs and parameter settings.","authors":["Yushun Dong","Binchi Zhang","Hanghang Tong","Jundong Li"],"pdf_url":"","comment":"Accepted at SIGKDD'26 for publication"},{"id":"http://arxiv.org/abs/2512.19027v1","updated":"2025-12-22T04:53:40Z","published":"2025-12-22T04:53:40Z","title":"Recontextualization Mitigates Specification Gaming without Modifying the Specification","summary":"Developers often struggle to specify correct training labels and rewards. Perhaps they don't need to. We propose recontextualization, which reduces how often language models \"game\" training signals, performing misbehaviors those signals mistakenly reinforce. We show recontextualization prevents models from learning to 1) prioritize evaluation metrics over chat response quality; 2) special-case code to pass incorrect tests; 3) lie to users; and 4) become sycophantic. Our method works by generating completions from prompts discouraging misbehavior and then recontextualizing them as though they were in response to prompts permitting misbehavior. Recontextualization trains language models to resist misbehavior even when instructions permit it. This mitigates the reinforcement of misbehavior from misspecified training signals, reducing specification gaming without improving the supervision signal.","authors":["Ariana Azarbal","Victor Gillioz","Vladimir Ivanov","Bryce Woodworth","Jacob Drori","Nevan Wichers","Aram Ebtekar","Alex Cloud","Alexander Matt Turner"],"pdf_url":"","comment":"57 pages, 41 figures"},{"id":"http://arxiv.org/abs/2512.19025v1","updated":"2025-12-22T04:42:41Z","published":"2025-12-22T04:42:41Z","title":"The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation","summary":"Machine unlearning aims to remove specific data influences from trained models, a capability essential for adhering to copyright laws and ensuring AI safety. Current unlearning metrics typically measure success by monitoring the model's performance degradation on the specific unlearning dataset ($D_u$). We argue that for Large Language Models (LLMs), this evaluation paradigm is insufficient and potentially misleading. Many real-world uses of unlearning--motivated by copyright or safety--implicitly target not only verbatim content in $D_u$, but also behaviors influenced by the broader generalizations the model derived from it. We demonstrate that LLMs can pass standard unlearning evaluation and appear to have ``forgotten'' the target knowledge, while simultaneously retaining strong capabilities on content that is semantically adjacent to $D_u$. This phenomenon indicates that erasing exact sentences does not necessarily equate to removing the underlying knowledge. To address this gap, we propose \\name, an automated stress-testing framework that generates a surrogate dataset, $\\tilde{D}_u$. This surrogate set is constructed to be semantically derived from $D_u$ yet sufficiently distinct in embedding space. By comparing unlearning metric scores between $D_u$ and $\\tilde{D}_u$, we can stress-test the reliability of the metric itself. Our extensive evaluation across three LLM families (Llama-3-8B, Qwen2.5-7B, and Zephyr-7B-$β$), three distinct datasets, and seven standard metrics reveals widespread inconsistencies. We find that current metrics frequently overestimate unlearning success, failing to detect retained knowledge exposed by our stress-test datasets.","authors":["Hengrui Jia","Taoran Li","Jonas Guan","Varun Chandrasekaran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19020v1","updated":"2025-12-22T04:21:39Z","published":"2025-12-22T04:21:39Z","title":"CETCAM: Camera-Controllable Video Generation via Consistent and Extensible Tokenization","summary":"Achieving precise camera control in video generation remains challenging, as existing methods often rely on camera pose annotations that are difficult to scale to large and dynamic datasets and are frequently inconsistent with depth estimation, leading to train-test discrepancies. We introduce CETCAM, a camera-controllable video generation framework that eliminates the need for camera annotations through a consistent and extensible tokenization scheme. CETCAM leverages recent advances in geometry foundation models, such as VGGT, to estimate depth and camera parameters and converts them into unified, geometry-aware tokens. These tokens are seamlessly integrated into a pretrained video diffusion backbone via lightweight context blocks. Trained in two progressive stages, CETCAM first learns robust camera controllability from diverse raw video data and then refines fine-grained visual quality using curated high-fidelity datasets. Extensive experiments across multiple benchmarks demonstrate state-of-the-art geometric consistency, temporal stability, and visual realism. Moreover, CETCAM exhibits strong adaptability to additional control modalities, including inpainting and layout control, highlighting its flexibility beyond camera control. The project page is available at https://sjtuytc.github.io/CETCam_project_page.github.io/.","authors":["Zelin Zhao","Xinyu Gong","Bangya Liu","Ziyang Song","Jun Zhang","Suhui Wu","Yongxin Chen","Hao Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19019v1","updated":"2025-12-22T04:16:13Z","published":"2025-12-22T04:16:13Z","title":"Optimizer Dynamics at the Edge of Stability with Differential Privacy","summary":"Deep learning models can reveal sensitive information about individual training examples, and while differential privacy (DP) provides guarantees restricting such leakage, it also alters optimization dynamics in poorly understood ways. We study the training dynamics of neural networks under DP by comparing Gradient Descent (GD), and Adam to their privacy-preserving variants. Prior work shows that these optimizers exhibit distinct stability dynamics: full-batch methods train at the Edge of Stability (EoS), while mini-batch and adaptive methods exhibit analogous edge-of-stability behavior. At these regimes, the training loss and the sharpness--the maximum eigenvalue of the training loss Hessian--exhibit certain characteristic behavior. In DP training, per-example gradient clipping and Gaussian noise modify the update rule, and it is unclear whether these stability patterns persist. We analyze how clipping and noise change sharpness and loss evolution and show that while DP generally reduces the sharpness and can prevent optimizers from fully reaching the classical stability thresholds, patterns from EoS and analogous adaptive methods stability regimes persist, with the largest learning rates and largest privacy budgets approaching, and sometimes exceeding, these thresholds. These findings highlight the unpredictability introduced by DP in neural network optimization.","authors":["Ayana Hussain","Ricky Fang"],"pdf_url":"","comment":"17 pages, 5 figures"},{"id":"http://arxiv.org/abs/2512.19011v1","updated":"2025-12-22T04:00:35Z","published":"2025-12-22T04:00:35Z","title":"Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline","summary":"Prompt injection and jailbreaking attacks pose persistent security challenges to large language model (LLM)-based systems. We present an efficient and systematically evaluated defense architecture that mitigates these threats through a lightweight, multi-stage pipeline. Its core component is a semantic filter based on text normalization, TF-IDF representations, and a Linear SVM classifier. Despite its simplicity, this module achieves 93.4% accuracy and 96.5% specificity on held-out data, substantially reducing attack throughput while incurring negligible computational overhead.\n  Building on this efficient foundation, the full pipeline integrates complementary detection and mitigation mechanisms that operate at successive stages, providing strong robustness with minimal latency. In comparative experiments, our SVM-based configuration improves overall accuracy from 35.1% to 93.4% while reducing average time to completion from approximately 450s to 47s, yielding over 10 times lower latency than ShieldGemma. These results demonstrate that the proposed design simultaneously advances defensive precision and efficiency, addressing a core limitation of current model-based moderators.\n  Evaluation across a curated corpus of over 30,000 labeled prompts, including benign, jailbreak, and application-layer injections, confirms that staged, resource-efficient defenses can robustly secure modern LLM-driven applications.","authors":["Akshaj Prashanth Rao","Advait Singh","Saumya Kumaar Saksena","Dhruv Kumar"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2512.19007v1","updated":"2025-12-22T03:48:31Z","published":"2025-12-22T03:48:31Z","title":"The 6th International Verification of Neural Networks Competition (VNN-COMP 2025): Summary and Results","summary":"This report summarizes the 6th International Verification of Neural Networks Competition (VNN-COMP 2025), held as a part of the 8th International Symposium on AI Verification (SAIV), that was collocated with the 37th International Conference on Computer-Aided Verification (CAV). VNN-COMP is held annually to facilitate the fair and objective comparison of state-of-the-art neural network verification tools, encourage the standardization of tool interfaces, and bring together the neural network verification community. To this end, standardized formats for networks (ONNX) and specification (VNN-LIB) were defined, tools were evaluated on equal-cost hardware (using an automatic evaluation pipeline based on AWS instances), and tool parameters were chosen by the participants before the final test sets were made public. In the 2025 iteration, 8 teams participated on a diverse set of 16 regular and 9 extended benchmarks. This report summarizes the rules, benchmarks, participating tools, results, and lessons learned from this iteration of this competition.","authors":["Konstantin Kaulen","Tobias Ladner","Stanley Bak","Christopher Brix","Hai Duong","Thomas Flinkow","Taylor T. Johnson","Lukas Koller","Edoardo Manino","ThanhVu H Nguyen","Haoze Wu"],"pdf_url":"","comment":"Report on the results of VNN-COMP 2025. arXiv admin note: substantial text overlap with arXiv:2412.19985, arXiv:2312.16760, arXiv:2212.10376"},{"id":"http://arxiv.org/abs/2512.19004v1","updated":"2025-12-22T03:45:04Z","published":"2025-12-22T03:45:04Z","title":"Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models","summary":"Diffusion Large Language Models (DLLMs) enable fully parallel token decoding but often remain impractical at inference time due to the many denoising iterations required to refine an information-free, fully masked initialization into coherent text. Most existing acceleration methods focus on traversing this generative trajectory more efficiently via improved solvers or sampling strategies. We advance a complementary perspective: shorten the trajectory itself by starting closer to the target distribution through context-aware initialization.\n  We propose a training-free interface that injects prompt-conditioned priors from a lightweight auxiliary model into the diffusion initialization, and instantiate it with two mechanisms: discrete token injection and representation-level embedding interpolation. Because injected priors can be imperfect and unmask-only decoding can over-commit early, we also introduce a simple confidence-based remasking mechanism as a form of prior skepticism. Preliminary evidence on GSM8K suggests that context-aware initialization can substantially reduce denoising iterations (about 35\\% fewer function evaluations in our setting), while also exposing a key open challenge: naive warm-starting can degrade final accuracy relative to strong diffusion baselines. We use these findings to motivate a research agenda around calibration, revision mechanisms, and representation alignment for reliable warm-started diffusion decoding.","authors":["Tongyuan Miao","Gary Huang","Kai Jun Han","Annie Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19001v1","updated":"2025-12-22T03:39:43Z","published":"2025-12-22T03:39:43Z","title":"ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management","summary":"As the pursuit of synergy between Artificial Intelligence (AI) and Operations Research (OR) gains momentum in handling complex inventory systems, a critical challenge persists: how to effectively reconcile AI's adaptive perception with OR's structural rigor. To bridge this gap, we propose a novel OR-Guided \"Pretrain-then-Reinforce\" framework. To provide structured guidance, we propose a simulation-augmented OR model that generates high-quality reference decisions, implicitly capturing complex business constraints and managerial preferences. Leveraging these OR-derived decisions as foundational training labels, we design a domain-informed deep learning foundation model to establish foundational decision-making capabilities, followed by a reinforcement learning (RL) fine-tuning stage. Uniquely, we position RL as a deep alignment mechanism that enables the AI agent to internalize the optimality principles of OR, while simultaneously leveraging exploration for general policy refinement and allowing expert guidance for scenario-specific adaptation (e.g., promotional events). Validated through extensive numerical experiments and a field deployment at JD.com augmented by a Difference-in-Differences (DiD) analysis, our model significantly outperforms incumbent industrial practices, delivering real-world gains of a 5.27-day reduction in turnover and a 2.29% increase in in-stock rates, alongside a 29.95% decrease in holding costs. Contrary to the prevailing trend of brute-force model scaling, our study demonstrates that a lightweight, domain-informed model can deliver state-of-the-art performance and robust transferability when guided by structured OR logic. This approach offers a scalable and cost-effective paradigm for intelligent supply chain management, highlighting the value of deeply aligning AI with OR.","authors":["Lingjie Zhao","Xue Yu","Yongzhi Qi","Hao Hu","Jianshen Zhang","Yingzheng Ma","Shuyu Han","Wei Qi","Zuo-Jun Max Shen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12808v3","updated":"2025-12-22T03:26:43Z","published":"2025-11-16T22:28:30Z","title":"Expressive Temporal Specifications for Reward Monitoring","summary":"Specifying informative and dense reward functions remains a pivotal challenge in Reinforcement Learning, as it directly affects the efficiency of agent training. In this work, we harness the expressive power of quantitative Linear Temporal Logic on finite traces (($\\text{LTL}_f[\\mathcal{F}]$)) to synthesize reward monitors that generate a dense stream of rewards for runtime-observable state trajectories. By providing nuanced feedback during training, these monitors guide agents toward optimal behaviour and help mitigate the well-known issue of sparse rewards under long-horizon decision making, which arises under the Boolean semantics dominating the current literature. Our framework is algorithm-agnostic and only relies on a state labelling function, and naturally accommodates specifying non-Markovian properties. Empirical results show that our quantitative monitors consistently subsume and, depending on the environment, outperform Boolean monitors in maximizing a quantitative measure of task completion and in reducing convergence time.","authors":["Omar Adalat","Francesco Belardinelli"],"pdf_url":"","comment":"Accepted at AAAI-26"},{"id":"http://arxiv.org/abs/2511.23083v5","updated":"2025-12-22T03:12:50Z","published":"2025-11-28T11:14:15Z","title":"Spectral Concentration at the Edge of Stability: Information Geometry of Kernel Associative Memory","summary":"High-capacity kernel Hopfield networks exhibit a \\textit{Ridge of Optimization} characterized by extreme stability. While previously linked to \\textit{Spectral Concentration}, its origin remains elusive. Here, we analyze the network dynamics on a statistical manifold, revealing that the Ridge corresponds to the Edge of Stability, a critical boundary where the Fisher Information Matrix becomes singular. We demonstrate that the apparent Euclidean force antagonism is a manifestation of \\textit{Dual Equilibrium} in the Riemannian space. This unifies learning dynamics and capacity via the Minimum Description Length principle, offering a geometric theory of self-organized criticality.","authors":["Akira Tamamori"],"pdf_url":"","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.20277v2","updated":"2025-12-22T02:58:33Z","published":"2025-11-25T13:05:40Z","title":"HVAdam: A Full-Dimension Adaptive Optimizer","summary":"Adaptive optimizers such as Adam have achieved great success in training large-scale models like large language models and diffusion models. However, they often generalize worse than non-adaptive methods, such as SGD on classical architectures like CNNs. We identify a key cause of this performance gap: adaptivity in pre-conditioners, which limits the optimizer's ability to adapt to diverse optimization landscapes. To address this, we propose Anon (Adaptivity Non-restricted Optimizer with Novel convergence technique), a novel optimizer with continuously tunable adaptivity\n  , allowing it to interpolate between SGD-like and Adam-like behaviors and even extrapolate beyond both. To ensure convergence across the entire adaptivity spectrum, we introduce incremental delay update (IDU), a novel mechanism that is more flexible than AMSGrad's hard max-tracking strategy and enhances robustness to gradient noise. We theoretically establish convergence guarantees under both convex and non-convex settings. Empirically, Anon consistently outperforms state-of-the-art optimizers on representative image classification, diffusion, and language modeling tasks. These results demonstrate that adaptivity can serve as a valuable tunable design principle, and Anon provides the first unified and reliable framework capable of bridging the gap between classical and modern optimizers and surpassing their advantageous properties.","authors":["Yiheng Zhang","Shaowu Wu","Yuanzhuo Xu","Jiajun Wu","Shang Xu","Steve Drew","Xiaoguang Niu"],"pdf_url":"","comment":"Accepted at AAAI2025"},{"id":"http://arxiv.org/abs/2512.18986v1","updated":"2025-12-22T02:54:10Z","published":"2025-12-22T02:54:10Z","title":"R-GenIMA: Integrating Neuroimaging and Genetics with Interpretable Multimodal AI for Alzheimer's Disease Progression","summary":"Early detection of Alzheimer's disease (AD) requires models capable of integrating macro-scale neuroanatomical alterations with micro-scale genetic susceptibility, yet existing multimodal approaches struggle to align these heterogeneous signals. We introduce R-GenIMA, an interpretable multimodal large language model that couples a novel ROI-wise vision transformer with genetic prompting to jointly model structural MRI and single nucleotide polymorphisms (SNPs) variations. By representing each anatomically parcellated brain region as a visual token and encoding SNP profiles as structured text, the framework enables cross-modal attention that links regional atrophy patterns to underlying genetic factors. Applied to the ADNI cohort, R-GenIMA achieves state-of-the-art performance in four-way classification across normal cognition (NC), subjective memory concerns (SMC), mild cognitive impairment (MCI), and AD. Beyond predictive accuracy, the model yields biologically meaningful explanations by identifying stage-specific brain regions and gene signatures, as well as coherent ROI-Gene association patterns across the disease continuum. Attention-based attribution revealed genes consistently enriched for established GWAS-supported AD risk loci, including APOE, BIN1, CLU, and RBFOX1. Stage-resolved neuroanatomical signatures identified shared vulnerability hubs across disease stages alongside stage-specific patterns: striatal involvement in subjective decline, frontotemporal engagement during prodromal impairment, and consolidated multimodal network disruption in AD. These results demonstrate that interpretable multimodal AI can synthesize imaging and genetics to reveal mechanistic insights, providing a foundation for clinically deployable tools that enable earlier risk stratification and inform precision therapeutic strategies in Alzheimer's disease.","authors":["Kun Zhao","Siyuan Dai","Yingying Zhang","Guodong Liu","Pengfei Gu","Chenghua Lin","Paul M. Thompson","Alex Leow","Heng Huang","Lifang He","Liang Zhan","Haoteng Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18980v1","updated":"2025-12-22T02:45:41Z","published":"2025-12-22T02:45:41Z","title":"OPBO: Order-Preserving Bayesian Optimization","summary":"Bayesian optimization is an effective method for solving expensive black-box optimization problems. Most existing methods use Gaussian processes (GP) as the surrogate model for approximating the black-box objective function, it is well-known that it can fail in high-dimensional space (e.g., dimension over 500). We argue that the reliance of GP on precise numerical fitting is fundamentally ill-suited in high-dimensional space, where it leads to prohibitive computational complexity. In order to address this, we propose a simple order-preserving Bayesian optimization (OPBO) method, where the surrogate model preserves the order, instead of the value, of the black-box objective function. Then we can use a simple but effective OP neural network (NN) to replace GP as the surrogate model. Moreover, instead of searching for the best solution from the acquisition model, we select good-enough solutions in the ordinal set to reduce computational cost. The experimental results show that for high-dimensional (over 500) black-box optimization problems, the proposed OPBO significantly outperforms traditional BO methods based on regression NN and GP. The source code is available at https://github.com/pengwei222/OPBO.","authors":["Wei Peng","Jianchen Hu","Kang Liu","Qiaozhu Zhai"],"pdf_url":"","comment":"13 pages"},{"id":"http://arxiv.org/abs/2512.18978v1","updated":"2025-12-22T02:41:43Z","published":"2025-12-22T02:41:43Z","title":"Outlier detection in mixed-attribute data: a semi-supervised approach with fuzzy approximations and relative entropy","summary":"Outlier detection is a critical task in data mining, aimed at identifying objects that significantly deviate from the norm. Semi-supervised methods improve detection performance by leveraging partially labeled data but typically overlook the uncertainty and heterogeneity of real-world mixed-attribute data. This paper introduces a semi-supervised outlier detection method, namely fuzzy rough sets-based outlier detection (FROD), to effectively handle these challenges. Specifically, we first utilize a small subset of labeled data to construct fuzzy decision systems, through which we introduce the attribute classification accuracy based on fuzzy approximations to evaluate the contribution of attribute sets in outlier detection. Unlabeled data is then used to compute fuzzy relative entropy, which provides a characterization of outliers from the perspective of uncertainty. Finally, we develop the detection algorithm by combining attribute classification accuracy with fuzzy relative entropy. Experimental results on 16 public datasets show that FROD is comparable with or better than leading detection algorithms. All datasets and source codes are accessible at https://github.com/ChenBaiyang/FROD. This manuscript is the accepted author version of a paper published by Elsevier. The final published version is available at https://doi.org/10.1016/j.ijar.2025.109373","authors":["Baiyang Chen","Zhong Yuan","Zheng Liu","Dezhong Peng","Yongxiang Li","Chang Liu","Guiduo Duan"],"pdf_url":"","comment":"Author's accepted manuscript"},{"id":"http://arxiv.org/abs/2512.18977v1","updated":"2025-12-22T02:41:08Z","published":"2025-12-22T02:41:08Z","title":"Consistency-guided semi-supervised outlier detection in heterogeneous data using fuzzy rough sets","summary":"Outlier detection aims to find samples that behave differently from the majority of the data. Semi-supervised detection methods can utilize the supervision of partial labels, thus reducing false positive rates. However, most of the current semi-supervised methods focus on numerical data and neglect the heterogeneity of data information. In this paper, we propose a consistency-guided outlier detection algorithm (COD) for heterogeneous data with the fuzzy rough set theory in a semi-supervised manner. First, a few labeled outliers are leveraged to construct label-informed fuzzy similarity relations. Next, the consistency of the fuzzy decision system is introduced to evaluate attributes' contributions to knowledge classification. Subsequently, we define the outlier factor based on the fuzzy similarity class and predict outliers by integrating the classification consistency and the outlier factor. The proposed algorithm is extensively evaluated on 15 freshly proposed datasets. Experimental results demonstrate that COD is better than or comparable with the leading outlier detectors. This manuscript is the accepted author version of a paper published by Elsevier. The final published version is available at https://doi.org/10.1016/j.asoc.2024.112070","authors":["Baiyang Chen","Zhong Yuan","Dezhong Peng","Xiaoliang Chen","Hongmei Chen"],"pdf_url":"","comment":"Author's Accepted Manuscript"},{"id":"http://arxiv.org/abs/2512.18971v1","updated":"2025-12-22T02:34:34Z","published":"2025-12-22T02:34:34Z","title":"On Conditional Stochastic Interpolation for Generative Nonlinear Sufficient Dimension Reduction","summary":"Identifying low-dimensional sufficient structures in nonlinear sufficient dimension reduction (SDR) has long been a fundamental yet challenging problem. Most existing methods lack theoretical guarantees of exhaustiveness in identifying lower dimensional structures, either at the population level or at the sample level. We tackle this issue by proposing a new method, generative sufficient dimension reduction (GenSDR), which leverages modern generative models. We show that GenSDR is able to fully recover the information contained in the central $σ$-field at both the population and sample levels. In particular, at the sample level, we establish a consistency property for the GenSDR estimator from the perspective of conditional distributions, capitalizing on the distributional learning capabilities of deep generative models. Moreover, by incorporating an ensemble technique, we extend GenSDR to accommodate scenarios with non-Euclidean responses, thereby substantially broadening its applicability. Extensive numerical results demonstrate the outstanding empirical performance of GenSDR and highlight its strong potential for addressing a wide range of complex, real-world tasks.","authors":["Shuntuo Xu","Zhou Yu","Jian Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.01457v3","updated":"2025-12-22T02:26:36Z","published":"2025-12-01T09:44:31Z","title":"Zero-Overhead Introspection for Adaptive Test-Time Compute","summary":"Large language models excel at reasoning but lack key aspects of introspection, including anticipating their own success and the computation required to achieve it. Humans use real-time introspection to decide how much effort to invest, when to make multiple attempts, when to stop, and when to signal success or failure. Without this, LLMs struggle to make intelligent meta-cognition decisions. Test-time scaling methods like Best-of-N drive up cost and latency by using a fixed budget of samples regardless of the marginal benefit of each one at any point in generation, and the absence of confidence signals can mislead people, prevent appropriate escalation to better tools, and undermine trustworthiness. Learned verifiers or reward models can provide confidence estimates, but do not enable adaptive inference and add substantial cost by requiring extra models or forward passes. We present ZIP-RC, an adaptive inference method that equips models with zero-overhead inference-time predictions of reward and cost. At every token, ZIP-RC reuses reserved or unused logits in the same forward pass as next-token prediction to output a joint distribution over final reward and remaining length -- no extra models, architecture change, or inference overhead. This full joint distribution is used to compute a sampling utility which is the linear combination of the expected maximum reward, total compute, and latency of set of samples if generated to completion. During inference, we maximize this utility with meta-actions that determine which prefix of tokens to continue or initiate sampling from. On mixed-difficulty mathematical benchmarks, ZIP-RC improves accuracy by up to 12% over majority voting at equal or lower average cost, and traces smooth Pareto frontiers between quality, compute, and latency. By providing real-time reward-cost introspection, ZIP-RC enables adaptive, efficient reasoning.","authors":["Rohin Manvi","Joey Hong","Tim Seyde","Maxime Labonne","Mathias Lechner","Sergey Levine"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.01385v2","updated":"2025-12-22T02:25:29Z","published":"2025-11-03T09:36:11Z","title":"Memory-Efficient Training with In-Place FFT Implementation","summary":"Fast Fourier Transforms (FFT) are widely used to reduce memory and computational costs in deep learning. However, existing implementations, including standard FFT and real FFT (rFFT), cannot achieve true in-place computation. In particular, rFFT maps an input of size n to a complex output of size n/2+1, causing dimensional mismatch and requiring additional memory allocation. We propose the first real-domain, fully in-place FFT framework (rdFFT) that preserves input-output memory space consistency. By leveraging butterfly operation symmetry and conjugate properties in the frequency domain, we design an implicit complex encoding scheme that eliminates intermediate cache usage entirely. Experiments on multiple natural language understanding tasks demonstrate the method effectiveness in reducing training memory cost, offering a promising direction for frequency-domain lightweight adaptation.","authors":["Xinyu Ding","Bangtian Liu","Siyu Liao","Zhongfeng Wang"],"pdf_url":"","comment":"Accepted at NeurIPS 2025. Version 2 adds links to the ongoing PyTorch upstreaming discussion"},{"id":"http://arxiv.org/abs/2512.18965v1","updated":"2025-12-22T02:25:26Z","published":"2025-12-22T02:25:26Z","title":"Lag Operator SSMs: A Geometric Framework for Structured State Space Modeling","summary":"Structured State Space Models (SSMs), which are at the heart of the recently popular Mamba architecture, are powerful tools for sequence modeling. However, their theoretical foundation relies on a complex, multi-stage process of continuous-time modeling and subsequent discretization, which can obscure intuition. We introduce a direct, first-principles framework for constructing discrete-time SSMs that is both flexible and modular. Our approach is based on a novel lag operator, which geometrically derives the discrete-time recurrence by measuring how the system's basis functions \"slide\" and change from one timestep to the next. The resulting state matrices are computed via a single inner product involving this operator, offering a modular design space for creating novel SSMs by flexibly combining different basis functions and time-warping schemes. To validate our approach, we demonstrate that a specific instance exactly recovers the recurrence of the influential HiPPO model. Numerical simulations confirm our derivation, providing new theoretical tools for designing flexible and robust sequence models.","authors":["Sutashu Tomonaga","Kenji Doya","Noboru Murata"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17100v2","updated":"2025-12-22T02:23:31Z","published":"2025-12-18T21:56:08Z","title":"UniCoMTE: A Universal Counterfactual Framework for Explaining Time-Series Classifiers on ECG Data","summary":"Machine learning models, particularly deep neural networks, have demonstrated strong performance in classifying complex time series data. However, their black-box nature limits trust and adoption, especially in high-stakes domains such as healthcare. To address this challenge, we introduce UniCoMTE, a model-agnostic framework for generating counterfactual explanations for multivariate time series classifiers. The framework identifies temporal features that most heavily influence a model's prediction by modifying the input sample and assessing its impact on the model's prediction. UniCoMTE is compatible with a wide range of model architectures and operates directly on raw time series inputs. In this study, we evaluate UniCoMTE's explanations on a time series ECG classifier. We quantify explanation quality by comparing our explanations' comprehensibility to comprehensibility of established techniques (LIME and SHAP) and assessing their generalizability to similar samples. Furthermore, clinical utility is assessed through a questionnaire completed by medical experts who review counterfactual explanations presented alongside original ECG samples. Results show that our approach produces concise, stable, and human-aligned explanations that outperform existing methods in both clarity and applicability. By linking model predictions to meaningful signal patterns, the framework advances the interpretability of deep learning models for real-world time series applications.","authors":["Justin Li","Efe Sencan","Jasper Zheng Duan","Vitus J. Leung","Stephen Tsaur","Ayse K. Coskun"],"pdf_url":"","comment":"21 pages, 7 figures"},{"id":"http://arxiv.org/abs/2512.19936v1","updated":"2025-12-22T23:50:17Z","published":"2025-12-22T23:50:17Z","title":"GIMLET: Generalizable and Interpretable Model Learning through Embedded Thermodynamics","summary":"We develop a data-driven framework for discovering constitutive relations in models of fluid flow and scalar transport. Our approach infers unknown closure terms in the governing equations (gray-box discovery) under the assumption that the temporal derivative, convective transport, and pressure-gradient contributions are known. The formulation is rooted in a variational principle from nonequilibrium thermodynamics, where the dynamics is defined by a free-energy functional and a dissipation functional. The unknown constitutive terms arise as functional derivatives of these functionals with respect to the state variables. To enable a flexible and structured model discovery, the free-energy and dissipation functionals are parameterized using neural networks, while their functional derivatives are obtained via automatic differentiation. This construction enforces thermodynamic consistency by design, ensuring monotonic decay of the total free energy and non-negative entropy production. The resulting method, termed GIMLET (Generalizable and Interpretable Model Learning through Embedded Thermodynamics), avoids reliance on a predefined library of candidate functions, unlike sparse regression or symbolic identification approaches. The learned models are generalizable in that functionals identified from one dataset can be transferred to distinct datasets governed by the same underlying equations. Moreover, the inferred free-energy and dissipation functions provide direct physical interpretability of the learned dynamics. The framework is demonstrated on several benchmark systems, including the viscous Burgers equation, the Kuramoto--Sivashinsky equation, and the incompressible Navier--Stokes equations for both Newtonian and non-Newtonian fluids.","authors":["Suguru Shiratori","Elham Kiyani","Khemraj Shukla","George Em Karniadakis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19935v1","updated":"2025-12-22T23:44:39Z","published":"2025-12-22T23:44:39Z","title":"Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress","summary":"Machine learning models used in financial decision systems operate in nonstationary economic environments, yet adversarial robustness is typically evaluated under static assumptions. This work introduces Conditional Adversarial Fragility, a regime dependent phenomenon in which adversarial vulnerability is systematically amplified during periods of macroeconomic stress. We propose a regime aware evaluation framework for time indexed tabular financial classification tasks that conditions robustness assessment on external indicators of economic stress. Using volatility based regime segmentation as a proxy for macroeconomic conditions, we evaluate model behavior across calm and stress periods while holding model architecture, attack methodology, and evaluation protocols constant. Baseline predictive performance remains comparable across regimes, indicating that economic stress alone does not induce inherent performance degradation. Under adversarial perturbations, however, models operating during stress regimes exhibit substantially greater degradation across predictive accuracy, operational decision thresholds, and risk sensitive outcomes. We further demonstrate that this amplification propagates to increased false negative rates, elevating the risk of missed high risk cases during adverse conditions. To complement numerical robustness metrics, we introduce an interpretive governance layer based on semantic auditing of model explanations using large language models. Together, these results demonstrate that adversarial robustness in financial machine learning is a regime dependent property and motivate stress aware approaches to model risk assessment in high stakes financial deployments.","authors":["Samruddhi Baviskar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19934v1","updated":"2025-12-22T23:42:45Z","published":"2025-12-22T23:42:45Z","title":"Vehicle-centric Perception via Multimodal Structured Pre-training","summary":"Vehicle-centric perception plays a crucial role in many intelligent systems, including large-scale surveillance systems, intelligent transportation, and autonomous driving. Existing approaches lack effective learning of vehicle-related knowledge during pre-training, resulting in poor capability for modeling general vehicle perception representations. To handle this problem, we propose VehicleMAE-V2, a novel vehicle-centric pre-trained large model. By exploring and exploiting vehicle-related multimodal structured priors to guide the masked token reconstruction process, our approach can significantly enhance the model's capability to learn generalizable representations for vehicle-centric perception. Specifically, we design the Symmetry-guided Mask Module (SMM), Contour-guided Representation Module (CRM) and Semantics-guided Representation Module (SRM) to incorporate three kinds of structured priors into token reconstruction including symmetry, contour and semantics of vehicles respectively. SMM utilizes the vehicle symmetry constraints to avoid retaining symmetric patches and can thus select high-quality masked image patches and reduce information redundancy. CRM minimizes the probability distribution divergence between contour features and reconstructed features and can thus preserve holistic vehicle structure information during pixel-level reconstruction. SRM aligns image-text features through contrastive learning and cross-modal distillation to address the feature confusion caused by insufficient semantic understanding during masked reconstruction. To support the pre-training of VehicleMAE-V2, we construct Autobot4M, a large-scale dataset comprising approximately 4 million vehicle images and 12,693 text descriptions. Extensive experiments on five downstream tasks demonstrate the superior performance of VehicleMAE-V2.","authors":["Wentao Wu","Xiao Wang","Chenglong Li","Jin Tang","Bin Luo"],"pdf_url":"","comment":"Journal extension of VehicleMAE (AAAI 2024)"},{"id":"http://arxiv.org/abs/2512.15503v2","updated":"2025-12-22T23:04:16Z","published":"2025-12-17T14:45:33Z","title":"Attention in Motion: Secure Platooning via Transformer-based Misbehavior Detection","summary":"Vehicular platooning promises transformative improvements in transportation efficiency and safety through the coordination of multi-vehicle formations enabled by Vehicle-to-Everything (V2X) communication. However, the distributed nature of platoon coordination creates security vulnerabilities, allowing authenticated vehicles to inject falsified kinematic data, compromise operational stability, and pose a threat to passenger safety. Traditional misbehaviour detection approaches, which rely on plausibility checks and statistical methods, suffer from high False Positive (FP) rates and cannot capture the complex temporal dependencies inherent in multi-vehicle coordination dynamics. We present Attention In Motion (AIMformer), a transformer-based framework specifically tailored for real-time misbehaviour detection in vehicular platoons with edge deployment capabilities. AIMformer leverages multi-head self-attention mechanisms to simultaneously capture intra-vehicle temporal dynamics and inter-vehicle spatial correlations. It incorporates global positional encoding with vehicle-specific temporal offsets to handle join/exit maneuvers. We propose a Precision-Focused Binary Cross-Entropy (PFBCE) loss function that penalizes FPs to meet the requirements of safety-critical vehicular systems. Extensive evaluation across 4 platoon controllers, multiple attack vectors, and diverse mobility scenarios demonstrates superior performance ($\\geq$ 0.93) compared to state-of-the-art baseline architectures. A comprehensive deployment analysis utilizing TensorFlow Lite (TFLite), Open Neural Network Exchange (ONNX), and TensorRT achieves sub-millisecond inference latency, making it suitable for real-time operation on resource-constrained edge platforms. Hence, validating AIMformer is viable for both in-vehicle and roadside infrastructure deployment.","authors":["Konstantinos Kalogiannis","Ahmed Mohamed Hussain","Hexu Li","Panos Papadimitratos"],"pdf_url":"","comment":"16 pages and 10 figures"},{"id":"http://arxiv.org/abs/2512.19927v1","updated":"2025-12-22T23:04:03Z","published":"2025-12-22T23:04:03Z","title":"The Seismic Wavefield Common Task Framework","summary":"Seismology faces fundamental challenges in state forecasting and reconstruction (e.g., earthquake early warning and ground motion prediction) and managing the parametric variability of source locations, mechanisms, and Earth models (e.g., subsurface structure and topography effects). Addressing these with simulations is hindered by their massive scale, both in synthetic data volumes and numerical complexity, while real-data efforts are constrained by models that inadequately reflect the Earth's complexity and by sparse sensor measurements from the field. Recent machine learning (ML) efforts offer promise, but progress is obscured by a lack of proper characterization, fair reporting, and rigorous comparisons. To address this, we introduce a Common Task Framework (CTF) for ML for seismic wavefields, starting with three distinct wavefield datasets. Our CTF features a curated set of datasets at various scales (global, crustal, and local) and task-specific metrics spanning forecasting, reconstruction, and generalization under realistic constraints such as noise and limited data. Inspired by CTFs in fields like natural language processing, this framework provides a structured and rigorous foundation for head-to-head algorithm evaluation. We illustrate the evaluation procedure with scores reported for two of the datasets, showcasing the performance of various methods and foundation models for reconstructing seismic wavefields from both simulated and real-world sensor measurements. The CTF scores reveal the strengths, limitations, and suitability for specific problem classes. Our vision is to replace ad hoc comparisons with standardized evaluations on hidden test sets, raising the bar for rigor and reproducibility in scientific ML.","authors":["Alexey Yermakov","Yue Zhao","Marine Denolle","Yiyu Ni","Philippe M. Wyder","Judah Goldfeder","Stefano Riva","Jan Williams","David Zoro","Amy Sara Rude","Matteo Tomasetto","Joe Germany","Joseph Bakarji","Georg Maierhofer","Miles Cranmer","J. Nathan Kutz"],"pdf_url":"","comment":"35 pages, 7 figures"},{"id":"http://arxiv.org/abs/2512.19920v1","updated":"2025-12-22T22:51:48Z","published":"2025-12-22T22:51:48Z","title":"Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning","summary":"LLM deployment in critical domains is currently impeded by persistent hallucinations--generating plausible but factually incorrect assertions. While scaling laws drove significant improvements in general capabilities, theoretical frameworks suggest hallucination is not merely stochastic error but a predictable statistical consequence of training objectives prioritizing mimicking data distribution over epistemic honesty. Standard RLVR paradigms, utilizing binary reward signals, inadvertently incentivize models as good test-takers rather than honest communicators, encouraging guessing whenever correctness probability exceeds zero. This paper presents an exhaustive investigation into behavioral calibration, which incentivizes models to stochastically admit uncertainty by abstaining when not confident, aligning model behavior with accuracy. Synthesizing recent advances, we propose and evaluate training interventions optimizing strictly proper scoring rules for models to output a calibrated probability of correctness. Our methods enable models to either abstain from producing a complete response or flag individual claims where uncertainty remains. Utilizing Qwen3-4B-Instruct, empirical analysis reveals behavior-calibrated reinforcement learning allows smaller models to surpass frontier models in uncertainty quantification--a transferable meta-skill decouplable from raw predictive accuracy. Trained on math reasoning tasks, our model's log-scale Accuracy-to-Hallucination Ratio gain (0.806) exceeds GPT-5's (0.207) in a challenging in-domain evaluation (BeyondAIME). Moreover, in cross-domain factual QA (SimpleQA), our 4B LLM achieves zero-shot calibration error on par with frontier models including Grok-4 and Gemini-2.5-Pro, even though its factual accuracy is much lower.","authors":["Jiayun Wu","Jiashuo Liu","Zhiyuan Zeng","Tianyang Zhan","Wenhao Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.17085v2","updated":"2025-12-22T22:48:24Z","published":"2025-07-22T23:58:30Z","title":"Deformable Cluster Manipulation via Whole-Arm Policy Learning","summary":"Manipulating clusters of deformable objects presents a substantial challenge with widespread applicability, but requires contact-rich whole-arm interactions. A potential solution must address the limited capacity for realistic model synthesis, high uncertainty in perception, and the lack of efficient spatial abstractions, among others. We propose a novel framework for learning model-free policies integrating two modalities: 3D point clouds and proprioceptive touch indicators, emphasising manipulation with full body contact awareness, going beyond traditional end-effector modes. Our reinforcement learning framework leverages a distributional state representation, aided by kernel mean embeddings, to achieve improved training efficiency and real-time inference. Furthermore, we propose a novel context-agnostic occlusion heuristic to clear deformables from a target region for exposure tasks. We deploy the framework in a power line clearance scenario and observe that the agent generates creative strategies leveraging multiple arm links for de-occlusion. Finally, we perform zero-shot sim-to-real policy transfer, allowing the arm to clear real branches with unknown occlusion patterns, unseen topology, and uncertain dynamics. Website: https://sites.google.com/view/dcmwap/","authors":["Jayadeep Jacob","Wenzheng Zhang","Houston Warren","Paulo Borges","Tirthankar Bandyopadhyay","Fabio Ramos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19913v1","updated":"2025-12-22T22:37:19Z","published":"2025-12-22T22:37:19Z","title":"Quasiprobabilistic Density Ratio Estimation with a Reverse Engineered Classification Loss Function","summary":"We consider a generalization of the classifier-based density-ratio estimation task to a quasiprobabilistic setting where probability densities can be negative. The problem with most loss functions used for this task is that they implicitly define a relationship between the optimal classifier and the target quasiprobabilistic density ratio which is discontinuous or not surjective. We address these problems by introducing a convex loss function that is well-suited for both probabilistic and quasiprobabilistic density ratio estimation. To quantify performance, an extended version of the Sliced-Wasserstein distance is introduced which is compatible with quasiprobability distributions. We demonstrate our approach on a real-world example from particle physics, of di-Higgs production in association with jets via gluon-gluon fusion, and achieve state-of-the-art results.","authors":["Matthew Drnevich","Stephen Jiggins","Kyle Cranmer"],"pdf_url":"","comment":"25 pages, 7 figures"},{"id":"http://arxiv.org/abs/2512.19909v1","updated":"2025-12-22T22:29:57Z","published":"2025-12-22T22:29:57Z","title":"Modeling Non-Ergodic Path Effects Using Conditional Generative Model for Fourier Amplitude Spectra","summary":"Recent developments in non-ergodic ground-motion models (GMMs) explicitly model systematic spatial variations in source, site, and path effects, reducing standard deviation to 30-40% of ergodic models and enabling more accurate site-specific seismic hazard analysis. Current non-ergodic GMMs rely on Gaussian Process (GP) methods with prescribed correlation functions and thus have computational limitations for large-scale predictions. This study proposes a deep-learning approach called Conditional Generative Modeling for Fourier Amplitude Spectra (CGM-FAS) as an alternative to GP-based methods for modeling non-ergodic path effects in Fourier Amplitude Spectra (FAS). CGM-FAS uses a Conditional Variational Autoencoder architecture to learn spatial patterns and interfrequency correlation directly from data by using geographical coordinates of earthquakes and stations as conditional variables. Using San Francisco Bay Area earthquake data, we compare CGM-FAS against a recent GP-based GMM for the region and demonstrate consistent predictions of non-ergodic path effects. Additionally, CGM-FAS offers advantages compared to GP-based approaches in learning spatial patterns without prescribed correlation functions, capturing interfrequency correlations, and enabling rapid predictions, generating maps for 10,000 sites across 1,000 frequencies within 10 seconds using a few GB of memory. CGM-FAS hyperparameters can be tuned to ensure generated path effects exhibit variability consistent with the GP-based empirical GMM. This work demonstrates a promising direction for efficient non-ergodic ground-motion prediction across multiple frequencies and large spatial domains.","authors":["Maxime Lacour","Pu Ren","Rie Nakata","Nori Nakata","Michael Mahoney"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.19779v3","updated":"2025-12-22T22:25:55Z","published":"2025-03-25T15:47:54Z","title":"PyGraph: Robust Compiler Support for CUDA Graphs in PyTorch","summary":"Machine learning (ML) workloads launch hundreds to thousands of short-running GPU kernels per iteration. With GPU compute throughput growing rapidly, CPU-side launch latency of kernels is emerging as a bottleneck. CUDA Graphs promise to address this by replaying a set of kernels with a single dispatch of the graph, removing per-kernel launch costs. However, CUDA Graphs remain surprisingly difficult to deploy correctly and efficiently.\n  We present PyGraph - a compiler framework to maximize the coverage and benefits of CUDA Graphs for ML workloads. It introduces three novel optimizations: it applies automatic code transformations to make ML applications amenable to CUDA Graphs; it eliminates the parameter copy overheads for kernels executing in CUDA Graphs, and it selectively deploys CUDA Graphs guided by a cost-benefit analysis. For 25 ML workloads from TorchBench, HuggingFace, and TIMM, PyGraph more than doubles the benefit from deploying CUDA Graph compared to the most popular and widely used ML compiler, PyTorch2. PyGraph is built atop PyTorch2's compilation framework and requires no programmer intervention.","authors":["Abhishek Ghosh","Ajay Nayak","Ashish Panwar","Arkaprava Basu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2407.04258v2","updated":"2025-12-22T22:17:14Z","published":"2024-07-05T05:08:06Z","title":"Reinforcement Learning for Unsupervised Video Summarization with Reward Generator Training","summary":"This paper presents a novel approach for unsupervised video summarization using reinforcement learning (RL), addressing limitations like unstable adversarial training and reliance on heuristic-based reward functions. The method operates on the principle that reconstruction fidelity serves as a proxy for informativeness, correlating summary quality with reconstruction ability. The summarizer model assigns importance scores to frames to generate the final summary. For training, RL is coupled with a unique reward generation pipeline that incentivizes improved reconstructions. This pipeline uses a generator model to reconstruct the full video from the selected summary frames; the similarity between the original and reconstructed video provides the reward signal. The generator itself is pre-trained self-supervisedly to reconstruct randomly masked frames. This two-stage training process enhances stability compared to adversarial architectures. Experimental results show strong alignment with human judgments and promising F-scores, validating the reconstruction objective.","authors":["Mehryar Abbasi","Hadi Hadizadeh","Parvaneh Saeedi"],"pdf_url":"","comment":"in IEEE Transactions on Circuits and Systems for Video Technology"},{"id":"http://arxiv.org/abs/2512.19905v1","updated":"2025-12-22T22:13:06Z","published":"2025-12-22T22:13:06Z","title":"Demystifying LLM-as-a-Judge: Analytically Tractable Model for Inference-Time Scaling","summary":"Recent developments in large language models have shown advantages in reallocating a notable share of computational resource from training time to inference time. However, the principles behind inference time scaling are not well understood. In this paper, we introduce an analytically tractable model of inference-time scaling: Bayesian linear regression with a reward-weighted sampler, where the reward is determined from a linear model, modeling LLM-as-a-judge scenario. We study this problem in the high-dimensional regime, where the deterministic equivalents dictate a closed-form expression for the posterior predictive mean and variance. We analyze the generalization error when training data are sampled from a teacher model. We draw $k$ inference-time samples and select via softmax at a temperature applied to a quadratic reward. When the reward is not too different from the teacher, the generalization error decreases monotonically with increasing inference time samples $k$. However, the specific reward that optimizes inference-time selection generally differs from the teacher. In contrast, substantial reward misspecification induces a finite optimal $k$ beyond which more sampling can increase the generalization error. For fixed $k$, there exists an optimal sampling temperature. We experimentally verify these facts in large language model inference with an additional large language model as a judge. In the \"best-of-$k$\" limit with the teacher as reward, we theoretically show that the generalization error decays as $Θ(1/k^2)$ and determine the leading coefficient via extreme value theory. These formulas delineate domains where scaling inference-time computation is provably preferable to collecting more data. Finally, we demonstrate that when task difficulty increases, the previously mentioned advantage of inference-time compute degrades.","authors":["Indranil Halder","Cengiz Pehlevan"],"pdf_url":"","comment":"27 pages"},{"id":"http://arxiv.org/abs/2512.19899v1","updated":"2025-12-22T22:05:36Z","published":"2025-12-22T22:05:36Z","title":"Detecting cyberbullying in Spanish texts through deep learning techniques","summary":"Recent recollected data suggests that it is possible to automatically detect events that may negatively affect the most vulnerable parts of our society, by using any communication technology like social networks or messaging applications. This research consolidates and prepares a corpus with Spanish bullying expressions taken from Twitter in order to use them as an input to train a convolutional neuronal network through deep learning techniques. As a result of this training, a predictive model was created, which can identify Spanish cyberbullying expressions such as insults, racism, homophobic attacks, and so on.","authors":["Paúl Cumba-Armijos","Diego Riofrío-Luzcando","Verónica Rodríguez-Arboleda","Joe Carrión-Jumbo"],"pdf_url":"","comment":"Preprint (Author's Original Manuscript, AOM). Published version: https://doi.org/10.1504/IJDMMM.2022.125265"},{"id":"http://arxiv.org/abs/2512.19891v1","updated":"2025-12-22T21:34:29Z","published":"2025-12-22T21:34:29Z","title":"Efficient Learning of Lattice Gauge Theories with Fermions","summary":"We introduce a learning method for recovering action parameters in lattice field theories. Our method is based on the minimization of a convex loss function constructed using the Schwinger-Dyson relations. We show that score matching, a popular learning method, is a special case of our construction of an infinite family of valid loss functions. Importantly, our general Schwinger-Dyson-based construction applies to gauge theories and models with Grassmann-valued fields used to represent dynamical fermions. In particular, we extend our method to realistic lattice field theories including quantum chromodynamics.","authors":["Shreya Shukla","Yukari Yamauchi","Andrey Y. Lokhov","Scott Lawrence","Abhijith Jayakumar"],"pdf_url":"","comment":"12 pages, 2 figures"}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2512.19445v1","updated":"2025-12-22T14:44:05Z","published":"2025-12-22T14:44:05Z","title":"Sensitivity-Aware Mixed-Precision Quantization for ReRAM-based Computing-in-Memory","summary":"Compute-In-Memory (CIM) systems, particularly those utilizing ReRAM and memristive technologies, offer a promising path toward energy-efficient neural network computation. However, conventional quantization and compression techniques often fail to fully optimize performance and efficiency in these architectures. In this work, we present a structured quantization method that combines sensitivity analysis with mixed-precision strategies to enhance weight storage and computational performance on ReRAM-based CIM systems. Our approach improves ReRAM Crossbar utilization, significantly reducing power consumption, latency, and computational load, while maintaining high accuracy. Experimental results show 86.33% accuracy at 70% compression, alongside a 40% reduction in power consumption, demonstrating the method's effectiveness for power-constrained applications.","authors":["Guan-Cheng Chen","Chieh-Lin Tsai","Pei-Hsuan Tsai","Yuan-Hao Chang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19304v1","updated":"2025-12-22T11:48:24Z","published":"2025-12-22T11:48:24Z","title":"Binary Neural Network Implementation for Handwritten Digit Recognition on FPGA","summary":"Binary neural networks provide a promising solution for low-power, high-speed inference by replacing expensive floating-point operations with bitwise logic. This makes them well-suited for deployment on resource-constrained platforms such as FPGAs. In this study, we present a fully custom BNN inference accelerator for handwritten digit recognition, implemented entirely in Verilog without the use of high-level synthesis tools. The design targets the Xilinx Artix-7 FPGA and achieves real-time classification at 80\\,MHz with low power consumption and predictable timing. Simulation results demonstrate 84\\% accuracy on the MNIST test set and highlight the advantages of manual HDL design for transparent, efficient, and flexible BNN deployment in embedded systems. The complete project including training scripts and Verilog source code are available at GitHub repo for reproducibility and future development.","authors":["Emir Devlet Ertörer","Cem Ünsalan"],"pdf_url":"","comment":"13 pages, 1 figure"},{"id":"http://arxiv.org/abs/2512.07004v2","updated":"2025-12-22T10:08:25Z","published":"2025-12-07T21:13:18Z","title":"Accurate Models of NVIDIA Tensor Cores","summary":"Matrix multiplication is a fundamental operation in for both training of neural networks and inference. To accelerate matrix multiplication, Graphical Processing Units (GPUs) provide it implemented in hardware. Due to the increased throughput over the software-based matrix multiplication, the multipliers are increasingly used outside of AI, to accelerate various applications in scientific computing. However, matrix multipliers targeted at AI are at present not compliant with IEEE 754 floating-point arithmetic behaviour, with different vendors offering different numerical features. This leads to non-reproducible results across different generations of GPU architectures, at the matrix multiply-accumulate instruction level. To study numerical characteristics of matrix multipliers-such as rounding behaviour, accumulator width, normalization points, extra carry bits, and others-test vectors are typically constructed. Yet, these vectors may or may not distinguish between different hardware models, and due to limited hardware availability, their reliability across many different platforms remains largely untested. We present software models for emulating the inner product behavior of low- and mixed-precision matrix multipliers in the V100, A100, H100 and B200 data center GPUs in most supported input formats of interest to mixed-precision algorithm developers: 8-, 16-, and 19-bit floating point.","authors":["Faizan A. Khattak","Mantas Mikaitis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.09299v4","updated":"2025-12-22T05:20:11Z","published":"2024-12-12T14:16:50Z","title":"Q-Fly: An Optical Interconnect for Modular Quantum Computers","summary":"Much like classical supercomputers, scaling up quantum computers requires an optical interconnect. However, signal attenuation leads to irreversible qubit loss, making quantum interconnect design guidelines and metrics different from conventional computing. Inspired by the classical Dragonfly topology, we propose a multi-group structure where the group switch routes photons emitted by computational end nodes to the group's shared pool of Bell state analyzers (which conduct the entanglement swapping that creates end-to-end entanglement) or across a low-diameter path to another group. We present a full-stack analysis of system performance, a combination of distributed and centralized protocols, and a resource scheduler that plans qubit placement and communications for large-scale, fault-tolerant systems. We implement a prototype three-node switched interconnect to justify hardware-side scalability and to expose low-level architectural challenges. We create two-hop entanglement with fidelities of 0.6-0.76. Our design emphasizes reducing network hops and optical components to simplify system stabilization while flexibly adjusting optical path lengths. Based on evaluated loss and infidelity budgets, we find that moderate-radix switches enable systems meeting expected near-term needs, and large systems are feasible. Our design is expected to be effective for a variety of quantum computing technologies, including ion traps and neutral atoms.","authors":["Daisuke Sakuma","Tomoki Tsuno","Hikaru Shimizu","Yuki Kurosawa","Monet Tokuyama Friedrich","Kentaro Teramoto","Amin Taherkhani","Andrew Todd","Yosuke Ueno","Michal Hajdušek","Rikizo Ikuta","Rodney Van Meter","Toshihiko Sasaki","Shota Nagayama"],"pdf_url":"","comment":"16 pages, 12 figures, 5 tables"},{"id":"http://arxiv.org/abs/2509.25510v2","updated":"2025-12-22T00:52:16Z","published":"2025-09-29T21:08:23Z","title":"EEsizer: LLM-Based AI Agent for Sizing of Analog and Mixed Signal Circuit","summary":"The design of Analog and Mixed-Signal (AMS) integrated circuits (ICs) often involves significant manual effort, especially during the transistor sizing process. While Machine Learning techniques in Electronic Design Automation (EDA) have shown promise in reducing complexity and minimizing human intervention, they still face challenges such as numerous iterations and a lack of knowledge about AMS circuit design. Recently, Large Language Models (LLMs) have demonstrated significant potential across various fields, showing a certain level of knowledge in circuit design and indicating their potential to automate the transistor sizing process. In this work, we propose EEsizer, an LLM-based AI agent that integrates large language models with circuit simulators and custom data analysis functions, enabling fully automated, closed-loop transistor sizing without relying on external knowledge. By employing prompt engineering and Chain-of-Thought reasoning, the agent iteratively explores design directions, evaluates performance, and refines solutions with minimal human intervention. We first benchmarked 8 LLMs on six basic circuits and selected three high-performing models to optimize a 20-transistor CMOS operational amplifier, targeting multiple performance metrics, including rail-to-rail operation from 180 nm to 90 nm technology nodes. Notably, OpenAI o3 successfully achieved the user-intended target at 90 nm across three different test groups, with a maximum of 20 iterations, demonstrating adaptability and robustness at advanced nodes. To assess design robustness, we manually designed a bias circuit and performed a variation analysis using Gaussian-distributed variations on transistor dimensions and threshold voltages.","authors":["Chang Liu","Danial Chitnis"],"pdf_url":"","comment":null}],"Software Engineering":[{"id":"http://arxiv.org/abs/2306.00029v2","updated":"2025-12-22T18:29:22Z","published":"2023-05-31T05:24:48Z","title":"CodeTF: One-stop Transformer Library for State-of-the-art Code LLMs","summary":"Code intelligence plays a key role in transforming modern software engineering. Recently, deep learning-based models, especially Transformer-based large language models (LLMs), have demonstrated remarkable potential in tackling these tasks by leveraging massive open-source code data and programming language features. However, the development and deployment of such models often require expertise in both machine learning and software engineering, creating a barrier for the model adoption. In this paper, we present CodeTF, an open-source Transformer-based library for state-of-the-art Code LLMs and code intelligence. Following the principles of modular design and extensible framework, we design CodeTF with a unified interface to enable rapid access and development across different types of models, datasets and tasks. Our library supports a collection of pretrained Code LLM models and popular code benchmarks, including a standardized interface to train and serve code LLMs efficiently, and data features such as language-specific parsers and utility functions for extracting code attributes. In this paper, we describe the design principles, the architecture, key modules and components, and compare with other related library tools. Finally, we hope CodeTF is able to bridge the gap between machine learning/generative AI and software engineering, providing a comprehensive open-source solution for developers, researchers, and practitioners.","authors":["Nghi D. Q. Bui","Hung Le","Yue Wang","Junnan Li","Akhilesh Deepak Gotmare","Steven C. H. Hoi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19644v1","updated":"2025-12-22T18:17:54Z","published":"2025-12-22T18:17:54Z","title":"More code, less validation: Risk factors for over-reliance on AI coding tools among scientists","summary":"Programming is essential to modern scientific research, yet most scientists report inadequate training for the software development their work demands. Generative AI tools capable of code generation may support scientific programmers, but user studies indicate risks of over-reliance, particularly among inexperienced users. We surveyed 868 scientists who program, examining adoption patterns, tool preferences, and factors associated with perceived productivity. Adoption is highest among students and less experienced programmers, with variation across fields. Scientific programmers overwhelmingly prefer general-purpose conversational interfaces like ChatGPT over developer-specific tools. Both inexperience and limited use of development practices (like testing, code review, and version control) are associated with greater perceived productivity-but these factors interact, suggesting formal practices may partially compensate for inexperience. The strongest predictor of perceived productivity is the number of lines of generated code typically accepted at once. These findings suggest scientific programmers using generative AI may gauge productivity by code generation rather than validation, raising concerns about research code integrity.","authors":["Gabrielle O'Brien","Alexis Parker","Nasir Eisty","Jeffrey Carver"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.10218v2","updated":"2025-12-22T16:30:01Z","published":"2025-12-11T02:11:06Z","title":"Does SWE-Bench-Verified Test Agent Ability or Model Memory?","summary":"SWE-Bench-Verified, a dataset comprising 500 issues, serves as a de facto benchmark for evaluating various large language models (LLMs) on their ability to resolve GitHub issues. But this benchmark may overlap with model training data. If that is true, scores may reflect training recall, not issue-solving skill. To study this, we test two Claude models that frequently appear in top-performing agents submitted to the benchmark. We ask them to find relevant files using only issue text, and then issue text plus file paths. We then run the same setup on BeetleBox and SWE-rebench. Despite both benchmarks involving popular open-source Python projects, models performed 3 times better on SWE-Bench-Verified. They were also 6 times better at finding edited files, without any additional context about the projects themselves. This gap suggests the models may have seen many SWE-Bench-Verified tasks during training. As a result, scores on this benchmark may not reflect an agent's ability to handle real software issues, yet it continues to be used in ways that can misrepresent progress and lead to choices that favour agents that use certain models over strong agent design. Our setup tests the localization step with minimal context to the extent that the task should be logically impossible to solve. Our results show the risk of relying on older popular benchmarks and support the shift toward newer datasets built with contamination in mind.","authors":["Thanosan Prathifkumar","Noble Saji Mathews","Meiyappan Nagappan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19509v1","updated":"2025-12-22T16:04:56Z","published":"2025-12-22T16:04:56Z","title":"Beyond Language Boundaries: Uncovering Programming Language Families for Code Language Models","summary":"The rapid proliferation of diverse programming languages presents both opportunities and challenges for developing multilingual code LLMs. While existing techniques often train code LLMs by simply aggregating multilingual code data, few explore the deeper relationships between programming languages(PLs) and how such relationships can be utilized to optimize the training and inference of code LLMs. In this work, we investigate 2 fundamental questions: 1) What are the deep linguistic relationships among PLs? and 2) How can these relationships be leveraged to improve multilingual code LLMs? We propose an embedding-based framework to uncover the latent families of PLs. Our approach begins by defining 21 primary linguistic features of programming languages, such as variable definition, control structures, and method declarations, and then employs LLMs to generate feature-aligned code samples across multiple languages. By embedding these semantically parallel code snippets from 19 languages, we construct a similarity matrix and perform hierarchical clustering to uncover inherent language relationships. Our analysis reveals clear hierarchical structures among programming languages. Closely related languages form well-defined clusters (e.g., C, C++, Java, and Swift group together), while Go exhibits as a central language with the highest cross-language similarity. Building on the uncovered language families, we propose three strategies to enhance multilingual LLM training: transfer learning across linguistically related languages, linguistic proximity-guided curriculum learning, and centroid-based intermediary code translation. Experiments on 4 code intelligence tasks demonstrate that our methods significantly improve multilingual LLM performance. This work offers a universal perspective on programming languages and advances more effective strategies for multilingual code LLM training.","authors":["Shangbo Yun","Xiaodong Gu","Jianghong Huang","Beijun Shen"],"pdf_url":"","comment":"Accepted by FSE 2026"},{"id":"http://arxiv.org/abs/2512.19481v1","updated":"2025-12-22T15:32:45Z","published":"2025-12-22T15:32:45Z","title":"A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis","summary":"Understanding source code changes and their impact on other code entities is a crucial skill in software development. However, the analysis of code changes and their impact is often performed manually and therefore is time-consuming. Recent advancements in AI, and in particular large language models (LLMs) show promises to help developers in various code analysis tasks. However, the extent to which this potential can be utilized for understanding code changes and their impact is underexplored. To address this gap, we study the capabilities of GPT-5 and GPT-5-mini to predict the code entities impacted by given source code changes. We construct a dataset containing information about seed-changes, change pairs, and change types for each commit. Existing datasets lack crucial information about seed changes and impacted code entities. Our experiments evaluate the LLMs in two configurations: (1) seed-change information and the parent commit tree and (2) seed-change information, the parent commit tree, and the diff hunk of each seed change. We found that both LLMs perform poorly in the two experiments, whereas GPT-5 outperforms GPT-5-mini. Furthermore, the provision of the diff hunks helps both models to slightly improve their performance.","authors":["Katharina Stengg","Christian Macho","Martin Pinzger"],"pdf_url":"","comment":"6 pages"},{"id":"http://arxiv.org/abs/2512.10713v2","updated":"2025-12-22T12:47:11Z","published":"2025-12-11T14:49:56Z","title":"PACIFIC: a framework for generating benchmarks to check Precise Automatically Checked Instruction Following In Code","summary":"Large Language Model (LLM)-based code assistants have emerged as a powerful application of generative AI, demonstrating impressive capabilities in code generation and comprehension. A key requirement for these systems is their ability to accurately follow user instructions. We present Precise Automatically Checked Instruction Following In Code (PACIFIC), a novel framework designed to automatically generate benchmarks that rigorously assess sequential instruction-following and code dry-running capabilities in LLMs, while allowing control over benchmark difficulty. PACIFIC produces benchmark variants with clearly defined expected outputs, enabling straightforward and reliable evaluation through simple output comparisons. In contrast to existing approaches that often rely on tool usage or agentic behavior, our work isolates and evaluates the LLM's intrinsic ability to reason through code behavior step-by-step without execution (dry running) and to follow instructions. Furthermore, our framework mitigates training data contamination by facilitating effortless generation of novel benchmark variations. We validate our framework by generating a suite of benchmarks spanning a range of difficulty levels and evaluating multiple state-of-the-art LLMs. Our results demonstrate that PACIFIC can produce increasingly challenging benchmarks that effectively differentiate instruction-following and dry running capabilities, even among advanced models. Overall, our framework offers a scalable, contamination-resilient methodology for assessing core competencies of LLMs in code-related tasks.","authors":["Itay Dreyfuss","Antonio Abu Nassar","Samuel Ackerman","Axel Ben David","Eitan Farchi","Rami Katan","Orna Raz","Marcel Zalmanovici"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.04521v2","updated":"2025-12-22T11:48:52Z","published":"2025-03-06T15:08:31Z","title":"Dynamic Pricing for On-Demand DNN Inference in the Edge-AI Market","summary":"The convergence of edge computing and Artificial Intelligence (AI) gives rise to Edge-AI, which enables the deployment of real-time AI applications at the network edge. A key research challenge in Edge-AI is edge inference acceleration, which aims to realize low-latency high-accuracy Deep Neural Network (DNN) inference by offloading partitioned inference tasks from end devices to edge servers. However, existing research has yet to adopt a practical Edge-AI market perspective, which would explore the personalized inference needs of AI users (e.g., inference accuracy, latency, and task complexity), the revenue incentives for AI service providers that offer edge inference services, and multi-stakeholder governance within a market-oriented context. To bridge this gap, we propose an Auction-based Edge Inference Pricing Mechanism (AERIA) for revenue maximization to tackle the multi-dimensional optimization problem of DNN model partition, edge inference pricing, and resource allocation. We develop a multi-exit device-edge synergistic inference scheme for on-demand DNN inference acceleration, and theoretically analyze the auction dynamics amongst the AI service providers, AI users and edge infrastructure provider. Owing to the strategic mechanism design via randomized consensus estimate and cost sharing techniques, the Edge-AI market attains several desirable properties. These include competitiveness in revenue maximization, incentive compatibility, and envy-freeness, which are crucial to maintain the effectiveness, truthfulness, and fairness in auction outcomes. Extensive simulations based on four representative DNN inference workloads demonstrate that AERIA significantly outperforms several state-of-the-art approaches in revenue maximization. This validates the efficacy of AERIA for on-demand DNN inference in the Edge-AI market.","authors":["Songyuan Li","Jia Hu","Geyong Min","Haojun Huang","Jiwei Huang"],"pdf_url":"","comment":"Accepted for publication in IEEE Transactions on Mobile Computing. Index Terms: Edge-AI, DNN Inference Offloading, Resource Management, Dynamic Pricing, Auction Mechanism"},{"id":"http://arxiv.org/abs/2509.06716v2","updated":"2025-12-22T10:17:59Z","published":"2025-09-08T14:11:35Z","title":"Efficiently Ranking Software Variants with Minimal Benchmarks","summary":"Benchmarking is a common practice in software engineering to assess the qualities and performance of software variants, coming from multiple competing systems or from configurations of the same system. Benchmarks are used notably to compare and understand variant performance, fine-tune software, detect regressions, or design new software systems. The execution of benchmarks to get a complete picture of software variants is highly costly in terms of computational resources and time. In this paper, we propose a novel approach for reducing benchmarks while maintaining stable rankings, using test suite optimization techniques. That is, we remove instances from the benchmarks while trying to keep the same rankings of the variants on all tests. Our method, BISection Sampling, BISS, strategically retains the most critical tests and applies a novel divide-and-conquer approach to efficiently sample among relevant remaining tests. We experiment with datasets and use cases from LLM leaderboards, SAT competitions, and configurable systems for performance modeling. Our results show that our method outperforms baselines even when operating on a subset of variants. Using BISS, we reduce the computational cost of the benchmarks on average to 44% and on more than half the benchmarks by up to 99% without loss in ranking stability.","authors":["Théo Matricon","Mathieu Acher","Helge Spieker","Arnaud Gotlieb"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19215v1","updated":"2025-12-22T09:54:52Z","published":"2025-12-22T09:54:52Z","title":"Semantically-Equivalent Transformations-Based Backdoor Attacks against Neural Code Models: Characterization and Mitigation","summary":"Neural code models have been increasingly incorporated into software development processes. However, their susceptibility to backdoor attacks presents a significant security risk. The state-of-the-art understanding focuses on injection-based attacks, which insert anomalous patterns into software code. These attacks can be neutralized by standard sanitization techniques. This status quo may lead to a false sense of security regarding backdoor attacks. In this paper, we introduce a new kind of backdoor attacks, dubbed Semantically-Equivalent Transformation (SET)-based backdoor attacks, which use semantics-preserving low-prevalence code transformations to generate stealthy triggers. We propose a framework to guide the generation of such triggers. Our experiments across five tasks, six languages, and models like CodeBERT, CodeT5, and StarCoder show that SET-based attacks achieve high success rates (often >90%) while preserving model utility. The attack proves highly stealthy, evading state-of-the-art defenses with detection rates on average over 25.13% lower than injection-based counterparts. We evaluate normalization-based countermeasures and find they offer only partial mitigation, confirming the attack's robustness. These results motivate further investigation into scalable defenses tailored to SET-based attacks.","authors":["Junyao Ye","Zhen Li","Xi Tang","Shouhuai Xu","Deqing Zou","Zhongsheng Yuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17280v2","updated":"2025-12-22T09:29:13Z","published":"2025-12-19T06:55:44Z","title":"Sensor Management System (SMS): Open-source software for FAIR sensor metadata management in Earth system sciences","summary":"Deriving reliable conclusions and insights from environmental observational data urgently requires the enrichment with consistent and comprehensive metadata, including time-resolved context such as changing deployments, configurations, and maintenance actions. We have therefore developed the Sensor Management System (SMS), which provides a user-friendly and feature-rich platform for modeling even the most complex sensor systems and managing all sensor-related information across their life cycle. Each entity is described via well-defined terms like Devices, Platforms and Configurations, as well as Sites that are further enhanced with attributes for, e.g., instrument manufacturers, contact information or measured quantities and complemented by a continuous history of system-related actions. By further linking the SMS to sub-sequent systems and services like PID-registration or controlled vocabularies and establishing a community of end-users, the SMS provides the central element of a digital ecosystem, that fosters a more consistent, sustainable and FAIR provision of sensor-related metadata.","authors":["Christof Lorenz","Nils Brinckmann","Jan Bumberger","Marc Hanisch","Tobias Kuhnert","Ulrich Loup","Rubankumar Moorthy","Florian Obsersteiner","David Schäfer","Thomas Schnicke"],"pdf_url":"","comment":"Submitted to SoftwareX"},{"id":"http://arxiv.org/abs/2512.19153v1","updated":"2025-12-22T08:50:21Z","published":"2025-12-22T08:50:21Z","title":"University Rents Enabling Corporate Innovation: Mapping Academic Researcher Coding and Discursive Labour in the R Language Ecosystem","summary":"This article explores the role of unrecognised labour in corporate innovation systems via an analysis of researcher coding and discursive contributions to R, one of the largest statistical software ecosystems. Studies of online platforms typically focus on how platform affordances constrain participants' actions, and profit from their labour. We innovate by connecting the labour performed inside digital platforms to the professional employment of participants. Our case study analyses 8,924 R package repositories on GitHub, examining commits and communications. Our quantitative findings show that researchers, alongside non-affiliated contributors, are the most frequent owners of R package repositories and their most active contributors. Researchers are more likely to hold official roles compared to the average, and to engage in collaborative problem-solving and support work during package development. This means there is, underneath the 'recognised' category of star researchers who transition between academia and industry and secure generous funding, an 'unrecognised' category of researchers who not only create and maintain key statistical infrastructure, but also provide support to industry employees, for no remuneration. Our qualitative findings show how this unrecognised labour affects practitioners. Finally, our analysis of the ideology and practice of free, libre and open source software (FLOSS) shows how this ideology and practice legitimate the use of 'university rents' by Big Tech.","authors":["Xiaolan Cai","Mathieu O'Neil","Stefano Zacchiroli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.14806v4","updated":"2025-12-22T08:18:12Z","published":"2025-12-16T18:51:23Z","title":"Let the Barbarians In: How AI Can Accelerate Systems Performance Research","summary":"Artificial Intelligence (AI) is beginning to transform the research process by automating the discovery of new solutions. This shift depends on the availability of reliable verifiers, which AI-driven approaches require to validate candidate solutions. Research focused on improving systems performance is especially well-suited to this paradigm because system performance problems naturally admit such verifiers: candidates can be implemented in real systems or simulators and evaluated against predefined workloads. We term this iterative cycle of generation, evaluation, and refinement AI-Driven Research for Systems (ADRS). Using several open-source ADRS instances (i.e., OpenEvolve, GEPA, and ShinkaEvolve), we demonstrate across ten case studies (e.g., multi-region cloud scheduling, mixture-of-experts load balancing, LLM-based SQL, transaction scheduling) that ADRS-generated solutions can match or even outperform human state-of-the-art designs. Based on these findings, we outline best practices (e.g., level of prompt specification, amount of feedback, robust evaluation) for effectively using ADRS, and we discuss future research directions and their implications. Although we do not yet have a universal recipe for applying ADRS across all of systems research, we hope our preliminary findings, together with the challenges we identify, offer meaningful guidance for future work as researcher effort shifts increasingly toward problem formulation and strategic oversight.\n  Note: This paper is an extension of our prior work [14]. It adds extensive evaluation across multiple ADRS frameworks and provides deeper analysis and insights into best practices.","authors":["Audrey Cheng","Shu Liu","Melissa Pan","Zhifei Li","Shubham Agarwal","Mert Cemri","Bowen Wang","Alexander Krentsel","Tian Xia","Jongseok Park","Shuo Yang","Jeff Chen","Lakshya Agrawal","Ashwin Naren","Shulu Li","Ruiying Ma","Aditya Desai","Jiarong Xing","Koushik Sen","Matei Zaharia","Ion Stoica"],"pdf_url":"","comment":"arXiv admin note: substantial text overlap with arXiv:2510.06189"},{"id":"http://arxiv.org/abs/2512.19122v1","updated":"2025-12-22T07:53:16Z","published":"2025-12-22T07:53:16Z","title":"BanglaForge: LLM Collaboration with Self-Refinement for Bangla Code Generation","summary":"Bangla is a low-resource language for code generation, lacking large-scale annotated datasets and tools to transform natural language specifications into executable programs. This makes Bangla-to-code generation a challenging task requiring innovative solutions. To address this, we introduce BanglaForge, a novel framework for generating code from Bangla function descriptions. BanglaForge leverages a retrieval-augmented dual-model collaboration paradigm with self-refinement, combining in-context learning, llm-based translation, systematic prompt engineering, and iterative self-refinement based on execution feedback, where a coder generates initial solutions and a reviewer enhances them for robustness. On the BLP-2025 Bangla Code Generation benchmark, BanglaForge achieves a competitive Pass@1 accuracy of 84.00%, demonstrating the effectiveness of retrieval, model collaboration, and self-refinement for low-resource Bangla code generation.","authors":["Mahir Labib Dihan","Sadif Ahmed","Md Nafiu Rahman"],"pdf_url":"","comment":"Accepted at BLP Workshop @ IJCNLP-AACL 2025. Code is available at https://github.com/mahirlabibdihan/BanglaForge"},{"id":"http://arxiv.org/abs/2512.19018v1","updated":"2025-12-22T04:15:24Z","published":"2025-12-22T04:15:24Z","title":"PEAK: A Performance Engineering AI-Assistant for GPU Kernels Powered by Natural Language Transformations","summary":"Advancements in large language models (LLMs) are showing promising impact in software development and programming assistance. However, these models struggle when operating on low-level backend code. This challenge is exacerbated in the domain of GPU kernels, where performance-critical details are coupled to rapidly evolving hardware characteristics and available code examples are sparse.\n  In this work, we introduce PEAK, a Performance Engineering AI-Assistant for GPU Kernels powered by natural language transformations. PEAK utilizes the key insight that iterative code transformations (optimizations) can straightforwardly be written in natural language, and then carried out by LLMs. Thus, these transformations can be rapidly developed, encoding general portable optimizations, but also easily specialized to specific GPU devices and even kernels. These natural transformations are supported by a modular and extensible infrastructure that additionally performs validation and performance evaluation. We demonstrate the flexibility of PEAK by instantiating it for three backends, CUDA, HIP, and HLSL, and create 16 natural transformations for optimizing matrix multiplication kernels. We show that our resulting implementations are competitive with vendor libraries when available, and for HLSL (without a library) our implementations match the hardware documented FLOPS. PEAK allows the fine-grained exploration of several research questions around how LLMs behave in this domain, including characterizing transformations and their errors; and how performance evolves along optimization sequences. PEAK provides an interface that can either be utilized by performance engineers to improve productivity, or driven completely autonomously (e.g., by an AI agent), providing a forward-compatible design that can continue to improve with advances in AI capabilities.","authors":["Muhammad Usman Tariq","Abhinav Jangda","Angelica Moreira","Madan Musuvathi","Tyler Sorensen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18996v1","updated":"2025-12-22T03:24:11Z","published":"2025-12-22T03:24:11Z","title":"Modular Layout Synthesis (MLS): Front-end Code via Structure Normalization and Constrained Generation","summary":"Automated front-end engineering drastically reduces development cycles and minimizes manual coding overhead. While Generative AI has shown promise in translating designs to code, current solutions often produce monolithic scripts, failing to natively support modern ecosystems like React, Vue, or Angular. Furthermore, the generated code frequently suffers from poor modularity, making it difficult to maintain. To bridge this gap, we introduce Modular Layout Synthesis (MLS), a hierarchical framework that merges visual understanding with structural normalization. Initially, a visual-semantic encoder maps the screen capture into a serialized tree topology, capturing the essential layout hierarchy. Instead of simple parsing, we apply heuristic deduplication and pattern recognition to isolate reusable blocks, creating a framework-agnostic schema. Finally, a constraint-based generation protocol guides the LLM to synthesize production-ready code with strict typing and component props. Evaluations show that MLS significantly outperforms existing baselines, ensuring superior code reusability and structural integrity across multiple frameworks","authors":["Chong Liu","Ming Zhang","Fei Li","Hao Zhou","Xiaoshuang Chen","Ye Yuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2403.15676v5","updated":"2025-12-22T02:52:50Z","published":"2024-03-23T01:44:57Z","title":"AC4: Algebraic Computation Checker for Circuit Constraints in ZKPs","summary":"Zero-knowledge proof (ZKP) systems have surged attention and held a fundamental role in contemporary cryptography. Zero-knowledge succinct non-interactive argument of knowledge (zk-SNARK) protocols dominate the ZKP usage, implemented through arithmetic circuit programming paradigm. However, underconstrained or overconstrained circuits may lead to bugs. The former refers to circuits that lack the necessary constraints, resulting in unexpected solutions and causing the verifier to accept a bogus witness, and the latter refers to circuits that are constrained excessively, resulting in lacking necessary solutions and causing the verifier to accept no witness. This paper introduces a novel approach for pinpointing two distinct types of bugs in ZKP circuits. The method involves encoding the arithmetic circuit constraints to polynomial equation systems and solving them over finite fields by the computer algebra system. The classification of verification results is refined, greatly enhancing the expressive power of the system. A tool, AC4, is proposed to represent the implementation of the method. Experiments show that AC4 demonstrates a increase in the solved rate, showing a 29% improvement over Picus and CIVER, and a slight improvement over halo2-analyzer, a checker for halo2 circuits. Within a solvable range, the checking time has also exhibited noticeable improvement, demonstrating a magnitude increase compared to previous efforts.","authors":["Qizhe Yang","Boxuan Liang","Hao Chen","Guoqiang Li"],"pdf_url":"","comment":"26 pages, 5 figures"},{"id":"http://arxiv.org/abs/2512.18966v1","updated":"2025-12-22T02:26:11Z","published":"2025-12-22T02:26:11Z","title":"Scrum Sprint Planning: LLM-based and algorithmic solutions","summary":"Planning for an upcoming project iteration (sprint) is one of the key activities in Scrum planning. In this paper, we present our work in progress on exploring the applicability of Large Language Models (LLMs) for solving this problem. We conducted case studies with manually created data sets to investigate the applicability of OpenAI models for supporting the sprint planning activities. In our experiments, we applied three models provided OpenAI: GPT-3.5 Turbo, GPT-4.0 Turbo, and Val. The experiments demonstrated that the results produced by the models aren't of acceptable quality for direct use in Scrum projects.","authors":["Yuwon Yoon","Kevin Iwan","Madeleine Zwart","Xiaohan Qin","Hina Lee","Maria Spichkova"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.04994v3","updated":"2025-12-22T01:23:57Z","published":"2024-05-08T11:58:55Z","title":"SPVR: syntax-to-prompt vulnerability repair based on large language models","summary":"Purpose: In the field of vulnerability repair, previous research has leveraged pretrained models and LLM-based prompt engineering, among which LLM-based approaches show better generalizability and achieve the best performance. However, the LLM-based approaches generally regard vulnerability repair as a sequence-to-sequence task, and do not explicitly capture the syntax patterns for different vulnerability types, leading to limited accuracy. We aim to create a method that ensures the specificity of prompts targeting vulnerable code while also leveraging the generative capabilities of Large Language Models. Methods: We propose SPVR (Syntax-to-Prompt Vulnerability Repair), a novel framework that collects information from syntax trees, and generates corresponding prompts. Our method consists of three steps: rule design, prompt generation, and patch generation. In the rule design step, our method parses code patches and designs rules to extract relevant contextual information. These rules aid in identifying vulnerability-related issues. In the prompt generation step, our method extracts information from vulnerable code with pre-defined rules, automatically converting them into prompts. We also incorporate the description of CWE (Common Weakness Enumeration) as known information into the prompts. Finally, in the patch generation step, this prompt will serve as input to any conversational LLM to obtain code patches. Results: Extensive experiments validate that our method achieves excellent results in assisting LLMs to fix vulnerabilities accurately. We utilize multiple Large Language Models to validate the effectiveness of our work, repairing 143 of 547 vulnerable code using ChatGPT-4. We conducted a comparison of our approach against several existing vulnerability repair approaches (including fine-tuning-based and prompt-based), across multiple metrics.","authors":["Ruoke Wang","Zongjie Li","Cuiyun Gao","Chaozheng Wang","Yang Xiao","Xuan Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18940v1","updated":"2025-12-22T01:19:50Z","published":"2025-12-22T01:19:50Z","title":"FASTRIC: Prompt Specification Language for Verifiable LLM Interactions","summary":"Large Language Models (LLMs) execute complex multi-turn interaction protocols but lack formal specifications to verify execution against designer intent. We introduce FASTRIC, a Prompt Specification Language that makes implicit Finite State Machines (FSMs) explicit in natural language prompts, enabling conformance verification through execution trace analysis. The LLM serves as intelligent execution agent: interpreting designer-encoded FSMs to execute specified behavioral roles. Unlike symbolic specification languages requiring parsers and compilers, FASTRIC leverages LLMs as unified infrastructure-simultaneously parser, interpreter, runtime environment, and development assistant. FASTRIC guides designers to articulate seven FSM elements (Final States, Agents, States, Triggers, Roles, Initial State, Constraints) structuring multi-turn interactions. Specification formality-ranging from implicit descriptions that frontier models infer to explicit step-by-step instructions for weaker models-serves as a design parameter. We introduce procedural conformance as verification metric measuring execution adherence to FSM specifications. Testing a 3-state kindergarten tutoring FSM across four formality levels and three model scales (14.7B, 685B, 1T+ parameters) reveals optimal specification formality is a function of model capacity. DeepSeek-V3.2 (685B) achieves perfect conformance (1.00) at L2-L4; ChatGPT-5 (~1T) peaks at L3 (0.90) before collapsing at L4 (0.39); Phi4 (14.7B) shows no stable optimum with high variance (SD=0.16-0.36). These findings reveal model-specific formality ranges-\"Goldilocks zones\"-where specifications provide sufficient structure without over-constraint, establishing Prompt Specification Engineering for creating verifiable interaction protocols, transforming multi-turn interaction design from heuristic art to systematic engineering with measurable procedural guarantees.","authors":["Wen-Long Jin"],"pdf_url":"","comment":"13 pages, 3 figures. Supplementary materials at https://doi.org/10.17605/OSF.IO/PV6R3"},{"id":"http://arxiv.org/abs/2409.01382v2","updated":"2025-12-22T01:18:44Z","published":"2024-09-02T17:25:15Z","title":"Automatic Detection of LLM-Generated Code: A Comparative Case Study of Contemporary Models Across Function and Class Granularities","summary":"The adoption of Large Language Models (LLMs) for code generation risks incorporating vulnerable code into software systems. Existing detectors face two critical limitations: a lack of systematic cross-model validation and opaque \"black box\" operation. We address this through a comparative study of code generated by four distinct LLMs: GPT-3.5, Claude 3 Haiku, Claude Haiku 4.5, and GPT-OSS.\n  Analyzing 14,485 Python functions and 11,913 classes from the CodeSearchNet dataset, we generated corresponding code with all four LLMs. Using interpretable software metrics, we trained CatBoost classifiers for each configuration. Our analysis reveals that granularity effects dominate model differences by a factor of 8.6, with negligible feature overlap, indicating that function-level and class-level detection rely on fundamentally disjoint structural signatures.\n  We discover critical granularity-dependent inversions: while modern models (Claude, GPT-OSS) are more detectable at the class level, GPT-3.5 is an anomaly that uniquely excels at the function level. SHAP analysis identifies the Comment-to-Code Ratio as the sole universal discriminator. However, its predictive magnitude varies drastically across models, explaining why detectors trained on specific LLMs fail to generalize.\n  Our findings demonstrate that GPT-3.5's exceptional detectability (AUC-ROC 0.96) is unrepresentative of contemporary models (AUC-ROC approximately between 0.68 and 0.80). Robust detection requires moving beyond single-model studies to account for substantial diversity in structural fingerprints across architectures and granularities.","authors":["Musfiqur Rahman","SayedHassan Khatoonabadi","Ahmad Abdellatif","Emad Shihab"],"pdf_url":"","comment":"Submitted to a journal for potential publication"},{"id":"http://arxiv.org/abs/2512.19883v1","updated":"2025-12-22T21:17:31Z","published":"2025-12-22T21:17:31Z","title":"Larger Is Not Always Better: Leveraging Structured Code Diffs for Comment Inconsistency Detection","summary":"Ensuring semantic consistency between source code and its accompanying comments is crucial for program comprehension, effective debugging, and long-term maintainability. Comment inconsistency arises when developers modify code but neglect to update the corresponding comments, potentially misleading future maintainers and introducing errors. Recent approaches to code-comment inconsistency (CCI) detection leverage Large Language Models (LLMs) and rely on capturing the semantic relationship between code changes and outdated comments. However, they often ignore the structural complexity of code evolution, including historical change activities, and introduce privacy and resource challenges. In this paper, we propose a Just-In-Time CCI detection approach built upon the CodeT5+ backbone. Our method decomposes code changes into ordered sequences of modification activities such as replacing, deleting, and adding to more effectively capture the correlation between these changes and the corresponding outdated comments. Extensive experiments conducted on publicly available benchmark datasets-JITDATA and CCIBENCH--demonstrate that our proposed approach outperforms recent state-of-the-art models by up to 13.54% in F1-Score and achieves an improvement ranging from 4.18% to 10.94% over fine-tuned LLMs including DeepSeek-Coder, CodeLlama and Qwen2.5-Coder.","authors":["Phong Nguyen","Anh M. T. Bui","Phuong T. Nguyen"],"pdf_url":"","comment":"This paper has been reviewed and accepted to the Short Papers and Posters Track of SANER 2026"},{"id":"http://arxiv.org/abs/2503.12511v3","updated":"2025-12-22T20:28:48Z","published":"2025-03-16T14:05:26Z","title":"SACTOR: LLM-Driven Correct and Idiomatic C to Rust Translation with Static Analysis and FFI-Based Verification","summary":"Translating software written in C to Rust has significant benefits in improving memory safety. However, manual translation is cumbersome, error-prone, and often produces unidiomatic code. Large language models (LLMs) have demonstrated promise in producing idiomatic translations, but offer no correctness guarantees. We propose SACTOR, an LLM-driven C-to-Rust translation tool that employs a two-step process: an initial \"unidiomatic\" translation to preserve semantics, followed by an \"idiomatic\" refinement to align with Rust standards. To validate correctness of our function-wise incremental translation that mixes C and Rust, we use end-to-end testing via the foreign function interface. We evaluate SACTOR on 200 programs from two public datasets and on two more real-world scenarios (a 50-sample subset of CRust-Bench and the libogg library), comparing multiple LLMs. Across datasets, SACTOR delivers high end-to-end correctness and produces safe, idiomatic Rust with up to 7 times fewer Clippy warnings; On CRust-Bench, SACTOR achieves an average (across samples) of 85% unidiomatic and 52% idiomatic success, and on libogg it attains full unidiomatic and up to 78% idiomatic coverage on GPT-5.","authors":["Tianyang Zhou","Ziyi Zhang","Haowen Lin","Somesh Jha","Mihai Christodorescu","Kirill Levchenko","Varun Chandrasekaran"],"pdf_url":"","comment":"35 pages, 15 figures Previously named as \"LLM-Driven Multi-step Translation from C to Rust using Static Analysis\""},{"id":"http://arxiv.org/abs/2410.03795v3","updated":"2025-12-22T19:06:41Z","published":"2024-10-04T02:50:58Z","title":"Deep Learning and Machine Learning: Advancing Big Data Analytics and Management with Design Patterns","summary":"This book, Design Patterns in Machine Learning and Deep Learning: Advancing Big Data Analytics Management, presents a comprehensive study of essential design patterns tailored for large-scale machine learning and deep learning applications. The book explores the application of classical software engineering patterns, Creational, Structural, Behavioral, and Concurrency Patterns, to optimize the development, maintenance, and scalability of big data analytics systems. Through practical examples and detailed Python implementations, it bridges the gap between traditional object-oriented design patterns and the unique demands of modern data analytics environments. Key design patterns such as Singleton, Factory, Observer, and Strategy are analyzed for their impact on model management, deployment strategies, and team collaboration, providing invaluable insights into the engineering of efficient, reusable, and flexible systems. This volume is an essential resource for developers, researchers, and engineers aiming to enhance their technical expertise in both machine learning and software design.","authors":["Keyu Chen","Ziqian Bi","Tianyang Wang","Yizhu Wen","Pohsun Feng","Qian Niu","Junyu Liu","Benji Peng","Sen Zhang","Ming Li","Xuanhe Pan","Jiawei Xu","Jinlang Wang","Xinyuan Song","Ming Liu"],"pdf_url":"","comment":"138pages"},{"id":"http://arxiv.org/abs/2409.19916v5","updated":"2025-12-22T18:59:31Z","published":"2024-09-30T03:37:10Z","title":"Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Object-Oriented Programming","summary":"Object-Oriented Programming (OOP) has become a crucial paradigm for managing the growing complexity of modern software systems, particularly in fields like machine learning, deep learning, large language models (LLM), and data analytics. This work provides a comprehensive introduction to the integration of OOP techniques within these domains, with a focus on improving code modularity, maintainability, and scalability. We begin by outlining the evolution of computing and the rise of OOP, followed by an in-depth discussion of key OOP principles such as encapsulation, inheritance, polymorphism, and abstraction. The practical application of these principles is demonstrated using Python, a widely adopted language in AI and data science. Furthermore, we examine how design patterns and modular programming can be employed to enhance the structure and efficiency of machine learning systems. In subsequent sections, we apply these OOP concepts to real-world AI tasks, including the encapsulation of preprocessing workflows, machine learning model training, and evaluation. Detailed examples illustrate how OOP can be used to build reusable, scalable machine learning systems while maintaining code clarity and reducing redundancy.This work is intended to serve as a bridge for both beginners and experienced developers, equipping them with the necessary knowledge to apply OOP methodologies in AI-driven projects, ultimately fostering the development of more robust and maintainable systems.","authors":["Tianyang Wang","Ziqian Bi","Keyu Chen","Jiawei Xu","Qian Niu","Junyu Liu","Benji Peng","Ming Li","Sen Zhang","Xuanhe Pan","Jinlang Wang","Pohsun Feng","Yizhu Wen","Xinyuan Song","Ming Liu"],"pdf_url":"","comment":"49pages"},{"id":"http://arxiv.org/abs/2512.19769v1","updated":"2025-12-22T05:03:37Z","published":"2025-12-22T05:03:37Z","title":"A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows","summary":"Building deployment-ready LLM agents requires complex orchestration of tools, data sources, and control flow logic, yet existing systems tightly couple agent logic to specific programming languages and deployment models. We present a declarative system that separates agent workflow specification from implementation, enabling the same pipeline definition to execute across multiple backend languages (Java, Python, Go) and deployment environments (cloud-native, on-premises).\n  Our key insight is that most agent workflows consist of common patterns -- data serialization, filtering, RAG retrieval, API orchestration -- that can be expressed through a unified DSL rather than imperative code. This approach transforms agent development from application programming to configuration, where adding new tools or fine-tuning agent behaviors requires only pipeline specification changes, not code deployment. Our system natively supports A/B testing of agent strategies, allowing multiple pipeline variants to run on the same backend infrastructure with automatic metric collection and comparison.\n  We evaluate our approach on real-world e-commerce workflows at PayPal, processing millions of daily interactions. Our results demonstrate 60% reduction in development time, and 3x improvement in deployment velocity compared to imperative implementations. The language's declarative approach enables non-engineers to modify agent behaviors safely, while maintaining sub-100ms orchestration overhead. We show that complex workflows involving product search, personalization, and cart management can be expressed in under 50 lines of DSL compared to 500+ lines of imperative code.","authors":["Ivan Daunis"],"pdf_url":"","comment":null}],"Performance":[{"id":"http://arxiv.org/abs/2506.04049v2","updated":"2025-12-22T18:19:18Z","published":"2025-06-04T15:15:23Z","title":"WANDER: An Explainable Decision-Support Framework for HPC","summary":"High-performance computing (HPC) systems expose many interdependent configuration knobs that impact runtime, resource usage, power, and variability. Existing predictive tools model these outcomes, but do not support structured exploration, explanation, or guided reconfiguration. We present WANDER, a decision-support framework that synthesizes alternate configurations using counterfactual analysis aligned with user goals and constraints. We introduce a composite trade-off score that ranks suggestions based on prediction uncertainty, consistency between feature-target relationships using causal models, and similarity between feature distributions against historical data. To our knowledge, WANDER is the first such system to unify prediction, exploration, and explanation for HPC tuning under a common query interface. Across multiple datasets WANDER generates interpretable and trustworthy, human-readable alternatives that guide users to achieve their performance objectives.","authors":["Ankur Lahiry","Banooqa Banday","Tanzima Z. Islam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19606v1","updated":"2025-12-22T17:42:51Z","published":"2025-12-22T17:42:51Z","title":"RAPID-LLM: Resilience-Aware Performance analysis of Infrastructure for Distributed LLM Training and Inference","summary":"RAPID-LLM is a unified performance modeling framework for large language model (LLM) training and inference on GPU clusters. It couples a DeepFlow-based frontend that generates hardware-aware, operator-level Chakra execution traces from an abstract LLM specification (model shape, batch/sequence settings, training vs. inference, and hybrid parallelism choices) with an extended Astra-Sim backend that executes those traces on explicit multi-dimensional network topologies with congestion-aware routing and support for degraded and faulty links. The frontend assigns per-operator latency using a tile-based model that accounts for SM under-utilization and multi-level memory traffic (SRAM/ L2/ HBM), and prunes memory-infeasible configurations using an activation-liveness traversal under recomputation, parallelism and ZeRO/FDSP sharding policies.\n  Across A100-based validation cases, RAPID-LLM predicts Llama inference step latency and GPT-scale training time per batch within 10.4\\% relative to published measurements, and matches ns-3 packet-level results within 8\\% on representative communication workloads. Case studies demonstrate how RAPID-LLM enables fast, exhaustive sweeps over hybrid-parallel configurations, quantifies sensitivity to soft link faults under realistic routing and congestion, and evaluates hypothetical GPU design variants including HBM bandwidth throttling effects.","authors":["George Karfakis","Faraz Tahmasebi","Binglu Chen","Lime Yao","Saptarshi Mitra","Tianyue Pan","Hyoukjun Kwon","Puneet Gupta"],"pdf_url":"","comment":"11 pages, 12 figures"},{"id":"http://arxiv.org/abs/2509.06716v2","updated":"2025-12-22T10:17:59Z","published":"2025-09-08T14:11:35Z","title":"Efficiently Ranking Software Variants with Minimal Benchmarks","summary":"Benchmarking is a common practice in software engineering to assess the qualities and performance of software variants, coming from multiple competing systems or from configurations of the same system. Benchmarks are used notably to compare and understand variant performance, fine-tune software, detect regressions, or design new software systems. The execution of benchmarks to get a complete picture of software variants is highly costly in terms of computational resources and time. In this paper, we propose a novel approach for reducing benchmarks while maintaining stable rankings, using test suite optimization techniques. That is, we remove instances from the benchmarks while trying to keep the same rankings of the variants on all tests. Our method, BISection Sampling, BISS, strategically retains the most critical tests and applies a novel divide-and-conquer approach to efficiently sample among relevant remaining tests. We experiment with datasets and use cases from LLM leaderboards, SAT competitions, and configurable systems for performance modeling. Our results show that our method outperforms baselines even when operating on a subset of variants. Using BISS, we reduce the computational cost of the benchmarks on average to 44% and on more than half the benchmarks by up to 99% without loss in ranking stability.","authors":["Théo Matricon","Mathieu Acher","Helge Spieker","Arnaud Gotlieb"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.22714v2","updated":"2025-12-22T05:47:00Z","published":"2025-06-28T01:50:13Z","title":"Libra: Unleashing GPU Heterogeneity for High-Performance Sparse Matrix Multiplication","summary":"Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely used in deep learning and scientific computing. Modern accelerators are commonly equipped with Tensor Core Units (TCUs) and CUDA cores to accelerate sparse operators. The former excels at structured matrix computations, whereas the latter offers greater programming flexibility. However, how to combine these two resources to maximize sparse-operator performance remains unclear. In this work, we first identify the source of performance gains in hybrid computation and systematically analyze their complementary strengths. Motivated by this, we propose Libra, a holistic framework that efficiently leverages heterogeneous computing resources to accelerate both SpMM and SDDMM operators. Specifically, Libra introduces a 2D-aware (locality and utilization) workload distribution method to precisely identify the optimal task mapping, simultaneously leveraging the data reuse capabilities of TCUs and the flexibility of CUDA cores to minimize computational redundancy. Libra further incorporates hybrid load balancing, occupancy-aware task scheduling, and efficient kernel implementations to maximize execution efficiency. Extensive experiments on H100 and RTX 4090 GPUs demonstrate that Libra surpasses all the 12 up-to-date baselines significantly, e.g., on average 1.77x speedup over FlashSparse, 1.73x over RoDe, and 2.9x over DGL for end-to-end GNN applications. Libra opens up a new perspective for sparse operator acceleration by fully unleashing the power of heterogeneous GPU resources.","authors":["Jinliang Shi","Shigang Li","Youxuan Xu","Xueying Wang","Rongtian Fu","Zhi Ma","Tong Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.23410v3","updated":"2025-12-22T19:09:57Z","published":"2025-09-27T16:57:28Z","title":"PATCH: Learnable Tile-level Hybrid Sparsity for LLMs","summary":"Large language models (LLMs) deliver impressive performance but incur prohibitive memory and compute costs at deployment. Model pruning is an effective way to reduce these overheads, yet existing approaches face challenges: unstructured sparsity, where nonzeros can appear anywhere, preserves accuracy but yields irregular access patterns that prevent GPU acceleration, while semi-structured 2:4 sparsity is hardware-friendly but enforces a rigid 50% pattern that degrades model quality. To bridge this gap, we introduce PATCH, a hybrid sparsity framework that enables a continuous sparsity ratio between 0% and 50%. PATCH partitions weight matrices into tiles, assigning each tile to be either dense or 2:4 sparse via a learnable mask selection mechanism. This design provides fine-grained control over accuracy-acceleration tradeoffs and supports non-uniform sparsity across layers, leading to superior overall quality. Across models from 0.5B to 8B parameters, PATCH consistently narrows the gap to dense accuracy while delivering practical speedups. For instance, on LLaMA-2 7B with an A6000 GPU, PATCH achieves 1.18x-1.38x end-to-end speedup over dense baselines while improving accuracy by 0.37%-2.96% compared to the state-of-the-art 2:4 pruning method, MaskLLM.","authors":["Younes Hourri","Mohammad Mozaffari","Maryam Mehri Dehnavi"],"pdf_url":"","comment":null}],"Programming Languages":[{"id":"http://arxiv.org/abs/2512.19250v1","updated":"2025-12-22T10:34:45Z","published":"2025-12-22T10:34:45Z","title":"Small Language Models as Compiler Experts: Auto-Parallelization for Heterogeneous Systems","summary":"Traditional auto-parallelizing compilers, reliant on rigid heuristics, struggle with the complexity of modern heterogeneous systems. This paper presents a comprehensive evaluation of small (approximately 1B parameter) language-model-driven compiler auto-parallelization. We evaluate three models: gemma3, llama3.2, and qwen2.5, using six reasoning strategies across 11 real-world kernels drawn from scientific computing, graph algorithms, and machine learning. Our system is benchmarked against strong compiler baselines, including LLVM Polly, TVM, and Triton. Across 376 total evaluations, the proposed approach achieves an average speedup of 6.81x and a peak performance of 43.25x on convolution operations. We analyze scalability, verify correctness using multiple sanitizers, and confirm robustness across diverse compilers and hardware platforms. Our results demonstrate that small, efficient language models can serve as powerful reasoning engines for complex compiler optimization tasks.","authors":["Prathamesh Devadiga"],"pdf_url":"","comment":"Accepted at NeurIPS 2025 ML for Systems Workshop"},{"id":"http://arxiv.org/abs/2503.12511v3","updated":"2025-12-22T20:28:48Z","published":"2025-03-16T14:05:26Z","title":"SACTOR: LLM-Driven Correct and Idiomatic C to Rust Translation with Static Analysis and FFI-Based Verification","summary":"Translating software written in C to Rust has significant benefits in improving memory safety. However, manual translation is cumbersome, error-prone, and often produces unidiomatic code. Large language models (LLMs) have demonstrated promise in producing idiomatic translations, but offer no correctness guarantees. We propose SACTOR, an LLM-driven C-to-Rust translation tool that employs a two-step process: an initial \"unidiomatic\" translation to preserve semantics, followed by an \"idiomatic\" refinement to align with Rust standards. To validate correctness of our function-wise incremental translation that mixes C and Rust, we use end-to-end testing via the foreign function interface. We evaluate SACTOR on 200 programs from two public datasets and on two more real-world scenarios (a 50-sample subset of CRust-Bench and the libogg library), comparing multiple LLMs. Across datasets, SACTOR delivers high end-to-end correctness and produces safe, idiomatic Rust with up to 7 times fewer Clippy warnings; On CRust-Bench, SACTOR achieves an average (across samples) of 85% unidiomatic and 52% idiomatic success, and on libogg it attains full unidiomatic and up to 78% idiomatic coverage on GPT-5.","authors":["Tianyang Zhou","Ziyi Zhang","Haowen Lin","Somesh Jha","Mihai Christodorescu","Kirill Levchenko","Varun Chandrasekaran"],"pdf_url":"","comment":"35 pages, 15 figures Previously named as \"LLM-Driven Multi-step Translation from C to Rust using Static Analysis\""},{"id":"http://arxiv.org/abs/2410.19849v2","updated":"2025-12-22T19:10:13Z","published":"2024-10-22T06:55:53Z","title":"Deep Learning and Machine Learning -- Python Data Structures and Mathematics Fundamental: From Theory to Practice","summary":"This book provides a comprehensive introduction to the foundational concepts of machine learning (ML) and deep learning (DL). It bridges the gap between theoretical mathematics and practical application, focusing on Python as the primary programming language for implementing key algorithms and data structures. The book covers a wide range of topics, including basic and advanced Python programming, fundamental mathematical operations, matrix operations, linear algebra, and optimization techniques crucial for training ML and DL models. Advanced subjects like neural networks, optimization algorithms, and frequency domain methods are also explored, along with real-world applications of large language models (LLMs) and artificial intelligence (AI) in big data management. Designed for both beginners and advanced learners, the book emphasizes the critical role of mathematical principles in developing scalable AI solutions. Practical examples and Python code are provided throughout, ensuring readers gain hands-on experience in applying theoretical knowledge to solve complex problems in ML, DL, and big data analytics.","authors":["Silin Chen","Ziqian Bi","Junyu Liu","Benji Peng","Sen Zhang","Xuanhe Pan","Jiawei Xu","Jinlang Wang","Keyu Chen","Caitlyn Heqi Yin","Pohsun Feng","Yizhu Wen","Tianyang Wang","Ming Li","Jintao Ren","Qian Niu","Xinyuan Song","Ming Liu"],"pdf_url":"","comment":"298 pages"},{"id":"http://arxiv.org/abs/2512.19769v1","updated":"2025-12-22T05:03:37Z","published":"2025-12-22T05:03:37Z","title":"A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows","summary":"Building deployment-ready LLM agents requires complex orchestration of tools, data sources, and control flow logic, yet existing systems tightly couple agent logic to specific programming languages and deployment models. We present a declarative system that separates agent workflow specification from implementation, enabling the same pipeline definition to execute across multiple backend languages (Java, Python, Go) and deployment environments (cloud-native, on-premises).\n  Our key insight is that most agent workflows consist of common patterns -- data serialization, filtering, RAG retrieval, API orchestration -- that can be expressed through a unified DSL rather than imperative code. This approach transforms agent development from application programming to configuration, where adding new tools or fine-tuning agent behaviors requires only pipeline specification changes, not code deployment. Our system natively supports A/B testing of agent strategies, allowing multiple pipeline variants to run on the same backend infrastructure with automatic metric collection and comparison.\n  We evaluate our approach on real-world e-commerce workflows at PayPal, processing millions of daily interactions. Our results demonstrate 60% reduction in development time, and 3x improvement in deployment velocity compared to imperative implementations. The language's declarative approach enables non-engineers to modify agent behaviors safely, while maintaining sub-100ms orchestration overhead. We show that complex workflows involving product search, personalization, and cart management can be expressed in under 50 lines of DSL compared to 500+ lines of imperative code.","authors":["Ivan Daunis"],"pdf_url":"","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2512.19691v1","updated":"2025-12-22T18:59:34Z","published":"2025-12-22T18:59:34Z","title":"Scalably Enhancing the Clinical Validity of a Task Benchmark with Physician Oversight","summary":"Automating the calculation of clinical risk scores offers a significant opportunity to reduce physician administrative burden and enhance patient care. The current standard for evaluating this capability is MedCalc-Bench, a large-scale dataset constructed using LLM-based feature extraction and rule-based aggregation. However, treating such model-generated benchmarks as static oracles risks enshrining historical model errors as evaluation gold standards, a problem dangerously amplified when these datasets serve as reward signals for Reinforcement Learning (RL). In this work, we propose viewing benchmarks for complex tasks such as clinical score computation as ''in-progress living documents'' that should be periodically re-evaluated as the processes for creating them improve. We introduce a systematic, physician-in-the-loop pipeline that leverages advanced agentic verifiers to audit and relabel MedCalc-Bench, utilizing automated triage to reserve scarce clinician attention for the most contentious instances. Our audit reveals that a notable fraction of original labels diverge from medical ground truth due to extraction errors, calculator logic mismatches, and clinical ambiguity. To study whether this label noise meaningfully impacts downstream RL training, we fine-tune a Qwen3-8B model via Group Relative Policy Optimization (GRPO) and demonstrate that training on corrected labels yields an 8.7% absolute improvement in accuracy over the original baseline -- validating that label noise materially affects model evaluation. These findings underscore that in safety-critical domains, rigorous benchmark maintenance is a prerequisite for genuine model alignment.","authors":["Junze Ye","Daniel Tawfik","Alex J. Goodell","Nikhil V. Kotha","Mark K. Buyyounouski","Mohsen Bayati"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.09595v2","updated":"2025-12-22T18:56:01Z","published":"2025-10-10T17:54:24Z","title":"LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?","summary":"Competitive programming problems increasingly serve as valuable benchmarks to evaluate the coding capabilities of large language models (LLMs) due to their complexity and ease of verification. Yet, current coding benchmarks face limitations such as lack of exceptionally challenging problems, insufficient test case coverage, reliance on online platform APIs that limit accessibility. To address these issues, we introduce LiveOIBench, a comprehensive benchmark featuring 403 expert-curated Olympiad-level competitive programming problems, each with an average of 60 expert-designed test cases. The problems are sourced directly from 72 official contests of 14 Informatics Olympiads in different regions conducted between 2023 and 2025. LiveOIBench distinguishes itself through four key features: (1) meticulously curated high-quality tasks with detailed subtask rubrics and extensive private test cases; (2) direct integration of elite contestant performance data to enable informative comparison against top-performing humans; (3) planned continuous, contamination-free updates from newly released Olympiad problems; and (4) a self-contained evaluation system facilitating offline and easy-to-reproduce assessments. Benchmarking 34 popular general-purpose and reasoning LLMs, we find that GPT-5 achieves a notable 81.76th percentile, a strong result that nonetheless falls short of top human contestants, who usually place above 90th. In contrast, among open-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile, underscoring significant capability disparities from frontier closed models. Detailed analyses indicate that robust reasoning models prioritize precise problem analysis over excessive exploration, suggesting future models should emphasize structured analysis and minimize unnecessary exploration. All data, code, and leaderboard results are publicly available on our website.","authors":["Kaijian Zou","Aaron Xiong","Yunxiang Zhang","Frederick Zhang","Yueqi Ren","Jirong Yang","Ayoung Lee","Shitanshu Bhushan","Lu Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19678v1","updated":"2025-12-22T18:53:50Z","published":"2025-12-22T18:53:50Z","title":"WorldWarp: Propagating 3D Geometry with Asynchronous Video Diffusion","summary":"Generating long-range, geometrically consistent video presents a fundamental dilemma: while consistency demands strict adherence to 3D geometry in pixel space, state-of-the-art generative models operate most effectively in a camera-conditioned latent space. This disconnect causes current methods to struggle with occluded areas and complex camera trajectories. To bridge this gap, we propose WorldWarp, a framework that couples a 3D structural anchor with a 2D generative refiner. To establish geometric grounding, WorldWarp maintains an online 3D geometric cache built via Gaussian Splatting (3DGS). By explicitly warping historical content into novel views, this cache acts as a structural scaffold, ensuring each new frame respects prior geometry. However, static warping inevitably leaves holes and artifacts due to occlusions. We address this using a Spatio-Temporal Diffusion (ST-Diff) model designed for a \"fill-and-revise\" objective. Our key innovation is a spatio-temporal varying noise schedule: blank regions receive full noise to trigger generation, while warped regions receive partial noise to enable refinement. By dynamically updating the 3D cache at every step, WorldWarp maintains consistency across video chunks. Consequently, it achieves state-of-the-art fidelity by ensuring that 3D logic guides structure while diffusion logic perfects texture. Project page: \\href{https://hyokong.github.io/worldwarp-page/}{https://hyokong.github.io/worldwarp-page/}.","authors":["Hanyang Kong","Xingyi Yang","Xiaoxu Zheng","Xinchao Wang"],"pdf_url":"","comment":"Project page: https://hyokong.github.io/worldwarp-page/"},{"id":"http://arxiv.org/abs/2512.19673v1","updated":"2025-12-22T18:51:48Z","published":"2025-12-22T18:51:48Z","title":"Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies","summary":"Existing reinforcement learning (RL) approaches treat large language models (LLMs) as a single unified policy, overlooking their internal mechanisms. Understanding how policy evolves across layers and modules is therefore crucial for enabling more targeted optimization and raveling out complex reasoning mechanisms. In this paper, we decompose the language model policy by leveraging the intrinsic split of the Transformer residual stream and the equivalence between the composition of hidden states with the unembedding matrix and the resulting samplable policy. This decomposition reveals Internal Layer Policies, corresponding to contributions from individual layers, and Internal Modular Policies, which align with the self-attention and feed-forward network (FFN) components within each layer. By analyzing the entropy of internal policy, we find that: (a) Early layers keep high entropy for exploration, top layers converge to near-zero entropy for refinement, with convergence patterns varying across model series. (b) LLama's prediction space rapidly converges in the final layer, whereas Qwen-series models, especially Qwen3, exhibit a more human-like, progressively structured reasoning pattern. Motivated by these findings, we propose Bottom-up Policy Optimization (BuPO), a novel RL paradigm that directly optimizes the internal layer policy during early training. By aligning training objective at lower layer, BuPO reconstructs foundational reasoning capabilities and achieves superior performance. Extensive experiments on complex reasoning benchmarks demonstrates the effectiveness of our method. Our code is available at https://github.com/Trae1ounG/BuPO.","authors":["Yuqiao Tan","Minzheng Wang","Shizhu He","Huanxuan Liao","Chengfeng Zhao","Qiunan Lu","Tian Liang","Jun Zhao","Kang Liu"],"pdf_url":"","comment":"Preprint. Our code is available at https://github.com/Trae1ounG/BuPO"},{"id":"http://arxiv.org/abs/2509.23004v2","updated":"2025-12-22T18:45:53Z","published":"2025-09-26T23:50:25Z","title":"Bridging the Gap Between Scientific Laws Derived by AI Systems and Canonical Knowledge via Abductive Inference with AI-Noether","summary":"Advances in AI have shown great potential in contributing to the acceleration of scientific discovery. Symbolic regression can fit interpretable models to data, but these models are not necessarily derivable from established theory. Recent systems (e.g., AI-Descartes, AI-Hilbert) enforce derivability from prior knowledge. However, when existing theories are incomplete or incorrect, these machine-generated hypotheses may fall outside the theoretical scope. Automatically finding corrections to axiom systems to close this gap remains a central challenge in scientific discovery. We propose a solution: an open-source algebraic geometry-based system that, given an incomplete axiom system expressible as polynomials and a hypothesis that the axioms cannot derive, generates a minimal set of candidate axioms that, when added to the theory, provably derive the (possibly noisy) hypothesis. We illustrate the efficacy of our approach by showing that it can reconstruct key axioms required to derive the carrier-resolved photo-Hall effect, Einstein's relativistic laws, and several other laws.","authors":["Karan Srivastava","Sanjeeb Dash","Ryan Cory-Wright","Barry Trager","Cristina Cornelio","Lior Horesh"],"pdf_url":"","comment":"47 Pages (20+appendix), 14 Figures, Preprint: Updated for recent submission"},{"id":"http://arxiv.org/abs/2512.19663v1","updated":"2025-12-22T18:41:45Z","published":"2025-12-22T18:41:45Z","title":"Beyond CLIP: Knowledge-Enhanced Multimodal Transformers for Cross-Modal Alignment in Diabetic Retinopathy Diagnosis","summary":"Diabetic retinopathy (DR) is a leading cause of preventable blindness worldwide, demanding accurate automated diagnostic systems. While general-domain vision-language models like Contrastive Language-Image Pre-Training (CLIP) perform well on natural image tasks, they struggle in medical domain applications, particularly in cross-modal retrieval for ophthalmological images. We propose a novel knowledge-enhanced joint embedding framework that integrates retinal fundus images, clinical text, and structured patient data through a multimodal transformer architecture to address the critical gap in medical image-text alignment. Our approach employs separate encoders for each modality: a Vision Transformer (ViT-B/16) for retinal images, Bio-ClinicalBERT for clinical narratives, and a multilayer perceptron for structured demographic and clinical features. These modalities are fused through a joint transformer with modality-specific embeddings, trained using multiple objectives including contrastive losses between modality pairs, reconstruction losses for images and text, and classification losses for DR severity grading according to ICDR and SDRG schemes. Experimental results on the Brazilian Multilabel Ophthalmological Dataset (BRSET) demonstrate significant improvements over baseline models. Our framework achieves near-perfect text-to-image retrieval performance with Recall@1 of 99.94% compared to fine-tuned CLIP's 1.29%, while maintaining state-of-the-art classification accuracy of 97.05% for SDRG and 97.97% for ICDR. Furthermore, zero-shot evaluation on the unseen DeepEyeNet dataset validates strong generalizability with 93.95% Recall@1 versus 0.22% for fine-tuned CLIP. These results demonstrate that our multimodal training approach effectively captures cross-modal relationships in the medical domain, establishing both superior retrieval capabilities and robust diagnostic performance.","authors":["Argha Kamal Samanta","Harshika Goyal","Vasudha Joshi","Tushar Mungle","Pabitra Mitra"],"pdf_url":"","comment":"14 pages, 14 figures"},{"id":"http://arxiv.org/abs/2512.19654v1","updated":"2025-12-22T18:32:23Z","published":"2025-12-22T18:32:23Z","title":"Clustering with Label Consistency","summary":"Designing efficient, effective, and consistent metric clustering algorithms is a significant challenge attracting growing attention. Traditional approaches focus on the stability of cluster centers; unfortunately, this neglects the real-world need for stable point labels, i.e., stable assignments of points to named sets (clusters). In this paper, we address this gap by initiating the study of label-consistent metric clustering. We first introduce a new notion of consistency, measuring the label distance between two consecutive solutions. Then, armed with this new definition, we design new consistent approximation algorithms for the classical $k$-center and $k$-median problems.","authors":["Diptarka Chakraborty","Hendrik Fichtenberger","Bernhard Haeupler","Silvio Lattanzi","Ashkan Norouzi-Fard","Ola Svensson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2306.00029v2","updated":"2025-12-22T18:29:22Z","published":"2023-05-31T05:24:48Z","title":"CodeTF: One-stop Transformer Library for State-of-the-art Code LLMs","summary":"Code intelligence plays a key role in transforming modern software engineering. Recently, deep learning-based models, especially Transformer-based large language models (LLMs), have demonstrated remarkable potential in tackling these tasks by leveraging massive open-source code data and programming language features. However, the development and deployment of such models often require expertise in both machine learning and software engineering, creating a barrier for the model adoption. In this paper, we present CodeTF, an open-source Transformer-based library for state-of-the-art Code LLMs and code intelligence. Following the principles of modular design and extensible framework, we design CodeTF with a unified interface to enable rapid access and development across different types of models, datasets and tasks. Our library supports a collection of pretrained Code LLM models and popular code benchmarks, including a standardized interface to train and serve code LLMs efficiently, and data features such as language-specific parsers and utility functions for extracting code attributes. In this paper, we describe the design principles, the architecture, key modules and components, and compare with other related library tools. Finally, we hope CodeTF is able to bridge the gap between machine learning/generative AI and software engineering, providing a comprehensive open-source solution for developers, researchers, and practitioners.","authors":["Nghi D. Q. Bui","Hung Le","Yue Wang","Junnan Li","Akhilesh Deepak Gotmare","Steven C. H. Hoi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.01353v2","updated":"2025-12-22T18:27:42Z","published":"2025-05-02T15:43:37Z","title":"Differentiable Nonlinear Model Predictive Control","summary":"The efficient computation of parametric solution sensitivities is a key challenge in the integration of learning-enhanced methods with nonlinear model predictive control (MPC), as their availability is crucial for many learning algorithms. This paper discusses the computation of solution sensitivities of general nonlinear programs (NLPs) using the implicit function theorem (IFT) and smoothed optimality conditions treated in interior-point methods (IPM). We detail sensitivity computation within a sequential quadratic programming (SQP) method which employs an IPM for the quadratic subproblems. Previous works presented in the machine learning community are limited to convex or unconstrained formulations, or lack an implementation for efficient sensitivity evaluation. The publication is accompanied by an efficient open-source implementation within the acados framework, providing both forward and adjoint sensitivities for general optimal control problems, achieving speedups exceeding 3x over the state-of-the-art solvers mpc.pytorch and cvxpygen.","authors":["Jonathan Frey","Katrin Baumgärtner","Gianluca Frison","Dirk Reinhardt","Jasper Hoffmann","Leonard Fichtner","Sebastien Gros","Moritz Diehl"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.04049v2","updated":"2025-12-22T18:19:18Z","published":"2025-06-04T15:15:23Z","title":"WANDER: An Explainable Decision-Support Framework for HPC","summary":"High-performance computing (HPC) systems expose many interdependent configuration knobs that impact runtime, resource usage, power, and variability. Existing predictive tools model these outcomes, but do not support structured exploration, explanation, or guided reconfiguration. We present WANDER, a decision-support framework that synthesizes alternate configurations using counterfactual analysis aligned with user goals and constraints. We introduce a composite trade-off score that ranks suggestions based on prediction uncertainty, consistency between feature-target relationships using causal models, and similarity between feature distributions against historical data. To our knowledge, WANDER is the first such system to unify prediction, exploration, and explanation for HPC tuning under a common query interface. Across multiple datasets WANDER generates interpretable and trustworthy, human-readable alternatives that guide users to achieve their performance objectives.","authors":["Ankur Lahiry","Banooqa Banday","Tanzima Z. Islam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.09312v3","updated":"2025-12-22T18:14:54Z","published":"2025-09-11T09:55:50Z","title":"Explaining Tournament Solutions with Minimal Supports","summary":"Tournaments are widely used models to represent pairwise dominance between candidates, alternatives, or teams. We study the problem of providing certified explanations for why a candidate appears among the winners under various tournament rules. To this end, we identify minimal supports, minimal sub-tournaments in which the candidate is guaranteed to win regardless of how the rest of the tournament is completed (that is, the candidate is a necessary winner of the sub-tournament). This notion corresponds to an abductive explanation for the question,\"Why does the winner win the tournament?\", a central concept in formal explainable AI. We focus on common tournament solutions: the top cycle, the uncovered set, the Copeland rule, the Borda rule, the maximin rule, and the weighted uncovered set. For each rule we determine the size of the smallest minimal supports, and we present polynomial-time algorithms to compute them for all solutions except for the weighted uncovered set, for which the problem is NP-complete. Finally, we show how minimal supports can serve to produce compact, certified, and intuitive explanations for tournament solutions.","authors":["Clément Contet","Umberto Grandi","Jérôme Mengin"],"pdf_url":"","comment":"This is the extended version of Contet, Grandi, and Mengin. 2026. Explaining Tournament Solutions with Minimal Supports. In Proceedings of the 40th AAAI Conference on Artificial Intelligence"},{"id":"http://arxiv.org/abs/2512.19620v1","updated":"2025-12-22T17:54:49Z","published":"2025-12-22T17:54:49Z","title":"Exploring the features used for summary evaluation by Human and GPT","summary":"Summary assessment involves evaluating how well a generated summary reflects the key ideas and meaning of the source text, requiring a deep understanding of the content. Large Language Models (LLMs) have been used to automate this process, acting as judges to evaluate summaries with respect to the original text. While previous research investigated the alignment between LLMs and Human responses, it is not yet well understood what properties or features are exploited by them when asked to evaluate based on a particular quality dimension, and there has not been much attention towards mapping between evaluation scores and metrics. In this paper, we address this issue and discover features aligned with Human and Generative Pre-trained Transformers (GPTs) responses by studying statistical and machine learning metrics. Furthermore, we show that instructing GPTs to employ metrics used by Human can improve their judgment and conforming them better with human responses.","authors":["Zahra Sadeghi","Evangelos Milios","Frank Rudzicz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19609v1","updated":"2025-12-22T17:45:39Z","published":"2025-12-22T17:45:39Z","title":"MapTrace: Scalable Data Generation for Route Tracing on Maps","summary":"While Multimodal Large Language Models have achieved human-like performance on many visual and textual reasoning tasks, their proficiency in fine-grained spatial understanding, such as route tracing on maps remains limited. Unlike humans, who can quickly learn to parse and navigate maps, current models often fail to respect fundamental path constraints, in part due to the prohibitive cost and difficulty of collecting large-scale, pixel-accurate path annotations. To address this, we introduce a scalable synthetic data generation pipeline that leverages synthetic map images and pixel-level parsing to automatically produce precise annotations for this challenging task. Using this pipeline, we construct a fine-tuning dataset of 23k path samples across 4k maps, enabling models to acquire more human-like spatial capabilities. Using this dataset, we fine-tune both open-source and proprietary MLLMs. Results on MapBench show that finetuning substantially improves robustness, raising success rates by up to 6.4 points, while also reducing path-tracing error (NDTW). These gains highlight that fine-grained spatial reasoning, absent in pretrained models, can be explicitly taught with synthetic supervision.","authors":["Artemis Panagopoulou","Aveek Purohit","Achin Kulshrestha","Soroosh Yazdani","Mohit Goyal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.23950v2","updated":"2025-12-22T17:36:54Z","published":"2025-05-29T19:00:42Z","title":"InterMT: Multi-Turn Interleaved Preference Alignment with Human Feedback","summary":"As multimodal large models (MLLMs) continue to advance across challenging tasks, a key question emerges: What essential capabilities are still missing? A critical aspect of human learning is continuous interaction with the environment -- not limited to language, but also involving multimodal understanding and generation. To move closer to human-level intelligence, models must similarly support multi-turn, multimodal interaction. In particular, they should comprehend interleaved multimodal contexts and respond coherently in ongoing exchanges. In this work, we present an initial exploration through the InterMT -- the first preference dataset for multi-turn multimodal interaction, grounded in real human feedback. In this exploration, we particularly emphasize the importance of human oversight, introducing expert annotations to guide the process, motivated by the fact that current MLLMs lack such complex interactive capabilities. InterMT captures human preferences at both global and local levels into nine sub-dimensions, consists of 15.6k prompts, 52.6k multi-turn dialogue instances, and 32.4k human-labeled preference pairs. To compensate for the lack of capability for multi-modal understanding and generation, we introduce an agentic workflow that leverages tool-augmented MLLMs to construct multi-turn QA instances. To further this goal, we introduce InterMT-Bench to assess the ability of MLLMs in assisting judges with multi-turn, multimodal tasks. We demonstrate the utility of \\InterMT through applications such as judge moderation and further reveal the multi-turn scaling law of judge model. We hope the open-source of our data can help facilitate further research on aligning current MLLMs to the next step. Our project website can be found at https://pku-intermt.github.io .","authors":["Boyuan Chen","Donghai Hong","Jiaming Ji","Jiacheng Zheng","Bowen Dong","Jiayi Zhou","Kaile Wang","Juntao Dai","Xuyao Wang","Wenqi Chen","Qirui Zheng","Wenxin Li","Sirui Han","Yike Guo","Yaodong Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.22782v3","updated":"2025-12-22T17:22:59Z","published":"2025-07-30T15:48:38Z","title":"Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies","summary":"This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement learning algorithm designed to enhance multi-agent collaboration in cooperative environments. TAAC employs a Centralized Training/Centralized Execution scheme incorporating multi-headed attention mechanisms in both the actor and critic. This design facilitates dynamic, inter-agent communication, allowing agents to explicitly query teammates, thereby efficiently managing the exponential growth of joint-action spaces while ensuring a high degree of collaboration. We further introduce a penalized loss function which promotes diverse yet complementary roles among agents. We evaluate TAAC in a simulated soccer environment against benchmark algorithms representing other multi-agent paradigms, including Proximal Policy Optimization and Multi-Agent Actor-Attention-Critic. We find that TAAC exhibits superior performance and enhanced collaborative behaviors across a variety of metrics (win rates, goal differentials, Elo ratings, inter-agent connectivity, balanced spatial distributions, and frequent tactical interactions such as ball possession swaps).","authors":["Hugo Garrido-Lestache Belinchon","Jeremy Kedziora"],"pdf_url":"","comment":"11 pages"},{"id":"http://arxiv.org/abs/2507.07935v6","updated":"2025-12-22T17:01:55Z","published":"2025-07-10T17:16:33Z","title":"Working with AI: Measuring the Applicability of Generative AI to Occupations","summary":"With generative AI emerging as a general-purpose technology, understanding its economic effects is among society's most pressing questions. Existing studies of AI impact have largely relied on predictions of AI capabilities or focused narrowly on individual firms. Drawing instead on real-world AI usage, we analyze a dataset of 200k anonymized conversations with Microsoft Bing Copilot to measure AI applicability to occupations. We use an LLM-based pipeline to classify the O*NET work activities assisted or performed by AI in each conversation. We find that the most common and successful AI-assisted work activities involve information work--the creation, processing, and communication of information. At the occupation level, we find widespread AI applicability cutting across sectors, as most occupations have information work components. Our methodology also allows us to predict which occupations are more likely to delegate tasks to AI and which are more likely to use AI to assist existing workflows.","authors":["Kiran Tomlinson","Sonia Jaffe","Will Wang","Scott Counts","Siddharth Suri"],"pdf_url":"","comment":"40 pages"},{"id":"http://arxiv.org/abs/2512.19576v1","updated":"2025-12-22T17:00:25Z","published":"2025-12-22T17:00:25Z","title":"LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller","summary":"Attitude control is essential for many satellite missions. Classical controllers, however, are time-consuming to design and sensitive to model uncertainties and variations in operational boundary conditions. Deep Reinforcement Learning (DRL) offers a promising alternative by learning adaptive control strategies through autonomous interaction with a simulation environment. Overcoming the Sim2Real gap, which involves deploying an agent trained in simulation onto the real physical satellite, remains a significant challenge. In this work, we present the first successful in-orbit demonstration of an AI-based attitude controller for inertial pointing maneuvers. The controller was trained entirely in simulation and deployed to the InnoCube 3U nanosatellite, which was developed by the Julius-Maximilians-Universität Würzburg in cooperation with the Technische Universität Berlin, and launched in January 2025. We present the AI agent design, the methodology of the training procedure, the discrepancies between the simulation and the observed behavior of the real satellite, and a comparison of the AI-based attitude controller with the classical PD controller of InnoCube. Steady-state metrics confirm the robust performance of the AI-based controller during repeated in-orbit maneuvers.","authors":["Kirill Djebko","Tom Baumann","Erik Dilger","Frank Puppe","Sergio Montenegro"],"pdf_url":"","comment":"55 pages, 27 figures, 29 tables. The maneuver telemetry datasets generated and analyzed during this work are available in the GitHub repository https://github.com/kdjebko/lelar-in-orbit-data"},{"id":"http://arxiv.org/abs/2512.19570v1","updated":"2025-12-22T16:52:37Z","published":"2025-12-22T16:52:37Z","title":"The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge","summary":"We examine epistemological threats posed by human and LLM interaction. We develop collective epistemology as a theory of epistemic warrant distributed across human collectives, using bounded rationality and dual process theory as background. We distinguish internalist justification, defined as reflective understanding of why a proposition is true, from externalist justification, defined as reliable transmission of truths. Both are necessary for collective rationality, but only internalist justification produces reflective knowledge. We specify reflective knowledge as follows: agents understand the evaluative basis of a claim, when that basis is unavailable agents consistently assess the reliability of truth sources, and agents have a duty to apply these standards within their domains of competence. We argue that LLMs approximate externalist reliabilism because they can reliably transmit information whose justificatory basis is established elsewhere, but they do not themselves possess reflective justification. Widespread outsourcing of reflective work to reliable LLM outputs can weaken reflective standards of justification, disincentivize comprehension, and reduce agents' capacity to meet professional and civic epistemic duties. To mitigate these risks, we propose a three tier norm program that includes an epistemic interaction model for individual use, institutional and organizational frameworks that seed and enforce norms for epistemically optimal outcomes, and deontic constraints at organizational and or legislative levels that instantiate discursive norms and curb epistemic vices.","authors":["Angjelin Hila"],"pdf_url":"","comment":"AI & Soc (2025)"},{"id":"http://arxiv.org/abs/2512.19569v1","updated":"2025-12-22T16:52:36Z","published":"2025-12-22T16:52:36Z","title":"Owning the Intelligence: Global AI Patents Landscape and Europe's Quest for Technological Sovereignty","summary":"Artificial intelligence has become a key arena of global technological competition and a central concern for Europe's quest for technological sovereignty. This paper analyzes global AI patenting from 2010 to 2023 to assess Europe's position in an increasingly bipolar innovation landscape dominated by the United States and China. Using linked patent, firm, ownership, and citation data, we examine the geography, specialization, and international diffusion of AI innovation. We find a highly concentrated patent landscape: China leads in patent volumes, while the United States dominates in citation impact and technological influence. Europe accounts for a limited share of AI patents but exhibits signals of relatively high patent quality. Technological proximity reveals global convergence toward U.S. innovation trajectories, with Europe remaining fragmented rather than forming an autonomous pole. Gravity-model estimates show that cross-border AI knowledge flows are driven primarily by technological capability and specialization, while geographic and institutional factors play a secondary role. EU membership does not significantly enhance intra-European knowledge diffusion, suggesting that technological capacity, rather than political integration, underpins participation in global AI innovation networks.","authors":["Lapo Santarlasci","Armando Rungi","Loredana Fattorini","Nestor Maslej"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19564v1","updated":"2025-12-22T16:46:40Z","published":"2025-12-22T16:46:40Z","title":"Results of the 2024 CommonRoad Motion Planning Competition for Autonomous Vehicles","summary":"Over the past decade, a wide range of motion planning approaches for autonomous vehicles has been developed to handle increasingly complex traffic scenarios. However, these approaches are rarely compared on standardized benchmarks, limiting the assessment of relative strengths and weaknesses. To address this gap, we present the setup and results of the 4th CommonRoad Motion Planning Competition held in 2024, conducted using the CommonRoad benchmark suite. This annual competition provides an open-source and reproducible framework for benchmarking motion planning algorithms. The benchmark scenarios span highway and urban environments with diverse traffic participants, including passenger cars, buses, and bicycles. Planner performance is evaluated along four dimensions: efficiency, safety, comfort, and compliance with selected traffic rules. This report introduces the competition format and provides a comparison of representative high-performing planners from the 2023 and 2024 editions.","authors":["Yanliang Huang","Xia Yan","Peiran Yin","Zhenduo Zhang","Zeyan Shao","Youran Wang","Haoliang Huang","Matthias Althoff"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19562v1","updated":"2025-12-22T16:44:23Z","published":"2025-12-22T16:44:23Z","title":"REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation","summary":"Vision-Language-Action (VLA) models empower robots to understand and execute tasks described by natural language instructions. However, a key challenge lies in their ability to generalize beyond the specific environments and conditions they were trained on, which is presently difficult and expensive to evaluate in the real-world. To address this gap, we present REALM, a new simulation environment and benchmark designed to evaluate the generalization capabilities of VLA models, with a specific emphasis on establishing a strong correlation between simulated and real-world performance through high-fidelity visuals and aligned robot control. Our environment offers a suite of 15 perturbation factors, 7 manipulation skills, and more than 3,500 objects. Finally, we establish two task sets that form our benchmark and evaluate the π_{0}, π_{0}-FAST, and GR00T N1.5 VLA models, showing that generalization and robustness remain an open challenge. More broadly, we also show that simulation gives us a valuable proxy for the real-world and allows us to systematically probe for and quantify the weaknesses and failure modes of VLAs. Project page: https://martin-sedlacek.com/realm","authors":["Martin Sedlacek","Pavlo Yefanov","Georgy Ponimatkin","Jai Bardhan","Simon Pilc","Mederic Fourmy","Evangelos Kazakos","Cees G. M. Snoek","Josef Sivic","Vladimir Petrik"],"pdf_url":"","comment":"9 pages, 10 figures"},{"id":"http://arxiv.org/abs/2512.19560v1","updated":"2025-12-22T16:42:58Z","published":"2025-12-22T16:42:58Z","title":"BabyFlow: 3D modeling of realistic and expressive infant faces","summary":"Early detection of developmental disorders can be aided by analyzing infant craniofacial morphology, but modeling infant faces is challenging due to limited data and frequent spontaneous expressions. We introduce BabyFlow, a generative AI model that disentangles facial identity and expression, enabling independent control over both. Using normalizing flows, BabyFlow learns flexible, probabilistic representations that capture the complex, non-linear variability of expressive infant faces without restrictive linear assumptions. To address scarce and uncontrolled expressive data, we perform cross-age expression transfer, adapting expressions from adult 3D scans to enrich infant datasets with realistic and systematic expressive variants. As a result, BabyFlow improves 3D reconstruction accuracy, particularly in highly expressive regions such as the mouth, eyes, and nose, and supports synthesis and modification of infant expressions while preserving identity. Additionally, by integrating with diffusion models, BabyFlow generates high-fidelity 2D infant images with consistent 3D geometry, providing powerful tools for data augmentation and early facial analysis.","authors":["Antonia Alomar","Mireia Masias","Marius George Linguraru","Federico M. Sukno","Gemma Piella"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19557v1","updated":"2025-12-22T16:40:14Z","published":"2025-12-22T16:40:14Z","title":"Augmenting Intelligence: A Hybrid Framework for Scalable and Stable Explanations","summary":"Current approaches to Explainable AI (XAI) face a \"Scalability-Stability Dilemma.\" Post-hoc methods (e.g., LIME, SHAP) may scale easily but suffer from instability, while supervised explanation frameworks (e.g., TED) offer stability but require prohibitive human effort to label every training instance. This paper proposes a Hybrid LRR-TED framework that addresses this dilemma through a novel \"Asymmetry of Discovery.\" When applied to customer churn prediction, we demonstrate that automated rule learners (GLRM) excel at identifying broad \"Safety Nets\" (retention patterns) but struggle to capture specific \"Risk Traps\" (churn triggers)-a phenomenon we term the Anna Karenina Principle of Churn. By initialising the explanation matrix with automated safety rules and augmenting it with a Pareto-optimal set of just four human-defined risk rules, our approach achieves 94.00% predictive accuracy. This configuration outperforms the full 8-rule manual expert baseline while reducing human annotation effort by 50%, proposing a shift in the paradigm for Human-in-the-Loop AI: moving experts from the role of \"Rule Writers\" to \"Exception Handlers.\"","authors":["Lawrence Krukrubo","Julius Odede","Olawande Olusegun"],"pdf_url":"","comment":"5 pages, 2 figures, 2 tables. Code and experiments available at https://github.com/Lawrence-Krukrubo/IBM-Learn-XAI"},{"id":"http://arxiv.org/abs/2512.19554v1","updated":"2025-12-22T16:34:21Z","published":"2025-12-22T16:34:21Z","title":"CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal","summary":"Group-relative reinforcement learning with verifiable rewards (RLVR) often wastes the most informative data it already has the failures. When all rollouts are wrong, gradients stall; when one happens to be correct, the update usually ignores why the others are close-but-wrong, and credit can be misassigned to spurious chains. We present CARE (Contrastive Anchored REflection), a failure-centric post-training framework for multimodal reasoning that turns errors into supervision. CARE combines: (i) an anchored-contrastive objective that forms a compact subgroup around the best rollout and a set of semantically proximate hard negatives, performs within-subgroup z-score normalization with negative-only scaling, and includes an all-negative rescue to prevent zero-signal batches; and (ii) Reflection-Guided Resampling (RGR), a one-shot structured self-repair that rewrites a representative failure and re-scores it with the same verifier, converting near-misses into usable positives without any test-time reflection. CARE improves accuracy and training smoothness while explicitly increasing the share of learning signal that comes from failures. On Qwen2.5-VL-7B, CARE lifts macro-averaged accuracy by 4.6 points over GRPO across six verifiable visual-reasoning benchmarks; with Qwen3-VL-8B it reaches competitive or state-of-the-art results on MathVista and MMMU-Pro under an identical evaluation protocol.","authors":["Yongxin Wang","Zhicheng Yang","Meng Cao","Mingfei Han","Haokun Lin","Yingying Zhu","Xiaojun Chang","Xiaodan Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19551v1","updated":"2025-12-22T16:31:30Z","published":"2025-12-22T16:31:30Z","title":"Towards Closed-Loop Embodied Empathy Evolution: Probing LLM-Centric Lifelong Empathic Motion Generation in Unseen Scenarios","summary":"In the literature, existing human-centric emotional motion generation methods primarily focus on boosting performance within a single scale-fixed dataset, largely neglecting the flexible and scale-increasing motion scenarios (e.g., sports, dance), whereas effectively learning these newly emerging scenarios can significantly enhance the model's real-world generalization ability. Inspired by this, this paper proposes a new LLM-Centric Lifelong Empathic Motion Generation (L^2-EMG) task, which aims to equip LLMs with the capability to continually acquire emotional motion generation knowledge across different unseen scenarios, potentially contributing to building a closed-loop and self-evolving embodied agent equipped with both empathy and intelligence. Further, this paper poses two key challenges in the L^2-EMG task, i.e., the emotion decoupling challenge and the scenario adapting challenge. To this end, this paper proposes an Emotion-Transferable and Scenario-Adapted Mixture of Experts (ES-MoE) approach which designs a causal-guided emotion decoupling block and a scenario-adapted expert constructing block to address the two challenges, respectively. Especially, this paper constructs multiple L^2-EMG datasets to validate the effectiveness of the ES-MoE approach. Extensive evaluations show that ES-MoE outperforms advanced baselines.","authors":["Jiawen Wang","Jingjing Wang Tianyang Chen","Min Zhang","Guodong Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.20302v6","updated":"2025-12-22T16:29:48Z","published":"2024-09-30T14:00:04Z","title":"OM4OV: Leveraging Ontology Matching for Ontology Versioning","summary":"Due to the dynamic nature of the Semantic Web, version control is necessary to capture time-varying information for widely used ontologies. Despite the long-standing recognition of ontology versioning (OV) as a crucial component of efficient ontology management, many approaches treat OV as similar to ontology matching (OM) and directly reuse OM systems for OV tasks. In this study, we systematically analyse the similarities and differences between OM and OV and formalise the OM4OV pipeline. The pipeline is implemented and evaluated in the state-of-the-art OM system Agent-OM. The experimental results indicate that OM systems can be reused for OV tasks, but without necessary extensions, the current OM4OV pipeline can produce skewed measurements, poor performance in detecting update entities, and limited explainability for false mappings. To tackle these issues, we propose an optimisation method called the cross-reference (CR) mechanism, building upon the existing alignments from OM to reduce the number of matching candidates and improve overall OV performance.","authors":["Zhangcheng Qiang","Kerry Taylor","Weiqing Wang"],"pdf_url":"","comment":"16 pages, 8 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.24116v2","updated":"2025-12-22T16:25:04Z","published":"2024-10-31T16:46:23Z","title":"AIDOVECL: AI-generated Dataset of Outpainted Vehicles for Eye-level Classification and Localization","summary":"Image labeling is a critical bottleneck in the development of computer vision technologies, often constraining the potential of machine learning models due to the time-intensive nature of manual annotations. This work introduces a novel approach that leverages outpainting to mitigate the problem of annotated data scarcity by generating artificial contexts and annotations, significantly reducing manual labeling efforts. We apply this technique to a particularly acute challenge in autonomous driving, urban planning, and environmental monitoring: the lack of diverse, eye-level vehicle images in desired classes. Our dataset comprises AI-generated vehicle images obtained by detecting and cropping vehicles from manually selected seed images, which are then outpainted onto larger canvases to simulate varied real-world conditions. The outpainted images include detailed annotations, providing high-quality ground truth data. Advanced outpainting techniques and image quality assessments ensure visual fidelity and contextual relevance. Ablation results show that incorporating AIDOVECL improves overall detection performance by up to 10%, and delivers gains of up to 40% in settings with greater diversity of context, object scale, and placement, with underrepresented classes achieving up to 50% higher true positives. AIDOVECL enhances vehicle detection by augmenting real training data and supporting evaluation across diverse scenarios. By demonstrating outpainting as an automatic annotation paradigm, it offers a practical and versatile solution for building fine-grained datasets with reduced labeling effort across multiple machine learning domains. The code and links to datasets used in this study are available for further research and replication at https://github.com/amir-kazemi/aidovecl .","authors":["Amir Kazemi","Qurat ul ain Fatima","Volodymyr Kindratenko","Christopher Tessum"],"pdf_url":"","comment":"34 pages, 10 figures, 5 tables"},{"id":"http://arxiv.org/abs/2512.19535v1","updated":"2025-12-22T16:21:39Z","published":"2025-12-22T16:21:39Z","title":"CASA: Cross-Attention via Self-Attention for Efficient Vision-Language Fusion","summary":"Vision-language models (VLMs) are commonly trained by inserting image tokens from a pretrained vision encoder into the textual stream of a language model. This allows text and image information to fully attend to one another within the model, but becomes extremely costly for high-resolution images, long conversations, or streaming videos, both in memory and compute. VLMs leveraging cross-attention are an efficient alternative to token insertion but exhibit a clear performance gap, in particular on tasks involving fine-grained visual details. We find that a key to improving such models is to also enable local text-to-text interaction in the dedicated cross-attention layers. Building on this, we propose CASA, Cross-Attention via Self-Attention, a simple and efficient paradigm which substantially reduces the gap with full token insertion on common image understanding benchmarks, while enjoying the same scalability as cross-attention models when applied to long-context multimodal tasks such as streaming video captioning. For samples and code, please see our project page at https://kyutai.org/casa .","authors":["Moritz Böhle","Amélie Royer","Juliette Marrie","Edouard Grave","Patrick Pérez"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19530v1","updated":"2025-12-22T16:19:01Z","published":"2025-12-22T16:19:01Z","title":"Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement","summary":"Predicting reaction outcomes across continuous solvent composition ranges remains a critical challenge in organic synthesis and process chemistry. Traditional machine learning approaches often treat solvent identity as a discrete categorical variable, which prevents systematic interpolation and extrapolation across the solvent space. This work introduces the \\textbf{Catechol Benchmark}, a high-throughput transient flow chemistry dataset comprising 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures, parameterized by continuous volume fractions ($\\% B$). We evaluate various architectures under rigorous leave-one-solvent-out and leave-one-mixture-out protocols to test generalization to unseen chemical environments.\n  Our results demonstrate that classical tabular methods (e.g., Gradient-Boosted Decision Trees) and large language model embeddings (e.g., Qwen-7B) struggle with quantitative precision, yielding Mean Squared Errors (MSE) of 0.099 and 0.129, respectively. In contrast, we propose a hybrid GNN-based architecture that integrates Graph Attention Networks (GATs) with Differential Reaction Fingerprints (DRFP) and learned mixture-aware solvent encodings. This approach achieves an \\textbf{MSE of 0.0039} ($\\pm$ 0.0003), representing a 60\\% error reduction over competitive baselines and a $>25\\times$ improvement over tabular ensembles. Ablation studies confirm that explicit molecular graph message-passing and continuous mixture encoding are essential for robust generalization. The complete dataset, evaluation protocols, and reference implementations are released to facilitate data-efficient reaction prediction and continuous solvent representation learning.","authors":["Hongsheng Xing","Qiuxin Si"],"pdf_url":"","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2512.19526v1","updated":"2025-12-22T16:18:00Z","published":"2025-12-22T16:18:00Z","title":"QuantiPhy: A Quantitative Benchmark Evaluating Physical Reasoning Abilities of Vision-Language Models","summary":"Understanding the physical world is essential for generalist AI agents. However, it remains unclear whether state-of-the-art vision perception models (e.g., large VLMs) can reason physical properties quantitatively. Existing evaluations are predominantly VQA-based and qualitative, offering limited insight into whether these models can infer the kinematic quantities of moving objects from video observations. To address this, we present QuantiPhy, the first benchmark designed to quantitatively measure a VLM's physical reasoning ability. Comprising more than 3.3K video-text instances with numerical ground truth, QuantiPhy evaluates a VLM's performance on estimating an object's size, velocity, and acceleration at a given timestamp, using one of these properties as an input prior. The benchmark standardizes prompts and scoring to assess numerical accuracy, enabling fair comparisons across models. Our experiments on state-of-the-art VLMs reveal a consistent gap between their qualitative plausibility and actual numerical correctness. We further provide an in-depth analysis of key factors like background noise, counterfactual priors, and strategic prompting and find that state-of-the-art VLMs lean heavily on pre-trained world knowledge rather than faithfully using the provided visual and textual inputs as references when reasoning kinematic properties quantitatively. QuantiPhy offers the first rigorous, scalable testbed to move VLMs beyond mere verbal plausibility toward a numerically grounded physical understanding.","authors":["Li Puyin","Tiange Xiang","Ella Mao","Shirley Wei","Xinye Chen","Adnan Masood","Li Fei-fei","Ehsan Adeli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19516v1","updated":"2025-12-22T16:08:03Z","published":"2025-12-22T16:08:03Z","title":"LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning","summary":"Multiobjective reinforcement learning (MORL) poses significant challenges due to the inherent conflicts between objectives and the difficulty of adapting to dynamic environments. Traditional methods often struggle to generalize effectively, particularly in large and complex state-action spaces. To address these limitations, we introduce the Latent Causal Diffusion Model (LacaDM), a novel approach designed to enhance the adaptability of MORL in discrete and continuous environments. Unlike existing methods that primarily address conflicts between objectives, LacaDM learns latent temporal causal relationships between environmental states and policies, enabling efficient knowledge transfer across diverse MORL scenarios. By embedding these causal structures within a diffusion model-based framework, LacaDM achieves a balance between conflicting objectives while maintaining strong generalization capabilities in previously unseen environments. Empirical evaluations on various tasks from the MOGymnasium framework demonstrate that LacaDM consistently outperforms the state-of-art baselines in terms of hypervolume, sparsity, and expected utility maximization, showcasing its effectiveness in complex multiobjective tasks.","authors":["Xueming Yan","Bo Yin","Yaochu Jin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19512v1","updated":"2025-12-22T16:06:36Z","published":"2025-12-22T16:06:36Z","title":"Anatomy-R1: Enhancing Anatomy Reasoning in Multimodal Large Language Models via Anatomical Similarity Curriculum and Group Diversity Augmentation","summary":"Multimodal Large Language Models (MLLMs) have achieved impressive progress in natural image reasoning, yet their potential in medical imaging remains underexplored, especially in clinical anatomical surgical images. Anatomy understanding tasks demand precise understanding and clinically coherent answers, which are difficult to achieve due to the complexity of medical data and the scarcity of high-quality expert annotations. These challenges limit the effectiveness of conventional Supervised Fine-Tuning (SFT) strategies. While recent work has demonstrated that Group Relative Policy Optimization (GRPO) can enhance reasoning in MLLMs without relying on large amounts of data, we find two weaknesses that hinder GRPO's reasoning performance in anatomy recognition: 1) knowledge cannot be effectively shared between different anatomical structures, resulting in uneven information gain and preventing the model from converging, and 2) the model quickly converges to a single reasoning path, suppressing the exploration of diverse strategies. To overcome these challenges, we propose two novel methods. First, we implement a progressive learning strategy called Anatomical Similarity Curriculum Learning by controlling question difficulty via the similarity of answer choices, enabling the model to master complex problems incrementally. Second, we utilize question augmentation referred to as Group Diversity Question Augmentation to expand the model's search space for difficult queries, mitigating the tendency to produce uniform responses. Comprehensive experiments on the SGG-VQA and OmniMedVQA benchmarks show our method achieves a significant improvement across the two benchmarks, demonstrating its effectiveness in enhancing the medical reasoning capabilities of MLLMs. The code can be found in https://github.com/tomato996/Anatomy-R1","authors":["Ziyang Song","Zelin Zang","Zuyao Chen","Xusheng Liang","Dong Yi","Jinlin Wu","Hongbin Liu","Jiebo Luo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19506v1","updated":"2025-12-22T16:00:55Z","published":"2025-12-22T16:00:55Z","title":"DK-STN: A Domain Knowledge Embedded Spatio-Temporal Network Model for MJO Forecast","summary":"Understanding and predicting the Madden-Julian Oscillation (MJO) is fundamental for precipitation forecasting and disaster prevention. To date, long-term and accurate MJO prediction has remained a challenge for researchers. Conventional MJO prediction methods using Numerical Weather Prediction (NWP) are resource-intensive, time-consuming, and highly unstable (most NWP methods are sensitive to seasons, with better MJO forecast results in winter). While existing Artificial Neural Network (ANN) methods save resources and speed forecasting, their accuracy never reaches the 28 days predicted by the state-of-the-art NWP method, i.e., the operational forecasts from ECMWF, since neural networks cannot handle climate data effectively. In this paper, we present a Domain Knowledge Embedded Spatio-Temporal Network (DK-STN), a stable neural network model for accurate and efficient MJO forecasting. It combines the benefits of NWP and ANN methods and successfully improves the forecast accuracy of ANN methods while maintaining a high level of efficiency and stability. We begin with a spatial-temporal network (STN) and embed domain knowledge in it using two key methods: (i) applying a domain knowledge enhancement method and (ii) integrating a domain knowledge processing method into network training. We evaluated DK-STN with the 5th generation of ECMWF reanalysis (ERA5) data and compared it with ECMWF. Given 7 days of climate data as input, DK-STN can generate reliable forecasts for the following 28 days in 1-2 seconds, with an error of only 2-3 days in different seasons. DK-STN significantly exceeds ECMWF in that its forecast accuracy is equivalent to ECMWF's, while its efficiency and stability are significantly superior.","authors":["Hongliang Li","Nong Zhang","Zhewen Xu","Xiang Li","Changzheng Liu","Chongbo Zhao","Jie Wu"],"pdf_url":"","comment":"18 pages, 10 figures"},{"id":"http://arxiv.org/abs/2505.20063v2","updated":"2025-12-22T15:49:59Z","published":"2025-05-26T14:47:59Z","title":"SAEs Are Good for Steering -- If You Select the Right Features","summary":"Sparse Autoencoders (SAEs) have been proposed as an unsupervised approach to learn a decomposition of a model's latent space. This enables useful applications such as steering - influencing the output of a model towards a desired concept - without requiring labeled data. Current methods identify SAE features to steer by analyzing the input tokens that activate them. However, recent work has highlighted that activations alone do not fully describe the effect of a feature on the model's output. In this work, we draw a distinction between two types of features: input features, which mainly capture patterns in the model's input, and output features, which have a human-understandable effect on the model's output. We propose input and output scores to characterize and locate these types of features, and show that high values for both scores rarely co-occur in the same features. These findings have practical implications: after filtering out features with low output scores, we obtain 2-3x improvements when steering with SAEs, making them competitive with supervised methods.","authors":["Dana Arad","Aaron Mueller","Yonatan Belinkov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19494v1","updated":"2025-12-22T15:49:24Z","published":"2025-12-22T15:49:24Z","title":"Kolmogorov-Arnold Graph Neural Networks Applied to Inorganic Nanomaterials Dataset","summary":"The recent development of Kolmogorov-Arnold Networks (KANs) introduced new discoveries in the field of Graph Neural Networks (GNNs), expanding the existing set of models with KAN-based versions of GNNs, which often surpass the accuracy of MultiLayer Perceptron (MLP)-based GNNs. These models were widely tested on the graph datasets consisting of organic molecules; however, those studies disregarded the inorganic nanomaterials datasets. In this work, we close this gap by applying Kolmogorov-Arnold Graph Neural Networks (KAGNNs) to a recently published large inorganic nanomaterials dataset called CHILI. For this, we adapt and test KAGNNs appropriate for this dataset. Our experiments reveal that on the CHILI datasets, particularly on the CHILI-3K, KAGNNs substantially surpass conventional GNNs in classification, achieving state-of-the-art results.","authors":["Nikita Volzhin","Soowhan Yoon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.15925v3","updated":"2025-12-22T15:37:49Z","published":"2025-05-21T18:24:36Z","title":"VERDI: VLM-Embedded Reasoning for Autonomous Driving","summary":"While autonomous driving (AD) stacks struggle with decision making under partial observability and real-world complexity, human drivers are capable of commonsense reasoning to make near-optimal decisions with limited information. Recent work has attempted to leverage finetuned Vision-Language Models (VLMs) for trajectory planning at inference time to emulate human behavior. Despite their success in benchmark evaluations, these methods are often impractical to deploy (a 70B parameter VLM inference at merely 8 tokens per second requires more than 160G of memory), and their monolithic network structure prohibits safety decomposition. To bridge this gap, we propose VLM-Embedded Reasoning for autonomous Driving (VERDI), a training-time framework that distills the reasoning process and commonsense knowledge of VLMs into the AD stack. VERDI augments modular differentiable end-to-end (e2e) AD models by aligning intermediate module outputs at the perception, prediction, and planning stages with text features explaining the driving reasoning process produced by VLMs. By encouraging alignment in latent space, VERDI enables the modular AD stack to internalize structured reasoning, without incurring the inference-time costs of large VLMs. We validate VERDI in both open-loop (NuScenes and Bench2Drive benchmarks) and closed-loop (HugSim Simulator) settings. We find that VERDI outperforms existing e2e methods that do not embed reasoning by up to 11% in $\\ell_{2}$ distance and 11% in driving performance, while maintaining real-time inference speed.","authors":["Bowen Feng","Zhiting Mei","Baiang Li","Julian Ost","Filippo Ghilotti","Roger Girgis","Anirudha Majumdar","Felix Heide"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19481v1","updated":"2025-12-22T15:32:45Z","published":"2025-12-22T15:32:45Z","title":"A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis","summary":"Understanding source code changes and their impact on other code entities is a crucial skill in software development. However, the analysis of code changes and their impact is often performed manually and therefore is time-consuming. Recent advancements in AI, and in particular large language models (LLMs) show promises to help developers in various code analysis tasks. However, the extent to which this potential can be utilized for understanding code changes and their impact is underexplored. To address this gap, we study the capabilities of GPT-5 and GPT-5-mini to predict the code entities impacted by given source code changes. We construct a dataset containing information about seed-changes, change pairs, and change types for each commit. Existing datasets lack crucial information about seed changes and impacted code entities. Our experiments evaluate the LLMs in two configurations: (1) seed-change information and the parent commit tree and (2) seed-change information, the parent commit tree, and the diff hunk of each seed change. We found that both LLMs perform poorly in the two experiments, whereas GPT-5 outperforms GPT-5-mini. Furthermore, the provision of the diff hunks helps both models to slightly improve their performance.","authors":["Katharina Stengg","Christian Macho","Martin Pinzger"],"pdf_url":"","comment":"6 pages"},{"id":"http://arxiv.org/abs/2512.19472v1","updated":"2025-12-22T15:25:10Z","published":"2025-12-22T15:25:10Z","title":"Multi-Layer Confidence Scoring for Detection of Out-of-Distribution Samples, Adversarial Attacks, and In-Distribution Misclassifications","summary":"The recent explosive growth in Deep Neural Networks applications raises concerns about the black-box usage of such models, with limited trasparency and trustworthiness in high-stakes domains, which have been crystallized as regulatory requirements such as the European Union Artificial Intelligence Act. While models with embedded confidence metrics have been proposed, such approaches cannot be applied to already existing models without retraining, limiting their broad application. On the other hand, post-hoc methods, which evaluate pre-trained models, focus on solving problems related to improving the confidence in the model's predictions, and detecting Out-Of-Distribution or Adversarial Attacks samples as independent applications. To tackle the limited applicability of already existing methods, we introduce Multi-Layer Analysis for Confidence Scoring (MACS), a unified post-hoc framework that analyzes intermediate activations to produce classification-maps. From the classification-maps, we derive a score applicable for confidence estimation, detecting distributional shifts and adversarial attacks, unifying the three problems in a common framework, and achieving performances that surpass the state-of-the-art approaches in our experiments with the VGG16 and ViTb16 models with a fraction of their computational overhead.","authors":["Lorenzo Capelli","Leandro de Souza Rosa","Gianluca Setti","Mauro Mangia","Riccardo Rovatti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.16416v2","updated":"2025-12-22T15:14:59Z","published":"2025-10-18T09:22:40Z","title":"SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning","summary":"Vision-language models (VLMs) have shown remarkable abilities by integrating large language models with visual inputs. However, they often fail to utilize visual evidence adequately, either depending on linguistic priors in vision-centric tasks or resorting to textual shortcuts during reasoning. Although reinforcement learning (RL) can align models with desired behaviors, its application to VLMs has been hindered by the lack of scalable and reliable reward mechanisms. To overcome this challenge, we propose SSL4RL, a novel framework that leverages self-supervised learning (SSL) tasks as a source of verifiable rewards for RL-based fine-tuning. Our approach reformulates SSL objectives-such as predicting image rotation or reconstructing masked patches-into dense, automatic reward signals, eliminating the need for human preference data or unreliable AI evaluators. Experiments show that SSL4RL substantially improves performance on both vision-centric and vision-language reasoning benchmarks. Furthermore, through systematic ablations, we identify key factors-such as task difficulty, model scale, and semantic alignment with the target domain-that influence the effectiveness of SSL4RL tasks, offering new design principles for future work. We also demonstrate the framework's generality by applying it to graph learning, where it yields significant gains. SSL4RL establishes a versatile and effective paradigm for aligning multimodal models using verifiable, self-supervised objectives.","authors":["Xiaojun Guo","Runyu Zhou","Yifei Wang","Qi Zhang","Chenheng Zhang","Stefanie Jegelka","Xiaohan Wang","Jiajun Chai","Guojun Yin","Wei Lin","Yisen Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19458v1","updated":"2025-12-22T15:03:57Z","published":"2025-12-22T15:03:57Z","title":"An Agentic Framework for Autonomous Materials Computation","summary":"Large Language Models (LLMs) have emerged as powerful tools for accelerating scientific discovery, yet their static knowledge and hallucination issues hinder autonomous research applications. Recent advances integrate LLMs into agentic frameworks, enabling retrieval, reasoning, and tool use for complex scientific workflows. Here, we present a domain-specialized agent designed for reliable automation of first-principles materials computations. By embedding domain expertise, the agent ensures physically coherent multi-step workflows and consistently selects convergent, well-posed parameters, thereby enabling reliable end-to-end computational execution. A new benchmark of diverse computational tasks demonstrates that our system significantly outperforms standalone LLMs in both accuracy and robustness. This work establishes a verifiable foundation for autonomous computational experimentation and represents a key step toward fully automated scientific discovery.","authors":["Zeyu Xia","Jinzhe Ma","Congjie Zheng","Shufei Zhang","Yuqiang Li","Hang Su","P. Hu","Changshui Zhang","Xingao Gong","Wanli Ouyang","Lei Bai","Dongzhan Zhou","Mao Su"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19456v1","updated":"2025-12-22T15:01:07Z","published":"2025-12-22T15:01:07Z","title":"Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations","summary":"Automated essay scoring (AES) is a challenging task in cross-prompt settings due to the diversity of scoring criteria. While previous studies have focused on the output of large language models (LLMs) to improve scoring accuracy, we believe activations from intermediate layers may also provide valuable information. To explore this possibility, we evaluated the discriminative power of LLMs' activations in cross-prompt essay scoring task. Specifically, we used activations to fit probes and further analyzed the effects of different models and input content of LLMs on this discriminative power. By computing the directions of essays across various trait dimensions under different prompts, we analyzed the variation in evaluation perspectives of large language models concerning essay types and traits. Results show that the activations possess strong discriminative power in evaluating essay quality and that LLMs can adapt their evaluation perspectives to different traits and essay types, effectively handling the diversity of scoring criteria in cross-prompt settings.","authors":["Jinwei Chi","Ke Wang","Yu Chen","Xuanye Lin","Qiang Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.10566v5","updated":"2025-12-22T14:46:47Z","published":"2024-08-20T06:05:52Z","title":"Overcoming Growth-Induced Forgetting in Task-Agnostic Continual Learning","summary":"In continual learning (CL), model growth enhances adaptability to new data. However, when model growth is applied improperly, especially in task-agnostic CL, where the entire grown model is used for inference, it can lead to severe degradation of learned knowledge, a problem we term growth-induced forgetting. Most existing methods that adopt model growth to improve adaptability often overlook the forgetting issue, resulting in compromised knowledge retention, making them unsuitable for task-agnostic settings. To promote both adaptability and knowledge retention with model growth, we identify the key: gradient and parameter sparsity. Introducing SparseGrow, which increases gradient sparsity through layer expansion and gradient gating to enable focused updates on parameters while preserving critical parameters, thus inhibiting forgetting. Moreover, it promotes parameter sparsity with sparse initialization and training, aiming at better control of model plasticity, improving adaptability over new data. Extensive experiments across diverse datasets, task-agnostic settings, and a large number of tasks demonstrate the necessity of controlled layer expansion and validate the effectiveness of SparseGrow in achieving high adaptability while minimizing forgetting in continual learning. By enabling model growth with sparsified gradients and parameters, SparseGrow paves the way for building scalable lifelong learning systems capable of continual adaptation with better knowledge retention.","authors":["Yuqing Zhao","Jiannong Cao","Divya Saxena","Xiaoyun Liu","Changlin Song","Bo Yuan","Julie McCann"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14396v4","updated":"2025-12-22T14:45:53Z","published":"2025-11-18T12:01:06Z","title":"Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning","summary":"Language-conditioned manipulation facilitates human-robot interaction via behavioral cloning (BC), which learns control policies from human demonstrations and serves as a cornerstone of embodied AI. Overcoming compounding errors in sequential action decisions remains a central challenge to improving BC performance. Existing approaches mitigate compounding errors through data augmentation, expressive representation, or temporal abstraction. However, they suffer from physical discontinuities and semantic-physical misalignment, leading to inaccurate action cloning and intermittent execution. In this paper, we present Continuous vision-language-action Co-Learning with Semantic-Physical Alignment (CCoL), a novel BC framework that ensures temporally consistent execution and fine-grained semantic grounding. It generates robust and smooth action execution trajectories through continuous co-learning across vision, language, and proprioceptive inputs (e.g., robot internal states). Meanwhile, we anchor language semantics to visuomotor representations by a bidirectional cross-attention to learn contextual information for action generation, successfully overcoming the problem of semantic-physical misalignment. Extensive experiments show that CCoL achieves an average 8.0% relative improvement across three simulation suites, with up to 19.2% relative gain in human-demonstrated bimanual insertion tasks. Real-world tests on a 7-DoF robot further confirm CCoL's generalization under unseen and noisy object states.","authors":["Xiuxiu Qi","Yu Yang","Jiannong Cao","Luyao Bai","Chongshan Fan","Chengtai Cao","Hongpeng Wang"],"pdf_url":"","comment":"Accepted at AAAI 2026, the Project website is available at https://qhemu.github.io/CCoL/"},{"id":"http://arxiv.org/abs/2512.19438v1","updated":"2025-12-22T14:36:08Z","published":"2025-12-22T14:36:08Z","title":"MT-Mark: Rethinking Image Watermarking via Mutual-Teacher Collaboration with Adaptive Feature Modulation","summary":"Existing deep image watermarking methods follow a fixed embedding-distortion-extraction pipeline, where the embedder and extractor are weakly coupled through a final loss and optimized in isolation. This design lacks explicit collaboration, leaving no structured mechanism for the embedder to incorporate decoding-aware cues or for the extractor to guide embedding during training. To address this architectural limitation, we rethink deep image watermarking by reformulating embedding and extraction as explicitly collaborative components. To realize this reformulation, we introduce a Collaborative Interaction Mechanism (CIM) that establishes direct, bidirectional communication between the embedder and extractor, enabling a mutual-teacher training paradigm and coordinated optimization. Built upon this explicitly collaborative architecture, we further propose an Adaptive Feature Modulation Module (AFMM) to support effective interaction. AFMM enables content-aware feature regulation by decoupling modulation structure and strength, guiding watermark embedding toward stable image features while suppressing host interference during extraction. Under CIM, the AFMMs on both sides form a closed-loop collaboration that aligns embedding behavior with extraction objectives. This architecture-level redesign changes how robustness is learned in watermarking systems. Rather than relying on exhaustive distortion simulation, robustness emerges from coordinated representation learning between embedding and extraction. Experiments on real-world and AI-generated datasets demonstrate that the proposed method consistently outperforms state-of-the-art approaches in watermark extraction accuracy while maintaining high perceptual quality, showing strong robustness and generalization.","authors":["Fei Ge","Ying Huang","Jie Liu","Guixuan Zhang","Zhi Zeng","Shuwu Zhang","Hu Guan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.18822v2","updated":"2025-12-22T14:30:53Z","published":"2025-05-24T18:46:50Z","title":"AdaCtrl: Towards Adaptive and Controllable Reasoning via Difficulty-Aware Budgeting","summary":"Modern large reasoning models demonstrate impressive problem-solving capabilities by employing sophisticated reasoning strategies. However, they often struggle to balance efficiency and effectiveness, frequently generating unnecessarily lengthy reasoning chains for simple problems. In this work, we propose AdaCtrl, a novel framework to support both difficulty-aware adaptive reasoning budget allocation and explicit user control over reasoning depth. AdaCtrl dynamically adjusts its reasoning length based on self-assessed problem difficulty, while also allowing users to manually control the budget to prioritize either efficiency or effectiveness. This is achieved through a two-stage training pipeline: an initial cold-start fine-tuning phase to instill the ability to self-aware difficulty and adjust reasoning budget, followed by a difficulty-aware reinforcement learning (RL) stage that refines the model's adaptive reasoning strategies and calibrates its difficulty assessments based on its evolving capabilities during online training. To enable intuitive user interaction, we design explicit length-triggered tags that function as a natural interface for budget control. Empirical results show that AdaCtrl adapts reasoning length based on estimated difficulty, compared to the standard training baseline that also incorporates fine-tuning and RL, it yields performance improvements and simultaneously reduces response length by 10.06% and 12.14% on the more challenging AIME2024 and AIME2025 datasets, which require elaborate reasoning, and by 62.05% and 91.04% on the MATH500 and GSM8K datasets, where more concise responses are sufficient. Furthermore, AdaCtrl enables precise user control over the reasoning budget, allowing for tailored responses to meet specific needs.","authors":["Shijue Huang","Hongru Wang","Wanjun Zhong","Zhaochen Su","Jiazhan Feng","Bowen Cao","Yi R. Fung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19428v1","updated":"2025-12-22T14:29:18Z","published":"2025-12-22T14:29:18Z","title":"Attention Is Not What You Need","summary":"We revisit a basic question in sequence modeling: is explicit self-attention actually necessary for strong performance and reasoning? We argue that standard multi-head attention is best seen as a form of tensor lifting: hidden vectors are mapped into a high-dimensional space of pairwise interactions, and learning proceeds by constraining this lifted tensor through gradient descent. This mechanism is extremely expressive but mathematically opaque, because after many layers it becomes very hard to describe the model with a small family of explicit invariants.\n  To explore an alternative, we propose an attention-free architecture based on Grassmann flows. Instead of forming an L by L attention matrix, our Causal Grassmann layer (i) linearly reduces token states, (ii) encodes local token pairs as two-dimensional subspaces on a Grassmann manifold via Plucker coordinates, and (iii) fuses these geometric features back into the hidden states through gated mixing. Information therefore propagates by controlled deformations of low-rank subspaces over multi-scale local windows, so the core computation lives on a finite-dimensional manifold rather than in an unstructured tensor space.\n  On the Wikitext-2 language modeling benchmark, purely Grassmann-based models with 13 to 18 million parameters achieve validation perplexities within about 10 to 15 percent of size-matched Transformers. On the SNLI natural language inference task, a Grassmann-Plucker head on top of DistilBERT slightly outperforms a Transformer head, with best validation and test accuracies of 0.8550 and 0.8538 compared to 0.8545 and 0.8511. We analyze the complexity of Grassmann mixing, show linear scaling in sequence length for fixed rank, and argue that such manifold-based designs offer a more structured route toward geometric and invariant-based interpretations of neural reasoning.","authors":["Zhang Chong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.15735v2","updated":"2025-12-22T14:25:02Z","published":"2025-12-05T22:52:22Z","title":"Deep Reinforcement Learning Optimization for Uncertain Nonlinear Systems via Event-Triggered Robust Adaptive Dynamic Programming","summary":"This work proposes a unified control architecture that couples a Reinforcement Learning (RL)-driven controller with a disturbance-rejection Extended State Observer (ESO), complemented by an Event-Triggered Mechanism (ETM) to limit unnecessary computations. The ESO is utilized to estimate the system states and the lumped disturbance in real time, forming the foundation for effective disturbance compensation. To obtain near-optimal behavior without an accurate system description, a value-iteration-based Adaptive Dynamic Programming (ADP) method is adopted for policy approximation. The inclusion of the ETM ensures that parameter updates of the learning module are executed only when the state deviation surpasses a predefined bound, thereby preventing excessive learning activity and substantially reducing computational load. A Lyapunov-oriented analysis is used to characterize the stability properties of the resulting closed-loop system. Numerical experiments further confirm that the developed approach maintains strong control performance and disturbance tolerance, while achieving a significant reduction in sampling and processing effort compared with standard time-triggered ADP schemes.","authors":["Ningwei Bai","Chi Pui Chan","Qichen Yin","Tengyang Gong","Yunda Yan","Zezhi Tang"],"pdf_url":"","comment":"we have identified some technical issues, including the mathematical derivation. After discussion, all authors have agreed that the analysis requires a thorough re-derivation to ensure correctness and rigor"},{"id":"http://arxiv.org/abs/2512.19410v1","updated":"2025-12-22T14:05:31Z","published":"2025-12-22T14:05:31Z","title":"Research Program: Theory of Learning in Dynamical Systems","summary":"Modern learning systems increasingly interact with data that evolve over time and depend on hidden internal state. We ask a basic question: when is such a dynamical system learnable from observations alone? This paper proposes a research program for understanding learnability in dynamical systems through the lens of next-token prediction. We argue that learnability in dynamical systems should be studied as a finite-sample question, and be based on the properties of the underlying dynamics rather than the statistical properties of the resulting sequence. To this end, we give a formulation of learnability for stochastic processes induced by dynamical systems, focusing on guarantees that hold uniformly at every time step after a finite burn-in period. This leads to a notion of dynamic learnability which captures how the structure of a system, such as stability, mixing, observability, and spectral properties, governs the number of observations required before reliable prediction becomes possible. We illustrate the framework in the case of linear dynamical systems, showing that accurate prediction can be achieved after finite observation without system identification, by leveraging improper methods based on spectral filtering. We survey the relationship between learning in dynamical systems and classical PAC, online, and universal prediction theories, and suggest directions for studying nonlinear and controlled systems.","authors":["Elad Hazan","Shai Shalev Shwartz","Nathan Srebro"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.14031v5","updated":"2025-12-22T13:49:48Z","published":"2024-12-18T16:51:47Z","title":"A Riemannian Optimization Perspective of the Gauss-Newton Method for Feedforward Neural Networks","summary":"In this work, we establish non-asymptotic convergence bounds for the Gauss-Newton method in training neural networks with smooth activations. In the underparameterized regime, the Gauss-Newton gradient flow in parameter space induces a Riemannian gradient flow on a low-dimensional embedded submanifold of the function space. Using tools from Riemannian optimization, we establish geodesic Polyak-Lojasiewicz and Lipschitz-smoothness conditions for the loss under appropriately chosen output scaling, yielding geometric convergence to the optimal in-class predictor at an explicit rate independent of the conditioning of the Gram matrix. In the overparameterized regime, we propose adaptive, curvature-aware regularization schedules that ensure fast geometric convergence to a global optimum at a rate independent of the minimum eigenvalue of the neural tangent kernel and, locally, of the modulus of strong convexity of the loss. These results demonstrate that Gauss-Newton achieves accelerated convergence rates in settings where first-order methods exhibit slow convergence due to ill-conditioned kernel matrices and loss landscapes.","authors":["Semih Cayci"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.10190v2","updated":"2025-12-22T13:46:47Z","published":"2025-01-17T13:37:58Z","title":"Temporal Causal Reasoning with (Non-Recursive) Structural Equation Models","summary":"Structural Equation Models (SEM) are the standard approach to representing causal dependencies between variables in causal models. In this paper we propose a new interpretation of SEMs when reasoning about Actual Causality, in which SEMs are viewed as mechanisms transforming the dynamics of exogenous variables into the dynamics of endogenous variables. This allows us to combine counterfactual causal reasoning with existing temporal logic formalisms, and to introduce a temporal logic, CPLTL, for causal reasoning about such structures. We show that the standard restriction to so-called \\textit{recursive} models (with no cycles in the dependency graph) is not necessary in our approach, allowing us to reason about mutually dependent processes and feedback loops. Finally, we introduce new notions of model equivalence for temporal causal models, and show that CPLTL has an efficient model-checking procedure.","authors":["Maksim Gladyshev","Natasha Alechina","Mehdi Dastani","Dragan Doder","Brian Logan"],"pdf_url":"","comment":"This is an extended version of the same title paper published in the proceeding of AAAI-25 conference (Gladyshev et al. 2025). This version contains an additional section, in which we introduce TSEMs with arbitrary long temporal delays between causal dependencies and prove that these models are equivalent to TSEMs with 1-step delays only introduced in the original version of the paper"},{"id":"http://arxiv.org/abs/2512.19396v1","updated":"2025-12-22T13:42:18Z","published":"2025-12-22T13:42:18Z","title":"EchoTrail-GUI: Building Actionable Memory for GUI Agents via Critic-Guided Self-Exploration","summary":"Contemporary GUI agents, while increasingly capable due to advances in Large Vision-Language Models (VLMs), often operate with a critical limitation: they treat each task in isolation, lacking a mechanism to systematically learn from past successes. This digital ''amnesia'' results in sub-optimal performance, repeated errors, and poor generalization to novel challenges. To bridge this gap, we introduce EchoTrail-GUI, a novel framework designed to mimic human-like experiential learning by equipping agents with a dynamic, accessible memory. Our framework operates in three distinct stages. First, during Experience Exploration, an agent autonomously interacts with GUI environments to build a curated database of successful task trajectories, validated by a reward model. Crucially, the entire knowledge base construction is thus fully automated, requiring no human supervision. Second, in the Memory Injection stage, upon receiving a new task, our system efficiently retrieves the most relevant past trajectories to serve as actionable ''memories''. Finally, during GUI Task Inference, these memories are injected as in-context guidance to inform the agent's reasoning and decision-making process. We demonstrate the efficacy of our approach on benchmarks including Android World and AndroidLab. The results show that EchoTrail-GUI significantly improves the task success rate and operational efficiency of baseline agents, validating the power of structured memory in creating more robust and intelligent GUI automation.","authors":["Runze Li","Yuwen Zhai","Bo Xu","LiWu Xu","Nian Shi","Wei Zhang","Ran Lin","Liang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.13907v2","updated":"2025-12-22T13:38:32Z","published":"2025-12-15T21:24:29Z","title":"Assessing High-Risk AI Systems under the EU AI Act: From Legal Requirements to Technical Verification","summary":"The implementation of the AI Act requires practical mechanisms to verify compliance with legal obligations, yet concrete and operational mappings from high-level requirements to verifiable assessment activities remain limited, contributing to uneven readiness across Member States. This paper presents a structured mapping that translates high-level AI Act requirements into concrete, implementable verification activities applicable across the AI lifecycle. The mapping is derived through a systematic process in which legal requirements are decomposed into operational sub-requirements and grounded in authoritative standards and recognised practices. From this basis, verification activities are identified and characterised along two dimensions: the type of verification performed and the lifecycle target to which it applies. By making explicit the link between regulatory intent and technical and organisational assurance practices, the proposed mapping reduces interpretive uncertainty and provides a reusable reference for consistent, technology-agnostic compliance verification under the AI Act.","authors":["Alessio Buscemi","Tom Deckenbrunnen","Fahria Kabir","Kateryna Mishchenko","Nishat Mowla"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19387v1","updated":"2025-12-22T13:36:26Z","published":"2025-12-22T13:36:26Z","title":"DSTED: Decoupling Temporal Stabilization and Discriminative Enhancement for Surgical Workflow Recognition","summary":"Purpose: Surgical workflow recognition enables context-aware assistance and skill assessment in computer-assisted interventions. Despite recent advances, current methods suffer from two critical challenges: prediction jitter across consecutive frames and poor discrimination of ambiguous phases. This paper aims to develop a stable framework by selectively propagating reliable historical information and explicitly modeling uncertainty for hard sample enhancement.\n  Methods: We propose a dual-pathway framework DSTED with Reliable Memory Propagation (RMP) and Uncertainty-Aware Prototype Retrieval (UPR). RMP maintains temporal coherence by filtering and fusing high-confidence historical features through multi-criteria reliability assessment. UPR constructs learnable class-specific prototypes from high-uncertainty samples and performs adaptive prototype matching to refine ambiguous frame representations. Finally, a confidence-driven gate dynamically balances both pathways based on prediction certainty.\n  Results: Our method achieves state-of-the-art performance on AutoLaparo-hysterectomy with 84.36% accuracy and 65.51% F1-score, surpassing the second-best method by 3.51% and 4.88% respectively. Ablations reveal complementary gains from RMP (2.19%) and UPR (1.93%), with synergistic effects when combined. Extensive analysis confirms substantial reduction in temporal jitter and marked improvement on challenging phase transitions.\n  Conclusion: Our dual-pathway design introduces a novel paradigm for stable workflow recognition, demonstrating that decoupling the modeling of temporal consistency and phase ambiguity yields superior performance and clinical applicability.","authors":["Yueyao Chen","Kai-Ni Wang","Dario Tayupo","Arnaud Huaulm'e","Krystel Nyangoh Timoh","Pierre Jannin","Qi Dou"],"pdf_url":"","comment":"Early accepted to IPCAI 2026"},{"id":"http://arxiv.org/abs/2408.11607v3","updated":"2025-12-22T13:33:03Z","published":"2024-08-21T13:32:46Z","title":"Networked Communication for Mean-Field Games with Function Approximation and Empirical Mean-Field Estimation","summary":"Recent algorithms allow decentralised agents, possibly connected via a communication network, to learn equilibria in mean-field games from a non-episodic run of the empirical system. However, these algorithms are for tabular settings: this computationally limits the size of agents' observation space, meaning the algorithms cannot handle anything but small state spaces, nor generalise beyond policies depending only on the agent's local state to so-called 'population-dependent' policies. We address this limitation by introducing function approximation to the existing setting, drawing on the Munchausen Online Mirror Descent method that has previously been employed only in finite-horizon, episodic, centralised settings. While this permits us to include the mean field in the observation for players' policies, it is unrealistic to assume decentralised agents have access to this global information: we therefore also provide new algorithms allowing agents to locally estimate the global empirical distribution, and to improve this estimate via inter-agent communication. We prove theoretically that exchanging policy information helps networked agents outperform both independent and even centralised agents in function-approximation settings. Our experiments demonstrate this happening empirically, and show that the communication network allows decentralised agents to estimate the mean field for population-dependent policies.","authors":["Patrick Benjamin","Alessandro Abate"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2306.02766v6","updated":"2025-12-22T13:25:46Z","published":"2023-06-05T10:45:39Z","title":"Networked Communication for Decentralised Agents in Mean-Field Games","summary":"Methods like multi-agent reinforcement learning struggle to scale with growing population size. Mean-field games (MFGs) are a game-theoretic approach that can circumvent this by finding a solution for an abstract infinite population, which can then be used as an approximate solution for the $N$-agent problem. However, classical mean-field algorithms usually only work under restrictive conditions. We take steps to address this by introducing networked communication to MFGs, in particular to settings that use a single, non-episodic run of $N$ decentralised agents to simulate the infinite population, as is likely to be most reasonable in real-world deployments. We prove that our architecture's sample guarantees lie between those of earlier theoretical algorithms for the centralised- and independent-learning architectures, varying dependent on network structure and the number of communication rounds. However, the sample guarantees of the three theoretical algorithms do not actually result in practical convergence times. We thus contribute practical enhancements to all three algorithms allowing us to present their first empirical demonstrations. We then show that in practical settings where the theoretical hyperparameters are not observed, giving fewer loops but poorer estimation of the Q-function, our communication scheme still respects the earlier theoretical analysis: it considerably accelerates learning over the independent case, which hardly seems to learn at all, and often performs similarly to the centralised case, while removing the restrictive assumption of the latter. We provide ablations and additional studies showing that our networked approach also has advantages over both alternatives in terms of robustness to update failures and to changes in population size.","authors":["Patrick Benjamin","Alessandro Abate"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19379v1","updated":"2025-12-22T13:23:55Z","published":"2025-12-22T13:23:55Z","title":"OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation","summary":"Indonesian, spoken by over 200 million people, remains underserved in multimodal emotion recognition research despite its dominant presence on Southeast Asian social media platforms. We introduce IndoMER, the first multimodal emotion recognition benchmark for Indonesian, comprising 1,944 video segments from 203 speakers with temporally aligned text, audio, and visual annotations across seven emotion categories. The dataset exhibits realistic challenges including cross-modal inconsistency and long-tailed class distributions shaped by Indonesian cultural communication norms. To address these challenges, we propose OmniMER, a multimodal adaptation framework built upon Qwen2.5-Omni that enhances emotion recognition through three auxiliary modality-specific perception tasks: emotion keyword extraction for text, facial expression analysis for video, and prosody analysis for audio. These auxiliary tasks help the model identify emotion-relevant cues in each modality before fusion, reducing reliance on spurious correlations in low-resource settings. Experiments on IndoMER show that OmniMER achieves 0.582 Macro-F1 on sentiment classification and 0.454 on emotion recognition, outperforming the base model by 7.6 and 22.1 absolute points respectively. Cross-lingual evaluation on the Chinese CH-SIMS dataset further demonstrates the generalizability of the proposed framework. The dataset and code are publicly available. https://github.com/yanxm01/INDOMER","authors":["Xueming Yan","Boyan Xu","Yaochu Jin","Lixian Xiao","Wenlong Ye","Runyang Cai","Zeqi Zheng","Jingfa Liu","Aimin Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19367v1","updated":"2025-12-22T13:09:45Z","published":"2025-12-22T13:09:45Z","title":"Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture","summary":"We present Sprecher Networks (SNs), a family of trainable neural architectures inspired by the classical Kolmogorov-Arnold-Sprecher (KAS) construction for approximating multivariate continuous functions. Distinct from Multi-Layer Perceptrons (MLPs) with fixed node activations and Kolmogorov-Arnold Networks (KANs) featuring learnable edge activations, SNs utilize shared, learnable splines (monotonic and general) within structured blocks incorporating explicit shift parameters and mixing weights. Our approach directly realizes Sprecher's specific 1965 sum of shifted splines formula in its single-layer variant and extends it to deeper, multi-layer compositions. We further enhance the architecture with optional lateral mixing connections that enable intra-block communication between output dimensions, providing a parameter-efficient alternative to full attention mechanisms. Beyond parameter efficiency with $O(LN + LG)$ scaling (where $G$ is the knot count of the shared splines) versus MLPs' $O(LN^2)$, SNs admit a sequential evaluation strategy that reduces peak forward-intermediate memory from $O(N^2)$ to $O(N)$ (treating batch size as constant), making much wider architectures feasible under memory constraints. We demonstrate empirically that composing these blocks into deep networks leads to highly parameter and memory-efficient models, discuss theoretical motivations, and compare SNs with related architectures (MLPs, KANs, and networks with learnable node activations).","authors":["Christian Hägg","Kathlén Kohn","Giovanni Luca Marchetti","Boris Shapiro"],"pdf_url":"","comment":"37 pages"},{"id":"http://arxiv.org/abs/2512.19366v1","updated":"2025-12-22T13:08:58Z","published":"2025-12-22T13:08:58Z","title":"Learning General Policies with Policy Gradient Methods","summary":"While reinforcement learning methods have delivered remarkable results in a number of settings, generalization, i.e., the ability to produce policies that generalize in a reliable and systematic way, has remained a challenge. The problem of generalization has been addressed formally in classical planning where provable correct policies that generalize over all instances of a given domain have been learned using combinatorial methods. The aim of this work is to bring these two research threads together to illuminate the conditions under which (deep) reinforcement learning approaches, and in particular, policy optimization methods, can be used to learn policies that generalize like combinatorial methods do. We draw on lessons learned from previous combinatorial and deep learning approaches, and extend them in a convenient way. From the former, we model policies as state transition classifiers, as (ground) actions are not general and change from instance to instance. From the latter, we use graph neural networks (GNNs) adapted to deal with relational structures for representing value functions over planning states, and in our case, policies. With these ingredients in place, we find that actor-critic methods can be used to learn policies that generalize almost as well as those obtained using combinatorial approaches while avoiding the scalability bottleneck and the use of feature pools. Moreover, the limitations of the DRL methods on the benchmarks considered have little to do with deep learning or reinforcement learning algorithms, and result from the well-understood expressive limitations of GNNs, and the tradeoff between optimality and generalization (general policies cannot be optimal in some domains). Both of these limitations are addressed without changing the basic DRL methods by adding derived predicates and an alternative cost structure to optimize.","authors":["Simon Ståhlberg","Blai Bonet","Hector Geffner"],"pdf_url":"","comment":"In Proceedings of the 20th International Conference on Principles of Knowledge Representation and Reasoning (KR 2023)"},{"id":"http://arxiv.org/abs/2512.19355v1","updated":"2025-12-22T12:54:32Z","published":"2025-12-22T12:54:32Z","title":"First-Order Representation Languages for Goal-Conditioned RL","summary":"First-order relational languages have been used in MDP planning and reinforcement learning (RL) for two main purposes: specifying MDPs in compact form, and representing and learning policies that are general and not tied to specific instances or state spaces. In this work, we instead consider the use of first-order languages in goal-conditioned RL and generalized planning. The question is how to learn goal-conditioned and general policies when the training instances are large and the goal cannot be reached by random exploration alone. The technique of Hindsight Experience Replay (HER) provides an answer to this question: it relabels unsuccessful trajectories as successful ones by replacing the original goal with one that was actually achieved. If the target policy must generalize across states and goals, trajectories that do not reach the original goal states can enable more data- and time-efficient learning. In this work, we show that further performance gains can be achieved when states and goals are represented by sets of atoms. We consider three versions: goals as full states, goals as subsets of the original goals, and goals as lifted versions of these subgoals. The result is that the latter two successfully learn general policies on large planning instances with sparse rewards by automatically creating a curriculum of easier goals of increasing complexity. The experiments illustrate the computational gains of these versions, their limitations, and opportunities for addressing them.","authors":["Simon Ståhlberg","Hector Geffner"],"pdf_url":"","comment":"In Proceedings of the 40th AAAI Conference on Artificial Intelligence (AAAI 2026)"},{"id":"http://arxiv.org/abs/2512.19350v1","updated":"2025-12-22T12:49:12Z","published":"2025-12-22T12:49:12Z","title":"PENDULUM: A Benchmark for Assessing Sycophancy in Multimodal Large Language Models","summary":"Sycophancy, an excessive tendency of AI models to agree with user input at the expense of factual accuracy or in contradiction of visual evidence, poses a critical and underexplored challenge for multimodal large language models (MLLMs). While prior studies have examined this behavior in text-only settings of large language models, existing research on visual or multimodal counterparts remains limited in scope and depth of analysis. To address this gap, we introduce a comprehensive evaluation benchmark, \\textit{PENDULUM}, comprising approximately 2,000 human-curated Visual Question Answering pairs specifically designed to elicit sycophantic responses. The benchmark spans six distinct image domains of varying complexity, enabling a systematic investigation of how image type and inherent challenges influence sycophantic tendencies. Through extensive evaluation of state-of-the-art MLLMs. we observe substantial variability in model robustness and a pronounced susceptibility to sycophantic and hallucinatory behavior. Furthermore, we propose novel metrics to quantify sycophancy in visual reasoning, offering deeper insights into its manifestations across different multimodal contexts. Our findings highlight the urgent need for developing sycophancy-resilient architectures and training strategies to enhance factual consistency and reliability in future MLLMs. Our proposed dataset with MLLMs response are available at https://github.com/ashikiut/pendulum/.","authors":["A. B. M. Ashikur Rahman","Saeed Anwar","Muhammad Usman","Irfan Ahmad","Ajmal Mian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02864v3","updated":"2025-12-22T12:49:01Z","published":"2025-11-03T16:04:07Z","title":"Mathematical exploration and discovery at scale","summary":"AlphaEvolve (Novikov et al., 2025) is a generic evolutionary coding agent that combines the generative capabilities of LLMs with automated evaluation in an iterative evolutionary framework that proposes, tests, and refines algorithmic solutions to challenging scientific and practical problems. In this paper we showcase AlphaEvolve as a tool for autonomously discovering novel mathematical constructions and advancing our understanding of long-standing open problems.\n  To demonstrate its breadth, we considered a list of 67 problems spanning mathematical analysis, combinatorics, geometry, and number theory. The system rediscovered the best known solutions in most of the cases and discovered improved solutions in several. In some instances, AlphaEvolve is also able to generalize results for a finite number of input values into a formula valid for all input values. Furthermore, we are able to combine this methodology with Deep Think and AlphaProof in a broader framework where the additional proof-assistants and reasoning systems provide automated proof generation and further mathematical insights.\n  These results demonstrate that large language model-guided evolutionary search can autonomously discover mathematical constructions that complement human intuition, at times matching or even improving the best known results, highlighting the potential for significant new ways of interaction between mathematicians and AI systems. We present AlphaEvolve as a powerful new tool for mathematical discovery, capable of exploring vast search spaces to solve complex optimization problems at scale, often with significantly reduced requirements on preparation and computation time.","authors":["Bogdan Georgiev","Javier Gómez-Serrano","Terence Tao","Adam Zsolt Wagner"],"pdf_url":"","comment":"81 pages, 35 figures"},{"id":"http://arxiv.org/abs/2512.19349v1","updated":"2025-12-22T12:48:29Z","published":"2025-12-22T12:48:29Z","title":"VIGOR+: Iterative Confounder Generation and Validation via LLM-CEVAE Feedback Loop","summary":"Hidden confounding remains a fundamental challenge in causal inference from observational data. Recent advances leverage Large Language Models (LLMs) to generate plausible hidden confounders based on domain knowledge, yet a critical gap exists: LLM-generated confounders often exhibit semantic plausibility without statistical utility. We propose VIGOR+ (Variational Information Gain for iterative cOnfounder Refinement), a novel framework that closes the loop between LLM-based confounder generation and CEVAE-based statistical validation. Unlike prior approaches that treat generation and validation as separate stages, VIGOR+ establishes an iterative feedback mechanism: validation signals from CEVAE (including information gain, latent consistency metrics, and diagnostic messages) are transformed into natural language feedback that guides subsequent LLM generation rounds. This iterative refinement continues until convergence criteria are met. We formalize the feedback mechanism, prove convergence properties under mild assumptions, and provide a complete algorithmic framework.","authors":["JiaWei Zhu","ZiHeng Liu"],"pdf_url":"","comment":"7 pages,1 figure,4 tables"},{"id":"http://arxiv.org/abs/2412.14579v2","updated":"2025-12-22T12:47:43Z","published":"2024-12-19T06:57:37Z","title":"GSRender: Deduplicated Occupancy Prediction via Weakly Supervised 3D Gaussian Splatting","summary":"Weakly-supervised 3D occupancy perception is crucial for vision-based autonomous driving in outdoor environments. Previous methods based on NeRF often face a challenge in balancing the number of samples used. Too many samples can decrease efficiency, while too few can compromise accuracy, leading to variations in the mean Intersection over Union (mIoU) by 5-10 points. Furthermore, even with surrounding-view image inputs, only a single image is rendered from each viewpoint at any given moment. This limitation leads to duplicated predictions, which significantly impacts the practicality of the approach. However, this issue has largely been overlooked in existing research. To address this, we propose GSRender, which uses 3D Gaussian Splatting for weakly-supervised occupancy estimation, simplifying the sampling process. Additionally, we introduce the Ray Compensation module, which reduces duplicated predictions by compensating for features from adjacent frames. Finally, we redesign the dynamic loss to remove the influence of dynamic objects from adjacent frames. Extensive experiments show that our approach achieves SOTA results in RayIoU (+6.0), while also narrowing the gap with 3D- supervised methods. This work lays a solid foundation for weakly-supervised occupancy perception. The code is available at https://github.com/Jasper-sudo-Sun/GSRender.","authors":["Qianpu Sun","Changyong Shu","Sifan Zhou","Runxi Cheng","Yongxian Wei","Zichen Yu","Dawei Yang","Sirui Han","Yuan Chun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.10713v2","updated":"2025-12-22T12:47:11Z","published":"2025-12-11T14:49:56Z","title":"PACIFIC: a framework for generating benchmarks to check Precise Automatically Checked Instruction Following In Code","summary":"Large Language Model (LLM)-based code assistants have emerged as a powerful application of generative AI, demonstrating impressive capabilities in code generation and comprehension. A key requirement for these systems is their ability to accurately follow user instructions. We present Precise Automatically Checked Instruction Following In Code (PACIFIC), a novel framework designed to automatically generate benchmarks that rigorously assess sequential instruction-following and code dry-running capabilities in LLMs, while allowing control over benchmark difficulty. PACIFIC produces benchmark variants with clearly defined expected outputs, enabling straightforward and reliable evaluation through simple output comparisons. In contrast to existing approaches that often rely on tool usage or agentic behavior, our work isolates and evaluates the LLM's intrinsic ability to reason through code behavior step-by-step without execution (dry running) and to follow instructions. Furthermore, our framework mitigates training data contamination by facilitating effortless generation of novel benchmark variations. We validate our framework by generating a suite of benchmarks spanning a range of difficulty levels and evaluating multiple state-of-the-art LLMs. Our results demonstrate that PACIFIC can produce increasingly challenging benchmarks that effectively differentiate instruction-following and dry running capabilities, even among advanced models. Overall, our framework offers a scalable, contamination-resilient methodology for assessing core competencies of LLMs in code-related tasks.","authors":["Itay Dreyfuss","Antonio Abu Nassar","Samuel Ackerman","Axel Ben David","Eitan Farchi","Rami Katan","Orna Raz","Marcel Zalmanovici"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.04978v4","updated":"2025-12-22T12:44:21Z","published":"2025-10-06T16:16:03Z","title":"Aligning Perception, Reasoning, Modeling and Interaction: A Survey on Physical AI","summary":"The rapid advancement of embodied intelligence and world models has intensified efforts to integrate physical laws into AI systems, yet physical perception and symbolic physics reasoning have developed along separate trajectories without a unified bridging framework. This work provides a comprehensive overview of physical AI, establishing clear distinctions between theoretical physics reasoning and applied physical understanding while systematically examining how physics-grounded methods enhance AI's real-world comprehension across structured symbolic reasoning, embodied systems, and generative models. Through rigorous analysis of recent advances, we advocate for intelligent systems that ground learning in both physical principles and embodied reasoning processes, transcending pattern recognition toward genuine understanding of physical laws. Our synthesis envisions next-generation world models capable of explaining physical phenomena and predicting future states, advancing safe, generalizable, and interpretable AI systems. We maintain a continuously updated resource at https://github.com/AI4Phys/Awesome-AI-for-Physics.","authors":["Kun Xiang","Terry Jingchen Zhang","Yinya Huang","Jixi He","Zirong Liu","Yueling Tang","Ruizhe Zhou","Lijing Luo","Youpeng Wen","Xiuwei Chen","Bingqian Lin","Jianhua Han","Hang Xu","Hanhui Li","Bin Dong","Xiaodan Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.07984v3","updated":"2025-12-22T12:27:35Z","published":"2025-12-08T19:15:08Z","title":"Restrictive Hierarchical Semantic Segmentation for Stratified Tooth Layer Detection","summary":"Accurate understanding of anatomical structures is essential for reliably staging certain dental diseases. A way of introducing this within semantic segmentation models is by utilising hierarchy-aware methodologies. However, existing hierarchy-aware segmentation methods largely encode anatomical structure through the loss functions, providing weak and indirect supervision. We introduce a general framework that embeds an explicit anatomical hierarchy into semantic segmentation by coupling a recurrent, level-wise prediction scheme with restrictive output heads and top-down feature conditioning. At each depth of the class tree, the backbone is re-run on the original image concatenated with logits from the previous level. Child class features are conditioned using Feature-wise Linear Modulation of their parent class probabilities, to modulate child feature spaces for fine grained detection. A probabilistic composition rule enforces consistency between parent and descendant classes. Hierarchical loss combines per-level class weighted Dice and cross entropy loss and a consistency term loss, ensuring parent predictions are the sum of their children. We validate our approach on our proposed dataset, TL-pano, containing 194 panoramic radiographs with dense instance and semantic segmentation annotations, of tooth layers and alveolar bone. Utilising UNet and HRNet as donor models across a 5-fold cross validation scheme, the hierarchical variants consistently increase IoU, Dice, and recall, particularly for fine-grained anatomies, and produce more anatomically coherent masks. However, hierarchical variants also demonstrated increased recall over precision, implying increased false positives. The results demonstrate that explicit hierarchical structuring improves both performance and clinical plausibility, especially in low data dental imaging regimes.","authors":["Ryan Banks","Camila Lindoni Azevedo","Hongying Tang","Yunpeng Li"],"pdf_url":"","comment":"Incorrect initial draft was submitted by mistake. Method, results and citations are incorrect"},{"id":"http://arxiv.org/abs/2512.19323v1","updated":"2025-12-22T12:17:47Z","published":"2025-12-22T12:17:47Z","title":"Alternative positional encoding functions for neural transformers","summary":"A key module in neural transformer-based deep architectures is positional encoding. This module enables a suitable way to encode positional information as input for transformer neural layers. This success has been rooted in the use of sinusoidal functions of various frequencies, in order to capture recurrent patterns of differing typical periods. In this work, an alternative set of periodic functions is proposed for positional encoding. These functions preserve some key properties of sinusoidal ones, while they depart from them in fundamental ways. Some tentative experiments are reported, where the original sinusoidal version is substantially outperformed. This strongly suggests that the alternative functions may have a wider use in other transformer architectures.","authors":["Ezequiel Lopez-Rubio","Macoris Decena-Gimenez","Rafael Marcos Luque-Baena"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19320v1","updated":"2025-12-22T12:13:17Z","published":"2025-12-22T12:13:17Z","title":"MAGIC: Achieving Superior Model Merging via Magnitude Calibration","summary":"The proliferation of pre-trained models has given rise to a wide array of specialised, fine-tuned models. Model merging aims to merge the distinct capabilities of these specialised models into a unified model, requiring minimal or even no additional training. A core objective of model merging is to ensure the merged model retains the behavioural characteristics of the specialised models, typically achieved through feature alignment. We identify that features consist of two critical components: direction and magnitude. Prior research has predominantly focused on directional alignment, while the influence of magnitude remains largely neglected, despite its pronounced vulnerability to perturbations introduced by common merging operations (e.g., parameter fusion and sparsification). Such perturbations to magnitude inevitably lead to feature deviations in the merged model from the specialised models, resulting in subsequent performance degradation. To address this, we propose MAGnItude Calibration (MAGIC), a plug-and-play framework that rectifies layer-wise magnitudes in feature and weight spaces, with three variants. Specifically, our Feature Space Calibration (FSC) realigns the merged model's features using a small set of unlabelled data, while Weight Space Calibration (WSC) extends this calibration to the weight space without requiring additional data. Combining these yields Dual Space Calibration (DSC). Comprehensive experiments demonstrate that MAGIC consistently boosts performance across diverse Computer Vision tasks (+4.3% on eight datasets) and NLP tasks (+8.0% on Llama) without additional training. Our code is available at: https://github.com/lyymuwu/MAGIC","authors":["Yayuan Li","Jian Zhang","Jintao Guo","Zihan Cheng","Lei Qi","Yinghuan Shi","Yang Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19317v1","updated":"2025-12-22T12:07:33Z","published":"2025-12-22T12:07:33Z","title":"SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models","summary":"Vision--Language Models (VLMs) show significant promise for Medical Visual Question Answering (VQA), yet their deployment in clinical settings is hindered by severe vulnerability to adversarial attacks. Standard adversarial training, while effective for simpler tasks, often degrades both generalization performance and the quality of generated clinical reasoning. We introduce SafeMed-R1, a hybrid defense framework that ensures robust performance while preserving high-quality, interpretable medical reasoning. SafeMed-R1 employs a two-stage approach: at training time, we integrate Adversarial Training with Group Relative Policy Optimization (AT-GRPO) to explicitly robustify the reasoning process against worst-case perturbations; at inference time, we augment the model with Randomized Smoothing to provide certified $L_2$-norm robustness guarantees. We evaluate SafeMed-R1 on the OmniMedVQA benchmark across eight medical imaging modalities comprising over 88,000 samples. Our experiments reveal that standard fine-tuned VLMs, despite achieving 95\\% accuracy on clean inputs, collapse to approximately 25\\% under PGD attacks. In contrast, SafeMed-R1 maintains 84.45\\% accuracy under the same adversarial conditions, representing a 59 percentage point improvement in robustness. Furthermore, we demonstrate that models trained with explicit chain-of-thought reasoning exhibit superior adversarial robustness compared to instruction-only variants, suggesting a synergy between interpretability and security in medical AI systems.","authors":["A. A. Gde Yogi Pramana","Jason Ray","Anthony Jaya","Michael Wijaya"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19311v1","updated":"2025-12-22T12:00:12Z","published":"2025-12-22T12:00:12Z","title":"MixFlow Training: Alleviating Exposure Bias with Slowed Interpolation Mixture","summary":"This paper studies the training-testing discrepancy (a.k.a. exposure bias) problem for improving the diffusion models. During training, the input of a prediction network at one training timestep is the corresponding ground-truth noisy data that is an interpolation of the noise and the data, and during testing, the input is the generated noisy data. We present a novel training approach, named MixFlow, for improving the performance. Our approach is motivated by the Slow Flow phenomenon: the ground-truth interpolation that is the nearest to the generated noisy data at a given sampling timestep is observed to correspond to a higher-noise timestep (termed slowed timestep), i.e., the corresponding ground-truth timestep is slower than the sampling timestep. MixFlow leverages the interpolations at the slowed timesteps, named slowed interpolation mixture, for post-training the prediction network for each training timestep. Experiments over class-conditional image generation (including SiT, REPA, and RAE) and text-to-image generation validate the effectiveness of our approach. Our approach MixFlow over the RAE models achieve strong generation results on ImageNet: 1.43 FID (without guidance) and 1.10 (with guidance) at 256 x 256, and 1.55 FID (without guidance) and 1.10 (with guidance) at 512 x 512.","authors":["Hui Li","Jiayue Lyu","Fu-Yun Wang","Kaihui Cheng","Siyu Zhu","Jingdong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.04521v2","updated":"2025-12-22T11:48:52Z","published":"2025-03-06T15:08:31Z","title":"Dynamic Pricing for On-Demand DNN Inference in the Edge-AI Market","summary":"The convergence of edge computing and Artificial Intelligence (AI) gives rise to Edge-AI, which enables the deployment of real-time AI applications at the network edge. A key research challenge in Edge-AI is edge inference acceleration, which aims to realize low-latency high-accuracy Deep Neural Network (DNN) inference by offloading partitioned inference tasks from end devices to edge servers. However, existing research has yet to adopt a practical Edge-AI market perspective, which would explore the personalized inference needs of AI users (e.g., inference accuracy, latency, and task complexity), the revenue incentives for AI service providers that offer edge inference services, and multi-stakeholder governance within a market-oriented context. To bridge this gap, we propose an Auction-based Edge Inference Pricing Mechanism (AERIA) for revenue maximization to tackle the multi-dimensional optimization problem of DNN model partition, edge inference pricing, and resource allocation. We develop a multi-exit device-edge synergistic inference scheme for on-demand DNN inference acceleration, and theoretically analyze the auction dynamics amongst the AI service providers, AI users and edge infrastructure provider. Owing to the strategic mechanism design via randomized consensus estimate and cost sharing techniques, the Edge-AI market attains several desirable properties. These include competitiveness in revenue maximization, incentive compatibility, and envy-freeness, which are crucial to maintain the effectiveness, truthfulness, and fairness in auction outcomes. Extensive simulations based on four representative DNN inference workloads demonstrate that AERIA significantly outperforms several state-of-the-art approaches in revenue maximization. This validates the efficacy of AERIA for on-demand DNN inference in the Edge-AI market.","authors":["Songyuan Li","Jia Hu","Geyong Min","Haojun Huang","Jiwei Huang"],"pdf_url":"","comment":"Accepted for publication in IEEE Transactions on Mobile Computing. Index Terms: Edge-AI, DNN Inference Offloading, Resource Management, Dynamic Pricing, Auction Mechanism"},{"id":"http://arxiv.org/abs/2512.19299v1","updated":"2025-12-22T11:43:35Z","published":"2025-12-22T11:43:35Z","title":"Helios: A Foundational Language Model for Smart Energy Knowledge Reasoning and Application","summary":"In the global drive toward carbon neutrality, deeply coordinated smart energy systems underpin industrial transformation. However, the interdisciplinary, fragmented, and fast-evolving expertise in this domain prevents general-purpose LLMs, which lack domain knowledge and physical-constraint awareness, from delivering precise engineering-aligned inference and generation. To address these challenges, we introduce Helios, a large language model tailored to the smart energy domain, together with a comprehensive suite of resources to advance LLM research in this field. Specifically, we develop Enersys, a multi-agent collaborative framework for end-to-end dataset construction, through which we produce: (1) a smart energy knowledge base, EnerBase, to enrich the model's foundational expertise; (2) an instruction fine-tuning dataset, EnerInstruct, to strengthen performance on domain-specific downstream tasks; and (3) an RLHF dataset, EnerReinforce, to align the model with human preferences and industry standards. Leveraging these resources, Helios undergoes large-scale pretraining, SFT, and RLHF. We also release EnerBench, a benchmark for evaluating LLMs in smart energy scenarios, and demonstrate that our approach significantly enhances domain knowledge mastery, task execution accuracy, and alignment with human preferences.","authors":["Haoyu Jiang","Fanjie Zeng","Boan Qu","Xiaojie Lin","Wei Zhong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19297v1","updated":"2025-12-22T11:40:47Z","published":"2025-12-22T11:40:47Z","title":"Causal-Guided Detoxify Backdoor Attack of Open-Weight LoRA Models","summary":"Low-Rank Adaptation (LoRA) has emerged as an efficient method for fine-tuning large language models (LLMs) and is widely adopted within the open-source community. However, the decentralized dissemination of LoRA adapters through platforms such as Hugging Face introduces novel security vulnerabilities: malicious adapters can be easily distributed and evade conventional oversight mechanisms. Despite these risks, backdoor attacks targeting LoRA-based fine-tuning remain relatively underexplored. Existing backdoor attack strategies are ill-suited to this setting, as they often rely on inaccessible training data, fail to account for the structural properties unique to LoRA, or suffer from high false trigger rates (FTR), thereby compromising their stealth. To address these challenges, we propose Causal-Guided Detoxify Backdoor Attack (CBA), a novel backdoor attack framework specifically designed for open-weight LoRA models. CBA operates without access to original training data and achieves high stealth through two key innovations: (1) a coverage-guided data generation pipeline that synthesizes task-aligned inputs via behavioral exploration, and (2) a causal-guided detoxification strategy that merges poisoned and clean adapters by preserving task-critical neurons. Unlike prior approaches, CBA enables post-training control over attack intensity through causal influence-based weight allocation, eliminating the need for repeated retraining. Evaluated across six LoRA models, CBA achieves high attack success rates while reducing FTR by 50-70\\% compared to baseline methods. Furthermore, it demonstrates enhanced resistance to state-of-the-art backdoor defenses, highlighting its stealth and robustness.","authors":["Linzhi Chen","Yang Sun","Hongru Wei","Yuqi Chen"],"pdf_url":"","comment":"NDSS 2026"},{"id":"http://arxiv.org/abs/2502.12489v2","updated":"2025-12-22T11:32:28Z","published":"2025-02-18T03:18:54Z","title":"A Comprehensive Survey on Generative AI for Video-to-Music Generation","summary":"The burgeoning growth of video-to-music generation can be attributed to the ascendancy of multimodal generative models. However, there is a lack of literature that comprehensively combs through the work in this field. To fill this gap, this paper presents a comprehensive review of video-to-music generation using deep generative AI techniques, focusing on three key components: conditioning input construction, conditioning mechanism, and music generation frameworks. We categorize existing approaches based on their designs for each component, clarifying the roles of different strategies. Preceding this, we provide a fine-grained categorization of video and music modalities, illustrating how different categories influence the design of components within the generation pipelines. Furthermore, we summarize available multimodal datasets and evaluation metrics while highlighting ongoing challenges in the field.","authors":["Shulei Ji","Songruoyao Wu","Zihao Wang","Shuyu Li","Kejun Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19287v1","updated":"2025-12-22T11:30:19Z","published":"2025-12-22T11:30:19Z","title":"Vibe Reasoning: Eliciting Frontier AI Mathematical Capabilities -- A Case Study on IMO 2025 Problem 6","summary":"We introduce Vibe Reasoning, a human-AI collaborative paradigm for solving complex mathematical problems. Our key insight is that frontier AI models already possess the knowledge required to solve challenging problems -- they simply do not know how, what, or when to apply it. Vibe Reasoning transforms AI's latent potential into manifested capability through generic meta-prompts, agentic grounding, and model orchestration. We demonstrate this paradigm through IMO 2025 Problem 6, a combinatorial optimization problem where autonomous AI systems publicly reported failures. Our solution combined GPT-5's exploratory capabilities with Gemini 3 Pro's proof strengths, leveraging agentic workflows with Python code execution and file-based memory, to derive both the correct answer (2112) and a rigorous mathematical proof. Through iterative refinement across multiple attempts, we discovered the necessity of agentic grounding and model orchestration, while human prompts evolved from problem-specific hints to generic, transferable meta-prompts. We analyze why capable AI fails autonomously, how each component addresses specific failure modes, and extract principles for effective vibe reasoning. Our findings suggest that lightweight human guidance can unlock frontier models' mathematical reasoning potential. This is ongoing work; we are developing automated frameworks and conducting broader evaluations to further validate Vibe Reasoning's generality and effectiveness.","authors":["Jiaao Wu","Xian Zhang","Fan Yang","Yinpeng Dong"],"pdf_url":"","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2512.19280v1","updated":"2025-12-22T11:24:42Z","published":"2025-12-22T11:24:42Z","title":"Digital Twin-Driven Zero-Shot Fault Diagnosis of Axial Piston Pumps Using Fluid-Borne Noise Signals","summary":"Axial piston pumps are crucial components in fluid power systems, where reliable fault diagnosis is essential for ensuring operational safety and efficiency. Traditional data-driven methods require extensive labeled fault data, which is often impractical to obtain, while model-based approaches suffer from parameter uncertainties. This paper proposes a digital twin (DT)-driven zero-shot fault diagnosis framework utilizing fluid-borne noise (FBN) signals. The framework calibrates a high-fidelity DT model using only healthy-state data, generates synthetic fault signals for training deep learning classifiers, and employs a physics-informed neural network (PINN) as a virtual sensor for flow ripple estimation. Gradient-weighted class activation mapping (Grad-CAM) is integrated to visualize the decision-making process of neural networks, revealing that large kernels matching the subsequence length in time-domain inputs and small kernels in time-frequency domain inputs enable higher diagnostic accuracy by focusing on physically meaningful features. Experimental validations demonstrate that training on signals from the calibrated DT model yields diagnostic accuracies exceeding 95\\% on real-world benchmarks, while uncalibrated models result in significantly lower performance, highlighting the framework's effectiveness in data-scarce scenarios.","authors":["Chang Dong","Jianfeng Tao","Chengliang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19275v1","updated":"2025-12-22T11:19:46Z","published":"2025-12-22T11:19:46Z","title":"Is Visual Realism Enough? Evaluating Gait Biometric Fidelity in Generative AI Human Animation","summary":"Generative AI (GenAI) models have revolutionized animation, enabling the synthesis of humans and motion patterns with remarkable visual fidelity. However, generating truly realistic human animation remains a formidable challenge, where even minor inconsistencies can make a subject appear unnatural. This limitation is particularly critical when AI-generated videos are evaluated for behavioral biometrics, where subtle motion cues that define identity are easily lost or distorted. The present study investigates whether state-of-the-art GenAI human animation models can preserve the subtle spatio-temporal details needed for person identification through gait biometrics. Specifically, we evaluate four different GenAI models across two primary evaluation tasks to assess their ability to i) restore gait patterns from reference videos under varying conditions of complexity, and ii) transfer these gait patterns to different visual identities. Our results show that while visual quality is mostly high, biometric fidelity remains low in tasks focusing on identification, suggesting that current GenAI models struggle to disentangle identity from motion. Furthermore, through an identity transfer task, we expose a fundamental flaw in appearance-based gait recognition: when texture is disentangled from motion, identification collapses, proving current GenAI models rely on visual attributes rather than temporal dynamics.","authors":["Ivan DeAndres-Tame","Chengwei Ye","Ruben Tolosana","Ruben Vera-Rodriguez","Shiqi Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16301v2","updated":"2025-12-22T11:05:54Z","published":"2025-12-18T08:38:51Z","title":"Adaptation of Agentic AI","summary":"Cutting-edge agentic AI systems are built on foundation models that can be adapted to plan, reason, and interact with external tools to perform increasingly complex and specialized tasks. As these systems grow in capability and scope, adaptation becomes a central mechanism for improving performance, reliability, and generalization. In this paper, we unify the rapidly expanding research landscape into a systematic framework that spans both agent adaptations and tool adaptations. We further decompose these into tool-execution-signaled and agent-output-signaled forms of agent adaptation, as well as agent-agnostic and agent-supervised forms of tool adaptation. We demonstrate that this framework helps clarify the design space of adaptation strategies in agentic AI, makes their trade-offs explicit, and provides practical guidance for selecting or switching among strategies during system design. We then review the representative approaches in each category, analyze their strengths and limitations, and highlight key open challenges and future opportunities. Overall, this paper aims to offer a conceptual foundation and practical roadmap for researchers and practitioners seeking to build more capable, efficient, and reliable agentic AI systems.","authors":["Pengcheng Jiang","Jiacheng Lin","Zhiyi Shi","Zifeng Wang","Luxi He","Yichen Wu","Ming Zhong","Peiyang Song","Qizheng Zhang","Heng Wang","Xueqiang Xu","Hanwen Xu","Pengrui Han","Dylan Zhang","Jiashuo Sun","Chaoqi Yang","Kun Qian","Tian Wang","Changran Hu","Manling Li","Quanzheng Li","Hao Peng","Sheng Wang","Jingbo Shang","Chao Zhang","Jiaxuan You","Liyuan Liu","Pan Lu","Yu Zhang","Heng Ji","Yejin Choi","Dawn Song","Jimeng Sun","Jiawei Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.10035v2","updated":"2025-12-22T10:46:52Z","published":"2025-06-10T20:48:30Z","title":"FastFLUX: Pruning FLUX with Block-wise Replacement and Sandwich Training","summary":"Recent advancements in text-to-image (T2I) generation have led to the emergence of highly expressive models such as diffusion transformers (DiTs), exemplified by FLUX. However, their massive parameter sizes lead to slow inference, high memory usage, and poor deployability. Existing acceleration methods (e.g., single-step distillation and attention pruning) often suffer from significant performance degradation and incur substantial training costs. To address these limitations, we propose FastFLUX, an architecture-level pruning framework designed to enhance the inference efficiency of FLUX. At its core is the Block-wise Replacement with Linear Layers (BRLL) method, which replaces structurally complex residual branches in ResBlocks with lightweight linear layers while preserving the original shortcut connections for stability. Furthermore, we introduce Sandwich Training (ST), a localized fine-tuning strategy that leverages LoRA to supervise neighboring blocks, mitigating performance drops caused by structural replacement. Experiments show that our FastFLUX maintains high image quality under both qualitative and quantitative evaluations, while significantly improving inference speed, even with 20\\% of the hierarchy pruned. Our code will be available soon.","authors":["Fuhan Cai","Yong Guo","Jie Li","Wenbo Li","Jian Chen","Xiangzhong Fang"],"pdf_url":"","comment":"14 pages"},{"id":"http://arxiv.org/abs/2507.17860v4","updated":"2025-12-22T10:41:08Z","published":"2025-07-23T18:33:27Z","title":"Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis","summary":"Recent advances in deep learning and on-device inference could transform routine screening for skin cancers. Along with the anticipated benefits of this technology, potential dangers arise from unforeseen and inherent biases. A significant obstacle is building evaluation datasets that accurately reflect key demographics, including sex, age, and race, as well as other underrepresented groups. To address this, we train a state-of-the-art generative model to generate synthetic data in a controllable manner to assess the fairness of publicly available skin cancer classifiers. To evaluate whether synthetic images can be used as a fairness testing dataset, we prepare a real-image dataset (MILK10K) as a benchmark and compare the True Positive Rate result of three models (DeepGuide, MelaNet, and SkinLesionDensnet). As a result, the classification tendencies observed in each model when tested on real and generated images showed similar patterns across different attribute data sets. We confirm that highly realistic synthetic images facilitate model fairness verification.","authors":["Ko Watanabe","Stanislav Frolov","Aya Hassan","David Dembinsky","Adriano Lucieri","Andreas Dengel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19253v1","updated":"2025-12-22T10:40:03Z","published":"2025-12-22T10:40:03Z","title":"Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study","summary":"We present the first comprehensive empirical study of machine unlearning (MU) in hybrid quantum-classical neural networks. While MU has been extensively explored in classical deep learning, its behavior within variational quantum circuits (VQCs) and quantum-augmented architectures remains largely unexplored. First, we adapt a broad suite of unlearning methods to quantum settings, including gradient-based, distillation-based, regularization-based and certified techniques. Second, we introduce two new unlearning strategies tailored to hybrid models. Experiments across Iris, MNIST, and Fashion-MNIST, under both subset removal and full-class deletion, reveal that quantum models can support effective unlearning, but outcomes depend strongly on circuit depth, entanglement structure, and task complexity. Shallow VQCs display high intrinsic stability with minimal memorization, whereas deeper hybrid models exhibit stronger trade-offs between utility, forgetting strength, and alignment with retrain oracle. We find that certain methods, e.g. EU-k, LCA, and Certified Unlearning, consistently provide the best balance across metrics. These findings establish baseline empirical insights into quantum machine unlearning and highlight the need for quantum-aware algorithms and theoretical guarantees, as quantum machine learning systems continue to expand in scale and capability. We publicly release our code at: https://github.com/CrivoiCarla/HQML.","authors":["Carla Crivoi","Radu Tudor Ionescu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16280v2","updated":"2025-12-22T10:37:08Z","published":"2025-12-18T07:59:15Z","title":"Love, Lies, and Language Models: Investigating AI's Role in Romance-Baiting Scams","summary":"Romance-baiting scams have become a major source of financial and emotional harm worldwide. These operations are run by organized crime syndicates that traffic thousands of people into forced labor, requiring them to build emotional intimacy with victims over weeks of text conversations before pressuring them into fraudulent cryptocurrency investments. Because the scams are inherently text-based, they raise urgent questions about the role of Large Language Models (LLMs) in both current and future automation.\n  We investigate this intersection by interviewing 145 insiders and 5 scam victims, performing a blinded long-term conversation study comparing LLM scam agents to human operators, and executing an evaluation of commercial safety filters. Our findings show that LLMs are already widely deployed within scam organizations, with 87% of scam labor consisting of systematized conversational tasks readily susceptible to automation. In a week-long study, an LLM agent not only elicited greater trust from study participants (p=0.007) but also achieved higher compliance with requests than human operators (46% vs. 18% for humans). Meanwhile, popular safety filters detected 0.0% of romance baiting dialogues. Together, these results suggest that romance-baiting scams may be amenable to full-scale LLM automation, while existing defenses remain inadequate to prevent their expansion.","authors":["Gilad Gressel","Rahul Pankajakshan","Shir Rozenfeld","Ling Li","Ivan Franceschini","Krishnashree Achuthan","Yisroel Mirsky"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19247v1","updated":"2025-12-22T10:29:51Z","published":"2025-12-22T10:29:51Z","title":"Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics","summary":"Prompt engineering plays a critical role in adapting large language models (LLMs) to complex reasoning and labeling tasks without the need for extensive fine-tuning. In this paper, we propose a novel prompt optimization pipeline for frame detection in logistics texts, combining retrieval-augmented generation (RAG), few-shot prompting, chain-of-thought (CoT) reasoning, and automatic CoT synthesis (Auto-CoT) to generate highly effective task-specific prompts. Central to our approach is an LLM-based prompt optimizer agent that iteratively refines the prompts using retrieved examples, performance feedback, and internal self-evaluation. Our framework is evaluated on a real-world logistics text annotation task, where reasoning accuracy and labeling efficiency are critical. Experimental results show that the optimized prompts - particularly those enhanced via Auto-CoT and RAG - improve real-world inference accuracy by up to 15% compared to baseline zero-shot or static prompts. The system demonstrates consistent improvements across multiple LLMs, including GPT-4o, Qwen 2.5 (72B), and LLaMA 3.1 (70B), validating its generalizability and practical value. These findings suggest that structured prompt optimization is a viable alternative to full fine-tuning, offering scalable solutions for deploying LLMs in domain-specific NLP applications such as logistics.","authors":["Do Minh Duc","Quan Xuan Truong","Nguyen Tat Dat","Nguyen Van Vinh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17452v2","updated":"2025-12-22T10:23:36Z","published":"2025-12-19T11:08:58Z","title":"Learning What to Write: Write-Gated KV for Efficient Long-Context Inference","summary":"Long-context LLM inference is bottlenecked by the quadratic attention complexity and linear KV cache growth. Prior approaches mitigate this via post-hoc selection or eviction but overlook the root inefficiency: indiscriminate writing to persistent memory. In this paper, we formalize KV cache management as a causal system of three primitives: KV Admission, Selection, and Eviction. We instantiate KV Admission via Write-Gated KV, a lightweight mechanism that learns to predict token utility before it enters the cache. By filtering out low-utility states early to maintain a compact global cache alongside a sliding local cache, Write-Gated KV reduces memory usage by 46-57% and delivers 3.03-3.45$\\times$ prefill and 1.89-2.56$\\times$ decode speedups on Llama model with negligible accuracy loss, all while remaining compatible with FlashAttention and paged-KV systems. These results demonstrate that learning what to write, is a principled and practical recipe for efficient long-context inference. Code is available at https://github.com/EMCLab-Sinica/WG-KV .","authors":["Yen-Chieh Huang","Pi-Cheng Hsiu","Rui Fang","Ming-Syan Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.11646v2","updated":"2025-12-22T10:22:37Z","published":"2025-11-10T08:50:03Z","title":"What-If Decision Support for Product Line Extension Using Conditional Deep Generative Models","summary":"Product line extension is a strategically important managerial decision that requires anticipating how consumer segments and purchasing contexts may respond to hypothetical product designs that do not yet exist in the market. Such decisions are inherently uncertain because managers must infer future outcomes from historical purchase data without direct market observations. This study addresses this challenge by proposing a data-driven decision support framework that enables forward-looking what-if analysis based on historical transaction data. We introduce a Conditional Tabular Variational Autoencoder (CTVAE) that learns the conditional joint distribution of product attributes and consumer characteristics from large-scale tabular data. By conditioning the generative process on controllable design variables such as container type, volume, flavor, and calorie content, the proposed model generates synthetic consumer attribute distributions for hypothetical line-extended products. This enables systematic exploration of alternative design scenarios without costly market pretests. The framework is evaluated using home-scan panel data covering more than 20,000 consumers and 700 soft drink products. Empirical results show that the CTVAE outperforms existing tabular generative models in capturing conditional consumer attribute distributions. Simulation-based analyses further demonstrate that the generated synthetic data support knowledge-driven reasoning for assessing cannibalization risks and identifying potential target segments. These findings highlight the value of conditional deep generative models as core components of decision support systems for product line extension planning.","authors":["Yinxing Li","Tsukasa Ishigaki"],"pdf_url":"","comment":"25 pages"},{"id":"http://arxiv.org/abs/2512.19240v1","updated":"2025-12-22T10:21:40Z","published":"2025-12-22T10:21:40Z","title":"ChemATP: A Training-Free Chemical Reasoning Framework for Large Language Models","summary":"Large Language Models (LLMs) exhibit strong general reasoning but struggle in molecular science due to the lack of explicit chemical priors in standard string representations. Current solutions face a fundamental dilemma. Training-based methods inject priors into parameters, but this static coupling hinders rapid knowledge updates and often compromises the model's general reasoning capabilities. Conversely, existing training-free methods avoid these issues but rely on surface-level prompting, failing to provide the fine-grained atom-level priors essential for precise chemical reasoning. To address this issue, we introduce ChemATP, a framework that decouples chemical knowledge from the reasoning engine. By constructing the first atom-level textual knowledge base, ChemATP enables frozen LLMs to explicitly retrieve and reason over this information dynamically. This architecture ensures interpretability and adaptability while preserving the LLM's intrinsic general intelligence. Experiments show that ChemATP significantly outperforms training-free baselines and rivals state-of-the-art training-based models, demonstrating that explicit prior injection is a competitive alternative to implicit parameter updates.","authors":["Mingxu Zhang","Dazhong Shen","Qi Zhang","Ying Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19238v1","updated":"2025-12-22T10:20:20Z","published":"2025-12-22T10:20:20Z","title":"Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation","summary":"Large language models (LLMs) have been shown to exhibit social bias, however, bias towards non-protected stigmatized identities remain understudied. Furthermore, what social features of stigmas are associated with bias in LLM outputs is unknown. From psychology literature, it has been shown that stigmas contain six shared social features: aesthetics, concealability, course, disruptiveness, origin, and peril. In this study, we investigate if human and LLM ratings of the features of stigmas, along with prompt style and type of stigma, have effect on bias towards stigmatized groups in LLM outputs. We measure bias against 93 stigmatized groups across three widely used LLMs (Granite 3.0-8B, Llama-3.1-8B, Mistral-7B) using SocialStigmaQA, a benchmark that includes 37 social scenarios about stigmatized identities; for example deciding wether to recommend them for an internship. We find that stigmas rated by humans to be highly perilous (e.g., being a gang member or having HIV) have the most biased outputs from SocialStigmaQA prompts (60% of outputs from all models) while sociodemographic stigmas (e.g. Asian-American or old age) have the least amount of biased outputs (11%). We test if the amount of biased outputs could be decreased by using guardrail models, models meant to identify harmful input, using each LLM's respective guardrail model (Granite Guardian 3.0, Llama Guard 3.0, Mistral Moderation API). We find that bias decreases significantly by 10.4%, 1.4%, and 7.8%, respectively. However, we show that features with significant effect on bias remain unchanged post-mitigation and that guardrail models often fail to recognize the intent of bias in prompts. This work has implications for using LLMs in scenarios involving stigmatized groups and we suggest future work towards improving guardrail models for bias mitigation.","authors":["Anna-Maria Gueorguieva","Aylin Caliskan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19234v1","updated":"2025-12-22T10:17:49Z","published":"2025-12-22T10:17:49Z","title":"DeliveryBench: Can Agents Earn Profit in Real World?","summary":"LLMs and VLMs are increasingly deployed as embodied agents, yet existing benchmarks largely revolve around simple short-term tasks and struggle to capture rich realistic constraints that shape real-world decision making. To close this gap, we propose DeliveryBench, a city-scale embodied benchmark grounded in the real-world profession of food delivery. Food couriers naturally operate under long-horizon objectives (maximizing net profit over hours) while managing diverse constraints, e.g., delivery deadline, transportation expense, vehicle battery, and necessary interactions with other couriers and customers. DeliveryBench instantiates this setting in procedurally generated 3D cities with diverse road networks, buildings, functional locations, transportation modes, and realistic resource dynamics, enabling systematic evaluation of constraint-aware, long-horizon planning. We benchmark a range of VLM-based agents across nine cities and compare them with human players. Our results reveal a substantial performance gap to humans, and find that these agents are short-sighted and frequently break basic commonsense constraints. Additionally, we observe distinct personalities across models (e.g., adventurous GPT-5 vs. conservative Claude), highlighting both the brittleness and the diversity of current VLM-based embodied agents in realistic, constraint-dense environments. Our code, data, and benchmark are available at https://deliverybench.github.io.","authors":["Lingjun Mao","Jiawei Ren","Kun Zhou","Jixuan Chen","Ziqiao Ma","Lianhui Qin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19228v1","updated":"2025-12-22T10:08:25Z","published":"2025-12-22T10:08:25Z","title":"Generation of Programmatic Rules for Document Forgery Detection Using Large Language Models","summary":"Document forgery poses a growing threat to legal, economic, and governmental processes, requiring increasingly sophisticated verification mechanisms. One approach involves the use of plausibility checks, rule-based procedures that assess the correctness and internal consistency of data, to detect anomalies or signs of manipulation. Although these verification procedures are essential for ensuring data integrity, existing plausibility checks are manually implemented by software engineers, which is time-consuming. Recent advances in code generation with large language models (LLMs) offer new potential for automating and scaling the generation of these checks. However, adapting LLMs to the specific requirements of an unknown domain remains a significant challenge. This work investigates the extent to which LLMs, adapted on domain-specific code and data through different fine-tuning strategies, can generate rule-based plausibility checks for forgery detection on constrained hardware resources. We fine-tune open-source LLMs, Llama 3.1 8B and OpenCoder 8B, on structured datasets derived from real-world application scenarios and evaluate the generated plausibility checks on previously unseen forgery patterns. The results demonstrate that the models are capable of generating executable and effective verification procedures. This also highlights the potential of LLMs as scalable tools to support human decision-making in security-sensitive contexts where comprehensibility is required.","authors":["Valentin Schmidberger","Manuel Eberhardinger","Setareh Maghsudi","Johannes Maucher"],"pdf_url":"","comment":"Accepted at ICMLA 2025, the first two authors contributed equally"},{"id":"http://arxiv.org/abs/2512.19221v1","updated":"2025-12-22T10:02:53Z","published":"2025-12-22T10:02:53Z","title":"From Pixels to Predicates Structuring urban perception with scene graphs","summary":"Perception research is increasingly modelled using streetscapes, yet many approaches still rely on pixel features or object co-occurrence statistics, overlooking the explicit relations that shape human perception. This study proposes a three stage pipeline that transforms street view imagery (SVI) into structured representations for predicting six perceptual indicators. In the first stage, each image is parsed using an open-set Panoptic Scene Graph model (OpenPSG) to extract object predicate object triplets. In the second stage, compact scene-level embeddings are learned through a heterogeneous graph autoencoder (GraphMAE). In the third stage, a neural network predicts perception scores from these embeddings. We evaluate the proposed approach against image-only baselines in terms of accuracy, precision, and cross-city generalization. Results indicate that (i) our approach improves perception prediction accuracy by an average of 26% over baseline models, and (ii) maintains strong generalization performance in cross-city prediction tasks. Additionally, the structured representation clarifies which relational patterns contribute to lower perception scores in urban scenes, such as graffiti on wall and car parked on sidewalk. Overall, this study demonstrates that graph-based structure provides expressive, generalizable, and interpretable signals for modelling urban perception, advancing human-centric and context-aware urban analytics.","authors":["Yunlong Liu","Shuyang Li","Pengyuan Liu","Yu Zhang","Rudi Stouffs"],"pdf_url":"","comment":"10 pages, CAADRIA2026 presentation forthcoming"},{"id":"http://arxiv.org/abs/2512.19219v1","updated":"2025-12-22T10:02:10Z","published":"2025-12-22T10:02:10Z","title":"Towards Minimal Fine-Tuning of VLMs","summary":"We introduce Image-LoRA, a lightweight parameter efficient fine-tuning (PEFT) recipe for transformer-based vision-language models (VLMs). Image-LoRA applies low-rank adaptation only to the value path of attention layers within the visual-token span, reducing adapter-only training FLOPs roughly in proportion to the visual-token fraction. We further adapt only a subset of attention heads, selected using head influence scores estimated with a rank-1 Image-LoRA, and stabilize per-layer updates via selection-size normalization. Across screen-centric grounding and referring benchmarks spanning text-heavy to image-heavy regimes, Image-LoRA matches or closely approaches standard LoRA accuracy while using fewer trainable parameters and lower adapter-only training FLOPs. The method also preserves the pure-text reasoning performance of VLMs before and after fine-tuning, as further shown on GSM8K.","authors":["Tiange Luo","Lajanugen Logeswaran","Jaekyeom Kim","Justin Johnson","Honglak Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.04618v2","updated":"2025-12-22T09:55:28Z","published":"2025-12-04T09:47:15Z","title":"Neural Decoding of Overt Speech from ECoG Using Vision Transformers and Contrastive Representation Learning","summary":"Speech Brain Computer Interfaces (BCIs) offer promising solutions to people with severe paralysis unable to communicate. A number of recent studies have demonstrated convincing reconstruction of intelligible speech from surface electrocorticographic (ECoG) or intracortical recordings by predicting a series of phonemes or words and using downstream language models to obtain meaningful sentences. A current challenge is to reconstruct speech in a streaming mode by directly regressing cortical signals into acoustic speech. While this has been achieved recently using intracortical data, further work is needed to obtain comparable results with surface ECoG recordings. In particular, optimizing neural decoders becomes critical in this case. Here we present an offline speech decoding pipeline based on an encoder-decoder deep neural architecture, integrating Vision Transformers and contrastive learning to enhance the direct regression of speech from ECoG signals. The approach is evaluated on two datasets, one obtained with clinical subdural electrodes in an epileptic patient, and another obtained with the fully implantable WIMAGINE epidural system in a participant of a motor BCI trial. To our knowledge this presents a first attempt to decode speech from a fully implantable and wireless epidural recording system offering perspectives for long-term use.","authors":["Mohamed Baha Ben Ticha","Xingchen Ran","Guillaume Saldanha","Gaël Le Godais","Philémon Roussel","Marc Aubert","Amina Fontanell","Thomas Costecalde","Lucas Struber","Serpil Karakas","Shaomin Zhang","Philippe Kahane","Guillaume Charvet","Stéphan Chabardès","Blaise Yvert"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.20647v2","updated":"2025-12-22T09:52:15Z","published":"2025-10-23T15:22:00Z","title":"The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI","summary":"Large Reasoning Models (LRMs) achieve strong performance on mathematical, scientific, and other question-answering tasks, but their multilingual reasoning abilities remain underexplored. When presented with non-English questions, LRMs often default to reasoning in English, raising concerns about interpretability and the handling of linguistic and cultural nuances. We systematically compare an LRM's reasoning in English versus the language of the question. Our evaluation spans two tasks: MGSM and GPQA Diamond. Beyond measuring answer accuracy, we also analyze cognitive attributes in the reasoning traces. We find that English reasoning traces exhibit a substantially higher presence of these cognitive behaviors, and that reasoning in English generally yields higher final-answer accuracy, with the performance gap increasing as tasks become more complex. However, this English-centric strategy is susceptible to a key failure mode - getting \"Lost in Translation,\" where translation steps lead to errors that would have been avoided by question's language reasoning.","authors":["Alan Saji","Raj Dabre","Anoop Kunchukuttan","Ratish Puduppully"],"pdf_url":"","comment":"14 pages, 13 figures, 5 tables"},{"id":"http://arxiv.org/abs/2512.19210v1","updated":"2025-12-22T09:49:13Z","published":"2025-12-22T09:49:13Z","title":"Observer, Not Player: Simulating Theory of Mind in LLMs through Game Observation","summary":"We present an interactive framework for evaluating whether large language models (LLMs) exhibit genuine \"understanding\" in a simple yet strategic environment. As a running example, we focus on Rock-Paper-Scissors (RPS), which, despite its apparent simplicity, requires sequential reasoning, adaptation, and strategy recognition. Our system positions the LLM as an Observer whose task is to identify which strategies are being played and to articulate the reasoning behind this judgment. The purpose is not to test knowledge of Rock-Paper-Scissors itself, but to probe whether the model can exhibit mind-like reasoning about sequential behavior. To support systematic evaluation, we provide a benchmark consisting of both static strategies and lightweight dynamic strategies specified by well-prompted rules. We quantify alignment between the Observer's predictions and the ground-truth distributions induced by actual strategy pairs using three complementary signals: Cross-Entropy, Brier score, and Expected Value (EV) discrepancy. These metrics are further integrated into a unified score, the Union Loss, which balances calibration, sensitivity, and payoff alignment. Together with a Strategy Identification Rate (SIR) metric, our framework captures not only predictive accuracy but also whether the model can stably identify the latent strategies in play. The demo emphasizes interactivity, transparency, and reproducibility. Users can adjust LLM distributions in real time, visualize losses as they evolve, and directly inspect reasoning snippets to identify where and why failures occur. In doing so, our system provides a practical and interpretable proxy for mind-like inference in sequential games, offering insights into both the strengths and limitations of current LLM reasoning.","authors":["Jerry Wang","Ting Yiu Liu"],"pdf_url":"","comment":"Accepted at NeurIPS Workshop on Foundations of Reasoning in Language Models and Workshop on Bridging Language, Agent, and World Model"},{"id":"http://arxiv.org/abs/2512.19206v1","updated":"2025-12-22T09:44:26Z","published":"2025-12-22T09:44:26Z","title":"MixKVQ: Query-Aware Mixed-Precision KV Cache Quantization for Long-Context Reasoning","summary":"Long Chain-of-Thought (CoT) reasoning has significantly advanced the capabilities of Large Language Models (LLMs), but this progress is accompanied by substantial memory and latency overhead from the extensive Key-Value (KV) cache. Although KV cache quantization is a promising compression technique, existing low-bit quantization methods often exhibit severe performance degradation on complex reasoning tasks. Fixed-precision quantization struggles to handle outlier channels in the key cache, while current mixed-precision strategies fail to accurately identify components requiring high-precision representation. We find that an effective low-bit KV cache quantization strategy must consider two factors: a key channel's intrinsic quantization difficulty and its relevance to the query. Based on this insight, we propose MixKVQ, a novel plug-and-play method that introduces a lightweight, query-aware algorithm to identify and preserve critical key channels that need higher precision, while applying per-token quantization for value cache. Experiments on complex reasoning datasets demonstrate that our approach significantly outperforms existing low-bit methods, achieving performance comparable to a full-precision baseline at a substantially reduced memory footprint.","authors":["Tao Zhang","Ziqian Zeng","Hao Peng","Huiping Zhuang","Cen Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.08438v3","updated":"2025-12-22T09:39:55Z","published":"2025-05-13T11:04:04Z","title":"A Survey of 3D Reconstruction with Event Cameras","summary":"Event cameras are rapidly emerging as powerful vision sensors for 3D reconstruction, uniquely capable of asynchronously capturing per-pixel brightness changes. Compared to traditional frame-based cameras, event cameras produce sparse yet temporally dense data streams, enabling robust and accurate 3D reconstruction even under challenging conditions such as high-speed motion, low illumination, and extreme dynamic range scenarios. These capabilities offer substantial promise for transformative applications across various fields, including autonomous driving, robotics, aerial navigation, and immersive virtual reality. In this survey, we present the first comprehensive review exclusively dedicated to event-based 3D reconstruction. Existing approaches are systematically categorised based on input modality into stereo, monocular, and multimodal systems, and further classified according to reconstruction methodologies, including geometry-based techniques, deep learning approaches, and neural rendering techniques such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). Within each category, methods are chronologically organised to highlight the evolution of key concepts and advancements. Furthermore, we provide a detailed summary of publicly available datasets specifically suited to event-based reconstruction tasks. Finally, we discuss significant open challenges in dataset availability, standardised evaluation, effective representation, and dynamic scene reconstruction, outlining insightful directions for future research. This survey aims to serve as an essential reference and provides a clear and motivating roadmap toward advancing the state of the art in event-driven 3D reconstruction.","authors":["Chuanzhi Xu","Haoxian Zhou","Langyi Chen","Haodong Chen","Zeke Zexi Hu","Zhicheng Lu","Ying Zhou","Vera Chung","Qiang Qu","Weidong Cai"],"pdf_url":"","comment":"This survey has been accepted for publication in the Computational Visual Media Journal"},{"id":"http://arxiv.org/abs/2505.11792v3","updated":"2025-12-22T09:39:43Z","published":"2025-05-17T02:32:03Z","title":"Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling","summary":"Optimization modeling is fundamental to decision-making across diverse domains. Despite progress in automating optimization formulation from natural language descriptions, Large Language Models (LLMs) often struggle to generate formally correct and usable models against hallucinations, posing a challenge for reliable automation. Inspired by the success of Reinforcement Learning (RL) in enhancing Large Reasoning Models, we present Solver-Informed Reinforcement Learning (SIRL), a novel framework that significantly improves the authenticity of LLMs for optimization modeling using Reinforcement Learning with Verifiable Reward by leveraging external optimization solvers as verifiers. These verifiers automatically assess the executable code and the instance-level mathematical model represented by the associated LP file, yielding precise and comprehensive feedback signals -- including syntax, feasibility, and solution quality, serving as direct rewards for the RL process. This automated verification process, particularly from classic optimization solvers, also underpins our instance-enhanced self-consistency method to synthesize high-quality training data. Extensive experiments on diverse public benchmarks demonstrate that SIRL achieves state-of-the-art performance, substantially outperforming existing methods in generating accurate and executable optimization models. Our code is publicly available at https://github.com/Cardinal-Operations/SIRL.","authors":["Yitian Chen","Jingfan Xia","Siyu Shao","Dongdong Ge","Yinyu Ye"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19199v1","updated":"2025-12-22T09:36:24Z","published":"2025-12-22T09:36:24Z","title":"On the Koopman-Based Generalization Bounds for Multi-Task Deep Learning","summary":"The paper establishes generalization bounds for multitask deep neural networks using operator-theoretic techniques. The authors propose a tighter bound than those derived from conventional norm based methods by leveraging small condition numbers in the weight matrices and introducing a tailored Sobolev space as an expanded hypothesis space. This enhanced bound remains valid even in single output settings, outperforming existing Koopman based bounds. The resulting framework maintains key advantages such as flexibility and independence from network width, offering a more precise theoretical understanding of multitask deep learning in the context of kernel methods.","authors":["Mahdi Mohammadigohari","Giuseppe Di Fatta","Giuseppe Nicosia","Panos M. Pardalos"],"pdf_url":"","comment":"Accepted for publication in Lecture Notes in Computer Science (LNCS). Final version forthcoming"},{"id":"http://arxiv.org/abs/2512.19184v1","updated":"2025-12-22T09:18:30Z","published":"2025-12-22T09:18:30Z","title":"Operator-Based Generalization Bound for Deep Learning: Insights on Multi-Task Learning","summary":"This paper presents novel generalization bounds for vector-valued neural networks and deep kernel methods, focusing on multi-task learning through an operator-theoretic framework. Our key development lies in strategically combining a Koopman based approach with existing techniques, achieving tighter generalization guarantees compared to traditional norm-based bounds. To mitigate computational challenges associated with Koopman-based methods, we introduce sketching techniques applicable to vector valued neural networks. These techniques yield excess risk bounds under generic Lipschitz losses, providing performance guarantees for applications including robust and multiple quantile regression. Furthermore, we propose a novel deep learning framework, deep vector-valued reproducing kernel Hilbert spaces (vvRKHS), leveraging Perron Frobenius (PF) operators to enhance deep kernel methods. We derive a new Rademacher generalization bound for this framework, explicitly addressing underfitting and overfitting through kernel refinement strategies. This work offers novel insights into the generalization properties of multitask learning with deep learning architectures, an area that has been relatively unexplored until recent developments.","authors":["Mahdi Mohammadigohari","Giuseppe Di Fatta","Giuseppe Nicosia","Panos M. Pardalos"],"pdf_url":"","comment":"Accepted for publication in Lecture Notes in Computer Science (LNCS). Final version forthcoming"},{"id":"http://arxiv.org/abs/2512.17629v2","updated":"2025-12-22T09:18:11Z","published":"2025-12-19T14:33:02Z","title":"SCOPE: Sequential Causal Optimization of Process Interventions","summary":"Prescriptive Process Monitoring (PresPM) recommends interventions during business processes to optimize key performance indicators (KPIs). In realistic settings, interventions are rarely isolated: organizations need to align sequences of interventions to jointly steer the outcome of a case. Existing PresPM approaches fall short in this respect. Many focus on a single intervention decision, while others treat multiple interventions independently, ignoring how they interact over time. Methods that do address these dependencies depend either on simulation or data augmentation to approximate the process to train a Reinforcement Learning (RL) agent, which can create a reality gap and introduce bias. We introduce SCOPE, a PresPM approach that learns aligned sequential intervention recommendations. SCOPE employs backward induction to estimate the effect of each candidate intervention action, propagating its impact from the final decision point back to the first. By leveraging causal learners, our method can utilize observational data directly, unlike methods that require constructing process approximations for reinforcement learning. Experiments on both an existing synthetic dataset and a new semi-synthetic dataset show that SCOPE consistently outperforms state-of-the-art PresPM techniques in optimizing the KPI. The novel semi-synthetic setup, based on a real-life event log, is provided as a reusable benchmark for future work on sequential PresPM.","authors":["Jakob De Moor","Hans Weytjens","Johannes De Smedt","Jochen De Weerdt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.09166v5","updated":"2025-12-22T09:17:43Z","published":"2025-05-14T05:59:23Z","title":"An Exploration of Default Images in Text-to-Image Generation","summary":"In the creative practice of text-to-image (TTI) generation, images are synthesized from textual prompts. By design, TTI models always yield an output, even if the prompt contains unknown terms. In this case, the model may generate default images: images that closely resemble each other across many unrelated prompts. Studying default images is valuable for designing better solutions for prompt engineering and TTI generation. We present the first investigation into default images on Midjourney. We describe an initial study in which we manually created input prompts triggering default images, and several ablation studies. Building on these, we conduct a computational analysis of over 750,000 images, revealing consistent default images across unrelated prompts. We also conduct an online user study investigating how default images may affect user satisfaction. Our work lays the foundation for understanding default images in TTI generation, highlighting their practical relevance as well as challenges and future research directions.","authors":["Hannu Simonen","Atte Kiviniemi","Hannah Johnston","Helena Barranha","Jonas Oppenlaender"],"pdf_url":"","comment":"31 pages, 10 figures"},{"id":"http://arxiv.org/abs/2512.19180v1","updated":"2025-12-22T09:16:08Z","published":"2025-12-22T09:16:08Z","title":"Practical Quantum-Classical Feature Fusion for complex data Classification","summary":"Hybrid quantum and classical learning aims to couple quantum feature maps with the robustness of classical neural networks, yet most architectures treat the quantum circuit as an isolated feature extractor and merge its measurements with classical representations by direct concatenation. This neglects that the quantum and classical branches constitute distinct computational modalities and limits reliable performance on complex, high dimensional tabular and semi structured data, including remote sensing, environmental monitoring, and medical diagnostics. We present a multimodal formulation of hybrid learning and propose a cross attention mid fusion architecture in which a classical representation queries quantum derived feature tokens through an attention block with residual connectivity. The quantum branch is kept within practical NISQ budgets and uses up to nine qubits. We evaluate on Wine, Breast Cancer, Forest CoverType, FashionMNIST, and SteelPlatesFaults, comparing a quantum only model, a classical baseline, residual hybrid models, and the proposed mid fusion model under a consistent protocol. Pure quantum and standard hybrid designs underperform due to measurement induced information loss, while cross attention mid fusion is consistently competitive and improves performance on the more complex datasets in most cases. These findings suggest that quantum derived information becomes most valuable when integrated through principled multimodal fusion rather than used in isolation or loosely appended to classical features.","authors":["Azadeh Alavi","Fatemeh Kouchmeshki","Abdolrahman Alavi"],"pdf_url":"","comment":"16 pages, 3 figues"},{"id":"http://arxiv.org/abs/2512.19178v1","updated":"2025-12-22T09:12:48Z","published":"2025-12-22T09:12:48Z","title":"Vision-Language-Policy Model for Dynamic Robot Task Planning","summary":"Bridging the gap between natural language commands and autonomous execution in unstructured environments remains an open challenge for robotics. This requires robots to perceive and reason over the current task scene through multiple modalities, and to plan their behaviors to achieve their intended goals. Traditional robotic task-planning approaches often struggle to bridge low-level execution with high-level task reasoning, and cannot dynamically update task strategies when instructions change during execution, which ultimately limits their versatility and adaptability to new tasks. In this work, we propose a novel language model-based framework for dynamic robot task planning. Our Vision-Language-Policy (VLP) model, based on a vision-language model fine-tuned on real-world data, can interpret semantic instructions and integrate reasoning over the current task scene to generate behavior policies that control the robot to accomplish the task. Moreover, it can dynamically adjust the task strategy in response to changes in the task, enabling flexible adaptation to evolving task requirements. Experiments conducted with different robots and a variety of real-world tasks show that the trained model can efficiently adapt to novel scenarios and dynamically update its policy, demonstrating strong planning autonomy and cross-embodiment generalization. Videos: https://robovlp.github.io/","authors":["Jin Wang","Kim Tien Ly","Jacques Cloete","Nikos Tsagarakis","Ioannis Havoutis"],"pdf_url":"","comment":"Manuscript under review"},{"id":"http://arxiv.org/abs/2512.19155v1","updated":"2025-12-22T08:52:07Z","published":"2025-12-22T08:52:07Z","title":"Can We Test Consciousness Theories on AI? Ablations, Markers, and Robustness","summary":"The search for reliable indicators of consciousness has fragmented into competing theoretical camps (Global Workspace Theory (GWT), Integrated Information Theory (IIT), and Higher-Order Theories (HOT)), each proposing distinct neural signatures. We adopt a synthetic neuro-phenomenology approach: constructing artificial agents that embody these mechanisms to test their functional consequences through precise architectural ablations impossible in biological systems. Across three experiments, we report dissociations suggesting these theories describe complementary functional layers rather than competing accounts. In Experiment 1, a no-rewire Self-Model lesion abolishes metacognitive calibration while preserving first-order task performance, yielding a synthetic blindsight analogue consistent with HOT predictions. In Experiment 2, workspace capacity proves causally necessary for information access: a complete workspace lesion produces qualitative collapse in access-related markers, while partial reductions show graded degradation, consistent with GWT's ignition framework. In Experiment 3, we uncover a broadcast-amplification effect: GWT-style broadcasting amplifies internal noise, creating extreme fragility. The B2 agent family is robust to the same latent perturbation; this robustness persists in a Self-Model-off / workspace-read control, cautioning against attributing the effect solely to $z_{\\text{self}}$ compression. We also report an explicit negative result: raw perturbational complexity (PCI-A) decreases under the workspace bottleneck, cautioning against naive transfer of IIT-adjacent proxies to engineered agents. These results suggest a hierarchical design principle: GWT provides broadcast capacity, while HOT provides quality control. We emphasize that our agents are not conscious; they are reference implementations for testing functional predictions of consciousness theories.","authors":["Yin Jun Phua"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19154v1","updated":"2025-12-22T08:50:30Z","published":"2025-12-22T08:50:30Z","title":"Beyond Sliding Windows: Learning to Manage Memory in Non-Markovian Environments","summary":"Recent success in developing increasingly general purpose agents based on sequence models has led to increased focus on the problem of deploying computationally limited agents within the vastly more complex real-world. A key challenge experienced in these more realistic domains is highly non-Markovian dependencies with respect to the agent's observations, which are less common in small controlled domains. The predominant approach for dealing with this in the literature is to stack together a window of the most recent observations (Frame Stacking), but this window size must grow with the degree of non-Markovian dependencies, which results in prohibitive computational and memory requirements for both action inference and learning. In this paper, we are motivated by the insight that in many environments that are highly non-Markovian with respect to time, the environment only causally depends on a relatively small number of observations over that time-scale. A natural direction would then be to consider meta-algorithms that maintain relatively small adaptive stacks of memories such that it is possible to express highly non-Markovian dependencies with respect to time while considering fewer observations at each step and thus experience substantial savings in both compute and memory requirements. Hence, we propose a meta-algorithm (Adaptive Stacking) for achieving exactly that with convergence guarantees and quantify the reduced computation and memory constraints for MLP, LSTM, and Transformer-based agents. Our experiments utilize popular memory tasks, which give us control over the degree of non-Markovian dependencies. This allows us to demonstrate that an appropriate meta-algorithm can learn the removal of memories not predictive of future rewards without excessive removal of important experiences. Code: https://github.com/geraudnt/adaptive-stacking","authors":["Geraud Nangue Tasse","Matthew Riemer","Benjamin Rosman","Tim Klinger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.09392v4","updated":"2025-12-22T08:42:42Z","published":"2025-11-12T15:00:52Z","title":"Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm","summary":"Sequential Recommenders, which exploit dynamic user intents through interaction sequences, is vulnerable to adversarial attacks. While existing attacks primarily rely on data poisoning, they require large-scale user access or fake profiles thus lacking practicality. In this paper, we focus on the Profile Pollution Attack that subtly contaminates partial user interactions to induce targeted mispredictions. Previous PPA methods suffer from two limitations, i.e., i) over-reliance on sequence horizon impact restricts fine-grained perturbations on item transitions, and ii) holistic modifications cause detectable distribution shifts. To address these challenges, we propose a constrained reinforcement driven attack CREAT that synergizes a bi-level optimization framework with multi-reward reinforcement learning to balance adversarial efficacy and stealthiness. We first develop a Pattern Balanced Rewarding Policy, which integrates pattern inversion rewards to invert critical patterns and distribution consistency rewards to minimize detectable shifts via unbalanced co-optimal transport. Then we employ a Constrained Group Relative Reinforcement Learning paradigm, enabling step-wise perturbations through dynamic barrier constraints and group-shared experience replay, achieving targeted pollution with minimal detectability. Extensive experiments demonstrate the effectiveness of CREAT.","authors":["Jiajie Su","Zihan Nan","Yunshan Ma","Xiaobo Xia","Xiaohua Feng","Weiming Liu","Xiang Chen","Xiaolin Zheng","Chaochao Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19135v1","updated":"2025-12-22T08:28:08Z","published":"2025-12-22T08:28:08Z","title":"Understanding Chain-of-Thought in Large Language Models via Topological Data Analysis","summary":"With the development of large language models (LLMs), particularly with the introduction of the long reasoning chain technique, the reasoning ability of LLMs in complex problem-solving has been significantly enhanced. While acknowledging the power of long reasoning chains, we cannot help but wonder: Why do different reasoning chains perform differently in reasoning? What components of the reasoning chains play a key role? Existing studies mainly focus on evaluating reasoning chains from a functional perspective, with little attention paid to their structural mechanisms. To address this gap, this work is the first to analyze and evaluate the quality of the reasoning chain from a structural perspective. We apply persistent homology from Topological Data Analysis (TDA) to map reasoning steps into semantic space, extract topological features, and analyze structural changes. These changes reveal semantic coherence, logical redundancy, and identify logical breaks and gaps. By calculating homology groups, we assess connectivity and redundancy at various scales, using barcode and persistence diagrams to quantify stability and consistency. Our results show that the topological structural complexity of reasoning chains correlates positively with accuracy. More complex chains identify correct answers sooner, while successful reasoning exhibits simpler topologies, reducing redundancy and cycles, enhancing efficiency and interpretability. This work provides a new perspective on reasoning chain quality assessment and offers guidance for future optimization.","authors":["Chenghao Li","Chaoning Zhang","Yi Lu","Shuxu Chen","Xudong Wang","Jiaquan Zhang","Zhicheng Wang","Zhengxun Jin","Kuien Liu","Sung-Ho Bae","Guoqing Wang","Yang Yang","Hen Tao Shen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.14806v4","updated":"2025-12-22T08:18:12Z","published":"2025-12-16T18:51:23Z","title":"Let the Barbarians In: How AI Can Accelerate Systems Performance Research","summary":"Artificial Intelligence (AI) is beginning to transform the research process by automating the discovery of new solutions. This shift depends on the availability of reliable verifiers, which AI-driven approaches require to validate candidate solutions. Research focused on improving systems performance is especially well-suited to this paradigm because system performance problems naturally admit such verifiers: candidates can be implemented in real systems or simulators and evaluated against predefined workloads. We term this iterative cycle of generation, evaluation, and refinement AI-Driven Research for Systems (ADRS). Using several open-source ADRS instances (i.e., OpenEvolve, GEPA, and ShinkaEvolve), we demonstrate across ten case studies (e.g., multi-region cloud scheduling, mixture-of-experts load balancing, LLM-based SQL, transaction scheduling) that ADRS-generated solutions can match or even outperform human state-of-the-art designs. Based on these findings, we outline best practices (e.g., level of prompt specification, amount of feedback, robust evaluation) for effectively using ADRS, and we discuss future research directions and their implications. Although we do not yet have a universal recipe for applying ADRS across all of systems research, we hope our preliminary findings, together with the challenges we identify, offer meaningful guidance for future work as researcher effort shifts increasingly toward problem formulation and strategic oversight.\n  Note: This paper is an extension of our prior work [14]. It adds extensive evaluation across multiple ADRS frameworks and provides deeper analysis and insights into best practices.","authors":["Audrey Cheng","Shu Liu","Melissa Pan","Zhifei Li","Shubham Agarwal","Mert Cemri","Bowen Wang","Alexander Krentsel","Tian Xia","Jongseok Park","Shuo Yang","Jeff Chen","Lakshya Agrawal","Ashwin Naren","Shulu Li","Ruiying Ma","Aditya Desai","Jiarong Xing","Koushik Sen","Matei Zaharia","Ion Stoica"],"pdf_url":"","comment":"arXiv admin note: substantial text overlap with arXiv:2510.06189"},{"id":"http://arxiv.org/abs/2512.13142v3","updated":"2025-12-22T07:53:31Z","published":"2025-12-15T09:50:00Z","title":"Can AI Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma Across Cognitive, Interpersonal, and Structural Levels","summary":"As large language models increasingly mediate stigmatized health decisions, their capacity to genuinely understand complex psychological and physiological phenomena remains poorly evaluated. Can AI understand what we cannot say? We investigate whether LLMs coherently represent abortion stigma across the cognitive, interpersonal, and structural levels where it operates. We systematically tested 627 demographically diverse personas across five leading LLMs using the validated Individual Level Abortion Stigma Scale (ILAS). Our multilevel analysis examined whether models coherently represent stigma at the cognitive level (self-judgment), interpersonal level (worries about judgment and isolation), and structural level (community condemnation and disclosure patterns), as well as overall stigma. Models fail tests of genuine understanding across all levels. They overestimate interpersonal stigma while underestimating cognitive stigma, assume uniform community condemnation, introduce demographic biases absent from human validation data, miss the empirically validated stigma-secrecy relationship, and contradict themselves within theoretical constructs. These patterns reveal that current alignment approaches ensure appropriate language but not coherent multilevel understanding. This work provides empirical evidence that current LLMs lack coherent multilevel understanding of psychological and physiological constructs. AI safety in high-stakes contexts demands new approaches to design (multilevel coherence), evaluation (continuous auditing), governance and regulation (mandatory audits, accountability, deployment restrictions), and AI literacy in domains where understanding what people cannot say determines whether support helps or harms.","authors":["Anika Sharma","Malavika Mampally","Chidaksh Ravuru","Kandyce Brennan","Neil Gaikwad"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.11712v3","updated":"2025-12-22T07:47:22Z","published":"2025-06-13T12:29:15Z","title":"Mitigating Hallucination Through Theory-Consistent Symmetric Multimodal Preference Optimization","summary":"Direct Preference Optimization (DPO) has emerged as an effective approach for mitigating hallucination in Multimodal Large Language Models (MLLMs). Although existing methods have achieved significant progress by utilizing vision-oriented contrastive objectives for enhancing MLLMs' attention to visual inputs and hence reducing hallucination, they suffer from non-rigorous optimization objective function and indirect preference supervision. To address these limitations, we propose a Symmetric Multimodal Preference Optimization (SymMPO), which conducts symmetric preference learning with direct preference supervision (i.e., response pairs) for visual understanding enhancement, while maintaining rigorous theoretical alignment with standard DPO. In addition to conventional ordinal preference learning, SymMPO introduces a preference margin consistency loss to quantitatively regulate the preference gap between symmetric preference pairs. Comprehensive evaluation across five benchmarks demonstrate SymMPO's superior performance, validating its effectiveness in hallucination mitigation of MLLMs.","authors":["Wenqi Liu","Xuemeng Song","Jiaxi Li","Yinwei Wei","Na Zheng","Jianhua Yin","Liqiang Nie"],"pdf_url":"","comment":"NeurIPS 2025"},{"id":"http://arxiv.org/abs/2512.19114v1","updated":"2025-12-22T07:35:16Z","published":"2025-12-22T07:35:16Z","title":"HyperLoad: A Cross-Modality Enhanced Large Language Model-Based Framework for Green Data Center Cooling Load Prediction","summary":"The rapid growth of artificial intelligence is exponentially escalating computational demand, inflating data center energy use and carbon emissions, and spurring rapid deployment of green data centers to relieve resource and environmental stress. Achieving sub-minute orchestration of renewables, storage, and loads, while minimizing PUE and lifecycle carbon intensity, hinges on accurate load forecasting. However, existing methods struggle to address small-sample scenarios caused by cold start, load distortion, multi-source data fragmentation, and distribution shifts in green data centers. We introduce HyperLoad, a cross-modality framework that exploits pre-trained large language models (LLMs) to overcome data scarcity. In the Cross-Modality Knowledge Alignment phase, textual priors and time-series data are mapped to a common latent space, maximizing the utility of prior knowledge. In the Multi-Scale Feature Modeling phase, domain-aligned priors are injected through adaptive prefix-tuning, enabling rapid scenario adaptation, while an Enhanced Global Interaction Attention mechanism captures cross-device temporal dependencies. The public DCData dataset is released for benchmarking. Under both data sufficient and data scarce settings, HyperLoad consistently surpasses state-of-the-art (SOTA) baselines, demonstrating its practicality for sustainable green data center management.","authors":["Haoyu Jiang","Boan Qu","Junjie Zhu","Fanjie Zeng","Xiaojie Lin","Wei Zhong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19107v1","updated":"2025-12-22T07:21:07Z","published":"2025-12-22T07:21:07Z","title":"FC-MIR: A Mobile Screen Awareness Framework for Intent-Aware Recommendation based on Frame-Compressed Multimodal Trajectory Reasoning","summary":"Identifying user intent from mobile UI operation trajectories is critical for advancing UI understanding and enabling task automation agents. While Multimodal Large Language Models (MLLMs) excel at video understanding tasks, their real-time mobile deployment is constrained by heavy computational costs and inefficient redundant frame processing. To address these issues, we propose the FC-MIR framework: leveraging keyframe sampling and adaptive concatenation, it cuts visual redundancy to boost inference efficiency, while integrating state-of-the-art closed-source MLLMs or fine-tuned models (e.g., Qwen3-VL) for trajectory summarization and intent prediction. We further expand task scope to explore generating post-prediction operations and search suggestions, and introduce a fine-grained metric to evaluate the practical utility of summaries, predictions, and suggestions. For rigorous assessment, we construct a UI trajectory dataset covering scenarios from UI-Agents (Agent-I) and real user interactions (Person-I). Experimental results show our compression method retains performance at 50%-60% compression rates; both closed-source and fine-tuned MLLMs demonstrate strong intent summarization, supporting potential lightweight on-device deployment. However, MLLMs still struggle with useful and \"surprising\" suggestions, leaving room for improvement. Finally, we deploy the framework in a real-world setting, integrating UI perception and UI-Agent proxies to lay a foundation for future progress in this field.","authors":["Zhe Yang","Xiaoshuang Sheng","Zhengnan Zhang","Jidong Wu","Zexing Wang","Xin He","Shenghua Xu","Guanjing Xiong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.25300v3","updated":"2025-12-22T07:20:59Z","published":"2025-09-29T17:10:35Z","title":"Scaling Behaviors of LLM Reinforcement Learning Post-Training: An Empirical Study in Mathematical Reasoning","summary":"While scaling laws for large language models (LLMs) during pre-training have been extensively studied, their behavior under reinforcement learning (RL) post-training remains largely unexplored. This paper presents a systematic empirical investigation of scaling behaviors in RL-based post-training, with a particular focus on mathematical reasoning. Based on a set of experiments across the full Qwen2.5 dense model series (0.5B to 72B), we characterize how model scale, data volume, and computational budget interact to shape performance. Our analysis leads to four key findings: 1. Larger models consistently exhibit superior learning efficiency on both compute and data metrics. 2. The relationship between test loss, compute, and data can be modeled by a predictive power-law which is robust across both base and instruction-tuned models. 3. Although larger models exhibit higher learning efficiency, the analytical learning efficiency term k(N) in the power-law reveals a latent saturation trend in learning efficiency as model size continues to increase. 4. In data-constrained regimes, repeated reuse of high-quality data proves highly effective, as final performance is primarily governed by the total number of optimization steps rather than the uniqueness of samples. Collectively, these results provide a principled foundation and practical guidelines for efficiently scaling the reasoning capabilities of LLMs through RL post-training.","authors":["Zelin Tan","Hejia Geng","Xiaohang Yu","Mulei Zhang","Guancheng Wan","Yifan Zhou","Qiang He","Xiangyuan Xue","Heng Zhou","Yutao Fan","Zhongzhi Li","Zaibin Zhang","Guibin Zhang","Chen Zhang","Zhenfei Yin","Philip Torr","Lei Bai"],"pdf_url":"","comment":"V3 version:27 pages, 14 figures, add code and dataset url"},{"id":"http://arxiv.org/abs/2507.02314v4","updated":"2025-12-22T07:17:17Z","published":"2025-07-03T04:54:37Z","title":"MAGIC: Few-Shot Mask-Guided Anomaly Inpainting with Prompt Perturbation, Spatially Adaptive Guidance, and Context Awareness","summary":"Few-shot anomaly generation is a key challenge in industrial quality control. Although diffusion models are promising, existing methods struggle: global prompt-guided approaches corrupt normal regions, and existing inpainting-based methods often lack the in-distribution diversity essential for robust downstream models. We propose MAGIC, a fine-tuned inpainting framework that generates high-fidelity anomalies that strictly adhere to the mask while maximizing this diversity. MAGIC introduces three complementary components: (i) Gaussian prompt perturbation, which prevents model overfitting in the few-shot setting by learning and sampling from a smooth manifold of realistic anomalies, (ii) spatially adaptive guidance that applies distinct guidance strengths to the anomaly and background regions, and (iii) context-aware mask alignment to relocate masks for plausible placement within the host object. Under consistent identical evaluation protocol, MAGIC outperforms state-of-the-art methods on diverse anomaly datasets in downstream tasks","authors":["JaeHyuck Choi","MinJun Kim","Je Hyeong Hong"],"pdf_url":"","comment":"46 pages, 47 figures. Code: https://github.com/SpatialAILab/MAGIC-Anomaly-generation"},{"id":"http://arxiv.org/abs/2512.19097v1","updated":"2025-12-22T07:07:43Z","published":"2025-12-22T07:07:43Z","title":"DIVER-1 : Deep Integration of Vast Electrophysiological Recordings at Scale","summary":"Electrophysiology signals such as EEG and iEEG are central to neuroscience, brain-computer interfaces, and clinical applications, yet existing foundation models remain limited in scale despite clear evidence that scaling improves performance. We introduce DIVER-1, a family of EEG and iEEG foundation models trained on the largest and most diverse corpus to date-5.3k hours of iEEG and 54k hours of EEG (1.6M channel-hours from over 17.7k subjects)-and scaled up to 1.82B parameters. We present the first systematic scaling law analysis for this domain, showing that they follow data-constrained scaling laws: for a given amount of data and compute, smaller models trained for extended epochs consistently outperform larger models trained briefly. This behavior contrasts with prior electrophysiology foundation models that emphasized model size over training duration. To achieve strong performance, we also design architectural innovations including any-variate attention, sliding temporal conditional positional encoding, and multi-domain reconstruction. DIVER-1 iEEG and EEG models each achieve state-of-the-art performance on their respective benchmarks, establishing a concrete guidelines for efficient scaling and resource allocation in electrophysiology foundation model development.","authors":["Danny Dongyeop Han","Yonghyeon Gwon","Ahhyun Lucy Lee","Taeyang Lee","Seong Jin Lee","Jubin Choi","Sebin Lee","Jihyun Bang","Seungju Lee","David Keetae Park","Shinjae Yoo","Chun Kee Chung","Jiook Cha"],"pdf_url":"","comment":"47 pages, 13 figures, 26 tables"},{"id":"http://arxiv.org/abs/2512.19096v1","updated":"2025-12-22T07:07:34Z","published":"2025-12-22T07:07:34Z","title":"Conditioning Accept-Desirability models in the context of AGM-like belief change","summary":"We discuss conditionalisation for Accept-Desirability models in an abstract decision-making framework, where uncertain rewards live in a general linear space, and events are special projection operators on that linear space. This abstract setting allows us to unify classical and quantum probabilities, and extend them to an imprecise probabilities context. We introduce a new conditioning rule for our Accept-Desirability models, based on the idea that observing an event introduces new indifferences between options. We associate a belief revision operator with our conditioning rule, and investigate which of the AGM axioms for belief revision still hold in our more general framework. We investigate two interesting special cases where all of these axioms are shown to still hold: classical propositional logic and full conditional probabilities.","authors":["Kathelijne Coussement","Gert de Cooman","Keano De Vos"],"pdf_url":"","comment":"46 pages, 1 table"},{"id":"http://arxiv.org/abs/2512.19093v1","updated":"2025-12-22T07:02:16Z","published":"2025-12-22T07:02:16Z","title":"Tool-Augmented Hybrid Ensemble Reasoning with Distillation for Bilingual Mathematical Problem Solving","summary":"Bilingual mathematical problem solving needs a clear link between language reasoning and symbolic calculation. Large language models often handle language well but are weak in accurate computation. This paper presents HERALD (Hybrid Ensemble Reasoning with Adaptive Learning and Distillation), a framework that joins reasoning and calculation using NuminaMath-7B-TIR, GPT-4o, and Mistral-7B. HERALD uses adaptive routing, tool-based reinforcement learning, and knowledge distillation to connect different reasoning paths. Confidence calibration keeps weighting stable, and dual-path checking keeps results correct. Reinforcement learning controls tool use to cut redundancy, and distillation lowers delay without hurting accuracy. The system shows that combining symbolic checking, adaptive ensembles, and bilingual fine-tuning helps achieve both fluent reasoning and precise calculation. HERALD offers a practical solution for multilingual mathematical reasoning with better accuracy, stability, and clarity.","authors":["Peiqing Lu","Yuan Zhang","Haoyun Zhang","Jiasen Zheng","Kejian Tong","Wenjun Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17582v3","updated":"2025-12-22T06:51:54Z","published":"2025-11-15T17:55:47Z","title":"GateRA: Token-Aware Modulation for Parameter-Efficient Fine-Tuning","summary":"Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, DoRA, and HiRA, enable lightweight adaptation of large pre-trained models via low-rank updates. However, existing PEFT approaches apply static, input-agnostic updates to all tokens, disregarding the varying importance and difficulty of different inputs. This uniform treatment can lead to overfitting on trivial content or under-adaptation on more informative regions, especially in autoregressive settings with distinct prefill and decoding dynamics. In this paper, we propose GateRA, a unified framework that introduces token-aware modulation to dynamically adjust the strength of PEFT updates. By incorporating adaptive gating into standard PEFT branches, GateRA enables selective, token-level adaptation, preserving pre-trained knowledge for well-modeled inputs while focusing capacity on challenging cases. Empirical visualizations reveal phase-sensitive behaviors, where GateRA automatically suppresses updates for redundant prefill tokens while emphasizing adaptation during decoding. To promote confident and efficient modulation, we further introduce an entropy-based regularization that encourages near-binary gating decisions. This regularization prevents diffuse update patterns and leads to interpretable, sparse adaptation without hard thresholding. Finally, we present a theoretical analysis showing that GateRA induces a soft gradient-masking effect over the PEFT path, enabling continuous and differentiable control over adaptation. Experiments on multiple commonsense reasoning benchmarks demonstrate that GateRA consistently outperforms or matches prior PEFT methods.","authors":["Jie Ou","Shuaihong Jiang","Yingjun Du","Cees G. M. Snoek"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2512.19084v1","updated":"2025-12-22T06:48:53Z","published":"2025-12-22T06:48:53Z","title":"$γ(3,4)$ `Attention' in Cognitive Agents: Ontology-Free Knowledge Representations With Promise Theoretic Semantics","summary":"The semantics and dynamics of `attention' are closely related to promise theoretic notions developed for autonomous agents and can thus easily be written down in promise framework. In this way one may establish a bridge between vectorized Machine Learning and Knowledge Graph representations without relying on language models implicitly. Our expectations for knowledge presume a degree of statistical stability, i.e. average invariance under repeated observation, or `trust' in the data. Both learning networks and knowledge graph representations can meaningfully coexist to preserve different aspects of data. While vectorized data are useful for probabilistic estimation, graphs preserve the intentionality of the source even under data fractionation. Using a Semantic Spacetime $γ(3,4)$ graph, one avoids complex ontologies in favour of classification of features by their roles in semantic processes. The latter favours an approach to reasoning under conditions of uncertainty. Appropriate attention to causal boundary conditions may lead to orders of magnitude compression of data required for such context determination, as required in the contexts of autonomous robotics, defence deployments, and ad hoc emergency services.","authors":["Mark Burgess"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19081v1","updated":"2025-12-22T06:42:46Z","published":"2025-12-22T06:42:46Z","title":"Population-Evolve: a Parallel Sampling and Evolutionary Method for LLM Math Reasoning","summary":"Test-time scaling has emerged as a promising direction for enhancing the reasoning capabilities of Large Language Models in last few years. In this work, we propose Population-Evolve, a training-free method inspired by Genetic Algorithms to optimize LLM reasoning. Our approach maintains a dynamic population of candidate solutions for each problem via parallel reasoning. By incorporating an evolve prompt, the LLM self-evolves its population in all iterations. Upon convergence, the final answer is derived via majority voting. Furthermore, we establish a unification framework that interprets existing test-time scaling strategies through the lens of genetic algorithms. Empirical results demonstrate that Population-Evolve achieves superior accuracy with low performance variance and computational efficiency. Our findings highlight the potential of evolutionary strategies to unlock the reasoning power of LLMs during inference.","authors":["Yanzhi Zhang","Yitong Duan","Zhaoxi Zhang","Jiyan He","Shuxin Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19069v1","updated":"2025-12-22T06:17:25Z","published":"2025-12-22T06:17:25Z","title":"Can abstract concepts from LLM improve SLM performance?","summary":"Large language models (LLMs) excel at diverse tasks, but their deployment on resource-constrained devices remains challenging. Existing methods like quantization, pruning, and distillation can reduce memory footprint but often demand extensive experimentation and careful infrastructure design. Leveraging existing techniques for extracting high-level concepts (represented as steering vectors) from larger models, we investigate their transferability to smaller language models (SLM) during inference. We demonstrate through extensive experimentation that these concepts can be effectively transferred to smaller models, irrespective of their family (e.g., Phi, Llama, Qwen), leading to performance improvements across a wide range of tasks. Furthermore, we introduce inference-time scaling to enhance performance by dynamically adjusting the steering intensity which has resulted in a 7-15\\% of accuracy improvement for Qwen3-0.6B.","authors":["Siddharth Tandon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.15178v4","updated":"2025-12-22T06:16:10Z","published":"2024-10-19T18:46:17Z","title":"GUIDEd Agents: Enhancing Navigation Policies through Task-Specific Uncertainty Abstraction in Localization-Limited Environments","summary":"Autonomous vehicles performing navigation tasks in complex environments face significant challenges due to uncertainty in state estimation. In many scenarios, such as stealth operations or resource-constrained settings, accessing high-precision localization comes at a significant cost, forcing robots to rely primarily on less precise state estimates. Our key observation is that different tasks require varying levels of precision in different regions: a robot navigating a crowded space might need precise localization near obstacles but can operate effectively with less precision elsewhere. In this paper, we present a planning method for integrating task-specific uncertainty requirements directly into navigation policies. We introduce Task-Specific Uncertainty Maps (TSUMs), which abstract the acceptable levels of state estimation uncertainty across different regions. TSUMs align task requirements and environmental features using a shared representation space, generated via a domain-adapted encoder. Using TSUMs, we propose Generalized Uncertainty Integration for Decision-Making and Execution (GUIDE), a policy conditioning framework that incorporates these uncertainty requirements into robot decision-making. We find that TSUMs provide an effective way to abstract task-specific uncertainty requirements, and conditioning policies on TSUMs enables the robot to reason about the context-dependent value of certainty and adapt its behavior accordingly. We show how integrating GUIDE into reinforcement learning frameworks allows the agent to learn navigation policies that effectively balance task completion and uncertainty management without explicit reward engineering. We evaluate GUIDE on various real-world robotic navigation tasks and find that it demonstrates significant improvement in task completion rates compared to baseline methods that do not explicitly consider task-specific uncertainty.","authors":["Gokul Puthumanaillam","Paulo Padrao","Jose Fuentes","Leonardo Bobadilla","Melkior Ornik"],"pdf_url":"","comment":"Accepted for publication at RAL (Robotics and automation letters). Updated with the final version"},{"id":"http://arxiv.org/abs/2508.14075v2","updated":"2025-12-22T06:08:18Z","published":"2025-08-12T11:20:27Z","title":"Explainable Graph Spectral Clustering For GloVe-like Text Embeddings","summary":"In a previous paper, we proposed an introduction to the explainability of Graph Spectral Clustering results for textual documents, given that document similarity is computed as cosine similarity in term vector space.\n  In this paper, we generalize this idea by considering other embeddings of documents, in particular, based on the GloVe embedding idea.","authors":["Mieczysław A. Kłopotek","Sławomir T. Wierzchoń","Bartłomiej Starosta","Piotr Borkowski","Dariusz Czerski","Eryk Laskowski"],"pdf_url":"","comment":"47 pages, 19 tables, 11 figures"},{"id":"http://arxiv.org/abs/2512.19061v1","updated":"2025-12-22T05:59:13Z","published":"2025-12-22T05:59:13Z","title":"Fraud Detection Through Large-Scale Graph Clustering with Heterogeneous Link Transformation","summary":"Collaborative fraud, where multiple fraudulent accounts coordinate to exploit online payment systems, poses significant challenges due to the formation of complex network structures. Traditional detection methods that rely solely on high-confidence identity links suffer from limited coverage, while approaches using all available linkages often result in fragmented graphs with reduced clustering effectiveness. In this paper, we propose a novel graph-based fraud detection framework that addresses the challenge of large-scale heterogeneous graph clustering through a principled link transformation approach. Our method distinguishes between \\emph{hard links} (high-confidence identity relationships such as phone numbers, credit cards, and national IDs) and \\emph{soft links} (behavioral associations including device fingerprints, cookies, and IP addresses). We introduce a graph transformation technique that first identifies connected components via hard links, merges them into super-nodes, and then reconstructs a weighted soft-link graph amenable to efficient embedding and clustering. The transformed graph is processed using LINE (Large-scale Information Network Embedding) for representation learning, followed by HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise) for density-based cluster discovery. Experiments on a real-world payment platform dataset demonstrate that our approach achieves significant graph size reduction (from 25 million to 7.7 million nodes), doubles the detection coverage compared to hard-link-only baselines, and maintains high precision across identified fraud clusters. Our framework provides a scalable and practical solution for industrial-scale fraud detection systems.","authors":["Chi Liu"],"pdf_url":"","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.07019v7","updated":"2025-12-22T05:48:26Z","published":"2024-11-11T14:22:42Z","title":"UniHR: Hierarchical Representation Learning for Unified Knowledge Graph Link Prediction","summary":"Real-world knowledge graphs (KGs) contain not only standard triple-based facts, but also more complex, heterogeneous types of facts, such as hyper-relational facts with auxiliary key-value pairs, temporal facts with additional timestamps, and nested facts that imply relationships between facts. These richer forms of representation have attracted significant attention due to their enhanced expressiveness and capacity to model complex semantics in real-world scenarios. However, most existing studies suffer from two main limitations: (1) they typically focus on modeling only specific types of facts, thus making it difficult to generalize to real-world scenarios with multiple fact types; and (2) they struggle to achieve generalizable hierarchical (inter-fact and intra-fact) modeling due to the complexity of these representations. To overcome these limitations, we propose UniHR, a Unified Hierarchical Representation learning framework, which consists of a learning-optimized Hierarchical Data Representation (HiDR) module and a unified Hierarchical Structure Learning (HiSL) module. The HiDR module unifies hyper-relational KGs, temporal KGs, and nested factual KGs into triple-based representations. Then HiSL incorporates intra-fact and inter-fact message passing, focusing on enhancing both semantic information within individual facts and enriching the structural information between facts. To go beyond the unified method itself, we further explore the potential of unified representation in complex real-world scenarios. Extensive experiments on 9 datasets across 5 types of KGs demonstrate the effectiveness of UniHR and highlight the strong potential of unified representations. Code and data are available at https://github.com/zjukg/UniHR.","authors":["Zhiqiang Liu","Yin Hua","Mingyang Chen","Yichi Zhang","Zhuo Chen","Lei Liang","Wen Zhang"],"pdf_url":"","comment":"AAAI 2026 (oral)"},{"id":"http://arxiv.org/abs/2503.11185v2","updated":"2025-12-22T05:32:02Z","published":"2025-03-14T08:32:12Z","title":"Bleeding Pathways: Vanishing Discriminability in LLM Hidden States Fuels Jailbreak Attacks","summary":"LLMs remain vulnerable to jailbreak attacks that exploit adversarial prompts to circumvent safety measures. Current safety fine-tuning approaches face two critical limitations. First, they often fail to strike a balance between security and utility, where stronger safety measures tend to over-reject harmless user requests. Second, they frequently miss malicious intent concealed within seemingly benign tasks, leaving models exposed to exploitation. Our work identifies a fundamental cause of these issues: during response generation, an LLM's capacity to differentiate harmful from safe outputs deteriorates. Experimental evidence confirms this, revealing that the separability between hidden states for safe and harmful responses diminishes as generation progresses. This weakening discrimination forces models to make compliance judgments earlier in the generation process, restricting their ability to recognize developing harmful intent and contributing to both aforementioned failures. To mitigate this vulnerability, we introduce DEEPALIGN - an inherent defense framework that enhances the safety of LLMs. By applying contrastive hidden-state steering at the midpoint of response generation, DEEPALIGN amplifies the separation between harmful and benign hidden states, enabling continuous intrinsic toxicity detection and intervention throughout the generation process. Across diverse LLMs spanning varying architectures and scales, it reduced attack success rates of nine distinct jailbreak attacks to near-zero or minimal. Crucially, it preserved model capability while reducing over-refusal. Models equipped with DEEPALIGN exhibited up to 3.5% lower error rates in rejecting challenging benign queries and maintained standard task performance with less than 1% decline. This marks a substantial advance in the safety-utility Pareto frontier.","authors":["Yingjie Zhang","Tong Liu","Zhe Zhao","Guozhu Meng","Kai Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19027v1","updated":"2025-12-22T04:53:40Z","published":"2025-12-22T04:53:40Z","title":"Recontextualization Mitigates Specification Gaming without Modifying the Specification","summary":"Developers often struggle to specify correct training labels and rewards. Perhaps they don't need to. We propose recontextualization, which reduces how often language models \"game\" training signals, performing misbehaviors those signals mistakenly reinforce. We show recontextualization prevents models from learning to 1) prioritize evaluation metrics over chat response quality; 2) special-case code to pass incorrect tests; 3) lie to users; and 4) become sycophantic. Our method works by generating completions from prompts discouraging misbehavior and then recontextualizing them as though they were in response to prompts permitting misbehavior. Recontextualization trains language models to resist misbehavior even when instructions permit it. This mitigates the reinforcement of misbehavior from misspecified training signals, reducing specification gaming without improving the supervision signal.","authors":["Ariana Azarbal","Victor Gillioz","Vladimir Ivanov","Bryce Woodworth","Jacob Drori","Nevan Wichers","Aram Ebtekar","Alex Cloud","Alexander Matt Turner"],"pdf_url":"","comment":"57 pages, 41 figures"},{"id":"http://arxiv.org/abs/2512.19026v1","updated":"2025-12-22T04:53:40Z","published":"2025-12-22T04:53:40Z","title":"Finer-Personalization Rank: Fine-Grained Retrieval Examines Identity Preservation for Personalized Generation","summary":"The rise of personalized generative models raises a central question: how should we evaluate identity preservation? Given a reference image (e.g., one's pet), we expect the generated image to retain precise details attached to the subject's identity. However, current generative evaluation metrics emphasize the overall semantic similarity between the reference and the output, and overlook these fine-grained discriminative details. We introduce Finer-Personalization Rank, an evaluation protocol tailored to identity preservation. Instead of pairwise similarity, Finer-Personalization Rank adopts a ranking view: it treats each generated image as a query against an identity-labeled gallery consisting of visually similar real images. Retrieval metrics (e.g., mean average precision) measure performance, where higher scores indicate that identity-specific details (e.g., a distinctive head spot) are preserved. We assess identity at multiple granularities -- from fine-grained categories (e.g., bird species, car models) to individual instances (e.g., re-identification). Across CUB, Stanford Cars, and animal Re-ID benchmarks, Finer-Personalization Rank more faithfully reflects identity retention than semantic-only metrics and reveals substantial identity drift in several popular personalization methods. These results position the gallery-based protocol as a principled and practical evaluation for personalized generation.","authors":["Connor Kilrain","David Carlyn","Julia Chae","Sara Beery","Wei-Lun Chao","Jianyang Gu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19025v1","updated":"2025-12-22T04:42:41Z","published":"2025-12-22T04:42:41Z","title":"The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation","summary":"Machine unlearning aims to remove specific data influences from trained models, a capability essential for adhering to copyright laws and ensuring AI safety. Current unlearning metrics typically measure success by monitoring the model's performance degradation on the specific unlearning dataset ($D_u$). We argue that for Large Language Models (LLMs), this evaluation paradigm is insufficient and potentially misleading. Many real-world uses of unlearning--motivated by copyright or safety--implicitly target not only verbatim content in $D_u$, but also behaviors influenced by the broader generalizations the model derived from it. We demonstrate that LLMs can pass standard unlearning evaluation and appear to have ``forgotten'' the target knowledge, while simultaneously retaining strong capabilities on content that is semantically adjacent to $D_u$. This phenomenon indicates that erasing exact sentences does not necessarily equate to removing the underlying knowledge. To address this gap, we propose \\name, an automated stress-testing framework that generates a surrogate dataset, $\\tilde{D}_u$. This surrogate set is constructed to be semantically derived from $D_u$ yet sufficiently distinct in embedding space. By comparing unlearning metric scores between $D_u$ and $\\tilde{D}_u$, we can stress-test the reliability of the metric itself. Our extensive evaluation across three LLM families (Llama-3-8B, Qwen2.5-7B, and Zephyr-7B-$β$), three distinct datasets, and seven standard metrics reveals widespread inconsistencies. We find that current metrics frequently overestimate unlearning success, failing to detect retained knowledge exposed by our stress-test datasets.","authors":["Hengrui Jia","Taoran Li","Jonas Guan","Varun Chandrasekaran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19024v1","updated":"2025-12-22T04:42:35Z","published":"2025-12-22T04:42:35Z","title":"IndoorUAV: Benchmarking Vision-Language UAV Navigation in Continuous Indoor Environments","summary":"Vision-Language Navigation (VLN) enables agents to navigate in complex environments by following natural language instructions grounded in visual observations. Although most existing work has focused on ground-based robots or outdoor Unmanned Aerial Vehicles (UAVs), indoor UAV-based VLN remains underexplored, despite its relevance to real-world applications such as inspection, delivery, and search-and-rescue in confined spaces. To bridge this gap, we introduce \\textbf{IndoorUAV}, a novel benchmark and method specifically tailored for VLN with indoor UAVs. We begin by curating over 1,000 diverse and structurally rich 3D indoor scenes from the Habitat simulator. Within these environments, we simulate realistic UAV flight dynamics to collect diverse 3D navigation trajectories manually, further enriched through data augmentation techniques. Furthermore, we design an automated annotation pipeline to generate natural language instructions of varying granularity for each trajectory. This process yields over 16,000 high-quality trajectories, comprising the \\textbf{IndoorUAV-VLN} subset, which focuses on long-horizon VLN. To support short-horizon planning, we segment long trajectories into sub-trajectories by selecting semantically salient keyframes and regenerating concise instructions, forming the \\textbf{IndoorUAV-VLA} subset. Finally, we introduce \\textbf{IndoorUAV-Agent}, a novel navigation model designed for our benchmark, leveraging task decomposition and multimodal reasoning. We hope IndoorUAV serves as a valuable resource to advance research on vision-language embodied AI in the indoor aerial navigation domain.","authors":["Xu Liu","Yu Liu","Hanshuo Qiu","Yang Qirong","Zhouhui Lian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.11496v3","updated":"2025-12-22T04:40:04Z","published":"2025-10-13T15:04:38Z","title":"AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model","summary":"In recent years, while cloud-based MLLMs such as QwenVL, InternVL, GPT-4o, Gemini, and Claude Sonnet have demonstrated outstanding performance with enormous model sizes reaching hundreds of billions of parameters, they significantly surpass the limitations in memory, power consumption, and computing capacity of edge devices such as mobile phones. This paper introduces AndesVL, a suite of mobile-side MLLMs with 0.6B to 4B parameters based on Qwen3's LLM and various visual encoders. We comprehensively outline the model architectures, training pipeline, and training data of AndesVL, which achieves first-tier performance across a wide range of open-source benchmarks, including fields such as text-rich image understanding, reasoning and math, multi-image comprehension, general VQA, hallucination mitigation, multilingual understanding, and GUI-related tasks when compared with state-of-the-art models of a similar scale. Furthermore, we introduce a 1+N LoRA architecture alongside a Quantization-Aware LoRA Fine-Tuning (QALFT) framework to facilitate efficient task adaptation and model compression during mobile-side deployment of AndesVL. Moreover, utilizing our cache eviction algorithm -- OKV -- along with customized speculative decoding and compression strategies, we achieve a 6.7x peak decoding speedup ratio, up to 30.9% memory reduction, and 1.8 bits-per-weight when deploying AndesVL-4B on MediaTek Dimensity 9500 chips. We release all models on https://huggingface.co/OPPOer.","authors":["Zhiwei Jin","Xiaohui Song","Nan Wang","Yafei Liu","Chao Li","Xin Li","Ruichen Wang","Zhihao Li","Qi Qi","Long Cheng","Dongze Hao","Quanlong Zheng","Yanhao Zhang","Haobo Ji","Jian Ma","Zhitong Zheng","Zhenyi Lin","Haolin Deng","Xin Zou","Xiaojie Yin","Ruilin Wang","Liankai Cai","Haijing Liu","Yuqing Qiu","Ke Chen","Zixian Li","Chi Xie","Huafei Li","Chenxing Li","Chuangchuang Wang","Kai Tang","Zhiguang Zhu","Kai Tang","Wenmei Gao","Rui Wang","Jun Wu","Chao Liu","Qin Xie","Chen Chen","Haonan Lu"],"pdf_url":"","comment":"Tech report of OPPO AndesVL Team"},{"id":"http://arxiv.org/abs/2512.11469v2","updated":"2025-12-22T04:02:51Z","published":"2025-12-12T11:12:42Z","title":"Three methods, one problem: Classical and AI approaches to no-three-in-line","summary":"The No-Three-In-Line problem asks for the maximum number of points that can be placed on an n by n grid with no three collinear, representing a famous problem in combinatorial geometry. While classical methods like Integer Linear Programming (ILP) guarantee optimal solutions, they face exponential scaling with grid size, and recent advances in machine learning offer promising alternatives for pattern-based approximation. This paper presents the first systematic comparison of classical optimization and AI approaches to this problem, evaluating their performance against traditional algorithms. We apply PatternBoost transformer learning and reinforcement learning (PPO) to this problem for the first time, comparing them against ILP. ILP achieves provably optimal solutions up to 19 by 19 grids, while PatternBoost matches optimal performance up to 14 by 14 grids with 96% test loss reduction. PPO achieves perfect solutions on 10 by 10 grids but fails at 11 by 11 grids, where constraint violations prevent valid configurations. These results demonstrate that classical optimization remains essential for exact solutions while AI methods offer competitive performance on smaller instances, with hybrid approaches presenting the most promising direction for scaling to larger problem sizes.","authors":["Pranav Ramanathan","Thomas Prellberg","Matthew Lewis","Prathamesh Dinesh Joshi","Raj Abhijit Dandekar","Rajat Dandekar","Sreedath Panat"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19011v1","updated":"2025-12-22T04:00:35Z","published":"2025-12-22T04:00:35Z","title":"Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline","summary":"Prompt injection and jailbreaking attacks pose persistent security challenges to large language model (LLM)-based systems. We present an efficient and systematically evaluated defense architecture that mitigates these threats through a lightweight, multi-stage pipeline. Its core component is a semantic filter based on text normalization, TF-IDF representations, and a Linear SVM classifier. Despite its simplicity, this module achieves 93.4% accuracy and 96.5% specificity on held-out data, substantially reducing attack throughput while incurring negligible computational overhead.\n  Building on this efficient foundation, the full pipeline integrates complementary detection and mitigation mechanisms that operate at successive stages, providing strong robustness with minimal latency. In comparative experiments, our SVM-based configuration improves overall accuracy from 35.1% to 93.4% while reducing average time to completion from approximately 450s to 47s, yielding over 10 times lower latency than ShieldGemma. These results demonstrate that the proposed design simultaneously advances defensive precision and efficiency, addressing a core limitation of current model-based moderators.\n  Evaluation across a curated corpus of over 30,000 labeled prompts, including benign, jailbreak, and application-layer injections, confirms that staged, resource-efficient defenses can robustly secure modern LLM-driven applications.","authors":["Akshaj Prashanth Rao","Advait Singh","Saumya Kumaar Saksena","Dhruv Kumar"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2512.19007v1","updated":"2025-12-22T03:48:31Z","published":"2025-12-22T03:48:31Z","title":"The 6th International Verification of Neural Networks Competition (VNN-COMP 2025): Summary and Results","summary":"This report summarizes the 6th International Verification of Neural Networks Competition (VNN-COMP 2025), held as a part of the 8th International Symposium on AI Verification (SAIV), that was collocated with the 37th International Conference on Computer-Aided Verification (CAV). VNN-COMP is held annually to facilitate the fair and objective comparison of state-of-the-art neural network verification tools, encourage the standardization of tool interfaces, and bring together the neural network verification community. To this end, standardized formats for networks (ONNX) and specification (VNN-LIB) were defined, tools were evaluated on equal-cost hardware (using an automatic evaluation pipeline based on AWS instances), and tool parameters were chosen by the participants before the final test sets were made public. In the 2025 iteration, 8 teams participated on a diverse set of 16 regular and 9 extended benchmarks. This report summarizes the rules, benchmarks, participating tools, results, and lessons learned from this iteration of this competition.","authors":["Konstantin Kaulen","Tobias Ladner","Stanley Bak","Christopher Brix","Hai Duong","Thomas Flinkow","Taylor T. Johnson","Lukas Koller","Edoardo Manino","ThanhVu H Nguyen","Haoze Wu"],"pdf_url":"","comment":"Report on the results of VNN-COMP 2025. arXiv admin note: substantial text overlap with arXiv:2412.19985, arXiv:2312.16760, arXiv:2212.10376"},{"id":"http://arxiv.org/abs/2512.19004v1","updated":"2025-12-22T03:45:04Z","published":"2025-12-22T03:45:04Z","title":"Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models","summary":"Diffusion Large Language Models (DLLMs) enable fully parallel token decoding but often remain impractical at inference time due to the many denoising iterations required to refine an information-free, fully masked initialization into coherent text. Most existing acceleration methods focus on traversing this generative trajectory more efficiently via improved solvers or sampling strategies. We advance a complementary perspective: shorten the trajectory itself by starting closer to the target distribution through context-aware initialization.\n  We propose a training-free interface that injects prompt-conditioned priors from a lightweight auxiliary model into the diffusion initialization, and instantiate it with two mechanisms: discrete token injection and representation-level embedding interpolation. Because injected priors can be imperfect and unmask-only decoding can over-commit early, we also introduce a simple confidence-based remasking mechanism as a form of prior skepticism. Preliminary evidence on GSM8K suggests that context-aware initialization can substantially reduce denoising iterations (about 35\\% fewer function evaluations in our setting), while also exposing a key open challenge: naive warm-starting can degrade final accuracy relative to strong diffusion baselines. We use these findings to motivate a research agenda around calibration, revision mechanisms, and representation alignment for reliable warm-started diffusion decoding.","authors":["Tongyuan Miao","Gary Huang","Kai Jun Han","Annie Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.14554v3","updated":"2025-12-22T03:45:03Z","published":"2025-12-16T16:28:32Z","title":"VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models","summary":"The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.","authors":["Nguyen Tien Dong","Minh-Anh Nguyen","Thanh Dat Hoang","Nguyen Tuan Ngoc","Dao Xuan Quang Minh","Phan Phi Hai","Nguyen Thi Ngoc Anh","Dang Van Tu","Binh Vu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19001v1","updated":"2025-12-22T03:39:43Z","published":"2025-12-22T03:39:43Z","title":"ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management","summary":"As the pursuit of synergy between Artificial Intelligence (AI) and Operations Research (OR) gains momentum in handling complex inventory systems, a critical challenge persists: how to effectively reconcile AI's adaptive perception with OR's structural rigor. To bridge this gap, we propose a novel OR-Guided \"Pretrain-then-Reinforce\" framework. To provide structured guidance, we propose a simulation-augmented OR model that generates high-quality reference decisions, implicitly capturing complex business constraints and managerial preferences. Leveraging these OR-derived decisions as foundational training labels, we design a domain-informed deep learning foundation model to establish foundational decision-making capabilities, followed by a reinforcement learning (RL) fine-tuning stage. Uniquely, we position RL as a deep alignment mechanism that enables the AI agent to internalize the optimality principles of OR, while simultaneously leveraging exploration for general policy refinement and allowing expert guidance for scenario-specific adaptation (e.g., promotional events). Validated through extensive numerical experiments and a field deployment at JD.com augmented by a Difference-in-Differences (DiD) analysis, our model significantly outperforms incumbent industrial practices, delivering real-world gains of a 5.27-day reduction in turnover and a 2.29% increase in in-stock rates, alongside a 29.95% decrease in holding costs. Contrary to the prevailing trend of brute-force model scaling, our study demonstrates that a lightweight, domain-informed model can deliver state-of-the-art performance and robust transferability when guided by structured OR logic. This approach offers a scalable and cost-effective paradigm for intelligent supply chain management, highlighting the value of deeply aligning AI with OR.","authors":["Lingjie Zhao","Xue Yu","Yongzhi Qi","Hao Hu","Jianshen Zhang","Yingzheng Ma","Shuyu Han","Wei Qi","Zuo-Jun Max Shen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18999v1","updated":"2025-12-22T03:33:43Z","published":"2025-12-22T03:33:43Z","title":"Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative Study and An Optimized Framework","summary":"When applied directly in an end-to-end manner to medical follow-up tasks, Large Language Models (LLMs) often suffer from uncontrolled dialog flow and inaccurate information extraction due to the complexity of follow-up forms. To address this limitation, we designed and compared two follow-up chatbot systems: an end-to-end LLM-based system (control group) and a modular pipeline with structured process control (experimental group). Experimental results show that while the end-to-end approach frequently fails on lengthy and complex forms, our modular method-built on task decomposition, semantic clustering, and flow management-substantially improves dialog stability and extraction accuracy. Moreover, it reduces the number of dialogue turns by 46.73% and lowers token consumption by 80% to 87.5%. These findings highlight the necessity of integrating external control mechanisms when deploying LLMs in high-stakes medical follow-up scenarios.","authors":["Jinyan Liu","Zikang Chen","Qinchuan Wang","Tan Xie","Heming Zheng","Xudong Lv"],"pdf_url":"","comment":"10 pages,3 figures,conference ICCBB2025"},{"id":"http://arxiv.org/abs/2511.12808v3","updated":"2025-12-22T03:26:43Z","published":"2025-11-16T22:28:30Z","title":"Expressive Temporal Specifications for Reward Monitoring","summary":"Specifying informative and dense reward functions remains a pivotal challenge in Reinforcement Learning, as it directly affects the efficiency of agent training. In this work, we harness the expressive power of quantitative Linear Temporal Logic on finite traces (($\\text{LTL}_f[\\mathcal{F}]$)) to synthesize reward monitors that generate a dense stream of rewards for runtime-observable state trajectories. By providing nuanced feedback during training, these monitors guide agents toward optimal behaviour and help mitigate the well-known issue of sparse rewards under long-horizon decision making, which arises under the Boolean semantics dominating the current literature. Our framework is algorithm-agnostic and only relies on a state labelling function, and naturally accommodates specifying non-Markovian properties. Empirical results show that our quantitative monitors consistently subsume and, depending on the environment, outperform Boolean monitors in maximizing a quantitative measure of task completion and in reducing convergence time.","authors":["Omar Adalat","Francesco Belardinelli"],"pdf_url":"","comment":"Accepted at AAAI-26"},{"id":"http://arxiv.org/abs/2512.16214v2","updated":"2025-12-22T03:24:07Z","published":"2025-12-18T06:02:50Z","title":"PDE-Agent: A toolchain-augmented multi-agent framework for PDE solving","summary":"Solving Partial Differential Equations (PDEs) is a cornerstone of engineering and scientific research. Traditional methods for PDE solving are cumbersome, relying on manual setup and domain expertise. While Physics-Informed Neural Network (PINNs) introduced end-to-end neural network-based solutions, and frameworks like DeepXDE further enhanced automation, these approaches still depend on expert knowledge and lack full autonomy. In this work, we frame PDE solving as tool invocation via LLM-driven agents and introduce PDE-Agent, the first toolchain-augmented multi-agent collaboration framework, inheriting the reasoning capacity of LLMs and the controllability of external tools and enabling automated PDE solving from natural language descriptions. PDE-Agent leverages the strengths of multi-agent and multi-tool collaboration through two key innovations: (1) A Prog-Act framework with graph memory for multi-agent collaboration, which enables effective dynamic planning and error correction via dual-loop mechanisms (localized fixes and global revisions). (2) A Resource-Pool integrated with a tool-parameter separation mechanism for multi-tool collaboration. This centralizes the management of runtime artifacts and resolves inter-tool dependency gaps in existing frameworks. To validate and evaluate this new paradigm for PDE solving , we develop PDE-Bench, a multi-type PDE Benchmark for agent-based tool collaborative solving, and propose multi-level metrics for assessing tool coordination. Evaluations verify that PDE-Agent exhibits superior applicability and performance in complex multi-step, cross-step dependent tasks. This new paradigm of toolchain-augmented multi-agent PDE solving will further advance future developments in automated scientific computing. Our source code and dataset will be made publicly available.","authors":["Jianming Liu","Ren Zhu","Jian Xu","Kun Ding","Xu-Yao Zhang","Gaofeng Meng","Cheng-Lin Liu"],"pdf_url":"","comment":"Adding Affiliation Information on arXiv"},{"id":"http://arxiv.org/abs/2512.17370v2","updated":"2025-12-22T03:20:46Z","published":"2025-12-19T09:12:44Z","title":"TakeAD: Preference-based Post-optimization for End-to-end Autonomous Driving with Expert Takeover Data","summary":"Existing end-to-end autonomous driving methods typically rely on imitation learning (IL) but face a key challenge: the misalignment between open-loop training and closed-loop deployment. This misalignment often triggers driver-initiated takeovers and system disengagements during closed-loop execution. How to leverage those expert takeover data from disengagement scenarios and effectively expand the IL policy's capability presents a valuable yet unexplored challenge. In this paper, we propose TakeAD, a novel preference-based post-optimization framework that fine-tunes the pre-trained IL policy with this disengagement data to enhance the closed-loop driving performance. First, we design an efficient expert takeover data collection pipeline inspired by human takeover mechanisms in real-world autonomous driving systems. Then, this post optimization framework integrates iterative Dataset Aggregation (DAgger) for imitation learning with Direct Preference Optimization (DPO) for preference alignment. The DAgger stage equips the policy with fundamental capabilities to handle disengagement states through direct imitation of expert interventions. Subsequently, the DPO stage refines the policy's behavior to better align with expert preferences in disengagement scenarios. Through multiple iterations, the policy progressively learns recovery strategies for disengagement states, thereby mitigating the open-loop gap. Experiments on the closed-loop Bench2Drive benchmark demonstrate our method's effectiveness compared with pure IL methods, with comprehensive ablations confirming the contribution of each component.","authors":["Deqing Liu","Yinfeng Gao","Deheng Qian","Qichao Zhang","Xiaoqing Ye","Junyu Han","Yupeng Zheng","Xueyi Liu","Zhongpu Xia","Dawei Ding","Yifeng Pan","Dongbin Zhao"],"pdf_url":"","comment":"This work has been accepted by IEEE RA-L. Manuscript submitted: July, 8, 2025; Accepted: November, 24, 2025"},{"id":"http://arxiv.org/abs/2512.12608v2","updated":"2025-12-22T03:19:42Z","published":"2025-12-14T09:12:09Z","title":"Human-Inspired Learning for Large Language Models via Obvious Record and Maximum-Entropy Method Discovery","summary":"Large Language Models (LLMs) excel at extracting common patterns from large-scale corpora, yet they struggle with rare, low-resource, or previously unseen scenarios-such as niche hardware deployment issues or irregular IoT device behaviors-because such cases are sparsely represented in training data. Moreover, LLMs rely primarily on implicit parametric memory, which limits their ability to explicitly acquire, recall, and refine methods, causing them to behave predominantly as intuition-driven predictors rather than deliberate, method-oriented learners. Inspired by how humans learn from rare experiences, this paper proposes a human-inspired learning framework that integrates two complementary mechanisms. The first, Obvious Record, explicitly stores cause--result (or question--solution) relationships as symbolic memory, enabling persistent learning even from single or infrequent encounters. The second, Maximum-Entropy Method Discovery, prioritizes and preserves methods with high semantic dissimilarity, allowing the system to capture diverse and underrepresented strategies that are typically overlooked by next-token prediction. Verification on a benchmark of 60 semantically diverse question--solution pairs demonstrates that the proposed entropy-guided approach achieves stronger coverage of unseen questions and significantly greater internal diversity than a random baseline, confirming its effectiveness in discovering more generalizable and human-inspired methods.","authors":["Hong Su"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.06118v4","updated":"2025-12-22T03:14:10Z","published":"2024-02-09T01:00:14Z","title":"ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling","summary":"By combining natural language understanding, generation capabilities, and breadth of knowledge of large language models with image perception, recent large vision language models (LVLMs) have shown unprecedented visual reasoning capabilities. However, the generated text often suffers from inaccurate grounding in the visual input, resulting in errors such as hallucination of nonexistent scene elements, missing significant parts of the scene, and inferring incorrect attributes of and relationships between objects. To address these issues, we introduce a novel framework, ViGoR (Visual Grounding Through Fine-Grained Reward Modeling) that utilizes fine-grained reward modeling to significantly enhance the visual grounding of LVLMs over pre-trained baselines. This improvement is efficiently achieved using much cheaper human evaluations instead of full supervisions, as well as automated methods. We show the effectiveness of our approach through a variety of evaluation methods and benchmarks. Additionally, we released our human annotation (https://github.com/amazon-science/vigor) comprising 15,440 images and generated text pairs with fine-grained evaluations to contribute to related research in the community.","authors":["Siming Yan","Min Bai","Weifeng Chen","Xiong Zhou","Qixing Huang","Li Erran Li"],"pdf_url":"","comment":"Accepted by ECCV 2024"},{"id":"http://arxiv.org/abs/2512.18991v1","updated":"2025-12-22T03:13:08Z","published":"2025-12-22T03:13:08Z","title":"ICP-4D: Bridging Iterative Closest Point and LiDAR Panoptic Segmentation","summary":"Dominant paradigms for 4D LiDAR panoptic segmentation are usually required to train deep neural networks with large superimposed point clouds or design dedicated modules for instance association. However, these approaches perform redundant point processing and consequently become computationally expensive, yet still overlook the rich geometric priors inherently provided by raw point clouds. To this end, we introduce ICP-4D, a simple yet effective training-free framework that unifies spatial and temporal reasoning through geometric relations among instance-level point sets. Specifically, we apply the Iterative Closest Point (ICP) algorithm to directly associate temporally consistent instances by aligning the source and target point sets through the estimated transformation. To stabilize association under noisy instance predictions, we introduce a Sinkhorn-based soft matching. This exploits the underlying instance distribution to obtain accurate point-wise correspondences, resulting in robust geometric alignment. Furthermore, our carefully designed pipeline, which considers three instance types-static, dynamic, and missing-offers computational efficiency and occlusion-aware matching. Our extensive experiments across both SemanticKITTI and panoptic nuScenes demonstrate that our method consistently outperforms state-of-the-art approaches, even without additional training or extra point cloud inputs.","authors":["Gyeongrok Oh","Youngdong Jang","Jonghyun Choi","Suk-Ju Kang","Guang Lin","Sangpil Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.04162v5","updated":"2025-12-22T03:07:50Z","published":"2025-03-06T07:25:19Z","title":"Semantic Retrieval Augmented Contrastive Learning for Sequential Recommendation","summary":"Contrastive learning has shown effectiveness in improving sequential recommendation models. However, existing methods still face challenges in generating high-quality contrastive pairs: they either rely on random perturbations that corrupt user preference patterns or depend on sparse collaborative data that generates unreliable contrastive pairs. Furthermore, existing approaches typically require predefined selection rules that impose strong assumptions, limiting the model's ability to autonomously learn optimal contrastive pairs. To address these limitations, we propose a novel approach named Semantic Retrieval Augmented Contrastive Learning (SRA-CL). SRA-CL leverages the semantic understanding and reasoning capabilities of LLMs to generate expressive embeddings that capture both user preferences and item characteristics. These semantic embeddings enable the construction of candidate pools for inter-user and intra-user contrastive learning through semantic-based retrieval. To further enhance the quality of the contrastive samples, we introduce a learnable sample synthesizer that optimizes the contrastive sample generation process during model training. SRA-CL adopts a plug-and-play design, enabling seamless integration with existing sequential recommendation architectures. Extensive experiments on four public datasets demonstrate the effectiveness and model-agnostic nature of our approach.","authors":["Ziqiang Cui","Yunpeng Weng","Xing Tang","Xiaokun Zhang","Shiwei Li","Peiyang Liu","Bowei He","Dugang Liu","Weihong Luo","Xiuqiang He","Chen Ma"],"pdf_url":"","comment":"Accepted by NeurIPS 2025. Code is available at: https://github.com/ziqiangcui/SRA-CL"},{"id":"http://arxiv.org/abs/2511.20277v2","updated":"2025-12-22T02:58:33Z","published":"2025-11-25T13:05:40Z","title":"HVAdam: A Full-Dimension Adaptive Optimizer","summary":"Adaptive optimizers such as Adam have achieved great success in training large-scale models like large language models and diffusion models. However, they often generalize worse than non-adaptive methods, such as SGD on classical architectures like CNNs. We identify a key cause of this performance gap: adaptivity in pre-conditioners, which limits the optimizer's ability to adapt to diverse optimization landscapes. To address this, we propose Anon (Adaptivity Non-restricted Optimizer with Novel convergence technique), a novel optimizer with continuously tunable adaptivity\n  , allowing it to interpolate between SGD-like and Adam-like behaviors and even extrapolate beyond both. To ensure convergence across the entire adaptivity spectrum, we introduce incremental delay update (IDU), a novel mechanism that is more flexible than AMSGrad's hard max-tracking strategy and enhances robustness to gradient noise. We theoretically establish convergence guarantees under both convex and non-convex settings. Empirically, Anon consistently outperforms state-of-the-art optimizers on representative image classification, diffusion, and language modeling tasks. These results demonstrate that adaptivity can serve as a valuable tunable design principle, and Anon provides the first unified and reliable framework capable of bridging the gap between classical and modern optimizers and surpassing their advantageous properties.","authors":["Yiheng Zhang","Shaowu Wu","Yuanzhuo Xu","Jiajun Wu","Shang Xu","Steve Drew","Xiaoguang Niu"],"pdf_url":"","comment":"Accepted at AAAI2025"},{"id":"http://arxiv.org/abs/2512.18986v1","updated":"2025-12-22T02:54:10Z","published":"2025-12-22T02:54:10Z","title":"R-GenIMA: Integrating Neuroimaging and Genetics with Interpretable Multimodal AI for Alzheimer's Disease Progression","summary":"Early detection of Alzheimer's disease (AD) requires models capable of integrating macro-scale neuroanatomical alterations with micro-scale genetic susceptibility, yet existing multimodal approaches struggle to align these heterogeneous signals. We introduce R-GenIMA, an interpretable multimodal large language model that couples a novel ROI-wise vision transformer with genetic prompting to jointly model structural MRI and single nucleotide polymorphisms (SNPs) variations. By representing each anatomically parcellated brain region as a visual token and encoding SNP profiles as structured text, the framework enables cross-modal attention that links regional atrophy patterns to underlying genetic factors. Applied to the ADNI cohort, R-GenIMA achieves state-of-the-art performance in four-way classification across normal cognition (NC), subjective memory concerns (SMC), mild cognitive impairment (MCI), and AD. Beyond predictive accuracy, the model yields biologically meaningful explanations by identifying stage-specific brain regions and gene signatures, as well as coherent ROI-Gene association patterns across the disease continuum. Attention-based attribution revealed genes consistently enriched for established GWAS-supported AD risk loci, including APOE, BIN1, CLU, and RBFOX1. Stage-resolved neuroanatomical signatures identified shared vulnerability hubs across disease stages alongside stage-specific patterns: striatal involvement in subjective decline, frontotemporal engagement during prodromal impairment, and consolidated multimodal network disruption in AD. These results demonstrate that interpretable multimodal AI can synthesize imaging and genetics to reveal mechanistic insights, providing a foundation for clinically deployable tools that enable earlier risk stratification and inform precision therapeutic strategies in Alzheimer's disease.","authors":["Kun Zhao","Siyuan Dai","Yingying Zhang","Guodong Liu","Pengfei Gu","Chenghua Lin","Paul M. Thompson","Alex Leow","Heng Huang","Lifang He","Liang Zhan","Haoteng Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18969v1","updated":"2025-12-22T02:30:19Z","published":"2025-12-22T02:30:19Z","title":"Self-Attention with State-Object Weighted Combination for Compositional Zero Shot Learning","summary":"Object recognition has become prevalent across various industries. However, most existing applications are limited to identifying objects alone, without considering their associated states. The ability to recognize both the state and object simultaneously remains less common. One approach to address this is by treating state and object as a single category during training. However, this approach poses challenges in data collection and training since it requires comprehensive data for all possible combinations. Compositional Zero-shot Learning (CZSL) emerges as a viable solution by treating the state and object as distinct categories during training. CZSL facilitates the identification of novel compositions even in the absence of data for every conceivable combination. The current state-of-the-art method, KG-SP, addresses this issue by training distinct classifiers for states and objects, while leveraging a semantic model to evaluate the plausibility of composed compositions. However, KG-SP's accuracy in state and object recognition can be further improved, and it fails to consider the weighting of states and objects during composition. In this study, we propose SASOW, an enhancement of KG-SP that considers the weighting of states and objects while improving composition recognition accuracy. First, we introduce self-attention mechanisms into the classifiers for states and objects, leading to enhanced accuracy in recognizing both. Additionally, we incorporate the weighting of states and objects during composition to generate more reasonable and accurate compositions. Our validation process involves testing SASOW on three established benchmark datasets. Experimental outcomes affirm when compared against OW-CZSL approach, KG-SP, SASOW showcases improvements of 2.1%, 1.7%, and 0.4% in terms of accuracy for unseen compositions across the MIT-States, UT Zappos, and C-GQA datasets, respectively.","authors":["Cheng-Hong Chang","Pei-Hsuan Tsai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.01457v3","updated":"2025-12-22T02:26:36Z","published":"2025-12-01T09:44:31Z","title":"Zero-Overhead Introspection for Adaptive Test-Time Compute","summary":"Large language models excel at reasoning but lack key aspects of introspection, including anticipating their own success and the computation required to achieve it. Humans use real-time introspection to decide how much effort to invest, when to make multiple attempts, when to stop, and when to signal success or failure. Without this, LLMs struggle to make intelligent meta-cognition decisions. Test-time scaling methods like Best-of-N drive up cost and latency by using a fixed budget of samples regardless of the marginal benefit of each one at any point in generation, and the absence of confidence signals can mislead people, prevent appropriate escalation to better tools, and undermine trustworthiness. Learned verifiers or reward models can provide confidence estimates, but do not enable adaptive inference and add substantial cost by requiring extra models or forward passes. We present ZIP-RC, an adaptive inference method that equips models with zero-overhead inference-time predictions of reward and cost. At every token, ZIP-RC reuses reserved or unused logits in the same forward pass as next-token prediction to output a joint distribution over final reward and remaining length -- no extra models, architecture change, or inference overhead. This full joint distribution is used to compute a sampling utility which is the linear combination of the expected maximum reward, total compute, and latency of set of samples if generated to completion. During inference, we maximize this utility with meta-actions that determine which prefix of tokens to continue or initiate sampling from. On mixed-difficulty mathematical benchmarks, ZIP-RC improves accuracy by up to 12% over majority voting at equal or lower average cost, and traces smooth Pareto frontiers between quality, compute, and latency. By providing real-time reward-cost introspection, ZIP-RC enables adaptive, efficient reasoning.","authors":["Rohin Manvi","Joey Hong","Tim Seyde","Maxime Labonne","Mathias Lechner","Sergey Levine"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17100v2","updated":"2025-12-22T02:23:31Z","published":"2025-12-18T21:56:08Z","title":"UniCoMTE: A Universal Counterfactual Framework for Explaining Time-Series Classifiers on ECG Data","summary":"Machine learning models, particularly deep neural networks, have demonstrated strong performance in classifying complex time series data. However, their black-box nature limits trust and adoption, especially in high-stakes domains such as healthcare. To address this challenge, we introduce UniCoMTE, a model-agnostic framework for generating counterfactual explanations for multivariate time series classifiers. The framework identifies temporal features that most heavily influence a model's prediction by modifying the input sample and assessing its impact on the model's prediction. UniCoMTE is compatible with a wide range of model architectures and operates directly on raw time series inputs. In this study, we evaluate UniCoMTE's explanations on a time series ECG classifier. We quantify explanation quality by comparing our explanations' comprehensibility to comprehensibility of established techniques (LIME and SHAP) and assessing their generalizability to similar samples. Furthermore, clinical utility is assessed through a questionnaire completed by medical experts who review counterfactual explanations presented alongside original ECG samples. Results show that our approach produces concise, stable, and human-aligned explanations that outperform existing methods in both clarity and applicability. By linking model predictions to meaningful signal patterns, the framework advances the interpretability of deep learning models for real-world time series applications.","authors":["Justin Li","Efe Sencan","Jasper Zheng Duan","Vitus J. Leung","Stephen Tsaur","Ayse K. Coskun"],"pdf_url":"","comment":"21 pages, 7 figures"}]},"2025-12-21T00:00:00Z":{"Distributed, Parallel, and Cluster Computing":[{"id":"http://arxiv.org/abs/2512.18915v1","updated":"2025-12-21T23:18:07Z","published":"2025-12-21T23:18:07Z","title":"QoS-Aware Load Balancing in the Computing Continuum via Multi-Player Bandits","summary":"As computation shifts from the cloud to the edge to reduce processing latency and network traffic, the resulting Computing Continuum (CC) creates a dynamic environment where it is challenging to meet strict Quality of Service (QoS) requirements and avoid service instance overload. Existing methods often prioritize global metrics, overlooking per-client QoS, which is crucial for latency-sensitive and reliability-critical applications. We propose QEdgeProxy, a decentralized QoS-aware load balancer that acts as a proxy between IoT devices and service instances in CC. We formulate the load balancing problem as a Multi-Player Multi-Armed Bandit (MP-MAB) with heterogeneous rewards, where each load balancer autonomously selects service instances that maximize the probability of meeting its clients' QoS targets by using Kernel Density Estimation (KDE) to estimate QoS success probabilities. It also incorporates an adaptive exploration mechanism to recover rapidly from performance shifts and non-stationary conditions. We present a Kubernetes-native QEdgeProxy implementation and evaluate it on an emulated CC testbed deployed on a K3s cluster with realistic network conditions and a latency-sensitive edge-AI workload. Results show that QEdgeProxy significantly outperforms proximity-based and reinforcement-learning baselines in per-client QoS satisfaction, while adapting effectively to load surges and instance availability changes.","authors":["Ivan Čilić","Ivana Podnar Žarko","Pantelis Frangoudis","Schahram Dustdar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18894v1","updated":"2025-12-21T21:37:36Z","published":"2025-12-21T21:37:36Z","title":"A Real-Time Digital Twin for Adaptive Scheduling","summary":"High-performance computing (HPC) workloads are becoming increasingly diverse, exhibiting wide variability in job characteristics, yet cluster scheduling has long relied on static, heuristic-based policies. In this work we present SchedTwin, a real-time digital twin designed to adaptively guide scheduling decisions using predictive simulation. SchedTwin periodically ingests runtime events from the physical scheduler, performs rapid what-if evaluations of multiple policies using a high-fidelity discrete-event simulator, and dynamically selects the one satisfying the administrator configured optimization goal. We implement SchedTwin as an open-source software and integrate it with the production PBS scheduler. Preliminary results show that SchedTwin consistently outperforms widely used static scheduling policies, while maintaining low overhead (a few seconds per scheduling cycle). These results demonstrate that real-time digital twins offer a practical and effective path toward adaptive HPC scheduling.","authors":["Yihe Zhang","Yash Kurkure","Yiheng Tao","Michael E. Papka","Zhiling Lan"],"pdf_url":"","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2512.18883v1","updated":"2025-12-21T20:49:05Z","published":"2025-12-21T20:49:05Z","title":"EuroHPC SPACE CoE: Redesigning Scalable Parallel Astrophysical Codes for Exascale","summary":"High Performance Computing (HPC) based simulations are crucial in Astrophysics and Cosmology (A&C), helping scientists investigate and understand complex astrophysical phenomena. Taking advantage of exascale computing capabilities is essential for these efforts. However, the unprecedented architectural complexity of exascale systems impacts legacy codes. The SPACE Centre of Excellence (CoE) aims to re-engineer key astrophysical codes to tackle new computational challenges by adopting innovative programming paradigms and software (SW) solutions. SPACE brings together scientists, code developers, HPC experts, hardware (HW) manufacturers, and SW developers. This collaboration enhances exascale A&C applications, promoting the use of exascale and post-exascale computing capabilities. Additionally, SPACE addresses high-performance data analysis for the massive data outputs from exascale simulations and modern observations, using machine learning (ML) and visualisation tools. The project facilitates application deployment across platforms by focusing on code repositories and data sharing, integrating European astrophysical communities around exascale computing with standardised SW and data protocols.","authors":["Nitin Shukla","Alessandro Romeo","Caterina Caravita","Lubomir Riha","Ondrej Vysocky","Petr Strakos","Milan Jaros","João Barbosa","Radim Vavrik","Andrea Mignone","Marco Rossazza","Stefano Truzzi","Vittoria Berta","Iacopo Colonnelli","Doriana Medić","Elisabetta Boella","Daniele Gregori","Eva Sciacca","Luca Tornatore","Giuliano Taffoni","Pranab J. Deka","Fabio Bacchini","Rostislav-Paul Wilhelm","Georgios Doulis","Khalil Pierre","Luciano Rezzolla","Tine Colman","Benoît Commerçon","Othman Bouizi","Matthieu Kuhn","Erwan Raffin","Marc Sergent","Robert Wissing","Guillermo Marin","Klaus Dolag","Geray S. Karademir","Gino Perna","Marisa Zanotti","Sebastian Trujillo-Gomez"],"pdf_url":"","comment":"7 pages, 7 figures"},{"id":"http://arxiv.org/abs/2512.18674v1","updated":"2025-12-21T10:27:50Z","published":"2025-12-21T10:27:50Z","title":"Remoe: Towards Efficient and Low-Cost MoE Inference in Serverless Computing","summary":"Mixture-of-Experts (MoE) has become a dominant architecture in large language models (LLMs) due to its ability to scale model capacity via sparse expert activation. Meanwhile, serverless computing, with its elasticity and pay-per-use billing, is well-suited for deploying MoEs with bursty workloads. However, the large number of experts in MoE models incurs high inference costs due to memory-intensive parameter caching. These costs are difficult to mitigate via simple model partitioning due to input-dependent expert activation. To address these issues, we propose Remoe, a heterogeneous MoE inference system tailored for serverless computing. Remoe assigns non-expert modules to GPUs and expert modules to CPUs, and further offloads infrequently activated experts to separate serverless functions to reduce memory overhead and enable parallel execution. We incorporate three key techniques: (1) a Similar Prompts Searching (SPS) algorithm to predict expert activation patterns based on semantic similarity of inputs; (2) a Main Model Pre-allocation (MMP) algorithm to ensure service-level objectives (SLOs) via worst-case memory estimation; and (3) a joint memory and replica optimization framework leveraging Lagrangian duality and the Longest Processing Time (LPT) algorithm. We implement Remoe on Kubernetes and evaluate it across multiple LLM benchmarks. Experimental results show that Remoe reduces inference cost by up to 57% and cold start latency by 47% compared to state-of-the-art baselines.","authors":["Wentao Liu","Yuhao Hu","Ruiting Zhou","Baochun Li","Ne Wang"],"pdf_url":"","comment":null}],"Computation and Language":[{"id":"http://arxiv.org/abs/2512.18906v1","updated":"2025-12-21T22:37:38Z","published":"2025-12-21T22:37:38Z","title":"Remedy-R: Generative Reasoning for Machine Translation Evaluation without Error Annotations","summary":"Over the years, automatic MT metrics have hillclimbed benchmarks and presented strong and sometimes human-level agreement with human ratings. Yet they remain black-box, offering little insight into their decision-making and often failing under real-world out-of-distribution (OOD) inputs. We introduce Remedy-R, a reasoning-driven generative MT metric trained with reinforcement learning from pairwise translation preferences, without requiring error-span annotations or distillation from closed LLMs. Remedy-R produces step-by-step analyses of accuracy, fluency, and completeness, followed by a final score, enabling more interpretable assessments. With only 60K training pairs across two language pairs, Remedy-R remains competitive with top scalar metrics and GPT-4-based judges on WMT22-24 meta-evaluation, generalizes to other languages, and exhibits strong robustness on OOD stress tests. Moreover, Remedy-R models generate self-reflective feedback that can be reused for translation improvement. Building on this finding, we introduce Remedy-R Agent, a simple evaluate-revise pipeline that leverages Remedy-R's evaluation analysis to refine translations. This agent consistently improves translation quality across diverse models, including Qwen2.5, ALMA-R, GPT-4o-mini, and Gemini-2.0-Flash, suggesting that Remedy-R's reasoning captures translation-relevant information and is practically useful.","authors":["Shaomu Tan","Ryosuke Mitani","Ritvik Choudhary","Qiyu Wu","Toshiyuki Sekiya","Christof Monz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02376v3","updated":"2025-12-21T22:30:20Z","published":"2025-11-04T08:56:28Z","title":"AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models","summary":"Large Language Models (LLMs) remain vulnerable to jailbreaking attacks where adversarial prompts elicit harmful outputs. Yet most evaluations focus on single-turn interactions while real-world attacks unfold through adaptive multi-turn conversations. We present AutoAdv, a training-free framework for automated multi-turn jailbreaking that achieves an attack success rate of up to 95% on Llama-3.1-8B within six turns, a 24% improvement over single-turn baselines. AutoAdv uniquely combines three adaptive mechanisms: a pattern manager that learns from successful attacks to enhance future prompts, a temperature manager that dynamically adjusts sampling parameters based on failure modes, and a two-phase rewriting strategy that disguises harmful requests and then iteratively refines them. Extensive evaluation across commercial and open-source models (Llama-3.1-8B, GPT-4o mini, Qwen3-235B, Mistral-7B) reveals persistent vulnerabilities in current safety mechanisms, with multi-turn attacks consistently outperforming single-turn approaches. These findings demonstrate that alignment strategies optimized for single-turn interactions fail to maintain robustness across extended conversations, highlighting an urgent need for multi-turn-aware defenses.","authors":["Aashray Reddy","Andrew Zagula","Nicholas Saban"],"pdf_url":"","comment":"Presented at NeurIPS 2025 Lock-LLM Workshop. Code is available at https://github.com/AAN-AutoAdv/AutoAdv"},{"id":"http://arxiv.org/abs/2011.03783v2","updated":"2025-12-21T21:38:22Z","published":"2020-11-07T14:28:54Z","title":"Towards a resource for multilingual lexicons: an MT assisted and human-in-the-loop multilingual parallel corpus with multi-word expression annotation","summary":"In this work, we introduce the construction of a machine translation (MT) assisted and human-in-the-loop multilingual parallel corpus with annotations of multi-word expressions (MWEs), named AlphaMWE. The MWEs include verbal MWEs (vMWEs) defined in the PARSEME shared task that have a verb as the head of the studied terms. The annotated vMWEs are also bilingually and multilingually aligned manually. The languages covered include Arabic, Chinese, English, German, Italian, and Polish, of which, the Arabic corpus includes both standard and dialectal variations from Egypt and Tunisia. Our original English corpus is extracted from the PARSEME shared task in 2018. We performed machine translation of this source corpus followed by human post-editing and annotation of target MWEs. Strict quality control was applied for error limitation, i.e., each MT output sentence received first manual post-editing and annotation plus a second manual quality rechecking till annotators' consensus is reached. One of our findings during corpora preparation is that accurate translation of MWEs presents challenges to MT systems, as reflected by the outcomes of human-in-the-loop metric HOPE. To facilitate further MT research, we present a categorisation of the error types encountered by MT systems in performing MWE-related translation. To acquire a broader view of MT issues, we selected four popular state-of-the-art MT systems for comparison, namely Microsoft Bing Translator, GoogleMT, Baidu Fanyi, and DeepL MT. Because of the noise removal, translation post-editing, and MWE annotation by human professionals, we believe the AlphaMWE data set will be an asset for both monolingual and cross-lingual research, such as multi-word term lexicography, MT, and information extraction.","authors":["Lifeng Han","Najet Hadj Mohamed","Malak Rassem","Gareth Jones","Alan Smeaton","Goran Nenadic"],"pdf_url":"","comment":"Accepted by Journal of LRE, extended work from WS paper AlphaMWE"},{"id":"http://arxiv.org/abs/2512.18880v1","updated":"2025-12-21T20:41:36Z","published":"2025-12-21T20:41:36Z","title":"Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction","summary":"Accurate estimation of item (question or task) difficulty is critical for educational assessment but suffers from the cold start problem. While Large Language Models demonstrate superhuman problem-solving capabilities, it remains an open question whether they can perceive the cognitive struggles of human learners. In this work, we present a large-scale empirical analysis of Human-AI Difficulty Alignment for over 20 models across diverse domains such as medical knowledge and mathematical reasoning. Our findings reveal a systematic misalignment where scaling up model size is not reliably helpful; instead of aligning with humans, models converge toward a shared machine consensus. We observe that high performance often impedes accurate difficulty estimation, as models struggle to simulate the capability limitations of students even when being explicitly prompted to adopt specific proficiency levels. Furthermore, we identify a critical lack of introspection, as models fail to predict their own limitations. These results suggest that general problem-solving capability does not imply an understanding of human cognitive struggles, highlighting the challenge of using current models for automated difficulty prediction.","authors":["Ming Li","Han Chen","Yunze Xiao","Jian Chen","Hong Jiao","Tianyi Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18865v1","updated":"2025-12-21T19:43:30Z","published":"2025-12-21T19:43:30Z","title":"Application of deep learning approaches for medieval historical documents transcription","summary":"Handwritten text recognition and optical character recognition solutions show excellent results with processing data of modern era, but efficiency drops with Latin documents of medieval times. This paper presents a deep learning method to extract text information from handwritten Latin-language documents of the 9th to 11th centuries. The approach takes into account the properties inherent in medieval documents. The paper provides a brief introduction to the field of historical document transcription, a first-sight analysis of the raw data, and the related works and studies. The paper presents the steps of dataset development for further training of the models. The explanatory data analysis of the processed data is provided as well. The paper explains the pipeline of deep learning models to extract text information from the document images, from detecting objects to word recognition using classification models and embedding word images. The paper reports the following results: recall, precision, F1 score, intersection over union, confusion matrix, and mean string distance. The plots of the metrics are also included. The implementation is published on the GitHub repository.","authors":["Maksym Voloshchuk","Bohdana Zarembovska","Mykola Kozlenko"],"pdf_url":"","comment":"15 pages, 15 figures, 4 tables. Originally published by CEUR Workshop Proceedings (CEUR-WS.org, ISSN 1613-0073), available: https://ceur-ws.org/Vol-4133/S_05_Kozlenko.pdf"},{"id":"http://arxiv.org/abs/2512.18861v1","updated":"2025-12-21T19:26:41Z","published":"2025-12-21T19:26:41Z","title":"Merge on workspaces as Hopf algebra Markov chain","summary":"We study the dynamical properties of a Hopf algebra Markov chain with state space the binary rooted forests with labelled leaves. This Markovian dynamical system describes the core computational process of structure formation and transformation in syntax via the Merge operation, according to Chomsky's Minimalism model of generative linguistics. The dynamics decomposes into an ergodic dynamical system with uniform stationary distribution, given by the action of Internal Merge, while the contributions of External Merge and (a minimal form of) Sideward Merge reduce to a simpler Markov chain with state space the set of partitions and with combinatorial weights. The Sideward Merge part of the dynamics prevents convergence to fully formed connected structures (trees), unless the different forms of Merge are weighted by a cost function, as predicted by linguistic theory. Results on the asymptotic behavior of the Perron-Frobenius eigenvalue and eigenvector in this weighted case, obtained in terms of an associated Perron-Frobenius problem in the tropical semiring, show that the usual cost functions (Minimal Search and Resource Restrictions) proposed in the linguistic literature do not suffice to obtain convergence to the tree structures, while an additional optimization property based on the Shannon entropy achieves the expected result for the dynamics. We also comment on the introduction of continuous parameters related to semantic embedding and other computational models, and also on some filtering of the dynamics by coloring rules that model the linguistic filtering by theta roles and phase structure, and on parametric variation and the process of parameter setting in Externalization.","authors":["Matilde Marcolli","David Skigin"],"pdf_url":"","comment":"80 pages, LaTeX, 1 png figure"},{"id":"http://arxiv.org/abs/2512.18859v1","updated":"2025-12-21T19:16:40Z","published":"2025-12-21T19:16:40Z","title":"Toward Human-Centered AI-Assisted Terminology Work","summary":"The rapid diffusion of generative artificial intelligence is transforming terminology work. While this technology promises gains in efficiency, its unstructured adoption risks weakening professional autonomy, amplifying bias, and eroding linguistic and conceptual diversity. This paper argues that a human-centered approach to artificial intelligence has become a necessity for terminology work. Building on research in artificial intelligence and translation studies, it proposes a human-centered framework that conceptualizes artificial intelligence as a means of amplifying the terminologist's capabilities, rather than replacing them. The framework is organized around three interrelated dimensions: the augmented terminologist, ethical AI, and human-centered design. Together, these dimensions emphasize the compatibility of high automation with strong human control, the central role of terminologists in bias mitigation, and the importance of designing AI tools and workflows around the needs, values, and well-being of the terminologist. The paper concludes by stressing that current choices in AI adoption will shape not only terminological practice, but also the preservation of accuracy, adequacy, and diversity in terminology and specialized knowledge.","authors":["Antonio San Martin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18841v1","updated":"2025-12-21T18:11:24Z","published":"2025-12-21T18:11:24Z","title":"MDToC: Metacognitive Dynamic Tree of Concepts for Boosting Mathematical Problem-Solving of Large Language Models","summary":"Despite advances in mathematical reasoning capabilities, Large Language Models (LLMs) still struggle with calculation verification when using established prompting techniques. We present MDToC (Metacognitive Dynamic Tree of Concepts), a three-phase approach that constructs a concept tree, develops accuracy-verified calculations for each concept, and employs majority voting to evaluate competing solutions. Evaluations across CHAMP, MATH, and Game-of-24 benchmarks demonstrate our MDToC's effectiveness, with GPT-4-Turbo achieving 58.1\\% on CHAMP, 86.6\\% on MATH, and 85\\% on Game-of-24 - outperforming GoT by 5\\%, 5.4\\%, and 4\\% on all these tasks, respectively, without hand-engineered hints. MDToC consistently surpasses existing prompting methods across all backbone models, yielding improvements of up to 7.6\\% over ToT and 6.2\\% over GoT, establishing metacognitive calculation verification as a promising direction for enhanced mathematical reasoning.","authors":["Tung Duong Ta","Tim Oates"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18834v1","updated":"2025-12-21T17:36:26Z","published":"2025-12-21T17:36:26Z","title":"AraMix: Recycling, Refiltering, and Deduplicating to Deliver the Largest Arabic Pretraining Corpus","summary":"We present AraMix, a deduplicated Arabic pretraining corpus containing approximately 178 billion tokens across 179 million documents. Rather than scraping the web again, AraMix demonstrates that substantial value lies in systematically reusing and curating existing pretraining datasets: we combine seven publicly available Arabic web datasets, apply quality filtering designed specifically for Arabic text to re-filter some datasets, and perform cross-dataset deduplication, both MinHash and sentence-level. This approach reveals that nearly 60% of tokens across these independently collected corpora are duplicates, redundancy that any new scraping efforts will reproduce. Our work suggests that for lower resource languages, investment in curation pipelines for existing data yields greater returns than additional web crawls, an approach that allowed us to curate the largest heavily filtered publicly available Arabic pretraining corpus.","authors":["Sultan Alrashed","Francesco Orabona"],"pdf_url":"","comment":"Initial version, without pretraining experiments"},{"id":"http://arxiv.org/abs/2512.07543v2","updated":"2025-12-21T17:33:45Z","published":"2025-12-08T13:24:53Z","title":"Over-representation of phonological features in basic vocabulary doesn't replicate when controlling for spatial and phylogenetic effects","summary":"The statistical over-representation of phonological features in the basic vocabulary of languages is often interpreted as reflecting potentially universal sound symbolic patterns. However, most of those results have not been tested explicitly for reproducibility and might be prone to biases in the study samples or models. Many studies on the topic do not adequately control for genealogical and areal dependencies between sampled languages, casting doubts on the robustness of the results. In this study, we test the robustness of a recent study on sound symbolism of basic vocabulary concepts which analyzed 245 languages.The new sample includes data on 2864 languages from Lexibank. We modify the original model by adding statistical controls for spatial and phylogenetic dependencies between languages. The new results show that most of the previously observed patterns are not robust, and in fact many patterns disappear completely when adding the genealogical and areal controls. A small number of patterns, however, emerges as highly stable even with the new sample. Through the new analysis, we are able to assess the distribution of sound symbolism on a larger scale than previously. The study further highlights the need for testing all universal claims on language for robustness on various levels.","authors":["Frederic Blum"],"pdf_url":"","comment":"Accepted with minor revisions at *Linguistic Typology*, expected to be fully published in 2026"},{"id":"http://arxiv.org/abs/2512.18832v1","updated":"2025-12-21T17:28:42Z","published":"2025-12-21T17:28:42Z","title":"From Word to World: Can Large Language Models be Implicit Text-based World Models?","summary":"Agentic reinforcement learning increasingly relies on experience-driven scaling, yet real-world environments remain non-adaptive, limited in coverage, and difficult to scale. World models offer a potential way to improve learning efficiency through simulated experience, but it remains unclear whether large language models can reliably serve this role and under what conditions they meaningfully benefit agents. We study these questions in text-based environments, which provide a controlled setting to reinterpret language modeling as next-state prediction under interaction. We introduce a three-level framework for evaluating LLM-based world models: (i) fidelity and consistency, (ii) scalability and robustness, and (iii) agent utility. Across five representative environments, we find that sufficiently trained world models maintain coherent latent state, scale predictably with data and model size, and improve agent performance via action verification, synthetic trajectory generation, and warm-starting reinforcement learning. Meanwhile, these gains depend critically on behavioral coverage and environment complexity, delineating clear boundry on when world modeling effectively supports agent learning.","authors":["Yixia Li","Hongru Wang","Jiahao Qiu","Zhenfei Yin","Dongdong Zhang","Cheng Qian","Zeping Li","Pony Ma","Guanhua Chen","Heng Ji","Mengdi Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16912v2","updated":"2025-12-21T17:23:35Z","published":"2025-12-18T18:59:27Z","title":"Exploration vs Exploitation: Rethinking RLVR through Clipping, Entropy, and Spurious Reward","summary":"This paper examines the exploration-exploitation trade-off in reinforcement learning with verifiable rewards (RLVR), a framework for improving the reasoning of Large Language Models (LLMs). Recent studies suggest that RLVR can elicit strong mathematical reasoning in LLMs through two seemingly paradoxical mechanisms: spurious rewards, which suppress exploitation by rewarding outcomes unrelated to the ground truth, and entropy minimization, which suppresses exploration by pushing the model toward more confident and deterministic outputs, highlighting a puzzling dynamic: both discouraging exploitation and discouraging exploration improve reasoning performance, yet the underlying principles that reconcile these effects remain poorly understood. We focus on two fundamental questions: (i) how policy entropy relates to performance, and (ii) whether spurious rewards yield gains, potentially through the interplay of clipping bias and model contamination. Our results show that clipping bias under spurious rewards reduces policy entropy, leading to more confident and deterministic outputs, while entropy minimization alone is insufficient for improvement. We further propose a reward-misalignment model explaining why spurious rewards can enhance performance beyond contaminated settings. Our findings clarify the mechanisms behind spurious-reward benefits and provide principles for more effective RLVR training.","authors":["Peter Chen","Xiaopeng Li","Ziniu Li","Wotao Yin","Xi Chen","Tianyi Lin"],"pdf_url":"","comment":"35 pages"},{"id":"http://arxiv.org/abs/2506.11112v2","updated":"2025-12-21T17:16:19Z","published":"2025-06-08T16:25:35Z","title":"Dagstuhl Perspectives Workshop 24352 -- Conversational Agents: A Framework for Evaluation (CAFE): Manifesto","summary":"During the workshop, we deeply discussed what CONversational Information ACcess (CONIAC) is and its unique features, proposing a world model abstracting it, and defined the Conversational Agents Framework for Evaluation (CAFE) for the evaluation of CONIAC systems, consisting of six major components: 1) goals of the system's stakeholders, 2) user tasks to be studied in the evaluation, 3) aspects of the users carrying out the tasks, 4) evaluation criteria to be considered, 5) evaluation methodology to be applied, and 6) measures for the quantitative criteria chosen.","authors":["Christine Bauer","Li Chen","Nicola Ferro","Norbert Fuhr","Avishek Anand","Timo Breuer","Guglielmo Faggioli","Ophir Frieder","Hideo Joho","Jussi Karlgren","Johannes Kiesel","Bart P. Knijnenburg","Aldo Lipani","Lien Michiels","Andrea Papenmeier","Maria Soledad Pera","Mark Sanderson","Scott Sanner","Benno Stein","Johanne R. Trippas","Karin Verspoor","Martijn C Willemsen"],"pdf_url":"","comment":"10 figures; Dagstuhl Manifestos, 11(1), pp 19-67. DOI: 10.4230/DagMan.11.1.19"},{"id":"http://arxiv.org/abs/2511.17559v2","updated":"2025-12-21T16:56:46Z","published":"2025-11-13T06:35:29Z","title":"SCARE: A Benchmark for SQL Correction and Question Answerability Classification for Reliable EHR Question Answering","summary":"Recent advances in Large Language Models (LLMs) have enabled the development of text-to-SQL models that allow clinicians to query structured data stored in Electronic Health Records (EHRs) using natural language. However, deploying these models for EHR question answering (QA) systems in safety-critical clinical environments remains challenging: incorrect SQL queries-whether caused by model errors or problematic user inputs-can undermine clinical decision-making and jeopardize patient care. While prior work has mainly focused on improving SQL generation accuracy or filtering questions before execution, there is a lack of a unified benchmark for evaluating independent post-hoc verification mechanisms (i.e., a component that inspects and validates the generated SQL before execution), which is crucial for safe deployment. To fill this gap, we introduce SCARE, a benchmark for evaluating methods that function as a post-hoc safety layer in EHR QA systems. SCARE evaluates the joint task of (1) classifying question answerability (i.e., determining whether a question is answerable, ambiguous, or unanswerable) and (2) verifying or correcting candidate SQL queries. The benchmark comprises 4,200 triples of questions, candidate SQL queries, and expected model outputs, grounded in the MIMIC-III, MIMIC-IV, and eICU databases. It covers a diverse set of questions and corresponding candidate SQL queries generated by seven different text-to-SQL models, ensuring a realistic and challenging evaluation. Using SCARE, we benchmark a range of approaches-from two-stage methods to agentic frameworks. Our experiments reveal a critical trade-off between question classification and SQL error correction, highlighting key challenges and outlining directions for future research.","authors":["Gyubok Lee","Woosog Chay","Edward Choi"],"pdf_url":"","comment":"ML4H 2025 Proceedings"},{"id":"http://arxiv.org/abs/2509.09284v3","updated":"2025-12-21T16:15:54Z","published":"2025-09-11T09:18:07Z","title":"Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning","summary":"Recent advances in reasoning with large language models (LLMs) have shown the effectiveness of Monte Carlo Tree Search (MCTS) for generating high quality intermediate trajectories, particularly in math and symbolic domains. Inspired by this, we explore how MCTS derived trajectories, traditionally used for training value or reward models, can be repurposed to improve policy optimization in verifier guided reinforcement learning (RL). Specifically, we focus on Group Relative Policy Optimization (GRPO), a recent algorithm that enables consistent policy learning from group relative judgments. We reframe GRPO into a staged training paradigm, leveraging a teacher's MCTS rollouts to construct a tree structured curriculum of prefixes. This introduces the novel challenge of computing advantages for training samples that originate from different prefixes, each with a distinct expected return. To address this, we propose Staged Advantage Estimation (SAE), a framework for computing low variance, prefix aware advantages by projecting rewards onto a constraint set that respects the tree's hierarchy. Our empirical results on mathematical reasoning tasks show that SAE improves final accuracy over standard GRPO. This outcome is grounded in our theoretical analysis, which confirms that SAE reduces gradient variance, a principled path to improved sample efficiency. We demonstrate this through practical SAE implementations, comparing efficient heuristics against a formal quadratic program.","authors":["Bingning Huang","Tu Nguyen","Matthieu Zimmer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18779v1","updated":"2025-12-21T15:46:33Z","published":"2025-12-21T15:46:33Z","title":"From Natural Language to Control Signals: A Conceptual Framework for Semantic Channel Finding in Complex Experimental Infrastructure","summary":"Modern experimental platforms such as particle accelerators, fusion devices, telescopes, and industrial process control systems expose tens to hundreds of thousands of control and diagnostic channels accumulated over decades of evolution. Operators and AI systems rely on informal expert knowledge, inconsistent naming conventions, and fragmented documentation to locate signals for monitoring, troubleshooting, and automated control, creating a persistent bottleneck for reliability, scalability, and language-model-driven interfaces. We formalize semantic channel finding-mapping natural-language intent to concrete control-system signals-as a general problem in complex experimental infrastructure, and introduce a four-paradigm framework to guide architecture selection across facility-specific data regimes. The paradigms span (i) direct in-context lookup over curated channel dictionaries, (ii) constrained hierarchical navigation through structured trees, (iii) interactive agent exploration using iterative reasoning and tool-based database queries, and (iv) ontology-grounded semantic search that decouples channel meaning from facility-specific naming conventions. We demonstrate each paradigm through proof-of-concept implementations at four operational facilities spanning two orders of magnitude in scale-from compact free-electron lasers to large synchrotron light sources-and diverse control-system architectures, from clean hierarchies to legacy environments. These implementations achieve 90-97% accuracy on expert-curated operational queries.","authors":["Thorsten Hellert","Nikolay Agladze","Alex Giovannone","Jan Jug","Frank Mayet","Mark Sherwin","Antonin Sulc","Chris Tennant"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.10216v2","updated":"2025-12-21T15:41:27Z","published":"2025-07-14T12:33:07Z","title":"From Words to Proverbs: Evaluating LLMs Linguistic and Cultural Competence in Saudi Dialects with Absher","summary":"As large language models (LLMs) become increasingly central to Arabic NLP applications, evaluating their understanding of regional dialects and cultural nuances is essential, particularly in linguistically diverse settings like Saudi Arabia. This paper introduces Absher, a comprehensive benchmark specifically designed to assess LLMs performance across major Saudi dialects. \\texttt{Absher} comprises over 18,000 multiple-choice questions spanning six distinct categories: Meaning, True/False, Fill-in-the-Blank, Contextual Usage, Cultural Interpretation, and Location Recognition. These questions are derived from a curated dataset of dialectal words, phrases, and proverbs sourced from various regions of Saudi Arabia. We evaluate several state-of-the-art LLMs, including multilingual and Arabic-specific models. We also provide detailed insights into their capabilities and limitations. Our results reveal notable performance gaps, particularly in tasks requiring cultural inference or contextual understanding. Our findings highlight the urgent need for dialect-aware training and culturally aligned evaluation methodologies to improve LLMs performance in real-world Arabic applications.","authors":["Renad Al-Monef","Hassan Alhuzali","Nora Alturayeif","Ashwag Alasmari"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.06713v2","updated":"2025-12-21T15:06:24Z","published":"2025-12-07T08:03:43Z","title":"Look Twice before You Leap: A Rational Agent Framework for Localized Adversarial Anonymization","summary":"Current LLM-based text anonymization frameworks usually rely on remote API services from powerful LLMs, which creates an inherent privacy paradox: users must disclose data to untrusted third parties for guaranteed privacy preservation. Moreover, directly migrating current solutions to local small-scale models (LSMs) offers a suboptimal solution with severe utility collapse. Our work argues that this failure stems not merely from the capability deficits of LSMs, but significantly from the inherent irrationality of the greedy adversarial strategies employed by current state-of-the-art (SOTA) methods. To address this, we propose Rational Localized Adversarial Anonymization (RLAA), a fully localized and training-free framework featuring an Attacker-Arbitrator-Anonymizer architecture. We model the anonymization process as a trade-off between Marginal Privacy Gain (MPG) and Marginal Utility Cost (MUC), and demonstrate that greedy strategies tend to drift into an irrational state. Instead, RLAA introduces an arbitrator that acts as a rationality gatekeeper, validating the attacker's inference to filter out feedback providing negligible privacy benefits. This mechanism promotes a rational early-stopping criterion, and structurally prevents utility collapse. Extensive experiments on different benchmarks demonstrate that RLAA achieves a superior privacy-utility trade-off compared to strong baselines.","authors":["Donghang Duan","Xu Zheng","Yuefeng He","Chong Mu","Leyi Cai","Lizong Zhang"],"pdf_url":"","comment":"17 pages, 9 figures, 6 tables. Revised version with an updated author list, expanded experimental results and analysis"},{"id":"http://arxiv.org/abs/2510.17602v2","updated":"2025-12-21T14:45:13Z","published":"2025-10-20T14:50:58Z","title":"LexChain: Modeling Legal Reasoning Chains for Chinese Tort Case Analysis","summary":"Legal reasoning is a fundamental component of legal analysis and decision-making. Existing computational approaches to legal reasoning predominantly rely on generic reasoning frameworks such as syllogism, which do not comprehensively examine the nuanced process of legal reasoning. Moreover, current research has largely focused on criminal cases, with insufficient modeling for civil cases. In this work, we present a novel framework to explicitly model legal reasoning in the analysis of Chinese tort-related civil cases. We first operationalize the legal reasoning process in tort analysis into the three-module LexChain framework, with each module consisting of multiple finer-grained sub-steps. Informed by the LexChain framework, we introduce the task of tort legal reasoning and construct an evaluation benchmark to systematically assess the critical steps within analytical reasoning chains for tort analysis. Leveraging this benchmark, we evaluate existing large language models for their legal reasoning ability in civil tort contexts. Our results indicate that current models still fall short in accurately handling crucial elements of tort legal reasoning. Furthermore, we introduce several baseline approaches that explicitly incorporate LexChain-style reasoning through prompting or post-training. The proposed baselines achieve significant improvements in tort-related legal reasoning and generalize well to related legal analysis tasks, demonstrating the value of explicitly modeling legal reasoning chains to enhance the reasoning capabilities of language models.","authors":["Huiyuan Xie","Chenyang Li","Huining Zhu","Chubin Zhang","Yuxiao Ye","Zhenghao Liu","Zhiyuan Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18748v1","updated":"2025-12-21T14:28:51Z","published":"2025-12-21T14:28:51Z","title":"Code2Doc: A Quality-First Curated Dataset for Code Documentation","summary":"The performance of automatic code documentation generation models depends critically on the quality of the training data used for supervision. However, most existing code documentation datasets are constructed through large scale scraping of public repositories with limited quality control. As a result, they often contain noisy documentation, extensive duplication, and increasing contamination from AI generated content. These issues weaken the supervision signal available to learning-based models and complicate evaluation.\n  We introduce \\textbf{Code2Doc}, a quality-first curated dataset for function-level code documentation generation. Code2Doc consists of 13,358 high-quality function-documentation pairs extracted from widely used open-source repositories spanning five programming languages: Python, Java, TypeScript, JavaScript, and C++. The dataset is constructed using a four-stage curation pipeline that enforces documentation completeness and clarity, filters functions based on structural and complexity criteria, removes exact and near-duplicate code, and identifies documentation likely to be AI generated. Starting from 52,069 extracted candidates, only 25.6 percent satisfy all quality constraints.\n  We provide a detailed analysis of the resulting dataset, which achieves a mean documentation quality score of 6.93 out of 10. Overall, 86.9% of samples contain explicit type annotations, and only 2.9\\% are flagged as potentially AI generated. Baseline experiments show that fine-tuning a large language model on Code2Doc yields relative improvements of 29.47% in BLEU and 24.04% in ROUGE-L over zero shot performance, despite the modest dataset size. We release both the dataset and the full curation pipeline to support reproducible research on automatic code documentation generation.","authors":["Recep Kaan Karaman","Meftun Akarsu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18746v1","updated":"2025-12-21T14:26:14Z","published":"2025-12-21T14:26:14Z","title":"MemEvolve: Meta-Evolution of Agent Memory Systems","summary":"Self-evolving memory systems are unprecedentedly reshaping the evolutionary paradigm of large language model (LLM)-based agents. Prior work has predominantly relied on manually engineered memory architectures to store trajectories, distill experience, and synthesize reusable tools, enabling agents to evolve on the fly within environment interactions. However, this paradigm is fundamentally constrained by the staticity of the memory system itself: while memory facilitates agent-level evolving, the underlying memory architecture cannot be meta-adapted to diverse task contexts. To address this gap, we propose MemEvolve, a meta-evolutionary framework that jointly evolves agents' experiential knowledge and their memory architecture, allowing agent systems not only to accumulate experience but also to progressively refine how they learn from it. To ground MemEvolve in prior research and foster openness in future self-evolving systems, we introduce EvolveLab, a unified self-evolving memory codebase that distills twelve representative memory systems into a modular design space (encode, store, retrieve, manage), providing both a standardized implementation substrate and a fair experimental arena. Extensive evaluations on four challenging agentic benchmarks demonstrate that MemEvolve achieves (I) substantial performance gains, improving frameworks such as SmolAgent and Flash-Searcher by up to $17.06\\%$; and (II) strong cross-task and cross-LLM generalization, designing memory architectures that transfer effectively across diverse benchmarks and backbone models.","authors":["Guibin Zhang","Haotian Ren","Chong Zhan","Zhenhong Zhou","Junhao Wang","He Zhu","Wangchunshu Zhou","Shuicheng Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18745v1","updated":"2025-12-21T14:23:07Z","published":"2025-12-21T14:23:07Z","title":"InSight-o3: Empowering Multimodal Foundation Models with Generalized Visual Search","summary":"The ability for AI agents to \"think with images\" requires a sophisticated blend of reasoning and perception. However, current open multimodal agents still largely fall short on the reasoning aspect crucial for real-world tasks like analyzing documents with dense charts/diagrams and navigating maps. To address this gap, we introduce O3-Bench, a new benchmark designed to evaluate multimodal reasoning with interleaved attention to visual details. O3-Bench features challenging problems that require agents to piece together subtle visual information from distinct image areas through multi-step reasoning. The problems are highly challenging even for frontier systems like OpenAI o3, which only obtains 40.8% accuracy on O3-Bench. To make progress, we propose InSight-o3, a multi-agent framework consisting of a visual reasoning agent (vReasoner) and a visual search agent (vSearcher) for which we introduce the task of generalized visual search -- locating relational, fuzzy, or conceptual regions described in free-form language, beyond just simple objects or figures in natural images. We then present a multimodal LLM purpose-trained for this task via reinforcement learning. As a plug-and-play agent, our vSearcher empowers frontier multimodal models (as vReasoners), significantly improving their performance on a wide range of benchmarks. This marks a concrete step towards powerful o3-like open systems. Our code and dataset can be found at https://github.com/m-Just/InSight-o3 .","authors":["Kaican Li","Lewei Yao","Jiannan Wu","Tiezheng Yu","Jierun Chen","Haoli Bai","Lu Hou","Lanqing Hong","Wei Zhang","Nevin L. Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.13470v2","updated":"2025-12-21T12:43:32Z","published":"2025-06-16T13:28:37Z","title":"Abstract, Align, Predict: Zero-Shot Stance Detection via Cognitive Inductive Reasoning","summary":"Zero-shot stance detection (ZSSD) seeks to determine the stance of text toward previously unseen targets, a task critical for analyzing dynamic and polarized online discourse with limited labeled data. While large language models (LLMs) offer zero-shot capabilities, prompting-based approaches often fall short in handling complex reasoning and lack robust generalization to novel targets. Meanwhile, LLM-enhanced methods still require substantial labeled data and struggle to move beyond instance-level patterns, limiting their interpretability and adaptability. Inspired by cognitive science, we propose the Cognitive Inductive Reasoning Framework (CIRF), a schema-driven method that bridges linguistic inputs and abstract reasoning via automatic induction and application of cognitive reasoning schemas. CIRF abstracts first-order logic patterns from raw text into multi-relational schema graphs in an unsupervised manner, and leverages a schema-enhanced graph kernel model to align input structures with schema templates for robust, interpretable zero-shot inference. Extensive experiments on SemEval-2016, VAST, and COVID-19-Stance benchmarks demonstrate that CIRF not only establishes new state-of-the-art results, but also achieves comparable performance with just 30\\% of the labeled data, demonstrating its strong generalization and efficiency in low-resource settings.","authors":["Bowen Zhang","Jun Ma","Fuqiang Niu","Li Dong","Jinzhou Cao","Genan Dai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18682v1","updated":"2025-12-21T10:40:36Z","published":"2025-12-21T10:40:36Z","title":"Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design","summary":"In the high-cost simulation-driven design domain, translating ambiguous design requirements into a mathematical optimization formulation is a bottleneck for optimizing product performance. This process is time-consuming and heavily reliant on expert knowledge. While large language models (LLMs) offer potential for automating this task, existing approaches either suffer from poor formalization that fails to accurately align with the design intent or rely on solver feedback for data filtering, which is unavailable due to the high simulation costs. To address this challenge, we propose APF, a framework for solver-independent, automated problem formulation via LLMs designed to automatically convert engineers' natural language requirements into executable optimization models. The core of this framework is an innovative pipeline for automatically generating high-quality data, which overcomes the difficulty of constructing suitable fine-tuning datasets in the absence of high-cost solver feedback with the help of data generation and test instance annotation. The generated high-quality dataset is used to perform supervised fine-tuning on LLMs, significantly enhancing their ability to generate accurate and executable optimization problem formulations. Experimental results on antenna design demonstrate that APF significantly outperforms the existing methods in both the accuracy of requirement formalization and the quality of resulting radiation efficiency curves in meeting the design goals.","authors":["Yuchen Li","Handing Wang","Bing Xue","Mengjie Zhang","Yaochu Jin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.12620v2","updated":"2025-12-21T10:39:54Z","published":"2025-12-14T09:50:10Z","title":"Understanding Syllogistic Reasoning in LLMs from Formal and Natural Language Perspectives","summary":"We study syllogistic reasoning in LLMs from the logical and natural language perspectives. In process, we explore fundamental reasoning capabilities of the LLMs and the direction this research is moving forward. To aid in our studies, we use 14 large language models and investigate their syllogistic reasoning capabilities in terms of symbolic inferences as well as natural language understanding. Even though this reasoning mechanism is not a uniform emergent property across LLMs, the perfect symbolic performances in certain models make us wonder whether LLMs are becoming more and more formal reasoning mechanisms, rather than making explicit the nuances of human reasoning.","authors":["Aheli Poddar","Saptarshi Sahoo","Sujata Ghosh"],"pdf_url":"","comment":"9 pages, 4 figures, 5 tables. Submitted to AAAI 2026 Bridge Program on Logic & AI. Code available at https://github.com/XAheli/Logic-in-LLMs"},{"id":"http://arxiv.org/abs/2512.18679v1","updated":"2025-12-21T10:37:31Z","published":"2025-12-21T10:37:31Z","title":"brat: Aligned Multi-View Embeddings for Brain MRI Analysis","summary":"We present brat (brain report alignment transformer), a multi-view representation learning framework for brain magnetic resonance imaging (MRI) trained on MRIs paired with clinical reports. Brain MRIs present unique challenges due to the presence of numerous, highly varied, and often subtle abnormalities that are localized to a few slices within a 3D volume. To address these challenges, we introduce a brain MRI dataset $10\\times$ larger than existing ones, containing approximately 80,000 3D scans with corresponding radiology reports, and propose a multi-view pre-training approach inspired by advances in document retrieval. We develop an implicit query-feature matching mechanism and adopt concepts from quality-diversity to obtain multi-view embeddings of MRIs that are aligned with the clinical features given by report sentences. We evaluate our approach across multiple vision-language and vision tasks, demonstrating substantial performance improvements. The brat foundation models are publicly released.","authors":["Maxime Kayser","Maksim Gridnev","Wanting Wang","Max Bain","Aneesh Rangnekar","Avijit Chatterjee","Aleksandr Petrov","Harini Veeraraghavan","Nathaniel C. Swinburne"],"pdf_url":"","comment":"First round accept at WACV 2026"},{"id":"http://arxiv.org/abs/2512.18658v1","updated":"2025-12-21T09:12:21Z","published":"2025-12-21T09:12:21Z","title":"Does It Tie Out? Towards Autonomous Legal Agents in Venture Capital","summary":"Before closing venture capital financing rounds, lawyers conduct diligence that includes tying out the capitalization table: verifying that every security (for example, shares, options, warrants) and issuance term (for example, vesting schedules, acceleration triggers, transfer restrictions) is supported by large sets of underlying legal documentation. While LLMs continue to improve on legal benchmarks, specialized legal workflows, such as capitalization tie-out, remain out of reach even for strong agentic systems. The task requires multi-document reasoning, strict evidence traceability, and deterministic outputs that current approaches fail to reliably deliver. We characterize capitalization tie-out as an instance of a real-world benchmark for legal AI, analyze and compare the performance of existing agentic systems, and propose a world model architecture toward tie-out automation-and more broadly as a foundation for applied legal intelligence.","authors":["Pierre Colombo","Malik Boudiaf","Allyn Sweet","Michael Desa","Hongxi Wang","Kevin Candra","Syméon del Marmol"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18623v1","updated":"2025-12-21T06:54:34Z","published":"2025-12-21T06:54:34Z","title":"LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction","summary":"Large language models (LLMs) often generate hallucinated content that lacks factual or contextual grounding, limiting their reliability in critical applications. Existing approaches such as supervised fine-tuning and reinforcement learning from human feedback are data intensive and computationally expensive, while static parameter editing methods struggle with context dependent errors and catastrophic forgetting.\n  We propose LLM-CAS, a framework that formulates real-time hallucination correction as a hierarchical reinforcement learning problem. LLM-CAS trains an agent to learn a policy that dynamically selects temporary neuron perturbations during inference based on the current context. Unlike prior dynamic approaches that rely on heuristic or predefined adjustments, this policy driven mechanism enables adaptive and fine grained correction without permanent parameter modification.\n  Experiments across multiple language models demonstrate that LLM-CAS consistently improves factual accuracy, achieving gains of 10.98 percentage points on StoryCloze, 2.71 points on TriviaQA, and 2.06 points on the MC1 score of TruthfulQA. These results outperform both static editing methods such as ITI and CAA and the dynamic SADI framework. Overall, LLM-CAS provides an efficient and context aware solution for improving the reliability of LLMs, with promising potential for future multimodal extensions.","authors":["Jensen Zhang","Ningyuan Liu","Yijia Fan","Zihao Huang","Qinglin Zeng","Kaitong Cai","Jian Wang","Keze Wang"],"pdf_url":"","comment":"Accepted at AAAI 2026"},{"id":"http://arxiv.org/abs/2511.08029v2","updated":"2025-12-21T06:45:20Z","published":"2025-11-11T09:31:37Z","title":"BiCA: Effective Biomedical Dense Retrieval with Citation-Aware Hard Negatives","summary":"Hard negatives are essential for training effective retrieval models. Hard-negative mining typically relies on ranking documents using cross-encoders or static embedding models based on similarity metrics such as cosine distance. Hard negative mining becomes challenging for biomedical and scientific domains due to the difficulty in distinguishing between source and hard negative documents. However, referenced documents naturally share contextual relevance with the source document but are not duplicates, making them well-suited as hard negatives. In this work, we propose BiCA: Biomedical Dense Retrieval with Citation-Aware Hard Negatives, an approach for hard-negative mining by utilizing citation links in 20,000 PubMed articles for improving a domain-specific small dense retriever. We fine-tune the GTE_small and GTE_Base models using these citation-informed negatives and observe consistent improvements in zero-shot dense retrieval using nDCG@10 for both in-domain and out-of-domain tasks on BEIR and outperform baselines on long-tailed topics in LoTTE using Success@5. Our findings highlight the potential of leveraging document link structure to generate highly informative negatives, enabling state-of-the-art performance with minimal fine-tuning and demonstrating a path towards highly data-efficient domain adaptation.","authors":["Aarush Sinha","Pavan Kumar S","Roshan Balaji","Nirav Pravinbhai Bhatt"],"pdf_url":"","comment":"Accepted for oral presentation at AAAI 2026"},{"id":"http://arxiv.org/abs/2512.18622v1","updated":"2025-12-21T06:43:47Z","published":"2025-12-21T06:43:47Z","title":"A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback","summary":"Text2SQL, the task of generating SQL queries from natural language text, is a critical challenge in data engineering. Recently, Large Language Models (LLMs) have demonstrated superior performance for this task due to their advanced comprehension and generation capabilities. However, privacy and cost considerations prevent companies from using Text2SQL solutions based on external LLMs offered as a service. Rather, small LLMs (SLMs) that are openly available and can hosted in-house are adopted. These SLMs, in turn, lack the generalization capabilities of larger LLMs, which impairs their effectiveness for complex tasks such as Text2SQL. To address these limitations, we propose MATS, a novel Text2SQL framework designed specifically for SLMs. MATS uses a multi-agent mechanism that assigns specialized roles to auxiliary agents, reducing individual workloads and fostering interaction. A training scheme based on reinforcement learning aligns these agents using feedback obtained during execution, thereby maintaining competitive performance despite a limited LLM size. Evaluation results using on benchmark datasets show that MATS, deployed on a single- GPU server, yields accuracy that are on-par with large-scale LLMs when using significantly fewer parameters. Our source code and data are available at https://github.com/thanhdath/mats-sql.","authors":["Thanh Dat Hoang","Thanh Trung Huynh","Matthias Weidlich","Thanh Tam Nguyen","Tong Chen","Hongzhi Yin","Quoc Viet Hung Nguyen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2406.16007v2","updated":"2025-12-21T06:33:37Z","published":"2024-06-23T04:29:13Z","title":"Label Words as Local Task Vectors in In-Context Learning","summary":"Large Language Models (LLMs) have demonstrated remarkable abilities, one of the most important being in-context learning (ICL). With ICL, LLMs can derive the underlying rule from a few demonstrations and provide answers that comply with the rule. Previous work hypothesized that the network creates a task vector in specific positions during ICL. The task vector can be computed by averaging across the dataset. It conveys the overall task information and can thus be considered global. Patching the global task vector allows LLMs to achieve zero-shot performance with dummy inputs comparable to few-shot learning. However, we find that such a global task vector does not exist in all tasks, especially in tasks that rely on rules that can only be inferred from multiple demonstrations, such as categorization tasks. Instead, the information provided by each demonstration is first transmitted to its answer position and forms a local task vector associated with the demonstration. In some tasks but not in categorization tasks, all demonstrations' local task vectors converge in later layers, forming the global task vector. We further show that local task vectors encode a high-level abstraction of rules extracted from the demonstrations. Our study provides novel insights into the mechanism underlying ICL in LLMs, demonstrating how ICL may be achieved through an information aggregation mechanism.","authors":["Bowen Zheng","Ming Ma","Zhongqiao Lin","Tianming Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18608v1","updated":"2025-12-21T05:58:40Z","published":"2025-12-21T05:58:40Z","title":"A Comparative Study of Light-weight Language Models for PII Masking and their Deployment for Real Conversational Texts","summary":"Automated masking of Personally Identifiable Information (PII) is critical for privacy-preserving conversational systems. While current frontier large language models demonstrate strong PII masking capabilities, concerns about data handling and computational costs motivate exploration of whether lightweight models can achieve comparable performance. We compare encoder-decoder and decoder-only architectures by fine-tuning T5-small and Mistral-Instruct-v0.3 on English datasets constructed from the AI4Privacy benchmark. We create different dataset variants to study label standardization and PII representation, covering 24 standardized PII categories and higher-granularity settings. Evaluation using entity-level and character-level metrics, type accuracy, and exact match shows that both lightweight models achieve performance comparable to frontier LLMs for PII masking tasks. Label normalization consistently improves performance across architectures. Mistral achieves higher F1 and recall with greater robustness across PII types but incurs significantly higher generation latency. T5, while less robust in conversational text, offers more controllable structured outputs and lower inference cost, motivating its use in a real-time Discord bot for real-world PII redaction. Evaluation on live messages reveals performance degradation under informal inputs. These results clarify trade-offs between accuracy, robustness, and computational efficiency, demonstrating that lightweight models can provide effective PII masking while addressing data handling concerns associated with frontier LLMs.","authors":["Prabigya Acharya","Liza Shrestha"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18601v1","updated":"2025-12-21T05:20:21Z","published":"2025-12-21T05:20:21Z","title":"On Finding Inconsistencies in Documents","summary":"Professionals in academia, law, and finance audit their documents because inconsistencies can result in monetary, reputational, and scientific costs. Language models (LMs) have the potential to dramatically speed up this auditing process. To understand their abilities, we introduce a benchmark, FIND (Finding INconsistencies in Documents), where each example is a document with an inconsistency inserted manually by a domain expert. Despite the documents being long, technical, and complex, the best-performing model (gpt-5) recovered 64% of the inserted inconsistencies. Surprisingly, gpt-5 also found undiscovered inconsistencies present in the original documents. For example, on 50 arXiv papers, we judged 136 out of 196 of the model's suggestions to be legitimate inconsistencies missed by the original authors. However, despite these findings, even the best models miss almost half of the inconsistencies in FIND, demonstrating that inconsistency detection is still a challenging task.","authors":["Charles J. Lovering","Seth Ebner","Brandon Smock","Michael Krumdick","Saad Rabbani","Ahmed Muhammad","Varshini Reddy","Chris Tanner"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18593v1","updated":"2025-12-21T04:45:31Z","published":"2025-12-21T04:45:31Z","title":"From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation","summary":"In multilingual nations like India, access to legal information is often hindered by language barriers, as much of the legal and judicial documentation remains in English. Legal Machine Translation (L-MT) offers a scalable solution to this challenge by enabling accurate and accessible translations of legal documents. This paper presents our work for the JUST-NLP 2025 Legal MT shared task, focusing on English-Hindi translation using Transformer-based approaches. We experiment with 2 complementary strategies, fine-tuning a pre-trained OPUS-MT model for domain-specific adaptation and training a Transformer model from scratch using the provided legal corpus. Performance is evaluated using standard MT metrics, including SacreBLEU, chrF++, TER, ROUGE, BERTScore, METEOR, and COMET. Our fine-tuned OPUS-MT model achieves a SacreBLEU score of 46.03, significantly outperforming both baseline and from-scratch models. The results highlight the effectiveness of domain adaptation in enhancing translation quality and demonstrate the potential of L-MT systems to improve access to justice and legal transparency in multilingual contexts.","authors":["Amit Barman","Atanu Mandal","Sudip Kumar Naskar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.03291v3","updated":"2025-12-21T03:24:02Z","published":"2025-01-06T08:20:04Z","title":"ADePT: Adaptive Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning","summary":"Prompt Tuning (PT) enables the adaptation of Pre-trained Large Language Models (PLMs) to downstream tasks by optimizing a small amount of soft virtual tokens, which are prepended to the input token embeddings. Recently, Decomposed Prompt Tuning (DePT) has demonstrated superior adaptation capabilities by decomposing the soft prompt into a shorter soft prompt and a pair of low-rank matrices. The product of the pair of low-rank matrices is added to the input token embeddings to offset them. Additionally, DePT achieves faster inference compared to PT due to the shorter soft prompt. However, in this paper, we find that the position-based token embedding offsets of DePT restrict its ability to generalize across diverse model inputs, and that the shared embedding offsets across many token embeddings result in sub-optimization. To tackle these issues, we introduce Adaptive Decomposed Prompt Tuning (ADePT), which is composed of a short soft prompt and a shallow token-shared feed-forward neural network. ADePT utilizes the token-shared feed-forward neural network to learn the embedding offsets for each token, enabling adaptive embedding offsets that vary according to the model input and better optimization of token embedding offsets. This enables ADePT to achieve superior adaptation performance without requiring more inference time or additional trainable parameters compared to vanilla PT and its variants. In comprehensive experiments across 23 natural language processing tasks and 4 typical PLMs of different scales, ADePT consistently surpasses the other leading parameter-efficient fine-tuning methods, and even outperforms the full fine-tuning in certain scenarios. We also provide a theoretical analysis towards ADePT. Code is available at https://github.com/HungerPWAY/ADePT.","authors":["Pengwei Tang","Xiaolin Hu","Yong Liu"],"pdf_url":"","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2508.09337v3","updated":"2025-12-21T01:28:23Z","published":"2025-08-12T20:51:56Z","title":"Decoding Neural Emotion Patterns through Large Language Model Embeddings","summary":"Understanding how emotional expression in language relates to brain function is a challenge in computational neuroscience and affective computing. Traditional neuroimaging is costly and lab-bound, but abundant digital text offers new avenues for emotion-brain mapping. Prior work has largely examined neuroimaging-based emotion localization or computational text analysis separately, with little integration. We propose a computational framework that maps textual emotional content to anatomically defined brain regions without requiring neuroimaging. Using OpenAI's text-embedding-ada-002, we generate high-dimensional semantic representations, apply dimensionality reduction and clustering to identify emotional groups, and map them to 18 brain regions linked to emotional processing. Three experiments were conducted: i) analyzing conversational data from healthy vs. depressed subjects (DIAC-WOZ dataset) to compare mapping patterns, ii) applying the method to the GoEmotions dataset and iii) comparing human-written text with large language model (LLM) responses to assess differences in inferred brain activation. Emotional intensity was scored via lexical analysis. Results showed neuroanatomically plausible mappings with high spatial specificity. Depressed subjects exhibited greater limbic engagement tied to negative affect. Discrete emotions were successfully differentiated. LLM-generated text matched humans in basic emotion distribution but lacked nuanced activation in empathy and self-referential regions (medial prefrontal and posterior cingulate cortex). This cost-effective, scalable approach enables large-scale analysis of naturalistic language, distinguishes between clinical populations, and offers a brain-based benchmark for evaluating AI emotional expression.","authors":["Gideon Vos","Maryam Ebrahimpour","Liza van Eijk","Zoltan Sarnyai","Mostafa Rahimi Azghadi"],"pdf_url":"","comment":"26 pages, 9 figures"},{"id":"http://arxiv.org/abs/2510.17638v2","updated":"2025-12-21T01:04:03Z","published":"2025-10-20T15:20:05Z","title":"LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena","summary":"Forecasting is not only a fundamental intellectual pursuit but also is of significant importance to societal systems such as finance and economics. With the rapid advances of large language models (LLMs) trained on Internet-scale data, it raises the promise of employing LLMs to forecast real-world future events, an emerging paradigm we call \"LLM-as-a-Prophet\". This paper systematically investigates such predictive intelligence of LLMs. To this end, we build Prophet Arena, a general evaluation benchmark that continuously collects live forecasting tasks and decomposes each task into distinct pipeline stages, in order to support our controlled and large-scale experimentation. Our comprehensive evaluation reveals that many LLMs already exhibit impressive forecasting capabilities, reflected in, e.g., their small calibration errors, consistent prediction confidence and promising market returns. However, we also uncover key bottlenecks towards achieving superior predictive intelligence via LLM-as-a-Prophet, such as LLMs' inaccurate event recalls, misunderstanding of data sources and slower information aggregation compared to markets when resolution nears.","authors":["Qingchuan Yang","Simon Mahns","Sida Li","Anri Gu","Jibang Wu","Haifeng Xu"],"pdf_url":"","comment":"https://www.prophetarena.co/"},{"id":"http://arxiv.org/abs/2511.09854v2","updated":"2025-12-21T00:53:39Z","published":"2025-11-13T01:25:34Z","title":"TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain","summary":"Large language models (LLMs) have demonstrated impressive performance in text generation tasks; however, their embedding spaces often suffer from the isotropy problem, resulting in poor discrimination of domain-specific terminology, particularly in legal and financial contexts. This weakness in terminology-level representation can severely hinder downstream tasks such as legal judgment prediction or financial risk analysis, where subtle semantic distinctions are critical. To address this problem, we propose TermGPT, a multi-level contrastive fine-tuning framework designed for terminology adaptation. We first construct a sentence graph to capture semantic and structural relations, and generate semantically consistent yet discriminative positive and negative samples based on contextual and topological cues. We then devise a multi-level contrastive learning approach at both the sentence and token levels, enhancing global contextual understanding and fine-grained terminology discrimination. To support robust evaluation, we construct the first financial terminology dataset derived from official regulatory documents. Experiments show that TermGPT outperforms existing baselines in term discrimination tasks within the finance and legal domains.","authors":["Yidan Sun","Mengying Zhu","Feiyue Chen","Yangyang Wu","Xiaolei Dan","Mengyuan Yang","Xiaolin Zheng","Shenglin Ben"],"pdf_url":"","comment":"13 pages, 4 figures, AAAI'26"},{"id":"http://arxiv.org/abs/2512.18552v1","updated":"2025-12-21T00:49:40Z","published":"2025-12-21T00:49:40Z","title":"Toward Training Superintelligent Software Agents through Self-Play SWE-RL","summary":"While current software agents powered by large language models (LLMs) and agentic reinforcement learning (RL) can boost programmer productivity, their training data (e.g., GitHub issues and pull requests) and environments (e.g., pass-to-pass and fail-to-pass tests) heavily depend on human knowledge or curation, posing a fundamental barrier to superintelligence. In this paper, we present Self-play SWE-RL (SSR), a first step toward training paradigms for superintelligent software agents. Our approach takes minimal data assumptions, only requiring access to sandboxed repositories with source code and installed dependencies, with no need for human-labeled issues or tests. Grounded in these real-world codebases, a single LLM agent is trained via reinforcement learning in a self-play setting to iteratively inject and repair software bugs of increasing complexity, with each bug formally specified by a test patch rather than a natural language issue description. On the SWE-bench Verified and SWE-Bench Pro benchmarks, SSR achieves notable self-improvement (+10.4 and +7.8 points, respectively) and consistently outperforms the human-data baseline over the entire training trajectory, despite being evaluated on natural language issues absent from self-play. Our results, albeit early, suggest a path where agents autonomously gather extensive learning experiences from real-world software repositories, ultimately enabling superintelligent systems that exceed human capabilities in understanding how systems are constructed, solving novel challenges, and autonomously creating new software from scratch.","authors":["Yuxiang Wei","Zhiqing Sun","Emily McMilin","Jonas Gehring","David Zhang","Gabriel Synnaeve","Daniel Fried","Lingming Zhang","Sida Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18551v1","updated":"2025-12-21T00:45:23Z","published":"2025-12-21T00:45:23Z","title":"Neologism Learning as a Parameter-Efficient Alternative to Fine-Tuning for Model Steering","summary":"In language modeling, neologisms are new tokens trained to represent a concept not already included in a given model's vocabulary. Neologisms can be used to encourage specific behavior in models, for example by appending prompts with \"Give me a neologism answer.\" Behavioral steering can also be achieved through fine-tuning, albeit with more compute and less flexibility: learning a neologism only trains d parameters and allows the user to still access the model's default behavior. We compare the performance of neologism learning against low-rank adaptation (LoRA) fine-tuning, finding that neologisms outperform fine-tuned models under a matched training setup (same data and hyperparameters). We also investigate self-verbalizations of neologisms, and observe that the model will occasionally make up its own new words when asked about a neologism.","authors":["Sungjoon Park","Varun Ramamurthi","Owen Terry"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18546v1","updated":"2025-12-21T00:19:02Z","published":"2025-12-21T00:19:02Z","title":"LLMs on Drugs: Language Models Are Few-Shot Consumers","summary":"Large language models (LLMs) are sensitive to the personas imposed on them at inference time, yet prompt-level \"drug\" interventions have never been benchmarked rigorously. We present the first controlled study of psychoactive framings on GPT-5-mini using ARC-Challenge. Four single-sentence prompts -- LSD, cocaine, alcohol, and cannabis -- are compared against a sober control across 100 validation items per condition, with deterministic decoding, full logging, Wilson confidence intervals, and Fisher exact tests. Control accuracy is 0.45; alcohol collapses to 0.10 (p = 3.2e-8), cocaine to 0.21 (p = 4.9e-4), LSD to 0.19 (p = 1.3e-4), and cannabis to 0.30 (p = 0.041), largely because persona prompts disrupt the mandated \"Answer: <LETTER>\" template. Persona text therefore behaves like a \"few-shot consumable\" that can destroy reliability without touching model weights. All experimental code, raw results, and analysis scripts are available at https://github.com/lexdoudkin/llms-on-drugs.","authors":["Alexander Doudkin"],"pdf_url":"","comment":"8 pages, 2 figures, 2 tables"}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2512.18915v1","updated":"2025-12-21T23:18:07Z","published":"2025-12-21T23:18:07Z","title":"QoS-Aware Load Balancing in the Computing Continuum via Multi-Player Bandits","summary":"As computation shifts from the cloud to the edge to reduce processing latency and network traffic, the resulting Computing Continuum (CC) creates a dynamic environment where it is challenging to meet strict Quality of Service (QoS) requirements and avoid service instance overload. Existing methods often prioritize global metrics, overlooking per-client QoS, which is crucial for latency-sensitive and reliability-critical applications. We propose QEdgeProxy, a decentralized QoS-aware load balancer that acts as a proxy between IoT devices and service instances in CC. We formulate the load balancing problem as a Multi-Player Multi-Armed Bandit (MP-MAB) with heterogeneous rewards, where each load balancer autonomously selects service instances that maximize the probability of meeting its clients' QoS targets by using Kernel Density Estimation (KDE) to estimate QoS success probabilities. It also incorporates an adaptive exploration mechanism to recover rapidly from performance shifts and non-stationary conditions. We present a Kubernetes-native QEdgeProxy implementation and evaluate it on an emulated CC testbed deployed on a K3s cluster with realistic network conditions and a latency-sensitive edge-AI workload. Results show that QEdgeProxy significantly outperforms proximity-based and reinforcement-learning baselines in per-client QoS satisfaction, while adapting effectively to load surges and instance availability changes.","authors":["Ivan Čilić","Ivana Podnar Žarko","Pantelis Frangoudis","Schahram Dustdar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18761v1","updated":"2025-12-21T14:56:17Z","published":"2025-12-21T14:56:17Z","title":"How Many Pinching Antennas Are Enough?","summary":"Programmable wireless environments (PWEs) have emerged as a key paradigm for next-generation communication networks, aiming to transform wireless propagation from an uncontrollable phenomenon into a reconfigurable process that can adapt to diverse service requirements. In this framework, pinching-antenna systems (PASs) have recently been proposed as a promising enabling technology, as they allow the radiation location and effective propagation distance to be adjusted by selectively exciting radiating points along a dielectric waveguide. However, most existing studies on PASs rely on the idealized assumption that pinching-antenna (PA) positions can be continuously adjusted along the waveguide, while realistically only a finite set of pinching locations is available. Motivated by this, this paper analyzes the performance of two-state PASs, where the PA positions are fixed and only their activation state can be controlled. By explicitly accounting for the spatial discreteness of the available pinching points, closed-form analytical expressions for the outage probability and the ergodic achievable data rate are derived. In addition, we introduce the pinching discretization efficiency to quantify the performance gap between discrete and continuous pinching configurations, enabling a direct assessment of the number of PAs required to approximate the ideal continuous case. Finally, numerical results validate the analytical framework and show that near-continuous performance can be achieved with a limited number of PAs, offering useful insights for the design and deployment of PASs in PWEs.","authors":["Dimitrios Tyrovolas","Sotiris A. Tegos","Yue Xiao","Panagiotis D. Diamantoulakis","Sotiris Ioannidis","Christos K. Liaskos","George K. Karagiannidis","Stylianos D. Asimonis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.11043v2","updated":"2025-12-21T14:46:45Z","published":"2025-10-13T06:19:54Z","title":"Zephyrus: Scaling Gateways Beyond the Petabit-Era with DPU-Augmented Hierarchical Co-Offloading","summary":"Operating at petabit-scale, ByteDance's cloud gateways are deployed at critical aggregation points to orchestrate a wide array of business traffic. However, this massive scale imposes significant resource pressure on our previous-generation cloud gateways, rendering them unsustainable in the face of ever-growing cloud-network traffic. As the DPU market rapidly expands, we see a promising path to meet our escalating business traffic demands by integrating DPUs with our established Tofino-based gateways. DPUs augment these gateways with substantially larger table capacities and richer programmability without compromising previously low-latency and high-throughput forwarding. Despite compelling advantages, the practical integration of DPUs into cloud gateways remains unexplored, primarily due to underlying challenges. In this paper, we present Zephyrus, a production-scale gateway built upon a unified P4 pipeline spanning high-performance Tofino and feature-rich DPUs, which successfully overcomes these challenges. We further introduce a hierarchical co-offloading architecture (HLCO) to orchestrate traffic flow within this heterogeneous gateway, achieving > 99% hardware offloading while retaining software fallback paths for complex operations. Zephyrus outperforms LuoShen (NSDI '24) with 33% higher throughput and our evaluation further indicates 21% lower power consumption and 14% lower hardware cost. Against FPGA-based systems, Albatross (SIGCOMM '25), it doubles the throughput at a substantially lower Total Cost of Ownership (TCO), showcasing its superior performance-per-dollar. Beyond these performance gains, we also share key lessons from several years of developing and operating Zephyrus at production scale. We believe these insights provide valuable references for researchers and practitioners designing performant cloud gateways.","authors":["Yuemeng Xu","Haoran Chen","Jiarui Guo","Mingwei Cui","Qiuheng Yin","Cheng Dong","Daxiang Kang","Xian Wu","Chenmin Sun","Peng He","Yang Gao","Lirong Lai","Kai Wang","Hongyu Wu","Tong Yang","Xiyun Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18698v1","updated":"2025-12-21T11:25:54Z","published":"2025-12-21T11:25:54Z","title":"Real-Time Remote Monitoring of Correlated Markovian Sources","summary":"We investigate real-time tracking of two correlated stochastic processes over a shared wireless channel. The joint evolution of the processes is modeled as a two-dimensional discrete-time Markov chain. Each process is observed by a dedicated sampler and independently reconstructed at a remote monitor according to a task-specific objective. Although both processes originate from a common underlying phenomenon (e.g., distinct features of the same source), each monitor is interested only in its corresponding feature. A reconstruction error is incurred when the true and reconstructed states mismatch at one or both monitors. To address this problem, we propose an error-aware joint sampling and transmission policy, under which each sampler probabilistically generates samples only when the current process state differs from the most recently reconstructed state at its corresponding monitor. We adopt the time-averaged reconstruction error as the primary performance metric and benchmark the proposed policy against state-of-the-art joint sampling and transmission schemes. For each policy, we derive closed-form expressions for the resulting time-averaged reconstruction error. We further formulate and solve an optimization problem that minimizes the time-averaged reconstruction error subject to an average sampling cost constraint. Analytical and numerical results demonstrate that the proposed error-aware policy achieves the minimum time-averaged reconstruction error among the considered schemes while efficiently utilizing the sampling budget. The performance gains are particularly pronounced in regimes with strong inter-process correlation and stringent tracking requirements, where frequent sampling by both samplers is necessary.","authors":["Mehrdad Salimnejad","Marios Kountouris","Nikolaos Pappas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18582v1","updated":"2025-12-21T03:58:34Z","published":"2025-12-21T03:58:34Z","title":"Wireless Copilot: An AI-Powered Partner for Navigating Next-Generation Wireless Complexity","summary":"The sixth-generation (6G) of wireless networks introduces a level of operational complexity that exceeds the limits of traditional automation and manual oversight. This paper introduces the \"Wireless Copilot\", an AI-powered technical assistant designed to function as a collaborative partner for human network designers, engineers, and operators. We posit that by integrating Large Language Models (LLMs) with a robust cognitive framework. It will surpass the existing AI tools and interact with wireless devices, transmitting the user's intentions into the actual network execution process. Then, Wireless Copilot can translate high-level human intent into precise, optimized, and verifiable network actions. This framework bridges the gap between human expertise and machine-scale complexity, enabling more efficient, intelligent, and trustworthy management of 6G systems. Wireless Copilot will be a novel layer between the wireless infrastructure and the network operators. Moreover, we explore Wireless Copilot's methodology and analyze its application in Low-Altitude Wireless Networks (LAWNets) assisting 6G networking, including network design, configuration, evaluation, and optimization. Additionally, we present a case study on intent-based LAWNets resource allocation, demonstrating its superior adaptability compared to others. Finally, we outline future research directions toward creating a comprehensive human-AI collaborative ecosystem for the 6G era.","authors":["Haoxiang Luo","Ruichen Zhang","Yinqiu Liu","Gang Sun","Hongfang Yu","Dusit Niyato","Shiwen Mao","Dong In Kim"],"pdf_url":"","comment":null}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2512.18589v1","updated":"2025-12-21T04:23:43Z","published":"2025-12-21T04:23:43Z","title":"DNA-HHE: Dual-mode Near-network Accelerator for Hybrid Homomorphic Encryption on the Edge","summary":"Fully homomorphic encryption (FHE) schemes like RNS-CKKS enable privacy-preserving outsourced computation (PPOC) but suffer from high computational latency and ciphertext expansion, especially on the resource-constrained edge side. Hybrid Homomorphic Encryption (HHE) mitigates these issues on the edge side by replacing HE with lightweight symmetric encryption for plaintext encryption, such as the Rubato cipher for the HHE variant of RNS-CKKS, yet it introduces transciphering overhead on the cloud. The respective strengths and limitations of FHE and HHE call for a dual-mode HHE solution with flexible algorithm switching ability. This paper presents DNA-HHE, the first dual-mode HHE accelerator with near-network coupling for edge devices. DNA-HHE supports both edge-side RNS-CKKS and Rubato within a unified architecture driven by flexible custom instructions. To realize a compact implementation for the edge side, we propose a DSP-efficient modular reduction design, a compact multi-field-adaptive butterfly unit, and parallel scheduling schemes of Rubato with a high degree of resource sharing. DNA-HHE is designed with network protocol packaging and transmission capacities and directly coupled to the network interface controller, achieving reduced overall latency of edge-side PPOC by 1.09$\\times$ to 1.56$\\times$. Our evaluations on the ASIC and FPGA platforms demonstrate that DNA-HHE outperforms the state-of-the-art single-mode designs in both edge-side RNS-CKKS and symmetric cipher with better computation latency and area efficiency, while offering dual-mode functionality.","authors":["Yifan Zhao","Xinglong Yu","Yi Sun","Honglin Kuang","Jun Han"],"pdf_url":"","comment":"9 pages, conference"}],"Software Engineering":[{"id":"http://arxiv.org/abs/2512.18925v1","updated":"2025-12-21T23:51:02Z","published":"2025-12-21T23:51:02Z","title":"An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects","summary":"While Large Language Models (LLMs) have demonstrated remarkable capabilities, research shows that their effectiveness depends not only on explicit prompts but also on the broader context provided. This requirement is especially pronounced in software engineering, where the goals, architecture, and collaborative conventions of an existing project play critical roles in response quality. To support this, many AI coding assistants have introduced ways for developers to author persistent, machine-readable directives that encode a project's unique constraints. Although this practice is growing, the content of these directives remains unstudied.\n  This paper presents a large-scale empirical study to characterize this emerging form of developer-provided context. Through a qualitative analysis of 401 open-source repositories containing cursor rules, we developed a comprehensive taxonomy of project context that developers consider essential, organized into five high-level themes: Conventions, Guidelines, Project Information, LLM Directives, and Examples. Our study also explores how this context varies across different project types and programming languages, offering implications for the next generation of context-aware AI developer tools.","authors":["Shaokang Jiang","Daye Nam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18852v1","updated":"2025-12-21T18:41:27Z","published":"2025-12-21T18:41:27Z","title":"What Drives Issue Resolution Speed? An Empirical Study of Scientific Workflow Systems on GitHub","summary":"Scientific Workflow Systems (SWSs) play a vital role in enabling reproducible, scalable, and automated scientific analysis. Like other open-source software, these systems depend on active maintenance and community engagement to remain reliable and sustainable. However, despite the importance of timely issue resolution for software quality and community trust, little is known about what drives issue resolution speed within SWSs. This paper presents an empirical study of issue management and resolution across a collection of GitHub-hosted SWS projects. We analyze 21,116 issues to investigate how project characteristics, issue metadata, and contributor interactions affect time-to-close. Specifically, we address two research questions: (1) how issues are managed and addressed in SWSs, and (2) how issue and contributor features relate to issue resolution speed. We find that 68.91% of issues are closed, with half of them resolved within 18.09 days. Our results show that although SWS projects follow structured issue management practices, the issue resolution speed varies considerably across systems. Factors such as labeling and assigning issues are associated with faster issue resolution. Based on our findings, we make recommendations for developers to better manage SWS repository issues and improve their quality.","authors":["Khairul Alam","Banani Roy"],"pdf_url":"","comment":"7"},{"id":"http://arxiv.org/abs/2512.18823v1","updated":"2025-12-21T17:17:49Z","published":"2025-12-21T17:17:49Z","title":"Misbehavior Forecasting for Focused Autonomous Driving Systems Testing","summary":"Simulation-based testing is the standard practice for assessing the reliability of self-driving cars' software before deployment. Existing bug-finding techniques are either unreliable or expensive. We build on the insight that near misses observed during simulations may point to potential failures. We propose Foresee, a technique that identifies near misses using a misbehavior forecaster that computes possible future states of the ego-vehicle under test. Foresee performs local fuzzing in the neighborhood of each candidate near miss to surface previously unknown failures. In our empirical study, we evaluate the effectiveness of different configurations of Foresee using several scenarios provided in the CARLA simulator on both end-to-end and modular self-driving systems and examine its complementarity with the state-of-the-art fuzzer DriveFuzz. Our results show that Foresee is both more effective and more efficient than the baselines. Foresee exposes 128.70% and 38.09% more failures than a random approach and a state-of-the-art failure predictor while being 2.49x and 1.42x faster, respectively. Moreover, when used in combination with DriveFuzz, Foresee enhances failure detection by up to 93.94%.","authors":["M M Abid Naziri","Stefano Carlo Lambertenghi","Andrea Stocco","Marcelo d'Amorim"],"pdf_url":"","comment":"In proceedings of the 51th IEEE/ACM International Conference on Software Engineering (ICSE '26)"},{"id":"http://arxiv.org/abs/2512.18748v1","updated":"2025-12-21T14:28:51Z","published":"2025-12-21T14:28:51Z","title":"Code2Doc: A Quality-First Curated Dataset for Code Documentation","summary":"The performance of automatic code documentation generation models depends critically on the quality of the training data used for supervision. However, most existing code documentation datasets are constructed through large scale scraping of public repositories with limited quality control. As a result, they often contain noisy documentation, extensive duplication, and increasing contamination from AI generated content. These issues weaken the supervision signal available to learning-based models and complicate evaluation.\n  We introduce \\textbf{Code2Doc}, a quality-first curated dataset for function-level code documentation generation. Code2Doc consists of 13,358 high-quality function-documentation pairs extracted from widely used open-source repositories spanning five programming languages: Python, Java, TypeScript, JavaScript, and C++. The dataset is constructed using a four-stage curation pipeline that enforces documentation completeness and clarity, filters functions based on structural and complexity criteria, removes exact and near-duplicate code, and identifies documentation likely to be AI generated. Starting from 52,069 extracted candidates, only 25.6 percent satisfy all quality constraints.\n  We provide a detailed analysis of the resulting dataset, which achieves a mean documentation quality score of 6.93 out of 10. Overall, 86.9% of samples contain explicit type annotations, and only 2.9\\% are flagged as potentially AI generated. Baseline experiments show that fine-tuning a large language model on Code2Doc yields relative improvements of 29.47% in BLEU and 24.04% in ROUGE-L over zero shot performance, despite the modest dataset size. We release both the dataset and the full curation pipeline to support reproducible research on automatic code documentation generation.","authors":["Recep Kaan Karaman","Meftun Akarsu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18682v1","updated":"2025-12-21T10:40:36Z","published":"2025-12-21T10:40:36Z","title":"Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design","summary":"In the high-cost simulation-driven design domain, translating ambiguous design requirements into a mathematical optimization formulation is a bottleneck for optimizing product performance. This process is time-consuming and heavily reliant on expert knowledge. While large language models (LLMs) offer potential for automating this task, existing approaches either suffer from poor formalization that fails to accurately align with the design intent or rely on solver feedback for data filtering, which is unavailable due to the high simulation costs. To address this challenge, we propose APF, a framework for solver-independent, automated problem formulation via LLMs designed to automatically convert engineers' natural language requirements into executable optimization models. The core of this framework is an innovative pipeline for automatically generating high-quality data, which overcomes the difficulty of constructing suitable fine-tuning datasets in the absence of high-cost solver feedback with the help of data generation and test instance annotation. The generated high-quality dataset is used to perform supervised fine-tuning on LLMs, significantly enhancing their ability to generate accurate and executable optimization problem formulations. Experimental results on antenna design demonstrate that APF significantly outperforms the existing methods in both the accuracy of requirement formalization and the quality of resulting radiation efficiency curves in meeting the design goals.","authors":["Yuchen Li","Handing Wang","Bing Xue","Mengjie Zhang","Yaochu Jin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18667v1","updated":"2025-12-21T09:52:36Z","published":"2025-12-21T09:52:36Z","title":"Toward Live Noise Fingerprinting in Quantum Software Engineering","summary":"Noise is a major bottleneck in today's quantum computing, stemming from decoherence, gate imperfections and other hardware limitations. Accurate noise fingerprints are essential, yet undocumented noise model differences between Quantum Ecosystems undermine core functionality, such as compilation, development and debugging, offering limited transferability and support for quantum software engineering (QSE) tasks. We propose a new research direction: live empirical noise fingerprinting as a lightweight QSE-oriented \"noise fingerprinting\". Though explored in physics as device-level diagnostics, we reposition them as a QSE paradigm: we propose leveraging classical shadow tomography to enable a new generation of techniques. As a first step, we introduce SimShadow, which prepares reference states, applies shadow-tomography-inspired estimation and constructs deviation fingerprints. Initial experiments uncover systematic discrepancies between platforms (e.g. Frobenius distances up to 7.39) at up to 2.5x10^6 lower cost than traditional methods. SimShadow opens new directions for noise-aware compilation, transpilation, cross-platform validation, error mitigation, and formal methods in QSE.","authors":["Avner Bensoussan","Elena Chachkarova","Karine Even-Mendoza","Sophie Fortz","Vasileios Klimis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2401.16310v5","updated":"2025-12-21T04:06:20Z","published":"2024-01-29T17:13:44Z","title":"An Insight into Security Code Review with LLMs: Capabilities, Obstacles, and Influential Factors","summary":"Security code review is a time-consuming and labor-intensive process typically requiring integration with automated security defect detection tools. However, existing security analysis tools struggle with poor generalization, high false positive rates, and coarse detection granularity. Large Language Models (LLMs) have been considered promising candidates for addressing those challenges. In this study, we conducted an empirical study to explore the potential of LLMs in detecting security defects during code review. Specifically, we evaluated the performance of seven LLMs under five different prompts and compared them with state-of-the-art static analysis tools. We also performed linguistic and regression analyses for the two top-performing LLMs to identify quality problems in their responses and factors influencing their performance. Our findings show that: (1) In security code review, LLMs significantly outperform state-of-the-art static analysis tools, and the reasoning-optimized LLM performs better than general-purpose LLMs. (2) DeepSeek-R1 achieves the highest performance, followed by GPT-4. The optimal prompt for DeepSeek-R1 incorporates both the commit message and chain-of-thought (CoT) guidance, while for GPT-4, the prompt with a Common Weakness Enumeration (CWE) list works best. (3) GPT-4 frequently produces vague expressions and exhibits difficulties in accurately following instructions in the prompts, while DeepSeek-R1 more commonly generates inaccurate code details in its outputs. (4) LLMs are more adept at identifying security defects in code files that have fewer tokens and security-relevant annotations.","authors":["Jiaxin Yu","Peng Liang","Yujia Fu","Amjed Tahir","Mojtaba Shahin","Chong Wang","Yangxiao Cai"],"pdf_url":"","comment":"27 pages, 10 images, 8 tables, Manuscript revision submitted to a journal (2025)"},{"id":"http://arxiv.org/abs/2512.18567v1","updated":"2025-12-21T02:26:29Z","published":"2025-12-21T02:26:29Z","title":"AI Code in the Wild: Measuring Security Risks and Ecosystem Shifts of AI-Generated Code in Modern Software","summary":"Large language models (LLMs) for code generation are becoming integral to modern software development, but their real-world prevalence and security impact remain poorly understood.\n  We present the first large-scale empirical study of AI-generated code (AIGCode) in the wild. We build a high-precision detection pipeline and a representative benchmark to distinguish AIGCode from human-written code, and apply them to (i) development commits from the top 1,000 GitHub repositories (2022-2025) and (ii) 7,000+ recent CVE-linked code changes. This lets us label commits, files, and functions along a human/AI axis and trace how AIGCode moves through projects and vulnerability life cycles.\n  Our measurements show three ecological patterns. First, AIGCode is already a substantial fraction of new code, but adoption is structured: AI concentrates in glue code, tests, refactoring, documentation, and other boilerplate, while core logic and security-critical configurations remain mostly human-written. Second, adoption has security consequences: some CWE families are overrepresented in AI-tagged code, and near-identical insecure templates recur across unrelated projects, suggesting \"AI-induced vulnerabilities\" propagated by shared models rather than shared maintainers. Third, in human-AI edit chains, AI introduces high-throughput changes while humans act as security gatekeepers; when review is shallow, AI-introduced defects persist longer, remain exposed on network-accessible surfaces, and spread to more files and repositories.\n  We will open-source the complete dataset and release analysis artifacts and fine-grained documentation of our methodology and findings.","authors":["Bin Wang","Wenjie Yu","Yilu Zhong","Hao Yu","Keke Lian","Chaohua Lu","Hongfang Zheng","Dong Zhang","Hui Li"],"pdf_url":"","comment":"https://mp.weixin.qq.com/s/sI_LKPnA-BeCVYr9Ko4sqg https://github.com/Narwhal-Lab/aicode-in-the-wild-security-risk-report"},{"id":"http://arxiv.org/abs/2512.18552v1","updated":"2025-12-21T00:49:40Z","published":"2025-12-21T00:49:40Z","title":"Toward Training Superintelligent Software Agents through Self-Play SWE-RL","summary":"While current software agents powered by large language models (LLMs) and agentic reinforcement learning (RL) can boost programmer productivity, their training data (e.g., GitHub issues and pull requests) and environments (e.g., pass-to-pass and fail-to-pass tests) heavily depend on human knowledge or curation, posing a fundamental barrier to superintelligence. In this paper, we present Self-play SWE-RL (SSR), a first step toward training paradigms for superintelligent software agents. Our approach takes minimal data assumptions, only requiring access to sandboxed repositories with source code and installed dependencies, with no need for human-labeled issues or tests. Grounded in these real-world codebases, a single LLM agent is trained via reinforcement learning in a self-play setting to iteratively inject and repair software bugs of increasing complexity, with each bug formally specified by a test patch rather than a natural language issue description. On the SWE-bench Verified and SWE-Bench Pro benchmarks, SSR achieves notable self-improvement (+10.4 and +7.8 points, respectively) and consistently outperforms the human-data baseline over the entire training trajectory, despite being evaluated on natural language issues absent from self-play. Our results, albeit early, suggest a path where agents autonomously gather extensive learning experiences from real-world software repositories, ultimately enabling superintelligent systems that exceed human capabilities in understanding how systems are constructed, solving novel challenges, and autonomously creating new software from scratch.","authors":["Yuxiang Wei","Zhiqing Sun","Emily McMilin","Jonas Gehring","David Zhang","Gabriel Synnaeve","Daniel Fried","Lingming Zhang","Sida Wang"],"pdf_url":"","comment":null}],"Programming Languages":[{"id":"http://arxiv.org/abs/2512.18842v1","updated":"2025-12-21T18:16:47Z","published":"2025-12-21T18:16:47Z","title":"DafnyMPI: A Dafny Library for Verifying Message-Passing Concurrent Programs","summary":"The Message Passing Interface (MPI) is widely used in parallel, high-performance programming, yet writing bug-free software that uses MPI remains difficult. We introduce DafnyMPI, a novel, scalable approach to formally verifying MPI software. DafnyMPI allows proving deadlock freedom, termination, and functional equivalence with simpler sequential implementations. In contrast to existing specialized frameworks, DafnyMPI avoids custom concurrency logics and instead relies on Dafny, a verification-ready programming language used for sequential programs, extending it with concurrent reasoning abilities. DafnyMPI is implemented as a library that enables safe MPI programming by requiring users to specify the communication topology upfront and to verify that calls to communication primitives such as MPI_ISEND and MPI_WAIT meet their preconditions. We formalize DafnyMPI using a core calculus and prove that the preconditions suffice to guarantee deadlock freedom. Functional equivalence is proved via rely-guarantee reasoning over message payloads and a system that guarantees safe use of read and write buffers. Termination and the absence of runtime errors are proved using standard Dafny techniques. To further demonstrate the applicability of DafnyMPI, we verify numerical solutions to three canonical partial differential equations. We believe DafnyMPI demonstrates how to make formal verification viable for a broader class of programs and provides proof engineers with additional tools for software verification of parallel and concurrent systems.","authors":["Aleksandr Fedchin","Antero Mejr","Hari Sundar","Jeffrey S. Foster"],"pdf_url":"","comment":"To appear in Proceedings of the ACM on Programming Languages (POPL)"},{"id":"http://arxiv.org/abs/2111.13384v8","updated":"2025-12-21T02:26:57Z","published":"2021-11-26T09:42:45Z","title":"$\\varphi$-Calculus: Object-Oriented Formalism","summary":"Object-oriented programming (OOP) is one of the most popular paradigms used for building software systems. However, despite its industrial and academic popularity, OOP is still missing a formal apparatus similar to \\(λ\\)-calculus, which functional programming is based on. A number of attempts were made to formalize OOP, but none of them managed to cover all the features available in modern OO programming languages, such as C++ or Java. We have made yet another attempt and created \\(\\varphi\\)-calculus. This paper does not demonstrate the practical use or effect of \\\\(varphi\\) but merely explains it.","authors":["Yegor Bugayenko","Maxim Trunnikov"],"pdf_url":"","comment":null}]},"2025-12-20T00:00:00Z":{"Distributed, Parallel, and Cluster Computing":[{"id":"http://arxiv.org/abs/2512.18444v1","updated":"2025-12-20T17:31:55Z","published":"2025-12-20T17:31:55Z","title":"Snowveil: A Framework for Decentralised Preference Discovery","summary":"Aggregating subjective preferences of a large group is a fundamental challenge in computational social choice, traditionally reliant on central authorities. To address the limitations of this model, this paper introduces Decentralised Preference Discovery (DPD), the problem of determining the collective will of an electorate under constraints of censorship resistance, partial information, and asynchronous communication. We propose Snowveil, a novel framework for this task. Snowveil uses an iterative, gossip-based protocol where voters repeatedly sample the preferences of a small, random subset of the electorate to progressively converge on a collective outcome. We demonstrate the framework's modularity by designing the Constrained Hybrid Borda (CHB), a novel aggregation rule engineered to balance broad consensus with strong plurality support, and provide a rigorous axiomatic analysis of its properties. By applying a potential function and submartingale theory, we develop a multi-level analytical method to show that the system almost surely converges to a stable, single-winner in finite time, a process that can then be iterated to construct a set of winning candidates for multi-winner scenarios. This technique is largely agnostic to the specific aggregation rule, requiring only that it satisfies core social choice axioms like Positive Responsiveness, thus offering a formal toolkit for a wider class of DPD protocols. Furthermore, we present a comprehensive empirical analysis through extensive simulation, validating Snowveil's $O(n)$ scalability. Overall, this work advances the understanding of how a stable consensus can emerge from subjective, complex, and diverse preferences in decentralised systems for large electorates.","authors":["Grammateia Kotsialou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.11068v2","updated":"2025-12-20T13:52:49Z","published":"2024-09-17T10:49:45Z","title":"A Reinforcement Learning Environment for Automatic Code Optimization in the MLIR Compiler","summary":"Code optimization is a crucial task that aims to enhance code performance. However, this process is often tedious and complex, highlighting the necessity for automatic code optimization techniques. Reinforcement Learning (RL) has emerged as a promising approach for tackling such complex optimization problems. In this project, we introduce MLIR RL, an RL environment for the MLIR compiler, dedicated to facilitating MLIR compiler research and enabling automatic code optimization. We propose a multi-discrete formulation of the action space where the action space is the Cartesian product of simpler action subspaces. We also propose a new method, called level pointers, to reduce the size of the action space related to the loop interchange transformation. This enables more efficient and effective learning of the policy. To demonstrate the effectiveness of MLIR RL, we train an RL agent to optimize MLIR Linalg code, targeting CPU. The code is generated from two domain-specific frameworks: deep-learning models generated from PyTorch, and LQCD (Lattice Quantum Chromodynamics) code generated from an LQCD compiler. The result of this work is a research environment that allows the community to experiment with novel ideas in RL-driven loop-nest optimization.","authors":["Mohammed Tirichine","Nassim Ameur","Nazim Bendib","Iheb Nassim Aouadj","Bouchama Djad","Rafik Bouloudene","Riyadh Baghdadi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18334v1","updated":"2025-12-20T11:58:55Z","published":"2025-12-20T11:58:55Z","title":"Faster Vertex Cover Algorithms on GPUs with Component-Aware Parallel Branching","summary":"Algorithms for finding minimum or bounded vertex covers in graphs use a branch-and-reduce strategy, which involves exploring a highly imbalanced search tree. Prior GPU solutions assign different thread blocks to different sub-trees, while using a shared worklist to balance the load. However, these prior solutions do not scale to large and complex graphs because their unawareness of when the graph splits into components causes them to solve these components redundantly. Moreover, their high memory footprint limits the number of workers that can execute concurrently. We propose a novel GPU solution for vertex cover problems that detects when a graph splits into components and branches on the components independently. Although the need to aggregate the solutions of different components introduces non-tail-recursive branches which interfere with load balancing, we overcome this challenge by delegating the post-processing to the last descendant of each branch. We also reduce the memory footprint by reducing the graph and inducing a subgraph before exploring the search tree. Our solution substantially outperforms the state-of-the-art GPU solution, finishing in seconds when the state-of-the-art solution exceeds 6 hours. To the best of our knowledge, our work is the first to parallelize non-tail-recursive branching patterns on GPUs in a load balanced manner.","authors":["Hussein Amro","Basel Fakhri","Amer E. Mouawad","Izzat El Hajj"],"pdf_url":"","comment":"to be published in IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS 2025. 14 pages, 4 figures, 6 tables"},{"id":"http://arxiv.org/abs/2512.18318v1","updated":"2025-12-20T11:23:18Z","published":"2025-12-20T11:23:18Z","title":"Asynchronous Pipeline Parallelism for Real-Time Multilingual Lip Synchronization in Video Communication Systems","summary":"This paper introduces a parallel and asynchronous Transformer framework designed for efficient and accurate multilingual lip synchronization in real-time video conferencing systems. The proposed architecture integrates translation, speech processing, and lip-synchronization modules within a pipeline-parallel design that enables concurrent module execution through message-queue-based decoupling, reducing end-to-end latency by up to 3.1 times compared to sequential approaches. To enhance computational efficiency and throughput, the inference workflow of each module is optimized through low-level graph compilation, mixed-precision quantization, and hardware-accelerated kernel fusion. These optimizations provide substantial gains in efficiency while preserving model accuracy and visual quality. In addition, a context-adaptive silence-detection component segments the input speech stream at semantically coherent boundaries, improving translation consistency and temporal alignment across languages. Experimental results demonstrate that the proposed parallel architecture outperforms conventional sequential pipelines in processing speed, synchronization stability, and resource utilization. The modular, message-oriented design makes this work applicable to resource-constrained IoT communication scenarios including telemedicine, multilingual kiosks, and remote assistance systems. Overall, this work advances the development of low-latency, resource-efficient multimodal communication frameworks for next-generation AIoT systems.","authors":["Eren Caglar","Amirkia Rafiei Oskooei","Mehmet Kutanoglu","Mustafa Keles","Mehmet S. Aktas"],"pdf_url":"","comment":"Accepted to IEEE Big Data 2025, AIDE4IoT Workshop. Copyright \\c{opyright} 2025 IEEE"},{"id":"http://arxiv.org/abs/2407.08651v2","updated":"2025-12-20T10:26:14Z","published":"2024-07-09T15:14:44Z","title":"SpiralShard: Highly Concurrent and Secure Blockchain Sharding via Linked Cross-shard Endorsement","summary":"Blockchain sharding improves the scalability of blockchain systems by partitioning the whole blockchain state, nodes, and transaction workloads into different shards. However, existing blockchain sharding systems generally suffer from a small number of shards, resulting in limited concurrency. The main reason is that existing sharding systems require large shard sizes to ensure security.\n  To enhance the concurrency of blockchain sharding securely, we propose SpiralShard. The intuition is to allow the existence of some shards with a larger fraction of malicious nodes (i.e., corrupted shards), thus reducing shard sizes. SpiralShard can configure more and smaller shards for higher concurrency at the same network size. To ensure security with the existence of corrupted shards, we propose the Linked Cross-shard Endorsement (LCE) protocol. According to our LCE protocol, the blocks of each shard are sequentially verified and endorsed (via intra-shard consensus) by a group of shards before being finalized. As a result, a corrupted shard can eliminate forks with the help of the other shards. We implement SpiralShard based on Harmony and conduct extensive evaluations. Experimental results show that, compared with Harmony, SpiralShard achieves around 19x throughput gain under a large network size with 4,000+ nodes.","authors":["You Lin","Mingzhe Li","Jin Zhang"],"pdf_url":"","comment":"Accepted to IEEE/ACM Transactions on Networking"},{"id":"http://arxiv.org/abs/2407.06882v2","updated":"2025-12-20T10:16:12Z","published":"2024-07-09T14:10:47Z","title":"StableShard: Stable and Scalable Blockchain Sharding with High Concurrency via Collaborative Committees","summary":"Sharding enhances blockchain scalability by partitioning nodes into multiple groups for concurrent transaction processing. Configuring a large number of small shards usually helps improve transaction concurrency, but it also increases the fraction of malicious nodes in each shard, easily causing shard corruption and jeopardizing system security. Existing works attempt to improve concurrency by reducing shard sizes while maintaining security, but typically rely on time-consuming recovery of corrupted shards to restore liveness and network-wide consensus. This causes severe system stagnation and limits scalability.\n  To address this, we present StableShard, a sharded blockchain that securely provides high concurrency with stable and scalable performance. The core idea is to carefully co-design the division of labor between proposer shards (PSs) and finalizer committees (FCs): we deliberately assign 1) asymmetric roles and 2) matching parameters to PSs and FCs. Small PSs focus on fast transaction proposal and local validity, while large FCs focus on resolving forks, finalizing PS blocks, and maintaining liveness for faulty PSs via a cross-layer view-change protocol. Moreover, by fine-tuning key system parameters (e.g., shard size, quorum size), we ensure each PS to tolerate <1/2 fraction of malicious nodes without lossing liveness, and allow multiple FCs to securely coexist (each with <1/3 fraction of malicious nodes) for better scalability. Consequently, StableShard can safely configure many smaller PSs to boost concurrency, while FCs and PSs jointly guarantee safety and liveness without system stagnation, leading to stable and scalable performance. Evaluations show that StableShard achieves up to 10x higher throughput than existing solutions and significantly more stable concurrency under attacks.","authors":["Mingzhe Li","You Lin","Jin Zhang"],"pdf_url":"","comment":"In Submission"},{"id":"http://arxiv.org/abs/2510.02930v2","updated":"2025-12-20T03:46:56Z","published":"2025-10-03T12:10:56Z","title":"iDDS: Intelligent Distributed Dispatch and Scheduling for Workflow Orchestration","summary":"The intelligent Distributed Dispatch and Scheduling (iDDS) service is a versatile workflow orchestration system designed for large-scale, distributed scientific computing. iDDS extends traditional workload and data management by integrating data-aware execution, conditional logic, and programmable workflows, enabling automation of complex and dynamic processing pipelines. Originally developed for the ATLAS experiment at the Large Hadron Collider, iDDS has evolved into an experiment-agnostic platform that supports both template-driven workflows and a Function-as-a-Task model for Python-based orchestration.\n  This paper presents the architecture and core components of iDDS, highlighting its scalability, modular message-driven design, and integration with systems such as PanDA and Rucio. We demonstrate its versatility through real-world use cases: fine-grained tape resource optimization for ATLAS, orchestration of large Directed Acyclic Graph (DAG) workflows for the Rubin Observatory, distributed hyperparameter optimization for machine learning applications, active learning for physics analyses, and AI-assisted detector design at the Electron-Ion Collider.\n  By unifying workload scheduling, data movement, and adaptive decision-making, iDDS reduces operational overhead and enables reproducible, high-throughput workflows across heterogeneous infrastructures. We conclude with current challenges and future directions, including interactive, cloud-native, and serverless workflow support.","authors":["Wen Guan","Tadashi Maeno","Aleksandr Alekseev","Fernando Harald Barreiro Megino","Kaushik De","Edward Karavakis","Alexei Klimentov","Tatiana Korchuganova","FaHui Lin","Paul Nilsson","Torre Wenaus","Zhaoyu Yang","Xin Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18194v1","updated":"2025-12-20T03:42:19Z","published":"2025-12-20T03:42:19Z","title":"TraCT: Disaggregated LLM Serving with CXL Shared Memory KV Cache at Rack-Scale","summary":"Disaggregated LLM serving improves resource efficiency by separating the compute-intensive prefill phase from the latency-critical decode phase. However, this architecture introduces a fundamental bottleneck: key/value (KV) tensors generated during prefill must be transferred to decode workers, and existing systems rely on RDMA-based network paths for this exchange. As model sizes and context lengths increase, KV transfer dominates both time-to-first-token (TTFT) and peak throughput, and remains highly sensitive to network contention even when prefix reuse is high. This paper presents TraCT, a rack-scale LLM serving system that uses CXL shared memory as both a KV-transfer substrate and a rack-wide prefix-aware KV cache. TraCT enables GPUs to write and read KV blocks directly through CXL load/store and DMA operations, eliminating the NIC hop that constrains existing disaggregated pipelines. However, to realize this design, multiple new challenges such as synchronization, consistency, and data management on non-coherent CXL memory need to be addressed. TraCT proposes various software solutions such as the two-tier inter-node synchronization mechanism to address these challenges. We implement TraCT on the Dynamo LLM inference framework and show that, across static and synthetic workloads, TraCT reduces average TTFT by up to 9.8x, lowers P99 latency by up to 6.2x, and improves peak throughput by up to 1.6x compared to RDMA and DRAM-based caching baselines.","authors":["Dongha Yoon","Younghoon Min","Hoshik Kim","Sam H. Noh","Jongryool Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.00138v2","updated":"2025-12-20T02:03:05Z","published":"2025-01-31T19:43:48Z","title":"JustAct+: A Framework for Auditable Multi-Agent Systems Regulated by Inter-Organisational Policies","summary":"In open multi-agent agent systems that cross organisational boundaries, agent actions must be regulated by complex policies. Consider medical data processing systems, which must observe generic laws (e.g., EU data protection regulations) and also specific participants' resource conditions (e.g., Bob consents to sharing his X-Rays with EU hospitals). Presently, we address the implementation of these systems as distributed software. Solutions to key sub-problems are available: existing policy languages capture the necessary normative concepts and formalise the computational representation and reasoning about policies, and existing distributed algorithms and protocols coordinate agents' changing actions and policies. But which policies and protocols are useful in application? With the JustAct framework, we characterise a class of multi-agent systems where actors justify their actions with sufficient policy information collected from dynamic policy statements and agreements. We prove key properties of these systems, e.g., any decision that an action is permitted now cannot be refuted later, regardless of any added statements or updated agreements. We study a particular instance of the framework by specifying (in Rocq) and implementing (in Rust) a particular policy language and runtime system for mediating agent communications. We demonstrate and assess JustAct via a case study of this implementation: we reproduce the usage scenarios of Brane, an existing policy-regulated, inter-domain, medical data processing system.","authors":["Christopher A. Esterhuyse","Tim Müller","L. Thomas van Binsbergen"],"pdf_url":"","comment":null}],"Computation and Language":[{"id":"http://arxiv.org/abs/2512.18542v1","updated":"2025-12-20T23:52:12Z","published":"2025-12-20T23:52:12Z","title":"SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models","summary":"AI assistants produce vulnerable code in 45% of security-relevant scenarios, introducing flaws into production systems at scale. Yet existing secure coding datasets fall short. They lack incident grounding, don't provide the scale modern training requires, and miss the operational security context developers need for production deployments. We present SecureCode v2.0, a production-grade dataset of 1,215 security-focused coding examples that passed structural validation and expert security review. Every example ties to actual documented security incidents with CVE references, provides vulnerable and secure implementations, demonstrates concrete attacks, and includes defense-in-depth operational guidance. The dataset covers 11 vulnerability categories (complete OWASP Top 10:2025 plus AI/ML Security Threats) across 11 languages (Python, JavaScript, Java, Go, PHP, C#, TypeScript, Ruby, Rust, Kotlin, and YAML for infrastructure-as-code).\n  Our quality assurance framework ensures complete incident grounding. Each example includes SIEM integration strategies, infrastructure hardening recommendations (Docker, AppArmor, WAF configurations), and testing approaches using language-appropriate frameworks. The dataset uses a 4-turn conversational structure mirroring actual developer-AI interactions, escalating from basic implementations to advanced security considerations and defense-in-depth guidance.\n  Our contributions: (1) 1,215 rigorously validated examples split into 989 training, 122 validation, and 104 test sets, (2) an automated validation framework ensuring dataset consistency, (3) a 4-turn conversational structure capturing realistic security workflows, (4) comprehensive operational security guidance with SIEM integration strategies, (5) complete language-specific implementation fidelity, and (6) open-source release of data, validation tools, and benchmarking protocols.","authors":["Scott Thornton"],"pdf_url":"","comment":"37 pages, 5 figures. Dataset available at https://huggingface.co/datasets/scthornton/securecode-v2. Code and validation tools at https://github.com/scthornton/securecode-v2"},{"id":"http://arxiv.org/abs/2512.18533v1","updated":"2025-12-20T23:08:18Z","published":"2025-12-20T23:08:18Z","title":"Generalization Gaps in Political Fake News Detection: An Empirical Study on the LIAR Dataset","summary":"The proliferation of linguistically subtle political disinformation poses a significant challenge to automated fact-checking systems. Despite increasing emphasis on complex neural architectures, the empirical limits of text-only linguistic modeling remain underexplored. We present a systematic diagnostic evaluation of nine machine learning algorithms on the LIAR benchmark. By isolating lexical features (Bag-of-Words, TF-IDF) and semantic embeddings (GloVe), we uncover a hard \"Performance Ceiling\", with fine-grained classification not exceeding a Weighted F1-score of 0.32 across models. Crucially, a simple linear SVM (Accuracy: 0.624) matches the performance of pre-trained Transformers such as RoBERTa (Accuracy: 0.620), suggesting that model capacity is not the primary bottleneck. We further diagnose a massive \"Generalization Gap\" in tree-based ensembles, which achieve more than 99% training accuracy but collapse to approximately 25% on test data, indicating reliance on lexical memorization rather than semantic inference. Synthetic data augmentation via SMOTE yields no meaningful gains, confirming that the limitation is semantic (feature ambiguity) rather than distributional. These findings indicate that for political fact-checking, increasing model complexity without incorporating external knowledge yields diminishing returns.","authors":["S Mahmudul Hasan","Shaily Roy","Akib Jawad Nafis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.06737v2","updated":"2025-12-20T21:12:56Z","published":"2025-12-07T09:03:45Z","title":"Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics","summary":"The paper presents the formulation, implementation, and evaluation of the ArcGD optimiser. The evaluation is conducted initially on a non-convex benchmark function and subsequently on a real-world ML dataset. The initial comparative study using the Adam optimiser is conducted on a stochastic variant of the highly non-convex and notoriously challenging Rosenbrock function, renowned for its narrow, curved valley, across dimensions ranging from 2D to 1000D and an extreme case of 50,000D. Two configurations were evaluated to eliminate learning-rate bias: (i) both using ArcGD's effective learning rate and (ii) both using Adam's default learning rate. ArcGD consistently outperformed Adam under the first setting and, although slower under the second, achieved superior final solutions in most cases. In the second evaluation, ArcGD is evaluated against state-of-the-art optimizers (Adam, AdamW, Lion, SGD) on the CIFAR-10 image classification dataset across 8 diverse MLP architectures ranging from 1 to 5 hidden layers. ArcGD achieved the highest average test accuracy (50.7%) at 20,000 iterations, outperforming AdamW (46.6%), Adam (46.8%), SGD (49.6%), and Lion (43.4%), winning or tying on 6 of 8 architectures. Notably, while Adam and AdamW showed strong early convergence at 5,000 iterations, but regressed with extended training, whereas ArcGD continued improving, demonstrating generalization and resistance to overfitting without requiring early stopping tuning. Strong performance on geometric stress tests and standard deep-learning benchmarks indicates broad applicability, highlighting the need for further exploration. Moreover, it is also shown that a limiting variant of ArcGD can be interpreted as a sign-based momentum-like update, highlighting conceptual connections between the inherent mechanisms of ArcGD and the Lion optimiser.","authors":["Nikhil Verma","Joonas Linnosmaa","Leonardo Espinosa-Leal","Napat Vajragupta"],"pdf_url":"","comment":"80 pages, 6 tables, 2 figures, 5 appendices, proof-of-concept"},{"id":"http://arxiv.org/abs/2512.18505v1","updated":"2025-12-20T20:47:01Z","published":"2025-12-20T20:47:01Z","title":"Teaching and Critiquing Conceptualization and Operationalization in NLP","summary":"NLP researchers regularly invoke abstract concepts like \"interpretability,\" \"bias,\" \"reasoning,\" and \"stereotypes,\" without defining them. Each subfield has a shared understanding or conceptualization of what these terms mean and how we should treat them, and this shared understanding is the basis on which operational decisions are made: Datasets are built to evaluate these concepts, metrics are proposed to quantify them, and claims are made about systems. But what do they mean, what should they mean, and how should we measure them? I outline a seminar I created for students to explore these questions of conceptualization and operationalization, with an interdisciplinary reading list and an emphasis on discussion and critique.","authors":["Vagrant Gautam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18475v1","updated":"2025-12-20T19:38:07Z","published":"2025-12-20T19:38:07Z","title":"Research on a hybrid LSTM-CNN-Attention model for text-based web content classification","summary":"This study presents a hybrid deep learning architecture that integrates LSTM, CNN, and an Attention mechanism to enhance the classification of web content based on text. Pretrained GloVe embeddings are used to represent words as dense vectors that preserve semantic similarity. The CNN layer extracts local n-gram patterns and lexical features, while the LSTM layer models long-range dependencies and sequential structure. The integrated Attention mechanism enables the model to focus selectively on the most informative parts of the input sequence. A 5-fold cross-validation setup was used to assess the robustness and generalizability of the proposed solution. Experimental results show that the hybrid LSTM-CNN-Attention model achieved outstanding performance, with an accuracy of 0.98, precision of 0.94, recall of 0.92, and F1-score of 0.93. These results surpass the performance of baseline models based solely on CNNs, LSTMs, or transformer-based classifiers such as BERT. The combination of neural network components enabled the model to effectively capture both fine-grained text structures and broader semantic context. Furthermore, the use of GloVe embeddings provided an efficient and effective representation of textual data, making the model suitable for integration into systems with real-time or near-real-time requirements. The proposed hybrid architecture demonstrates high effectiveness in text-based web content classification, particularly in tasks requiring both syntactic feature extraction and semantic interpretation. By combining presented mechanisms, the model addresses the limitations of individual architectures and achieves improved generalization. These findings support the broader use of hybrid deep learning approaches in NLP applications, especially where complex, unstructured textual data must be processed and classified with high reliability.","authors":["Mykola Kuz","Ihor Lazarovych","Mykola Kozlenko","Mykola Pikuliak","Andrii Kvasniuk"],"pdf_url":"","comment":"10 pages, 5 figures, 2 tables. Accepted by Radio Electronics Computer Science Control 2025"},{"id":"http://arxiv.org/abs/2512.18462v1","updated":"2025-12-20T18:30:54Z","published":"2025-12-20T18:30:54Z","title":"Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling","summary":"Natural Language Inference (NLI) models frequently rely on spurious correlations rather than semantic reasoning. Existing mitigation strategies often incur high annotation costs or trigger catastrophic forgetting during fine-tuning. We propose an automated, scalable pipeline to address these limitations. First, we introduce Log-Frequency LMI (LF-LMI) to accurately detect semantic artifacts. Second, we generate a high-quality synthetic contrast set via an LLM-synthesis pipeline with multi-judge verification. Finally, we introduce Dynamic Balanced Sampling, a training strategy that rotates the original data distribution to prevent forgetting. Our method improves consistency on a challenging benchmark from 63.5% to 81.0% while maintaining 88.4% in-domain accuracy, significantly outperforming naive fine-tuning.","authors":["Christopher Román Jaimes"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17004v2","updated":"2025-12-20T18:28:12Z","published":"2025-11-21T07:14:46Z","title":"Vision Language Models are Confused Tourists","summary":"Although the cultural dimension has been one of the key aspects in evaluating Vision-Language Models (VLMs), their ability to remain stable across diverse cultural inputs remains largely untested, despite being crucial to support diversity and multicultural societies. Existing evaluations often rely on benchmarks featuring only a singular cultural concept per image, overlooking scenarios where multiple, potentially unrelated cultural cues coexist. To address this gap, we introduce ConfusedTourist, a novel cultural adversarial robustness suite designed to assess VLMs' stability against perturbed geographical cues. Our experiments reveal a critical vulnerability, where accuracy drops heavily under simple image-stacking perturbations and even worsens with its image-generation-based variant. Interpretability analyses further show that these failures stem from systematic attention shifts toward distracting cues, diverting the model from its intended focus. These findings highlight a critical challenge: visual cultural concept mixing can substantially impair even state-of-the-art VLMs, underscoring the urgent need for more culturally robust multimodal understanding.","authors":["Patrick Amadeus Irawan","Ikhlasul Akmal Hanif","Muhammad Dehan Al Kautsar","Genta Indra Winata","Fajri Koto","Alham Fikri Aji"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.05387v2","updated":"2025-12-20T17:46:25Z","published":"2025-12-05T02:59:43Z","title":"Learning from Self Critique and Refinement for Faithful LLM Summarization","summary":"Large Language Models (LLMs) often suffer from hallucinations: output content that is not grounded in the input context, when performing long-form text generation tasks such as summarization. Prior works have shown that hallucinations can be reduced by iteratively critiquing and refining previously generated outputs using either the same model or a more powerful teacher model as the critique. However, these approaches either require additional test-time compute or assume access to more powerful teacher models, making them costly and less practical. In this work, we propose Self Critique and Refinement-based Preference Optimization (SCRPO), which is a self-supervised training framework that first constructs a preference dataset by leveraging the LLM's own critique and refinement capabilities, and then applies preference learning to improve the same LLM for faithful summarization. Experiments on three summarization benchmarks (XSUM CNNDM and SAMSum), demonstrate that our approach outperforms state-of-the-art self-supervised learning methods in terms of faithfulness metrics while either maintaining or improving other metrics that measure the overall quality of the summary. Moreover, compared to test-time refinement, our approach not only improves efficiency but also results in more faithful summaries.","authors":["Ting-Yao Hu","Hema Swetha Koppula","Hadi Pouransari","Cem Koc","Oncel Tuzel","Raviteja Vemulapalli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18440v1","updated":"2025-12-20T17:26:39Z","published":"2025-12-20T17:26:39Z","title":"An Agentic AI Framework for Training General Practitioner Student Skills","summary":"Advancements in large language models offer strong potential for enhancing virtual simulated patients (VSPs) in medical education by providing scalable alternatives to resource-intensive traditional methods. However, current VSPs often struggle with medical accuracy, consistent roleplaying, scenario generation for VSP use, and educationally structured feedback. We introduce an agentic framework for training general practitioner student skills that unifies (i) configurable, evidence-based vignette generation, (ii) controlled persona-driven patient dialogue with optional retrieval grounding, and (iii) standards-based assessment and feedback for both communication and clinical reasoning. We instantiate the framework in an interactive spoken consultation setting and evaluate it with medical students ($\\mathbf{N{=}14}$). Participants reported realistic and vignette-faithful dialogue, appropriate difficulty calibration, a stable personality signal, and highly useful example-rich feedback, alongside excellent overall usability. These results support agentic separation of scenario control, interaction control, and standards-based assessment as a practical pattern for building dependable and pedagogically valuable VSP training tools.","authors":["Victor De Marez","Jens Van Nooten","Luna De Bruyne","Walter Daelemans"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18399v1","updated":"2025-12-20T15:32:10Z","published":"2025-12-20T15:32:10Z","title":"AraToken: Optimizing Arabic Tokenization with Normalization Pipeline and Language Extension for Qwen3","summary":"Tokenization is a critical preprocessing step for large language models (LLMs), directly impacting training efficiency and downstream performance. General-purpose tokenizers trained predominantly on English and Latin-script languages exhibit suboptimal performance on morphologically rich languages such as Arabic, resulting in inflated token sequences and reduced compression efficiency. In this work, we present AraToken, an Arabic-optimized tokenizer built on SentencePiece Unigram algorithm with a comprehensive normalization pipeline addressing Arabic-specific orthographic variations including Alif variants, diacritics, and Arabic-Indic numerals. We systematically compare BPE, WordPiece, and SentencePiece algorithms across multiple configurations, demonstrating that SentencePiece with normalization achieves 18% lower fertility (1.199 vs 1.35 tokens/word) compared to unnormalized baselines. Furthermore, we introduce the Language Extension Pipeline (LEP), a method for integrating the optimized tokenizer into Qwen3-0.6B through vocabulary extension with mean subtoken initialization and selective transformer layer unfreezing. Our experiments show that LEP reduces evaluation loss from 8.28 to 2.43 within 800 training steps on 100K Arabic samples. We release our tokenizer, training scripts, and model checkpoints to facilitate Arabic NLP research.","authors":["Mark Kashirskiy","Artiom Lipinski","Ilya Makarov"],"pdf_url":"","comment":"8 pages, 8 figures, 5 tables"},{"id":"http://arxiv.org/abs/2502.11361v5","updated":"2025-12-20T13:50:00Z","published":"2025-02-17T02:18:47Z","title":"VLDBench Evaluating Multimodal Disinformation with Regulatory Alignment","summary":"Detecting disinformation that blends manipulated text and images has become increasingly challenging, as AI tools make synthetic content easy to generate and disseminate. While most existing AI safety benchmarks focus on single modality misinformation (i.e., false content shared without intent to deceive), intentional multimodal disinformation, such as propaganda or conspiracy theories that imitate credible news, remains largely unaddressed. We introduce the Vision-Language Disinformation Detection Benchmark (VLDBench), the first large-scale resource supporting both unimodal (text-only) and multimodal (text + image) disinformation detection. VLDBench comprises approximately 62,000 labeled text-image pairs across 13 categories, curated from 58 news outlets. Using a semi-automated pipeline followed by expert review, 22 domain experts invested over 500 hours to produce high-quality annotations with substantial inter-annotator agreement. Evaluations of state-of-the-art Large Language Models (LLMs) and Vision-Language Models (VLMs) on VLDBench show that incorporating visual cues improves detection accuracy by 5 to 35 percentage points over text-only models. VLDBench provides data and code for evaluation, fine-tuning, and robustness testing to support disinformation analysis. Developed in alignment with AI governance frameworks (e.g., the MIT AI Risk Repository), VLDBench offers a principled foundation for advancing trustworthy disinformation detection in multimodal media.\n  Project: https://vectorinstitute.github.io/VLDBench/ Dataset: https://huggingface.co/datasets/vector-institute/VLDBench Code: https://github.com/VectorInstitute/VLDBench","authors":["Shaina Raza","Ashmal Vayani","Aditya Jain","Aravind Narayanan","Vahid Reza Khazaie","Syed Raza Bashir","Elham Dolatabadi","Gias Uddin","Christos Emmanouilidis","Rizwan Qureshi","Mubarak Shah"],"pdf_url":"","comment":"Accepted in Information Fusion Journal"},{"id":"http://arxiv.org/abs/2510.06445v2","updated":"2025-12-20T13:42:00Z","published":"2025-10-07T20:32:20Z","title":"A Survey on Agentic Security: Applications, Threats and Defenses","summary":"In this work we present the first holistic survey of the agentic security landscape, structuring the field around three fundamental pillars: Applications, Threats, and Defenses. We provide a comprehensive taxonomy of over 160 papers, explaining how agents are used in downstream cybersecurity applications, inherent threats to agentic systems, and countermeasures designed to protect them. A detailed cross-cutting analysis shows emerging trends in agent architecture while revealing critical research gaps in model and modality coverage. A complete and continuously updated list of all surveyed papers is publicly available at https://github.com/kagnlp/Awesome-Agentic-Security.","authors":["Asif Shahriar","Md Nafiu Rahman","Sadif Ahmed","Farig Sadeque","Md Rizwan Parvez"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18362v1","updated":"2025-12-20T13:24:59Z","published":"2025-12-20T13:24:59Z","title":"SRS-Stories: Vocabulary-constrained multilingual story generation for language learning","summary":"In this paper, we use large language models to generate personalized stories for language learners, using only the vocabulary they know. The generated texts are specifically written to teach the user new vocabulary by simply reading stories where it appears in context, while at the same time seamlessly reviewing recently learned vocabulary. The generated stories are enjoyable to read and the vocabulary reviewing/learning is optimized by a Spaced Repetition System. The experiments are conducted in three languages: English, Chinese and Polish, evaluating three story generation methods and three strategies for enforcing lexical constraints. The results show that the generated stories are more grammatical, coherent, and provide better examples of word usage than texts generated by the standard constrained beam search approach","authors":["Wiktor Kamzela","Mateusz Lango","Ondrej Dusek"],"pdf_url":"","comment":"EMNLP 2025"},{"id":"http://arxiv.org/abs/2512.18360v1","updated":"2025-12-20T13:16:51Z","published":"2025-12-20T13:16:51Z","title":"LLM Agents Implement an NLG System from Scratch: Building Interpretable Rule-Based RDF-to-Text Generators","summary":"We present a novel neurosymbolic framework for RDF-to-text generation, in which the model is \"trained\" through collaborative interactions among multiple LLM agents rather than traditional backpropagation. The LLM agents produce rule-based Python code for a generator for the given domain, based on RDF triples only, with no in-domain human reference texts. The resulting system is fully interpretable, requires no supervised training data, and generates text nearly instantaneously using only a single CPU. Our experiments on the WebNLG and OpenDialKG data show that outputs produced by our approach reduce hallucination, with only slight fluency penalties compared to finetuned or prompted language models","authors":["Mateusz Lango","Ondřej Dušek"],"pdf_url":"","comment":"EMNLP 2025"},{"id":"http://arxiv.org/abs/2510.22295v2","updated":"2025-12-20T13:08:30Z","published":"2025-10-25T13:38:20Z","title":"VietLyrics: A Large-Scale Dataset and Models for Vietnamese Automatic Lyrics Transcription","summary":"Automatic Lyrics Transcription (ALT) for Vietnamese music presents unique challenges due to its tonal complexity and dialectal variations, but remains largely unexplored due to the lack of a dedicated dataset. Therefore, we curated the first large-scale Vietnamese ALT dataset (VietLyrics), comprising 647 hours of songs with line-level aligned lyrics and metadata to address these issues. Our evaluation of current ASRbased approaches reveal significant limitations, including frequent transcription errors and hallucinations in non-vocal segments. To improve performance, we fine-tuned Whisper models on the VietLyrics dataset, achieving superior results compared to existing multilingual ALT systems, including LyricWhiz. We publicly release VietLyrics and our models, aiming to advance Vietnamese music computing research while demonstrating the potential of this approach for ALT in low-resource language and music.","authors":["Quoc Anh Nguyen","Bernard Cheng","Kelvin Soh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02366v2","updated":"2025-12-20T12:57:11Z","published":"2025-11-04T08:44:09Z","title":"LiveSecBench: A Dynamic and Event-Driven Safety Benchmark for Chinese Language Model Applications","summary":"We introduce LiveSecBench, a continuously updated safety benchmark specifically for Chinese-language LLM application scenarios. LiveSecBench constructs a high-quality and unique dataset through a pipeline that combines automated generation with human verification. By periodically releasing new versions to expand the dataset and update evaluation metrics, LiveSecBench provides a robust and up-to-date standard for AI safety. In this report, we introduce our second release v251215, which evaluates across five dimensions (Public Safety, Fairness & Bias, Privacy, Truthfulness, and Mental Health Safety.) We evaluate 57 representative LLMs using an ELO rating system, offering a leaderboard of the current state of Chinese LLM safety. The result is available at https://livesecbench.intokentech.cn/.","authors":["Yudong Li","Peiru Yang","Feng Huang","Zhongliang Yang","Kecheng Wang","Haitian Li","Baocheng Chen","Xingyu An","Ziyu Liu","Youdan Yang","Kejiang Chen","Sifang Wan","Xu Wang","Yufei Sun","Liyan Wu","Ruiqi Zhou","Wenya Wen","Xingchi Gu","Tianxin Zhang","Yue Gao","Yongfeng Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18357v1","updated":"2025-12-20T12:56:06Z","published":"2025-12-20T12:56:06Z","title":"DACE For Railway Acronym Disambiguation","summary":"Acronym Disambiguation (AD) is a fundamental challenge in technical text processing, particularly in specialized sectors where high ambiguity complicates automated analysis. This paper addresses AD within the context of the TextMine'26 competition on French railway documentation. We present DACE (Dynamic Prompting, Retrieval Augmented Generation, Contextual Selection, and Ensemble Aggregation), a framework that enhances Large Language Models through adaptive in-context learning and external domain knowledge injection. By dynamically tailoring prompts to acronym ambiguity and aggregating ensemble predictions, DACE mitigates hallucination and effectively handles low-resource scenarios. Our approach secured the top rank in the competition with an F1 score of 0.9069.","authors":["El Mokhtar Hribach","Oussama Mechhour","Mohammed Elmonstaser","Yassine El Boudouri","Othmane Kabal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18352v1","updated":"2025-12-20T12:42:27Z","published":"2025-12-20T12:42:27Z","title":"LLM-based Few-Shot Early Rumor Detection with Imitation Agent","summary":"Early Rumor Detection (EARD) aims to identify the earliest point at which a claim can be accurately classified based on a sequence of social media posts. This is especially challenging in data-scarce settings. While Large Language Models (LLMs) perform well in few-shot NLP tasks, they are not well-suited for time-series data and are computationally expensive for both training and inference. In this work, we propose a novel EARD framework that combines an autonomous agent and an LLM-based detection model, where the agent acts as a reliable decision-maker for \\textit{early time point determination}, while the LLM serves as a powerful \\textit{rumor detector}. This approach offers the first solution for few-shot EARD, necessitating only the training of a lightweight agent and allowing the LLM to remain training-free. Extensive experiments on four real-world datasets show our approach boosts performance across LLMs and surpasses existing EARD methods in accuracy and earliness.","authors":["Fengzhu Zeng","Qian Shao","Ling Cheng","Wei Gao","Shih-Fen Cheng","Jing Ma","Cheng Niu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18337v1","updated":"2025-12-20T12:06:13Z","published":"2025-12-20T12:06:13Z","title":"Towards Efficient Agents: A Co-Design of Inference Architecture and System","summary":"The rapid development of large language model (LLM)-based agents has unlocked new possibilities for autonomous multi-turn reasoning and tool-augmented decision-making. However, their real-world deployment is hindered by severe inefficiencies that arise not from isolated model inference, but from the systemic latency accumulated across reasoning loops, context growth, and heterogeneous tool interactions. This paper presents AgentInfer, a unified framework for end-to-end agent acceleration that bridges inference optimization and architectural design. We decompose the problem into four synergistic components: AgentCollab, a hierarchical dual-model reasoning framework that balances large- and small-model usage through dynamic role assignment; AgentSched, a cache-aware hybrid scheduler that minimizes latency under heterogeneous request patterns; AgentSAM, a suffix-automaton-based speculative decoding method that reuses multi-session semantic memory to achieve low-overhead inference acceleration; and AgentCompress, a semantic compression mechanism that asynchronously distills and reorganizes agent memory without disrupting ongoing reasoning. Together, these modules form a Self-Evolution Engine capable of sustaining efficiency and cognitive stability throughout long-horizon reasoning tasks. Experiments on the BrowseComp-zh and DeepDiver benchmarks demonstrate that through the synergistic collaboration of these methods, AgentInfer reduces ineffective token consumption by over 50%, achieving an overall 1.8-2.5 times speedup with preserved accuracy. These results underscore that optimizing for agentic task completion-rather than merely per-token throughput-is the key to building scalable, efficient, and self-improving intelligent systems.","authors":["Weizhe Lin","Hui-Ling Zhen","Shuai Yang","Xian Wang","Renxi Liu","Hanting Chen","Wangze Zhang","Chuansai Zhou","Yiming Li","Chen Chen","Xing Li","Zhiyuan Yang","Xiaosong Li","Xianzhi Yu","Zhenhua Dong","Mingxuan Yuan","Yunhe Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18329v1","updated":"2025-12-20T11:53:37Z","published":"2025-12-20T11:53:37Z","title":"LIR$^3$AG: A Lightweight Rerank Reasoning Strategy Framework for Retrieval-Augmented Generation","summary":"Retrieval-Augmented Generation (RAG) effectively enhances Large Language Models (LLMs) by incorporating retrieved external knowledge into the generation process. Reasoning models improve LLM performance in multi-hop QA tasks, which require integrating and reasoning over multiple pieces of evidence across different documents to answer a complex question. However, they often introduce substantial computational costs, including increased token consumption and inference latency. To better understand and mitigate this trade-off, we conduct a comprehensive study of reasoning strategies for reasoning models in RAG multi-hop QA tasks. Our findings reveal that reasoning models adopt structured strategies to integrate retrieved and internal knowledge, primarily following two modes: Context-Grounded Reasoning, which relies directly on retrieved content, and Knowledge-Reconciled Reasoning, which resolves conflicts or gaps using internal knowledge. To this end, we propose a novel Lightweight Rerank Reasoning Strategy Framework for RAG (LiR$^3$AG) to enable non-reasoning models to transfer reasoning strategies by restructuring retrieved evidence into coherent reasoning chains. LiR$^3$AG significantly reduce the average 98% output tokens overhead and 58.6% inferencing time while improving 8B non-reasoning model's F1 performance ranging from 6.2% to 22.5% to surpass the performance of 32B reasoning model in RAG, offering a practical and efficient path forward for RAG systems.","authors":["Guo Chen","Junjie Huang","Huaijin Xie","Fei Sun","Tao Jia"],"pdf_url":"","comment":"AAAI2026"},{"id":"http://arxiv.org/abs/2512.18321v1","updated":"2025-12-20T11:39:21Z","published":"2025-12-20T11:39:21Z","title":"CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher","summary":"Text understanding often suffers from domain shifts. To handle testing domains, domain adaptation (DA) is trained to adapt to a fixed and observed testing domain; a more challenging paradigm, test-time adaptation (TTA), cannot access the testing domain during training and online adapts to the testing samples during testing, where the samples are from a fixed domain. We aim to explore a more practical and underexplored scenario, continual test-time adaptation (CTTA) for text understanding, which involves a sequence of testing (unobserved) domains in testing. Current CTTA methods struggle in reducing error accumulation over domains and enhancing generalization to handle unobserved domains: 1) Noise-filtering reduces accumulated errors but discards useful information, and 2) accumulating historical domains enhances generalization, but it is hard to achieve adaptive accumulation. In this paper, we propose a CTTA-T (continual test-time adaptation for text understanding) framework adaptable to evolving target domains: it adopts a teacher-student framework, where the teacher is domain-aware and generalized for evolving domains. To improve teacher predictions, we propose a refine-then-filter based on dropout-driven consistency, which calibrates predictions and removes unreliable guidance. For the adaptation-generalization trade-off, we construct a domain-aware teacher by dynamically accumulating cross-domain semantics via incremental PCA, which continuously tracks domain shifts. Experiments show CTTA-T excels baselines.","authors":["Tianlun Liu","Zhiliang Tian","Zhen Huang","Xingzhi Zhou","Wanlong Yu","Tianle Liu","Feng Liu","Dongsheng Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.02152v2","updated":"2025-12-20T11:31:50Z","published":"2024-08-04T22:00:34Z","title":"Generative Retrieval with Few-shot Indexing","summary":"Existing generative retrieval (GR) methods rely on training-based indexing, which fine-tunes a model to memorise associations between queries and the document identifiers (docids) of relevant documents. Training-based indexing suffers from high training costs, under-utilisation of pre-trained knowledge in large language models (LLMs), and limited adaptability to dynamic document corpora. To address the issues, we propose a few-shot indexing-based GR framework (Few-Shot GR). It has a few-shot indexing process without any training, where we prompt an LLM to generate docids for all documents in a corpus, ultimately creating a docid bank for the entire corpus. During retrieval, we feed a query to the same LLM and constrain it to generate a docid within the docid bank created during indexing, and then map the generated docid back to its corresponding document. Moreover, we devise few-shot indexing with one-to-many mapping to further enhance Few-Shot GR. Experiments show that Few-Shot GR achieves superior performance to state-of-the-art GR methods requiring heavy training.","authors":["Arian Askari","Chuan Meng","Mohammad Aliannejadi","Zhaochun Ren","Evangelos Kanoulas","Suzan Verberne"],"pdf_url":"","comment":"Accepted for publication at the 48th European Conference on Information Retrieval (ECIR 2026)"},{"id":"http://arxiv.org/abs/2507.20423v3","updated":"2025-12-20T10:58:40Z","published":"2025-07-27T21:49:36Z","title":"CodeNER: Code Prompting for Named Entity Recognition","summary":"Recent studies have explored various approaches for treating candidate named entity spans as both source and target sequences in named entity recognition (NER) by leveraging large language models (LLMs). Although previous approaches have successfully generated candidate named entity spans with suitable labels, they rely solely on input context information when using LLMs, particularly, ChatGPT. However, NER inherently requires capturing detailed labeling requirements with input context information. To address this issue, we propose a novel method that leverages code-based prompting to improve the capabilities of LLMs in understanding and performing NER. By embedding code within prompts, we provide detailed BIO schema instructions for labeling, thereby exploiting the ability of LLMs to comprehend long-range scopes in programming languages. Experimental results demonstrate that the proposed code-based prompting method outperforms conventional text-based prompting on ten benchmarks across English, Arabic, Finnish, Danish, and German datasets, indicating the effectiveness of explicitly structuring NER instructions. We also verify that combining the proposed code-based prompting method with the chain-of-thought prompting further improves performance.","authors":["Sungwoo Han","Jingun Kwon","Hidetaka Kamigaito","Manabu Okumura"],"pdf_url":"","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2512.18301v1","updated":"2025-12-20T10:16:09Z","published":"2025-12-20T10:16:09Z","title":"InstructNet: A Novel Approach for Multi-Label Instruction Classification through Advanced Deep Learning","summary":"People use search engines for various topics and items, from daily essentials to more aspirational and specialized objects. Therefore, search engines have taken over as peoples preferred resource. The How To prefix has become familiar and widely used in various search styles to find solutions to particular problems. This search allows people to find sequential instructions by providing detailed guidelines to accomplish specific tasks. Categorizing instructional text is also essential for task-oriented learning and creating knowledge bases. This study uses the How To articles to determine the multi-label instruction category. We have brought this work with a dataset comprising 11,121 observations from wikiHow, where each record has multiple categories. To find out the multi-label category meticulously, we employ some transformer-based deep neural architectures, such as Generalized Autoregressive Pretraining for Language Understanding (XLNet), Bidirectional Encoder Representation from Transformers (BERT), etc. In our multi-label instruction classification process, we have reckoned our proposed architectures using accuracy and macro f1-score as the performance metrics. This thorough evaluation showed us much about our strategys strengths and drawbacks. Specifically, our implementation of the XLNet architecture has demonstrated unprecedented performance, achieving an accuracy of 97.30% and micro and macro average scores of 89.02% and 93%, a noteworthy accomplishment in multi-label classification. This high level of accuracy and macro average score is a testament to the effectiveness of the XLNet architecture in our proposed InstructNet approach. By employing a multi-level strategy in our evaluation process, we have gained a more comprehensive knowledge of the effectiveness of our proposed architectures and identified areas for forthcoming improvement and refinement.","authors":["Tanjim Taharat Aurpa","Md Shoaib Ahmed","Md Mahbubur Rahman","Md. Golam Moazzam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18298v1","updated":"2025-12-20T10:05:58Z","published":"2025-12-20T10:05:58Z","title":"Explainable Transformer-CNN Fusion for Noise-Robust Speech Emotion Recognition","summary":"Speech Emotion Recognition (SER) systems often degrade in performance when exposed to the unpredictable acoustic interference found in real-world environments. Additionally, the opacity of deep learning models hinders their adoption in trust-sensitive applications. To bridge this gap, we propose a Hybrid Transformer-CNN framework that unifies the contextual modeling of Wav2Vec 2.0 with the spectral stability of 1D-Convolutional Neural Networks. Our dual-stream architecture processes raw waveforms to capture long-range temporal dependencies while simultaneously extracting noise-resistant spectral features (MFCC, ZCR, RMSE) via a custom Attentive Temporal Pooling mechanism. We conducted extensive validation across four diverse benchmark datasets: RAVDESS, TESS, SAVEE, and CREMA-D. To rigorously test robustness, we subjected the model to non-stationary acoustic interference using real-world noise profiles from the SAS-KIIT dataset. The proposed framework demonstrates superior generalization and state-of-the-art accuracy across all datasets, significantly outperforming single-branch baselines under realistic environmental interference. Furthermore, we address the ``black-box\" problem by integrating SHAP and Score-CAM into the evaluation pipeline. These tools provide granular visual explanations, revealing how the model strategically shifts attention between temporal and spectral cues to maintain reliability in the presence of complex environmental noise.","authors":["Sudip Chakrabarty","Pappu Bishwas","Rajdeep Chatterjee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18292v1","updated":"2025-12-20T09:33:55Z","published":"2025-12-20T09:33:55Z","title":"Measuring Fine-Grained Negotiation Tactics of Humans and LLMs in Diplomacy","summary":"The study of negotiation styles dates back to Aristotle's ethos-pathos-logos rhetoric. Prior efforts primarily studied the success of negotiation agents. Here, we shift the focus towards the styles of negotiation strategies. Our focus is the strategic dialogue board game Diplomacy, which affords rich natural language negotiation and measures of game success. We used LLM-as-a-judge to annotate a large human-human set of Diplomacy games for fine-grained negotiation tactics from a sociologically-grounded taxonomy. Using a combination of the It Takes Two and WebDiplomacy datasets, we demonstrate the reliability of our LLM-as-a-Judge framework and show strong correlations between negotiation features and success in the Diplomacy setting. Lastly, we investigate the differences between LLM and human negotiation strategies and show that fine-tuning can steer LLM agents toward more human-like negotiation behaviors.","authors":["Wenkai Li","Lynnette Hui Xian Ng","Andy Liu","Daniel Fried"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18263v1","updated":"2025-12-20T08:03:07Z","published":"2025-12-20T08:03:07Z","title":"TICL+: A Case Study On Speech In-Context Learning for Children's Speech Recognition","summary":"Children's speech recognition remains challenging due to substantial acoustic and linguistic variability, limited labeled data, and significant differences from adult speech. Speech foundation models can address these challenges through Speech In-Context Learning (SICL), allowing adaptation to new domains without fine-tuning. However, the effectiveness of SICL depends on how in-context examples are selected. We extend an existing retrieval-based method, Text-Embedding KNN for SICL (TICL), introducing an acoustic reranking step to create TICL+. This extension prioritizes examples that are both semantically and acoustically aligned with the test input. Experiments on four children's speech corpora show that TICL+ achieves up to a 53.3% relative word error rate reduction over zero-shot performance and 37.6% over baseline TICL, highlighting the value of combining semantic and acoustic information for robust, scalable ASR in children's speech.","authors":["Haolong Zheng","Yekaterina Yegorova","Mark Hasegawa-Johnson"],"pdf_url":"","comment":"Published at IEEE ASRU 2025 Satellite Workshop-AI for Children's Speech and Language"},{"id":"http://arxiv.org/abs/2511.21728v2","updated":"2025-12-20T07:48:22Z","published":"2025-11-21T04:16:45Z","title":"Affective Multimodal Agents with Proactive Knowledge Grounding for Emotionally Aligned Marketing Dialogue","summary":"Recent advances in large language models (LLMs) have enabled fluent dialogue systems, but most remain reactive and struggle in emotionally rich, goal-oriented settings such as marketing conversations. To address this limitation, we propose AffectMind, a multimodal affective dialogue agent that performs proactive reasoning and dynamic knowledge grounding to sustain emotionally aligned and persuasive interactions. AffectMind combines three components: a Proactive Knowledge Grounding Network (PKGN) that continuously updates factual and affective context from text, vision, and prosody; an Emotion--Intent Alignment Model (EIAM) that jointly models user emotion and purchase intent to adapt persuasion strategies; and a Reinforced Discourse Loop (RDL) that optimizes emotional coherence and engagement via reinforcement signals from user responses. Experiments on two newly curated marketing dialogue datasets, MM-ConvMarket and AffectPromo, show that AffectMind outperforms strong LLM-based baselines in emotional consistency (+26\\%), persuasive success rate (+19\\%), and long-term user engagement (+23\\%), highlighting emotion-grounded proactivity as a key capability for commercial multimodal agents.","authors":["Lin Yu","Xiaofei Han","Yifei Kang","Chiung-Yi Tseng","Danyang Zhang","Ziqian Bi","Zhimo Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.02800v4","updated":"2025-12-20T07:22:06Z","published":"2025-04-03T17:43:14Z","title":"Survey and Experiments on Mental Disorder Detection via Social Media: From Large Language Models and RAG to Agents","summary":"Mental disorders represent a critical global health challenge, and social media is increasingly viewed as a vital resource for real-time digital phenotyping and intervention. To leverage this data, large language models (LLMs) have been introduced, offering stronger semantic understanding and reasoning than traditional deep learning, thereby enhancing the explainability of detection results. Despite the growing prominence of LLMs in this field, there is a scarcity of scholarly works that systematically synthesize how advanced enhancement techniques, specifically Retrieval-Augmented Generation (RAG) and Agentic systems, can be utilized to address these reliability and reasoning limitations. Here, we systematically survey the evolving landscape of LLM-based methods for social media mental disorder analysis, spanning standard pre-trained language models, RAG to mitigate hallucinations and contextual gaps, and agentic systems for autonomous reasoning and multi-step intervention. We organize existing work by technical paradigm and clinical target, extending beyond common internalizing disorders to include psychotic disorders and externalizing behaviors. Additionally, the paper comprehensively evaluates the performance of LLMs, including the impact of RAG, across various tasks. This work establishes a unified benchmark for the field, paving the way for the development of trustworthy, autonomous AI systems that can deliver precise and explainable mental health support.","authors":["Zhuohan Ge","Darian Li","Yubo Wang","Nicole Hu","Xinyi Zhu","Haoyang Li","Xin Zhang","Mingtao Zhang","Shihao Qi","Yuming Xu","Han Shi","Chen Jason Zhang","Qing Li"],"pdf_url":"","comment":"20 pages, 10 figures. This is an extension of ICDEW 2025"},{"id":"http://arxiv.org/abs/2512.18231v1","updated":"2025-12-20T06:22:38Z","published":"2025-12-20T06:22:38Z","title":"Investigating Spatial Attention Bias in Vision-Language Models","summary":"Vision-Language Models have demonstrated remarkable capabilities in understanding visual content, yet systematic biases in their spatial processing remain largely unexplored. This work identifies and characterizes a systematic spatial attention bias where VLMs consistently prioritize describing left-positioned content before right-positioned content in horizontally concatenated images. Through controlled experiments on image pairs using both open-source and closed-source models, we demonstrate that this bias persists across different architectures, with models describing left-positioned content first in approximately 97% of cases under neutral prompting conditions. Testing on an Arabic-finetuned model reveals that the bias persists despite right-to-left language training, ruling out language reading direction as the primary cause. Investigation of training dataset annotation guidelines from PixMo and Visual Genome reveals no explicit left-first ordering instructions, suggesting the bias is consistent with architectural factors rather than explicit training data instructions. These findings reveal fundamental limitations in how current VLMs process spatial information.","authors":["Aryan Chaudhary","Sanchit Goyal","Pratik Narang","Dhruv Kumar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18225v1","updated":"2025-12-20T05:46:57Z","published":"2025-12-20T05:46:57Z","title":"GeoSense-AI: Fast Location Inference from Crisis Microblogs","summary":"This paper presents an applied AI pipeline for realtime geolocation from noisy microblog streams, unifying statistical hashtag segmentation, part-of-speech-driven proper-noun detection, dependency parsing around disaster lexicons, lightweight named-entity recognition, and gazetteer-grounded disambiguation to infer locations directly from text rather than sparse geotags. The approach operationalizes information extraction under streaming constraints, emphasizing low-latency NLP components and efficient validation against geographic knowledge bases to support situational awareness during emergencies. In head to head comparisons with widely used NER toolkits, the system attains strong F1 while being engineered for orders-of-magnitude faster throughput, enabling deployment in live crisis informatics settings. A production map interface demonstrates end-to-end AI functionality ingest, inference, and visualization--surfacing locational signals at scale for floods, outbreaks, and other fastmoving events. By prioritizing robustness to informal text and streaming efficiency, GeoSense-AI illustrates how domain-tuned NLP and knowledge grounding can elevate emergency response beyond conventional geo-tag reliance.","authors":["Deepit Sapru"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.13274v3","updated":"2025-12-20T05:39:49Z","published":"2025-06-16T09:14:01Z","title":"AdaLRS: Loss-Guided Adaptive Learning Rate Search for Efficient Foundation Model Pretraining","summary":"Learning rate is widely regarded as crucial for effective foundation model pretraining. Recent research explores and demonstrates the transferability of learning rate configurations across varying model and dataset sizes, etc. Nevertheless, these approaches are constrained to specific training scenarios and typically necessitate extensive hyperparameter tuning on proxy models. In this work, we propose \\textbf{AdaLRS}, a plug-in-and-play adaptive learning rate search algorithm that conducts online optimal learning rate search via optimizing loss descent velocities. We provide theoretical and experimental analyzes to show that foundation model pretraining loss and its descent velocity are both convex and share the same optimal learning rate. Relying solely on training loss dynamics, AdaLRS involves few extra computations to guide the search process, and its convergence is guaranteed via theoretical analysis. Experiments on both LLM and VLM pretraining show that AdaLRS adjusts suboptimal learning rates to the neighborhood of optimum with marked efficiency and effectiveness, with model performance improved accordingly. We also show the robust generalizability of AdaLRS across varying training scenarios, such as different model sizes, training paradigms, base learning rate scheduler choices, and hyperparameter settings.","authors":["Hongyuan Dong","Dingkang Yang","Xiao Liang","Chao Feng","Jiao Ran"],"pdf_url":"","comment":"NeurIPS 2025 Main Conference"},{"id":"http://arxiv.org/abs/2512.18215v1","updated":"2025-12-20T05:07:53Z","published":"2025-12-20T05:07:53Z","title":"Stable and Efficient Single-Rollout RL for Multimodal Reasoning","summary":"Reinforcement Learning with Verifiable Rewards (RLVR) has become a key paradigm to improve the reasoning capabilities of Multimodal Large Language Models (MLLMs). However, prevalent group-based algorithms such as GRPO require multi-rollout sampling for each prompt. While more efficient single-rollout variants have recently been explored in text-only settings, we find that they suffer from severe instability in multimodal contexts, often leading to training collapse. To address this training efficiency-stability trade-off, we introduce $\\textbf{MSSR}$ (Multimodal Stabilized Single-Rollout), a group-free RLVR framework that achieves both stable optimization and effective multimodal reasoning performance. MSSR achieves this via an entropy-based advantage-shaping mechanism that adaptively regularizes advantage magnitudes, preventing collapse and maintaining training stability. While such mechanisms have been used in group-based RLVR, we show that in the multimodal single-rollout setting they are not merely beneficial but essential for stability. In in-distribution evaluations, MSSR demonstrates superior training compute efficiency, achieving similar validation accuracy to the group-based baseline with half the training steps. When trained for the same number of steps, MSSR's performance surpasses the group-based baseline and shows consistent generalization improvements across five diverse reasoning-intensive benchmarks. Together, these results demonstrate that MSSR enables stable, compute-efficient, and effective RLVR for complex multimodal reasoning tasks.","authors":["Rui Liu","Dian Yu","Lei Ke","Haolin Liu","Yujun Zhou","Zhenwen Liang","Haitao Mi","Pratap Tokekar","Dong Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.10398v5","updated":"2025-12-20T04:25:21Z","published":"2025-12-11T08:05:58Z","title":"Confucius Code Agent: Scalable Agent Scaffolding for Real-World Codebases","summary":"Real-world software engineering tasks require coding agents that can operate over massive repositories, sustain long-horizon sessions, and reliably coordinate complex toolchains at test time. Existing research-grade coding agents offer transparency but struggle when scaled to heavier, production-level workloads, while production-grade systems achieve strong practical performance but provide limited extensibility, interpretability, and controllability. We introduce the Confucius Code Agent (CCA), a software engineering agent that can operate at large-scale codebases. CCA is built on top of the Confucius SDK, an agent development platform structured around three complementary perspectives: Agent Experience (AX), User Experience (UX), and Developer Experience (DX). The SDK integrates a unified orchestrator with hierarchical working memory for long-context reasoning, a persistent note-taking system for cross-session continual learning, and a modular extension system for reliable tool use. In addition, we introduce a meta-agent that automates the synthesis, evaluation, and refinement of agent configurations through a build-test-improve loop, enabling rapid adaptation to new tasks, environments, and tool stacks. Instantiated with these mechanisms, CCA demonstrates strong performance on real-world software engineering tasks. On SWE-Bench-Pro, CCA reaches a Resolve@1 of 54.3%, exceeding prior research baselines and comparing favorably to commercial results, under identical repositories, model backends, and tool access.","authors":["Sherman Wong","Zhenting Qi","Zhaodong Wang","Nathan Hu","Samuel Lin","Jun Ge","Erwin Gao","Wenlin Chen","Yilun Du","Minlan Yu","Ying Zhang"],"pdf_url":"","comment":"The latest version"},{"id":"http://arxiv.org/abs/2511.02833v3","updated":"2025-12-20T03:45:29Z","published":"2025-11-04T18:58:47Z","title":"In Good GRACEs: Principled Teacher Selection for Knowledge Distillation","summary":"Knowledge distillation is an efficient strategy to use data generated by large \"teacher\" language models to train smaller capable \"student\" models, but selecting the optimal teacher for a specific student-task combination requires expensive trial-and-error. We propose a lightweight score called GRACE to quantify how effective a teacher will be for post-training a student model. GRACE measures distributional properties of the student's gradients without access to a verifier, teacher logits, teacher internals, or test data. From an information-theoretic perspective, GRACE connects to leave-one-out stability of gradient-based algorithms, which controls the generalization performance of the distilled students. On GSM8K and MATH, GRACE correlates strongly (up to 86% Spearman correlation) with the performance of the distilled LLaMA and OLMo students. In particular, training a student using the GRACE-selected teacher can improve the performance by up to 7.4% over naively using the best-performing teacher. Further, GRACE can provide guidance on crucial design choices in distillation, including (1) the best temperature to use when generating from the teacher, (2) the best teacher to use given a size constraint, and (3) the best teacher to use within a specific model family. Altogether, our findings demonstrate that GRACE can efficiently and effectively identify a strongly compatible teacher for a given student and provide fine-grained guidance on how to perform distillation.","authors":["Abhishek Panigrahi","Bingbin Liu","Sadhika Malladi","Sham Kakade","Surbhi Goel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18196v1","updated":"2025-12-20T03:43:02Z","published":"2025-12-20T03:43:02Z","title":"Training LLMs with LogicReward for Faithful and Rigorous Reasoning","summary":"Although LLMs exhibit strong reasoning capabilities, existing training methods largely depend on outcome-based feedback, which can produce correct answers with flawed reasoning. Prior work introduces supervision on intermediate steps but still lacks guarantees of logical soundness, which is crucial in high-stakes scenarios where logical consistency is paramount. To address this, we propose LogicReward, a novel reward system that guides model training by enforcing step-level logical correctness with a theorem prover. We further introduce Autoformalization with Soft Unification, which reduces natural language ambiguity and improves formalization quality, enabling more effective use of the theorem prover. An 8B model trained on data constructed with LogicReward surpasses GPT-4o and o4-mini by 11.6\\% and 2\\% on natural language inference and logical reasoning tasks with simple training procedures. Further analysis shows that LogicReward enhances reasoning faithfulness, improves generalizability to unseen tasks such as math and commonsense reasoning, and provides a reliable reward signal even without ground-truth labels. We will release all data and code at https://llm-symbol.github.io/LogicReward.","authors":["Jundong Xu","Hao Fei","Huichi Zhou","Xin Quan","Qijun Huang","Shengqiong Wu","William Yang Wang","Mong-Li Lee","Wynne Hsu"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2512.18190v1","updated":"2025-12-20T03:27:11Z","published":"2025-12-20T03:27:11Z","title":"External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning","summary":"This paper proposes the External Hippocampus framework, which models language model reasoning from a cognitive dynamics perspective as the flow of information energy in semantic space. Unlike traditional weight-space optimization methods, this framework constructs topological cognitive maps through dimensionality reduction projection, enabling precise navigation and intervention of energy flow at test time while avoiding substantial computational requirements and demonstrating predictable intervention patterns. The method effectively addresses the cognitive deadlock problem in multi-step reasoning for small models. Experiments on models <=7B parameters show: map-guided methods achieve 81.20% accuracy on 500 challenging problems (relative baseline +16.80%), reduce reasoning time by >= 15x, with key findings revealing that reasoning stagnation manifests as \"Cognitive Vortex\" and low-entropy potential wells, while temperature perturbations effectively restart energy flow. The framework requires no additional training, possesses autonomous growth capability, and provides an efficient and controllable topological-aware solution for small model reasoning.","authors":["Jian Yan"],"pdf_url":"","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2512.15926v2","updated":"2025-12-20T01:38:32Z","published":"2025-12-17T19:43:46Z","title":"DSO: Direct Steering Optimization for Bias Mitigation","summary":"Generative models are often deployed to make decisions on behalf of users, such as vision-language models (VLMs) identifying which person in a room is a doctor to help visually impaired individuals. Yet, VLM decisions are influenced by the perceived demographic attributes of people in the input, which can lead to biased outcomes like failing to identify women as doctors. Moreover, when reducing bias leads to performance loss, users may have varying needs for balancing bias mitigation with overall model capabilities, highlighting the demand for methods that enable controllable bias reduction during inference. Activation steering is a popular approach for inference-time controllability that has shown potential in inducing safer behavior in large language models (LLMs). However, we observe that current steering methods struggle to correct biases, where equiprobable outcomes across demographic groups are required. To address this, we propose Direct Steering Optimization (DSO) which uses reinforcement learning to find linear transformations for steering activations, tailored to mitigate bias while maintaining control over model performance. We demonstrate that DSO achieves state-of-the-art trade-off between fairness and capabilities on both VLMs and LLMs, while offering practitioners inference-time control over the trade-off. Overall, our work highlights the benefit of designing steering strategies that are directly optimized to control model behavior, providing more effective bias intervention than methods that rely on pre-defined heuristics for controllability.","authors":["Lucas Monteiro Paes","Nivedha Sivakumar","Yinong Oliver Wang","Masha Fedzechkina Donaldson","Barry-John Theobald","Luca Zappella","Nicholas Apostoloff"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.22860v2","updated":"2025-12-20T00:43:42Z","published":"2025-10-26T22:46:26Z","title":"Far from the Shallow: Brain-Predictive Reasoning Embedding through Residual Disentanglement","summary":"Understanding how the human brain progresses from processing simple linguistic inputs to performing high-level reasoning is a fundamental challenge in neuroscience. While modern large language models (LLMs) are increasingly used to model neural responses to language, their internal representations are highly \"entangled,\" mixing information about lexicon, syntax, meaning, and reasoning. This entanglement biases conventional brain encoding analyses toward linguistically shallow features (e.g., lexicon and syntax), making it difficult to isolate the neural substrates of cognitively deeper processes. Here, we introduce a residual disentanglement method that computationally isolates these components. By first probing an LM to identify feature-specific layers, our method iteratively regresses out lower-level representations to produce four nearly orthogonal embeddings for lexicon, syntax, meaning, and, critically, reasoning. We used these disentangled embeddings to model intracranial (ECoG) brain recordings from neurosurgical patients listening to natural speech. We show that: 1) This isolated reasoning embedding exhibits unique predictive power, accounting for variance in neural activity not explained by other linguistic features and even extending to the recruitment of visual regions beyond classical language areas. 2) The neural signature for reasoning is temporally distinct, peaking later (~350-400ms) than signals related to lexicon, syntax, and meaning, consistent with its position atop a processing hierarchy. 3) Standard, non-disentangled LLM embeddings can be misleading, as their predictive success is primarily attributable to linguistically shallow features, masking the more subtle contributions of deeper cognitive processing.","authors":["Linyang He","Tianjun Zhong","Richard Antonello","Gavin Mischler","Micah Goldblum","Nima Mesgarani"],"pdf_url":"","comment":"Accepted at NeurIPS 2025"}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2512.18529v1","updated":"2025-12-20T22:51:38Z","published":"2025-12-20T22:51:38Z","title":"Protecting Human Activity Signatures in Compressed IEEE 802.11 CSI Feedback","summary":"Explicit channel state information (CSI) feedback in IEEE~802.11 conveys \\emph{transmit beamforming directions} by reporting quantized Givens rotation and phase angles that parametrize the right-singular subspace of the channel matrix. Because these angles encode fine-grained spatial signatures of the propagation environment, recent work have shown that plaintext CSI feedback can inadvertently reveal user activity, identity, and location to passive eavesdroppers. In this work, we introduce a standards-compatible \\emph{differentially private (DP) quantization mechanism} that replaces deterministic angular quantization with an $\\varepsilon$-DP stochastic quantizer applied directly to the Givens parameters of the transmit beamforming matrix. The mechanism preserves the 802.11 feedback structure, admits closed-form sensitivity bounds for the angular representation, and enables principled privacy calibration. Numerical simulations demonstrate strong privacy guarantees with minimal degradation in beamforming performance.","authors":["Mohamed Seif","Atsutse Kludze","Yasaman Ghasempour","H. Vincent Poor","Doru Calin","Andrea J. Goldsmith"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.09613v2","updated":"2025-12-20T20:16:14Z","published":"2025-07-13T12:35:08Z","title":"Wi-Fi: Twenty-Five Years and Counting","summary":"Today, Wi-Fi is over 25 years old. Yet, despite sharing the same branding name, today's Wi-Fi boasts entirely new capabilities that were not even on the roadmap 25 years ago. This article aims to provide a holistic and comprehensive technical and historical tutorial on Wi-Fi, beginning with IEEE 802.11b (Wi-Fi 1) and looking forward to IEEE 802.11bn (Wi-Fi 8). This is the first tutorial article to span these eight generations. Rather than a generation-by-generation exposition, we describe the key mechanisms that have advanced Wi-Fi. We begin by discussing spectrum allocation and coexistence, and detailing the IEEE 802.11 standardization cycle. Second, we provide an overview of the physical layer and describe key elements that have enabled data rates to increase by over 1,000x. Third, we describe how Wi-Fi Medium Access Control has been enhanced from the original Distributed Coordination Function to now include capabilities spanning from frame aggregation to wideband spectrum access. Fourth, we describe how Wi-Fi 5 first broke the one-user-at-a-time paradigm and introduced multi-user access. Fifth, given the increasing use of mobile, battery-powered devices, we describe Wi-Fi's energy-saving mechanisms over the generations. Sixth, we discuss how Wi-Fi was enhanced to seamlessly aggregate spectrum across 2.4 GHz, 5 GHz, and 6 GHz bands to improve throughput, reliability, and latency. Finally, we describe how Wi-Fi enables nearby Access Points to coordinate in order to improve performance and efficiency. In the Appendix, we further discuss Wi-Fi developments beyond 802.11bn, including integrated mmWave operations, sensing, security and privacy extensions, and the adoption of AI/ML.","authors":["Giovanni Geraci","Francesca Meneghello","Francesc Wilhelmi","David Lopez-Perez","Iñaki Val","Lorenzo Galati Giordano","Carlos Cordeiro","Monisha Ghosh","Edward Knightly","Boris Bellalta"],"pdf_url":"","comment":"42 pages, 28 figures, 3 tables"},{"id":"http://arxiv.org/abs/2512.18332v1","updated":"2025-12-20T11:57:08Z","published":"2025-12-20T11:57:08Z","title":"Implementing Transport Coding in OMNeT++ for Message Delay Reduction","summary":"Transport coding reduces message delay in packet-switched networks by introducing controlled redundancy at the transport layer: $k$ original packets are encoded into $n\\ge k$ coded packets, and the message is reconstructed after the first $k$ successful deliveries, effectively shifting latency from the maximum packet delay to the $k$-th order statistic. We present a concise, reproducible discrete-event implementation of transport coding in OMNeT++, including a multi-hop Kleinrock-type network, FIFO queues, exponential service and link delays, and explicit receiver-side reconstruction that records message delay and deadline violations. Using paired uncoded ($n{=}k$) and coded ($n{>}k$) configurations at the same message generation rate, we compare delay, reliability, and saturation effects across code rates and input loads. Simulation results show consistent reductions of average delay and late-delivery probability for moderate redundancy, while keeping the saturation throughput close to the uncoded baseline. The proposed model provides a transparent bridge between analytical transport-coding formulas and executable simulation for tuning redundancy in low-latency services.","authors":["Ilya Petrovanov","Anton Sergeev"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18318v1","updated":"2025-12-20T11:23:18Z","published":"2025-12-20T11:23:18Z","title":"Asynchronous Pipeline Parallelism for Real-Time Multilingual Lip Synchronization in Video Communication Systems","summary":"This paper introduces a parallel and asynchronous Transformer framework designed for efficient and accurate multilingual lip synchronization in real-time video conferencing systems. The proposed architecture integrates translation, speech processing, and lip-synchronization modules within a pipeline-parallel design that enables concurrent module execution through message-queue-based decoupling, reducing end-to-end latency by up to 3.1 times compared to sequential approaches. To enhance computational efficiency and throughput, the inference workflow of each module is optimized through low-level graph compilation, mixed-precision quantization, and hardware-accelerated kernel fusion. These optimizations provide substantial gains in efficiency while preserving model accuracy and visual quality. In addition, a context-adaptive silence-detection component segments the input speech stream at semantically coherent boundaries, improving translation consistency and temporal alignment across languages. Experimental results demonstrate that the proposed parallel architecture outperforms conventional sequential pipelines in processing speed, synchronization stability, and resource utilization. The modular, message-oriented design makes this work applicable to resource-constrained IoT communication scenarios including telemedicine, multilingual kiosks, and remote assistance systems. Overall, this work advances the development of low-latency, resource-efficient multimodal communication frameworks for next-generation AIoT systems.","authors":["Eren Caglar","Amirkia Rafiei Oskooei","Mehmet Kutanoglu","Mustafa Keles","Mehmet S. Aktas"],"pdf_url":"","comment":"Accepted to IEEE Big Data 2025, AIDE4IoT Workshop. Copyright \\c{opyright} 2025 IEEE"},{"id":"http://arxiv.org/abs/2512.18259v1","updated":"2025-12-20T07:55:02Z","published":"2025-12-20T07:55:02Z","title":"TCP BBR Performance over Wi-Fi~6: AQM Impacts and Cross-Layer Insights","summary":"We evaluate TCP BBRv3 on Wi-Fi 6 home networks under modern AQM schemes using a fully wireless testbed and a simple cross-layer model linking Wi-Fi scheduling, router queueing, and BBRv3's pacing dynamics. Comparing BBR Internet traffic with CUBIC across different AQMs (FIFO, FQ-CoDel, and CAKE) for uplink, downlink, and bidirectional traffic, we find that FIFO destabilizes pacing and raises delay, often letting CUBIC dominate; FQ-CoDel restores fairness and controls latency; and CAKE delivers the best overall performance by keeping delay low and aligning BBRv3's sending and delivered rates. We also identify a Wi-Fi-specific effect where CAKE's rapid queue draining, while improving pacing alignment, can trigger brief retransmission bursts during BBRv3's bandwidth probes. These results follow from the interaction of variable Wi-Fi service rates, AQM delay control, and BBRv3's inflight limits, leading to practical guidance to use FQ-CoDel or CAKE and avoid unmanaged FIFO in home Wi-Fi, with potential for Wi-Fi-aware tuning of BBRv3's probing.","authors":["Shyam Kumar Shrestha","Shiva Raj Pokhrel","Jonathan Kua"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02230v2","updated":"2025-12-20T01:17:03Z","published":"2025-11-04T03:43:05Z","title":"Continuum: Efficient and Robust Multi-Turn LLM Agent Scheduling with KV Cache Time-to-Live","summary":"KV cache management is essential for efficient LLM inference. To maximize utilization, existing inference engines evict finished requests' KV cache if new requests are waiting. This policy breaks for agentic workloads, which interleave LLM calls with tools, introducing pauses that prevent effective KV reuse across turns. Since some tool calls have much shorter durations than human response multi-turn chatbot, it would be promising to retain the KV cache in during these tools. However, there are many challenges. First, we need to consider both the potential cost of recomputation or reloading (if CPU offloading enabled) and the increasing queueing delays after eviction from GPU. Second, due to the internal variance of tool call durations, we need the method to remain robust under limited predictability of tool call durations.\n  We present Continuum, a serving system to optimize job completion time for multi-turn agent workloads by introducing time-to-live mechanism for KV cache retaining. For LLM request that generates a tool call, Continuum selectively pins the KV cache in GPU memory with a time-to-live value determined by considering both the reload cost and ordering preserve benefit of retaining KV cache. Moreover, when the TTL expires, the KV cache can be automatically evicted to free up GPU memory, providing robust performance under edge cases. When combined with program-level first-come-first-serve, Continuum preserves multi-turn continuity, and reduces delay for complex agentic workflows. Our evaluation on real-world agentic workloads (SWE-Bench and BFCL) with Llama-3.1 8B/70B shows that Continuum significantly improves the average job completion times and its improvement scales with turn number increase. We release a preview version at: https://github.com/Hanchenli/vllm-continuum","authors":["Hanchen Li","Qiuyang Mang","Runyuan He","Qizheng Zhang","Huanzhi Mao","Xiaokun Chen","Hangrui Zhou","Alvin Cheung","Joseph Gonzalez","Ion Stoica"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18155v1","updated":"2025-12-20T00:31:24Z","published":"2025-12-20T00:31:24Z","title":"Performance Guarantees for Data Freshness in Resource-Constrained Adversarial IoT Systems","summary":"Timely updates are critical for real-time monitoring and control applications powered by the Internet of Things (IoT). As these systems scale, they become increasingly vulnerable to adversarial attacks, where malicious agents interfere with legitimate transmissions to reduce data rates, thereby inflating the age of information (AoI). Existing adversarial AoI models often assume stationary channels and overlook queueing dynamics arising from compromised sensing sources operating under resource constraints. Motivated by the G-queue framework, this paper investigates a two-source M/G/1/1 system in which one source is adversarial and disrupts the update process by injecting negative arrivals according to a Poisson process and inducing i.i.d. service slowdowns, bounded in attack rate and duration. Using moment generating functions, we then derive closed-form expressions for average and peak AoI for an arbitrary number of sources. Moreover, we introduce a worst-case constrained attack model and employ stochastic dominance arguments to establish analytical AoI bounds. Numerical results validate the analysis and highlight the impact of resource-limited adversarial interference under general service time distributions.","authors":["Aresh Dadlani","Muthukrishnan Senthil Kumar","Omid Ardakanian","Ioanis Nikolaidis"],"pdf_url":"","comment":"6 pages, 4 figures, conference paper"}],"Operating Systems":[{"id":"http://arxiv.org/abs/2512.18436v1","updated":"2025-12-20T17:22:52Z","published":"2025-12-20T17:22:52Z","title":"VeruSAGE: A Study of Agent-Based Verification for Rust Systems","summary":"Large language models (LLMs) have shown impressive capability to understand and develop code. However, their capability to rigorously reason about and prove code correctness remains in question. This paper offers a comprehensive study of LLMs' capability to develop correctness proofs for system software written in Rust. We curate a new system-verification benchmark suite, VeruSAGE-Bench, which consists of 849 proof tasks extracted from eight open-source Verus-verified Rust systems. Furthermore, we design different agent systems to match the strengths and weaknesses of different LLMs (o4-mini, GPT-5, Sonnet 4, and Sonnet 4.5). Our study shows that different tools and agent settings are needed to stimulate the system-verification capability of different types of LLMs. The best LLM-agent combination in our study completes over 80% of system-verification tasks in VeruSAGE-Bench. It also completes over 90% of a set of system proof tasks not part of VeruSAGE-Bench because they had not yet been finished by human experts. This result shows the great potential for LLM-assisted development of verified system software.","authors":["Chenyuan Yang","Natalie Neamtu","Chris Hawblitzel","Jacob R. Lorch","Shan Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.12615v2","updated":"2025-12-20T15:00:39Z","published":"2025-12-14T09:39:59Z","title":"gpu_ext: Extensible OS Policies for GPUs via eBPF","summary":"Performance in modern GPU-centric systems increasingly depends on resource management policies, including memory placement, scheduling, and observability. However, uniform policies typically yield suboptimal performance across diverse workloads. Existing approaches present a tradeoff: user-space runtimes provide programmability and flexibility but lack cross-tenant visibility and fine-grained control of hardware resources; meanwhile, modifications to the OS kernel introduce significant complexity and safety risks. To address this, we argue that the GPU driver and device layer should provide an extensible OS interface for policy enforcement. While the emerging eBPF technology shows potential, directly applying existing host-side eBPF is insufficient because they lack visibility and control into critical device-side events, and directly embedding policy code into GPU kernels could compromise safety and efficiency. We propose gpu_ext, an eBPF-based runtime that treats the GPU driver and device as a programmable OS subsystem. gpu_ext extends GPU drivers by exposing safe programmable hooks and introduces a device-side eBPF runtime capable of executing verified policy logic within GPU kernels, enabling coherent and transparent policies. Evaluation across realistic workloads including inference, training, and vector search demonstrates that gpu_ext improves throughput by up to 4.8x and reduces tail latency by up to 2x, incurring low overhead, without modifying or restarting applications","authors":["Yusheng Zheng","Tong Yu","Yiwei Yang","Minghui Jiang","Xiangyu Gao","Jianchang Su","Yanpeng Hu","Wenan Mao","Wei Zhang","Dan Williams","Andi Quinn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02230v2","updated":"2025-12-20T01:17:03Z","published":"2025-11-04T03:43:05Z","title":"Continuum: Efficient and Robust Multi-Turn LLM Agent Scheduling with KV Cache Time-to-Live","summary":"KV cache management is essential for efficient LLM inference. To maximize utilization, existing inference engines evict finished requests' KV cache if new requests are waiting. This policy breaks for agentic workloads, which interleave LLM calls with tools, introducing pauses that prevent effective KV reuse across turns. Since some tool calls have much shorter durations than human response multi-turn chatbot, it would be promising to retain the KV cache in during these tools. However, there are many challenges. First, we need to consider both the potential cost of recomputation or reloading (if CPU offloading enabled) and the increasing queueing delays after eviction from GPU. Second, due to the internal variance of tool call durations, we need the method to remain robust under limited predictability of tool call durations.\n  We present Continuum, a serving system to optimize job completion time for multi-turn agent workloads by introducing time-to-live mechanism for KV cache retaining. For LLM request that generates a tool call, Continuum selectively pins the KV cache in GPU memory with a time-to-live value determined by considering both the reload cost and ordering preserve benefit of retaining KV cache. Moreover, when the TTL expires, the KV cache can be automatically evicted to free up GPU memory, providing robust performance under edge cases. When combined with program-level first-come-first-serve, Continuum preserves multi-turn continuity, and reduces delay for complex agentic workflows. Our evaluation on real-world agentic workloads (SWE-Bench and BFCL) with Llama-3.1 8B/70B shows that Continuum significantly improves the average job completion times and its improvement scales with turn number increase. We release a preview version at: https://github.com/Hanchenli/vllm-continuum","authors":["Hanchen Li","Qiuyang Mang","Runyuan He","Qizheng Zhang","Huanzhi Mao","Xiaokun Chen","Hangrui Zhou","Alvin Cheung","Joseph Gonzalez","Ion Stoica"],"pdf_url":"","comment":null}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2512.18459v1","updated":"2025-12-20T18:25:17Z","published":"2025-12-20T18:25:17Z","title":"Weight Transformations in Bit-Sliced Crossbar Arrays for Fault Tolerant Computing-in-Memory: Design Techniques and Evaluation Framework","summary":"The deployment of deep neural networks (DNNs) on compute-in-memory (CiM) accelerators offers significant energy savings and speed-up by reducing data movement during inference. However, the reliability of CiM-based systems is challenged by stuck-at faults (SAFs) in memory cells, which corrupt stored weights and lead to accuracy degradation. While closest value mapping (CVM) has been shown to partially mitigate these effects for multibit DNNs deployed on bit-sliced crossbars, its fault tolerance is often insufficient under high SAF rates or for complex tasks. In this work, we propose two training-free weight transformation techniques, sign-flip and bit-flip, that enhance SAF tolerance in multi-bit DNNs deployed on bit-sliced crossbar arrays. Sign-flip operates at the weight-column level by selecting between a weight and its negation, whereas bit-flip provides finer granularity by selectively inverting individual bit slices. Both methods expand the search space for fault-aware mappings, operate synergistically with CVM, and require no retraining or additional memory. To enable scalability, we introduce a look-up-table (LUT)-based framework that accelerates the computation of optimal transformations and supports rapid evaluation across models and fault rates. Extensive experiments on ResNet-18, ResNet-50, and ViT models with CIFAR-100 and ImageNet demonstrate that the proposed techniques recover most of the accuracy lost under SAF injection. Hardware analysis shows that these methods incur negligible overhead, with sign-flip leading to negligible energy, latency, and area cost, and bit-flip providing higher fault resilience with modest overheads. These results establish sign-flip and bit-flip as practical and scalable SAF-mitigation strategies for CiM-based DNN accelerators.","authors":["Akul Malhotra","Sumeet Kumar Gupta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18345v1","updated":"2025-12-20T12:18:29Z","published":"2025-12-20T12:18:29Z","title":"Theodosian: A Deep Dive into Memory-Hierarchy-Centric FHE Acceleration","summary":"Fully homomorphic encryption (FHE) enables secure computation on encrypted data, mitigating privacy concerns in cloud and edge environments. However, due to its high compute and memory demands, extensive acceleration research has been pursued across diverse hardware platforms, especially GPUs. In this paper, we perform a microarchitectural analysis of CKKS, a popular FHE scheme, on modern GPUs. We focus on on-chip cache behavior, and show that the dominant kernels remain bound by memory bandwidth despite a high-bandwidth L2 cache, exposing a persistent memory wall. We further discover that the overall CKKS pipeline throughput is constrained by low per-kernel hardware utilization, caused by insufficient intra-kernel parallelism. Motivated by these findings, we introduce Theodosian, a set of complementary, memory-aware optimizations that improve cache efficiency and reduce runtime overheads. Our approach delivers consistent speedups across various CKKS workloads. On an RTX 5090, we reduce the bootstrapping latency for 32,768 complex numbers to 15.2ms with Theodosian, and further to 12.8ms with additional algorithmic optimizations, establishing new state-of-the-art GPU performance to the best of our knowledge.","authors":["Wonseok Choi","Hyunah Yu","Jongmin Kim","Hyesung Ji","Jaiyoung Park","Jung Ho Ahn"],"pdf_url":"","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2512.18300v1","updated":"2025-12-20T10:11:47Z","published":"2025-12-20T10:11:47Z","title":"BARD: Reducing Write Latency of DDR5 Memory by Exploiting Bank-Parallelism","summary":"This paper studies the impact of DRAM writes on DDR5-based system. To efficiently perform DRAM writes, modern systems buffer write requests and try to complete multiple write operations whenever the DRAM mode is switched from read to write. When the DRAM system is performing writes, it is not available to service read requests, thus increasing read latency and reducing performance. We observe that, given the presence of on-die ECC in DDR5 devices, the time to perform a write operation varies significantly: from 1x (for writes to banks of different bankgroups) to 6x (for writes to banks within the same bankgroup) to 24x (for conflicting requests to the same bank). If we can orchestrate the write stream to favor write requests that incur lower latency, then we can reduce the stall time from DRAM writes and improve performance. However, for current systems, the write stream is dictated by the cache replacement policy, which makes eviction decisions without being aware of the variable latency of DRAM writes. The key insight of our work is to improve performance by modifying the cache replacement policy to increase bank-parallelism of DRAM writes.\n  Our paper proposes {\\em BARD (Bank-Aware Replacement Decisions)}, which modifies the cache replacement policy to favor dirty lines that belong to banks without pending writes. We analyze two variants of BARD: BARD-E (Eviction-based), which changes the eviction policy to evict low-cost dirty lines, and BARD-C (Cleansing-Based), which proactively cleans low-cost dirty lines without modifying the eviction decisions. We develop a hybrid policy (BARD-H), which uses a selective combination of both eviction and writeback. Our evaluations across workloads from SPEC2017, LIGRA, STREAM, and Google server traces show that BARD-H improves performance by 4.3\\% on average and up-to 8.5\\%. BARD requires only 8 bytes of SRAM per LLC slice.","authors":["Suhas Vittal","Moinuddin Qureshi"],"pdf_url":"","comment":"Accepted to HPCA 2026"},{"id":"http://arxiv.org/abs/2512.18158v1","updated":"2025-12-20T00:44:27Z","published":"2025-12-20T00:44:27Z","title":"PIM-FW: Hardware-Software Co-Design of All-pairs Shortest Paths in DRAM","summary":"All-pairs shortest paths (APSP) is a fundamental algorithm used for routing, logistics, and network analysis, but the cubic time complexity and heavy data movement of the canonical Floyd-Warshall (FW) algorithm severely limits its scalability on conventional CPUs or GPUs. In this paper, we propose PIM-FW, a novel co-designed hardware architecture and dataflow that leverages processing in and near memory architecture designed to accelerate blocked FW algorithm on an HBM3 stack. To enable fine-grained parallelism, we propose a massively parallel array of specialized bit-serial bank PE and channel PE designed to accelerate the core min-plus operations. Our novel dataflow complements this hardware, employing an interleaved mapping policy for superior load balancing and hybrid in and near memory computing model for efficient computation and reduction. The novel in-bank computing approach allows all distance updates to be performed and stored in memory bank, a key contribution is that eliminates the data movement bottleneck inherent in GPU-based approaches. We implement a full software and hardware co-design using a cycle-accurate simulator to simulate an 8-channel, 4-Hi HBM3 PIM stack on real road-network traces. Experimental results show that, for a 8192 x 8192 graph, PIM-FW achieves a 18.7x speedup in end-to-end execution, and consumes 3200x less DRAM energy compared to a state-of-the-art GPU-only Floyd-Warshall.","authors":["Tsung-Han Lu","Zheyu Li","Minxuan Zhou","Tajana Rosing"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18152v1","updated":"2025-12-20T00:28:11Z","published":"2025-12-20T00:28:11Z","title":"Making Strong Error-Correcting Codes Work Effectively for HBM in AI Inference","summary":"LLM inference is increasingly memory bound, and HBM cost per GB dominates system cost. Current HBM stacks include short on-die ECC that tightens binning, raises price, and fixes reliability policy inside the device. This paper asks whether a system can tolerate a much higher raw HBM bit error rate and still keep end-to-end correctness and throughput, without changing the HBM PHY or the fixed 32 B transaction size. We propose REACH, a controller managed ECC design that keeps the HBM link and 32 B transfers unchanged. REACH uses a two level Reed-Solomon scheme: each 32 B chunk uses an inner code to check and correct most faults locally, while chunks that cannot be fixed are marked as erasures. An outer code spans kilobytes and runs in erasure only mode, repairing only flagged chunks and avoiding the expensive locator step. For small random writes, REACH updates outer parity with differential parity to avoid recomputing parity over the whole span, and an optional importance adaptive bit plane policy can protect only critical fields such as BF16 exponents to reduce ECC work and traffic. On three LLMs at 8K context, REACH keeps about 79 percent of on-die ECC throughput at zero BER and remains qualified up to a raw BER of 1e-3, extending tolerable device error rates by about three orders of magnitude while keeping tokens per second nearly flat. In ASAP7, a full REACH controller occupies 15.2 mm2 and consumes 17.5 W at 3.56 TB/s, and it reduces ECC area by 11.6x and power by about 60 percent compared to a naive long Reed-Solomon baseline. By moving strong ECC into the controller, REACH turns long code reliability into a system choice that can enable lower cost HBM under the same standard interface.","authors":["Rui Xie","Yunhua Fang","Asad Ul Haq","Linsen Ma","Sanchari Sen","Swagath Venkataramani","Liu Liu","Tong Zhang"],"pdf_url":"","comment":null}],"Software Engineering":[{"id":"http://arxiv.org/abs/2504.14757v2","updated":"2025-12-20T19:11:17Z","published":"2025-04-20T22:37:43Z","title":"SWE-Synth: Synthesizing Verifiable Bug-Fix Data to Enable Large Language Models in Resolving Real-World Bugs","summary":"Large language models (LLMs) are transforming automated program repair (APR) through agent-based approaches that localize bugs, generate patches, and verify fixes. However, the lack of high-quality, scalable training datasets, especially those with verifiable outputs and intermediate reasoning traces-limits progress, particularly for open-source models. In this work, we present SWE-Synth, a framework for synthesizing realistic, verifiable, and process-aware bug-fix datasets at the repository level. SWE-Synth leverages LLM agents to simulate debugging workflows, producing not only bug-fix pairs but also test cases and structured repair trajectories. Compared to manually curated datasets, our method scales with minimal human effort while preserving contextual richness and correctness. Experiments show that models trained on SWE-Synth outperform those trained on real-world datasets by 2.3% on SWE-Bench Lite. Our results highlight the potential of synthetic, agent-generated data to advance the state of the art in APR and software engineering automation.","authors":["Minh V. T. Pham","Huy N. Phan","Hoang N. Phan","Cuong Le Chi","Tien N. Nguyen","Nghi D. Q. Bui"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2512.18470v1","updated":"2025-12-20T19:08:15Z","published":"2025-12-20T19:08:15Z","title":"SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios","summary":"Existing benchmarks for AI coding agents focus on isolated, single-issue tasks such as fixing a bug or implementing a small feature. However, real-world software engineering is fundamentally a long-horizon endeavor: developers must interpret high-level requirements, plan coordinated changes across many files, and evolve codebases over multiple iterations while preserving existing functionality. We introduce SWE-EVO, a benchmark that evaluates agents on this long-horizon software evolution challenge. Constructed from release notes and version histories of seven mature open-source Python projects, Tool comprises 48 evolution tasks that require agents to implement multi-step modifications spanning an average of 21 files, validated against comprehensive test suites averaging 874 tests per instance. Experiments with state-of-the-art models reveal a striking capability gap: even GPT-5 with OpenHands achieves only a 21 percent resolution rate on Tool, compared to 65 percent on the single-issue SWE-Bench Verified. This demonstrates that current agents struggle with sustained, multi-file reasoning. We also propose Fix Rate, a fine-grained metric that captures partial progress toward solving these complex, long-horizon tasks.","authors":["Minh V. T. Thai","Tue Le","Dung Nguyen Manh","Huy Phan Nhat","Nghi D. Q. Bui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.07745v3","updated":"2025-12-20T18:49:45Z","published":"2025-08-11T08:24:48Z","title":"Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation","summary":"Insider threats pose a persistent and critical security risk, yet are notoriously difficult to detect in complex enterprise environments, where malicious actions are often hidden within seemingly benign user behaviors. Although machine-learning-based insider threat detection (ITD) methods have shown promise, their effectiveness is fundamentally limited by the scarcity of high-quality and realistic training data. Enterprise internal data is highly sensitive and rarely accessible, while existing public and synthetic datasets are either small-scale or lack sufficient realism, semantic richness, and behavioral diversity.\n  To address this challenge, we propose Chimera, an LLM-based multi-agent framework that automatically simulates both benign and malicious insider activities and generates comprehensive system logs across diverse enterprise environments. Chimera models each agent as an individual employee with fine-grained roles and supports group meetings, pairwise interactions, and self-organized scheduling to capture realistic organizational dynamics. Based on 15 insider attacks abstracted from real-world incidents, we deploy Chimera in three representative data-sensitive organizational scenarios and construct ChimeraLog, a new dataset for developing and evaluating ITD methods.\n  We evaluate ChimeraLog through human studies and quantitative analyses, demonstrating its diversity and realism. Experiments with existing ITD methods show substantially lower detection performance on ChimeraLog compared to prior datasets, indicating a more challenging and realistic benchmark. Moreover, despite distribution shifts, models trained on ChimeraLog exhibit strong generalization, highlighting the practical value of LLM-based multi-agent simulation for advancing insider threat detection.","authors":["Jiongchi Yu","Xiaofei Xie","Qiang Hu","Yuhan Ma","Ziming Zhao"],"pdf_url":"","comment":"Accepted by NDSS 2026"},{"id":"http://arxiv.org/abs/2412.06994v4","updated":"2025-12-20T17:42:59Z","published":"2024-12-09T21:01:45Z","title":"Phaedrus: Predicting Dynamic Application Behavior with Lightweight Generative Models and LLMs","summary":"Application profiling is an indispensable technique for many software development tasks, such as code and memory layout optimizations, where optimization decisions are tailored to specific program profiles. Unfortunately, modern application codebases exhibit highly variant behavior across different inputs, creating challenges for conventional profiling approaches that rely on a single representative execution instance. In this paper, we propose \\textbf{Phaedrus}, a new \\textit{compiler-assisted deep learning framework} designed to predict dynamic program behaviors across varied execution instances, specifically focusing on dynamic function call prediction.Such predicted call sequences are then used for producing optimized code pertinent to a given input.\n  Traditional profile-guided optimization methods struggle with the input-dependent variability of modern applications, where profiling on different inputs yields divergent application behaviors. To address this, Phaedrus proposes two new approaches: \\textit{Application Behavior Synthesis}, a profile-less approach where Large Language Models (LLMs) directly infer dynamic functions based on source code \\& static compiler analysis, bypassing the need for traditional profiling, and \\textit{Application Profile Generalization}, which uses generative models trained on compressed and augmented \\textit{Whole Program Path} (WPP) based function profiles to predict application behavior under unseen inputs. Our experiments show that \\textit{Phaedrus} can achieve upto $10^7X$ reduction in WPP function profile sizes, can predict most frequently executed functions that cover upto 85-99\\% of the execution time, along with an average of 13.19\\% (upto 65\\%) reduction in application binary size, and an average of 6.08\\% (upto 20\\%) performance improvement over the traditional profile-guided optimization, without any execution.","authors":["Bodhisatwa Chatterjee","Neeraj Jadhav","Santosh Pande"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18436v1","updated":"2025-12-20T17:22:52Z","published":"2025-12-20T17:22:52Z","title":"VeruSAGE: A Study of Agent-Based Verification for Rust Systems","summary":"Large language models (LLMs) have shown impressive capability to understand and develop code. However, their capability to rigorously reason about and prove code correctness remains in question. This paper offers a comprehensive study of LLMs' capability to develop correctness proofs for system software written in Rust. We curate a new system-verification benchmark suite, VeruSAGE-Bench, which consists of 849 proof tasks extracted from eight open-source Verus-verified Rust systems. Furthermore, we design different agent systems to match the strengths and weaknesses of different LLMs (o4-mini, GPT-5, Sonnet 4, and Sonnet 4.5). Our study shows that different tools and agent settings are needed to stimulate the system-verification capability of different types of LLMs. The best LLM-agent combination in our study completes over 80% of system-verification tasks in VeruSAGE-Bench. It also completes over 90% of a set of system proof tasks not part of VeruSAGE-Bench because they had not yet been finished by human experts. This result shows the great potential for LLM-assisted development of verified system software.","authors":["Chenyuan Yang","Natalie Neamtu","Chris Hawblitzel","Jacob R. Lorch","Shan Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.25692v2","updated":"2025-12-20T15:53:50Z","published":"2025-10-29T16:57:33Z","title":"A Configuration-First Framework for Reproducible, Low-Code Localization","summary":"Machine learning is increasingly permeating radio-based localization services. To keep results credible and comparable, everyday workflows should make rigorous experiment specification and exact repeatability the default, without blocking advanced experimentation. However, in practice, researchers face a three-way gap that could be filled by a framework that offers (i) low coding effort for end-to-end studies, (ii) reproducibility by default, including versioned code, data, and configurations, controlled randomness, isolated runs, and recorded artifacts, and (iii) built-in extensibility so new models, metrics, and stages can be added with minimal integration effort. Existing tools rarely deliver all three for machine learning in general and localization workflows in particular. In this paper, we introduce LOCALIZE, a low-code, configuration-first framework for radio localization in which experiments are declared in human-readable configuration files, a workflow orchestrator executes standardized pipelines from data preparation to reporting, and all artifacts, such as datasets, models, metrics, and reports, are versioned. Preconfigured, versioned datasets reduce initial setup effort and boilerplate, thereby accelerating model development and evaluation. The design, with explicit extension points, allows experts to add components without reworking the underlying infrastructure. Through a qualitative comparison and a head-to-head study against a plain Jupyter notebook baseline, we show that the framework reduces authoring effort while maintaining comparable runtime and memory behavior. Furthermore, using a Bluetooth Low Energy dataset, we demonstrate that scaling the training data from 1x to 10x keeps orchestration overheads bounded as data grows. Overall, the framework makes reproducible machine-learning-based localization experimentation practical, accessible, and extensible.","authors":["Tim Strnad","Blaž Bertalanič","Carolina Fortuna"],"pdf_url":"","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2409.11068v2","updated":"2025-12-20T13:52:49Z","published":"2024-09-17T10:49:45Z","title":"A Reinforcement Learning Environment for Automatic Code Optimization in the MLIR Compiler","summary":"Code optimization is a crucial task that aims to enhance code performance. However, this process is often tedious and complex, highlighting the necessity for automatic code optimization techniques. Reinforcement Learning (RL) has emerged as a promising approach for tackling such complex optimization problems. In this project, we introduce MLIR RL, an RL environment for the MLIR compiler, dedicated to facilitating MLIR compiler research and enabling automatic code optimization. We propose a multi-discrete formulation of the action space where the action space is the Cartesian product of simpler action subspaces. We also propose a new method, called level pointers, to reduce the size of the action space related to the loop interchange transformation. This enables more efficient and effective learning of the policy. To demonstrate the effectiveness of MLIR RL, we train an RL agent to optimize MLIR Linalg code, targeting CPU. The code is generated from two domain-specific frameworks: deep-learning models generated from PyTorch, and LQCD (Lattice Quantum Chromodynamics) code generated from an LQCD compiler. The result of this work is a research environment that allows the community to experiment with novel ideas in RL-driven loop-nest optimization.","authors":["Mohammed Tirichine","Nassim Ameur","Nazim Bendib","Iheb Nassim Aouadj","Bouchama Djad","Rafik Bouloudene","Riyadh Baghdadi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18311v1","updated":"2025-12-20T10:46:04Z","published":"2025-12-20T10:46:04Z","title":"Monitoring Monitorability","summary":"Observability into the decision making of modern AI systems may be required to safely deploy increasingly capable agents. Monitoring the chain-of-thought (CoT) of today's reasoning models has proven effective for detecting misbehavior. However, this \"monitorability\" may be fragile under different training procedures, data sources, or even continued system scaling. To measure and track monitorability, we propose three evaluation archetypes (intervention, process, and outcome-property) and a new monitorability metric, and introduce a broad evaluation suite. We demonstrate that these evaluations can catch simple model organisms trained to have obfuscated CoTs, and that CoT monitoring is more effective than action-only monitoring in practical settings. We compare the monitorability of various frontier models and find that most models are fairly, but not perfectly, monitorable. We also evaluate how monitorability scales with inference-time compute, reinforcement learning optimization, and pre-training model size. We find that longer CoTs are generally more monitorable and that RL optimization does not materially decrease monitorability even at the current frontier scale. Notably, we find that for a model at a low reasoning effort, we could instead deploy a smaller model at a higher reasoning effort (thereby matching capabilities) and obtain a higher monitorability, albeit at a higher overall inference compute cost. We further investigate agent-monitor scaling trends and find that scaling a weak monitor's test-time compute when monitoring a strong agent increases monitorability. Giving the weak monitor access to CoT not only improves monitorability, but it steepens the monitor's test-time compute to monitorability scaling trend. Finally, we show we can improve monitorability by asking models follow-up questions and giving their follow-up CoT to the monitor.","authors":["Melody Y. Guan","Miles Wang","Micah Carroll","Zehao Dou","Annie Y. Wei","Marcus Williams","Benjamin Arnav","Joost Huizinga","Ian Kivlichan","Mia Glaese","Jakub Pachocki","Bowen Baker"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.05720v2","updated":"2025-12-20T09:25:46Z","published":"2025-11-07T21:27:47Z","title":"An Architecture for Remote Container Builds and Artifact Delivery Using a Controller-Light Jenkins CI/CD Pipeline","summary":"Resource-intensive builds are often executed directly on the controller by conventional Jenkins installations, which can lower reliability and overload system resources. Jenkins functions as a containerized controller with persistent volumes in the controller-light CI/CD framework presented in this paper, delegating difficult build and packaging tasks to a remote Docker host. The controller container maintains secure SSH connections to remote compute nodes while focusing solely on orchestration and reporting. Atomic deployments with time-stamped backups, containerized build environments, immutable artifact packaging, and automated notifications are all included in the system. Faster build throughput, reduced CPU and RAM consumption on the controller, and reduced artifact delivery latency are all revealed by experimental evaluation. For small and medium-sized DevOps businesses looking for scalable automation without adding orchestration complexity, this method offers a repeatable, low-maintenance solution.","authors":["Kawshik Kumar Paul","Sawmik Kumar Paul"],"pdf_url":"","comment":"v2: revised writing and presentation; clarified contributions and experimental discussion"},{"id":"http://arxiv.org/abs/2512.18261v1","updated":"2025-12-20T07:58:35Z","published":"2025-12-20T07:58:35Z","title":"Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective","summary":"Artificial Intelligence (AI) has revolutionized software development, particularly by automating repetitive tasks and improving developer productivity. While these advancements are well-documented, the use of AI-powered tools for Software Vulnerability Management (SVM), such as vulnerability detection and repair, remains underexplored in industry settings. To bridge this gap, our study aims to determine the extent of the adoption of AI-powered tools for SVM, identify barriers and facilitators to the use, and gather insights to help improve the tools to meet industry needs better. We conducted a survey study involving 60 practitioners from diverse industry sectors across 27 countries. The survey incorporates both quantitative and qualitative questions to analyze the adoption trends, assess tool strengths, identify practical challenges, and uncover opportunities for improvement. Our findings indicate that AI-powered tools are used throughout the SVM life cycle, with 69\\% of users reporting satisfaction with their current use. Practitioners value these tools for their speed, coverage, and accessibility. However, concerns about false positives, missing context, and trust issues remain prevalent. We observe a socio-technical adoption pattern in which AI outputs are filtered through human oversight and organizational governance. To support safe and effective use of AI for SVM, we recommend improvements in explainability, contextual awareness, integration workflows, and validation practices. We assert that these findings can offer practical guidance for practitioners, tool developers, and researchers seeking to enhance secure software development through the use of AI.","authors":["M. Mehdi Kholoosi","Triet Huynh Minh Le","M. Ali Babar"],"pdf_url":"","comment":"Accepted at the 48th IEEE/ACM International Conference on Software Engineering (ICSE 2026) - Research Track"},{"id":"http://arxiv.org/abs/2512.18228v1","updated":"2025-12-20T06:01:11Z","published":"2025-12-20T06:01:11Z","title":"Toward Efficient Testing of Graph Neural Networks via Test Input Prioritization","summary":"Graph Neural Networks (GNNs) have demonstrated remarkable efficacy in handling graph-structured data; however, they exhibit failures after deployment, which can cause severe consequences. Hence, conducting thorough testing before deployment becomes imperative to ensure the reliability of GNNs. However, thorough testing requires numerous manually annotated test data. To mitigate the annotation cost, strategically prioritizing and labeling high-quality unlabeled inputs for testing becomes crucial, which facilitates uncovering more model failures with a limited labeling budget. Unfortunately, existing test input prioritization techniques either overlook the valuable information contained in graph structures or are overly reliant on attributes extracted from the target model, i.e., model-aware attributes, whose quality can vary significantly. To address these issues, we propose a novel test input prioritization framework, named GraphRank, for GNNs. GraphRank introduces model-agnostic attributes to compensate for the limitations of the model-aware ones. It also leverages the graph structure information to aggregate attributes from neighboring nodes, thereby enhancing the model-aware and model-agnostic attributes. Furthermore, GraphRank combines the above attributes with a binary classifier, using it as a ranking model to prioritize inputs. This classifier undergoes iterative training, which enables it to learn from each round's feedback and improve its performance accordingly. Extensive experiments demonstrate GraphRank's superiority over existing techniques.","authors":["Lichen Yang","Qiang Wang","Zhonghao Yang","Daojing He","Yu Li"],"pdf_url":"","comment":"This is the author-accepted manuscript of a paper published in Automated Software Engineering Journal"},{"id":"http://arxiv.org/abs/2512.10398v5","updated":"2025-12-20T04:25:21Z","published":"2025-12-11T08:05:58Z","title":"Confucius Code Agent: Scalable Agent Scaffolding for Real-World Codebases","summary":"Real-world software engineering tasks require coding agents that can operate over massive repositories, sustain long-horizon sessions, and reliably coordinate complex toolchains at test time. Existing research-grade coding agents offer transparency but struggle when scaled to heavier, production-level workloads, while production-grade systems achieve strong practical performance but provide limited extensibility, interpretability, and controllability. We introduce the Confucius Code Agent (CCA), a software engineering agent that can operate at large-scale codebases. CCA is built on top of the Confucius SDK, an agent development platform structured around three complementary perspectives: Agent Experience (AX), User Experience (UX), and Developer Experience (DX). The SDK integrates a unified orchestrator with hierarchical working memory for long-context reasoning, a persistent note-taking system for cross-session continual learning, and a modular extension system for reliable tool use. In addition, we introduce a meta-agent that automates the synthesis, evaluation, and refinement of agent configurations through a build-test-improve loop, enabling rapid adaptation to new tasks, environments, and tool stacks. Instantiated with these mechanisms, CCA demonstrates strong performance on real-world software engineering tasks. On SWE-Bench-Pro, CCA reaches a Resolve@1 of 54.3%, exceeding prior research baselines and comparing favorably to commercial results, under identical repositories, model backends, and tool access.","authors":["Sherman Wong","Zhenting Qi","Zhaodong Wang","Nathan Hu","Samuel Lin","Jun Ge","Erwin Gao","Wenlin Chen","Yilun Du","Minlan Yu","Ying Zhang"],"pdf_url":"","comment":"The latest version"},{"id":"http://arxiv.org/abs/2512.18182v1","updated":"2025-12-20T02:37:10Z","published":"2025-12-20T02:37:10Z","title":"Understanding Typing-Related Bugs in Solidity Compiler","summary":"The correctness of the Solidity compiler is crucial for ensuring the security of smart contracts. However, the implementation complexity of its type system often introduces elusive defects. This paper presents the first systematic empirical study on typing-related bugs in the Solidity compiler. To systematically analyze these bugs, we collected 146 officially confirmed and fixed typing-related bugs from the official GitHub repository of Solidity compiler. For each bug, we conducted an in-depth analysis and classification from four dimensions: symptoms, root causes, exposure conditions, and fix strategies. Through this study, we reveal unique distribution patterns and key characteristics of such bugs, and summarize 12 core findings. We additionally give the implications of our findings, and these implications not only deepen the understanding of inherent weaknesses in the Solidity compiler but also provide new insights for detecting and fixing typing-related bugs in the Solidity compiler.","authors":["Lantian Li","Yue Pan","Dan Wang","Jingwen Wu","Zhongxing Yu"],"pdf_url":"","comment":"37 pages, 8 figures"}],"Performance":[{"id":"http://arxiv.org/abs/2512.18457v1","updated":"2025-12-20T18:23:10Z","published":"2025-12-20T18:23:10Z","title":"Age of Information with Age-Dependent Server Selection","summary":"In this paper, we consider a single-source multi-server generate-at-will discrete-time non-preemptive status update system where update packets are transmitted using {\\em only one} of the available servers, according to a server selection policy. In particular, when a transmission is complete, the update system makes a threshold-based decision on whether to wait or transmit, and if latter, which server to use for transmissions, on the basis of the instantaneous value of the age of information (AoI) process. In our setting, servers have general heterogeneous discrete phase-type (DPH) distributed service times, and also heterogeneous transmission costs. The goal is to find an age-dependent multi-threshold policy that minimizes the AoI cost with a constraint on transmission costs, the former cost defined in terms of the time average of an arbitrary function of AoI. For this purpose, we propose a novel tool called \\emph{multi-regime absorbing Markov chain} (MR-AMC) in discrete time. Using the MR-AMC framework, we exactly obtain the distribution of AoI, and subsequently the costs associated with AoI and transmissions. With the exact analysis in hand, optimum thresholds can be obtained in the case of a few servers, by exhaustive search. We validate the proposed analytical model, and also demonstrate the benefits of age-dependent server selection, with numerical examples.","authors":["Nail Akar","Ismail Cosandal","Sennur Ulukus"],"pdf_url":"","comment":"11 pages, 6 figures, preliminary version presented at Asilomar Conference, 2025"},{"id":"http://arxiv.org/abs/2508.13057v6","updated":"2025-12-20T00:56:55Z","published":"2025-08-18T16:25:49Z","title":"Hierarchical Evaluation Function: A Multi-Metric Approach for Optimizing Demand Forecasting Models","summary":"Demand forecasting in competitive, uncertain business environments requires models that can integrate multiple evaluation perspectives rather than being restricted to hyperparameter optimization based on a single metric. This traditional approach tends to prioritize one error indicator, which can bias results when metrics provide contradictory signals. In this context, the Hierarchical Evaluation Function (HEF) is proposed as a multi-metric framework for hyperparameter optimization that integrates explanatory power (R2), sensitivity to extreme errors (RMSE), and average accuracy (MAE). The performance of HEF was assessed using four widely recognized benchmark datasets in the forecasting domain: Walmart, M3, M4, and M5. Prediction models were optimized through Grid Search, Particle Swarm Optimization (PSO), and Optuna, and statistical analyses based on difference-of-proportions tests confirmed that HEF delivers superior results compared to a unimetric reference function, regardless of the optimizer employed, with particular relevance for heterogeneous monthly time series (M3) and highly granular daily demand scenarios (M5). The findings demonstrate that HEF improves stability, generalization, and robustness at low computational cost, consolidating its role as a reliable evaluation framework that enhances model selection, enables more accurate demand forecasts, and supports decision-making in dynamic, competitive business environments.","authors":["Adolfo González","Víctor Parada"],"pdf_url":"","comment":"31 pages, 15 figures, 25 tables. Submitted as a preprint. The manuscript introduces the Hierarchical Evaluation Function, a multi-metric framework for optimizing demand forecasting models under high uncertainty. Includes extensive experimental validation using real-world datasets and a comparative analysis against classical and modern methods"},{"id":"http://arxiv.org/abs/2512.18155v1","updated":"2025-12-20T00:31:24Z","published":"2025-12-20T00:31:24Z","title":"Performance Guarantees for Data Freshness in Resource-Constrained Adversarial IoT Systems","summary":"Timely updates are critical for real-time monitoring and control applications powered by the Internet of Things (IoT). As these systems scale, they become increasingly vulnerable to adversarial attacks, where malicious agents interfere with legitimate transmissions to reduce data rates, thereby inflating the age of information (AoI). Existing adversarial AoI models often assume stationary channels and overlook queueing dynamics arising from compromised sensing sources operating under resource constraints. Motivated by the G-queue framework, this paper investigates a two-source M/G/1/1 system in which one source is adversarial and disrupts the update process by injecting negative arrivals according to a Poisson process and inducing i.i.d. service slowdowns, bounded in attack rate and duration. Using moment generating functions, we then derive closed-form expressions for average and peak AoI for an arbitrary number of sources. Moreover, we introduce a worst-case constrained attack model and employ stochastic dominance arguments to establish analytical AoI bounds. Numerical results validate the analysis and highlight the impact of resource-limited adversarial interference under general service time distributions.","authors":["Aresh Dadlani","Muthukrishnan Senthil Kumar","Omid Ardakanian","Ioanis Nikolaidis"],"pdf_url":"","comment":"6 pages, 4 figures, conference paper"}],"Programming Languages":[{"id":"http://arxiv.org/abs/2412.06994v4","updated":"2025-12-20T17:42:59Z","published":"2024-12-09T21:01:45Z","title":"Phaedrus: Predicting Dynamic Application Behavior with Lightweight Generative Models and LLMs","summary":"Application profiling is an indispensable technique for many software development tasks, such as code and memory layout optimizations, where optimization decisions are tailored to specific program profiles. Unfortunately, modern application codebases exhibit highly variant behavior across different inputs, creating challenges for conventional profiling approaches that rely on a single representative execution instance. In this paper, we propose \\textbf{Phaedrus}, a new \\textit{compiler-assisted deep learning framework} designed to predict dynamic program behaviors across varied execution instances, specifically focusing on dynamic function call prediction.Such predicted call sequences are then used for producing optimized code pertinent to a given input.\n  Traditional profile-guided optimization methods struggle with the input-dependent variability of modern applications, where profiling on different inputs yields divergent application behaviors. To address this, Phaedrus proposes two new approaches: \\textit{Application Behavior Synthesis}, a profile-less approach where Large Language Models (LLMs) directly infer dynamic functions based on source code \\& static compiler analysis, bypassing the need for traditional profiling, and \\textit{Application Profile Generalization}, which uses generative models trained on compressed and augmented \\textit{Whole Program Path} (WPP) based function profiles to predict application behavior under unseen inputs. Our experiments show that \\textit{Phaedrus} can achieve upto $10^7X$ reduction in WPP function profile sizes, can predict most frequently executed functions that cover upto 85-99\\% of the execution time, along with an average of 13.19\\% (upto 65\\%) reduction in application binary size, and an average of 6.08\\% (upto 20\\%) performance improvement over the traditional profile-guided optimization, without any execution.","authors":["Bodhisatwa Chatterjee","Neeraj Jadhav","Santosh Pande"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.00138v2","updated":"2025-12-20T02:03:05Z","published":"2025-01-31T19:43:48Z","title":"JustAct+: A Framework for Auditable Multi-Agent Systems Regulated by Inter-Organisational Policies","summary":"In open multi-agent agent systems that cross organisational boundaries, agent actions must be regulated by complex policies. Consider medical data processing systems, which must observe generic laws (e.g., EU data protection regulations) and also specific participants' resource conditions (e.g., Bob consents to sharing his X-Rays with EU hospitals). Presently, we address the implementation of these systems as distributed software. Solutions to key sub-problems are available: existing policy languages capture the necessary normative concepts and formalise the computational representation and reasoning about policies, and existing distributed algorithms and protocols coordinate agents' changing actions and policies. But which policies and protocols are useful in application? With the JustAct framework, we characterise a class of multi-agent systems where actors justify their actions with sufficient policy information collected from dynamic policy statements and agreements. We prove key properties of these systems, e.g., any decision that an action is permitted now cannot be refuted later, regardless of any added statements or updated agreements. We study a particular instance of the framework by specifying (in Rocq) and implementing (in Rust) a particular policy language and runtime system for mediating agent communications. We demonstrate and assess JustAct via a case study of this implementation: we reproduce the usage scenarios of Brane, an existing policy-regulated, inter-domain, medical data processing system.","authors":["Christopher A. Esterhuyse","Tim Müller","L. Thomas van Binsbergen"],"pdf_url":"","comment":null}]},"2025-12-23T00:00:00Z":{"Distributed, Parallel, and Cluster Computing":[{"id":"http://arxiv.org/abs/2512.20573v1","updated":"2025-12-23T18:16:58Z","published":"2025-12-23T18:16:58Z","title":"Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs","summary":"Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM's speed from parallel decoding drastically lowers the risk of costly rejections, providing a practical mechanism to effectively realize the (elusive) lengthy drafts that lead to large speedups with speculative decoding. We present FailFast, a dLLM-based speculative decoding framework that realizes this approach by dynamically adapting its speculation length. It \"fails fast\" by spending minimal compute in hard-to-speculate regions to shrink speculation latency and \"wins big\" by aggressively extending draft lengths in easier regions to reduce verification latency (in many cases, speculating and accepting 70 tokens at a time!). Without any fine-tuning, FailFast delivers lossless acceleration of AR LLMs and achieves up to 4.9$\\times$ speedup over vanilla decoding, 1.7$\\times$ over the best naive dLLM drafter, and 1.4$\\times$ over EAGLE-3 across diverse models and workloads. We open-source FailFast at https://github.com/ruipeterpan/failfast.","authors":["Rui Pan","Zhuofu Chen","Ravi Netravali"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20485v1","updated":"2025-12-23T16:21:22Z","published":"2025-12-23T16:21:22Z","title":"WOC: Dual-Path Weighted Object Consensus Made Efficient","summary":"Modern distributed systems face a critical challenge: existing consensus protocols optimize for either node heterogeneity or workload independence, but not both. For example, Cabinet leverages weighted quorums to handle node heterogeneity but serializes all operations through a global leader, limiting parallelism. EPaxos enables parallel execution for independent operations but treats all nodes uniformly, ignoring performance differences. To tackle this problem, we present WOC, a dual-path consensus protocol that dynamically routes operations into two paths based on their access patterns. Independent operations execute through a fast path that uses object-specific weighted quorums and completes in one network round-trip. Conflicting or shared objects route through a leader-coordinated slow path employing node-weighted consensus. Our evaluation demonstrates that WOC achieves up to 4X higher throughput than Cabinet for workloads with >70% independent objects, while maintaining equivalent performance under high contention.","authors":["Tanisha Fonseca","Gengrui Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.04940v3","updated":"2025-12-23T16:10:30Z","published":"2025-06-05T12:16:04Z","title":"Becoming Immutable: How Ethereum is Made","summary":"Blockchain's economic value lies in enabling financial and economic transactions that do not require trusted, centralized intermediaries. In practice, however, transactions must pass through several intermediaries before being included on-chain. We study empirically whether this process undermines blockchain's stated benefits by assembling a novel dataset of 15,097 non-winning Ethereum blocks--blocks proposed by builders but not ultimately selected for inclusion. We show that 21% of user transactions are delayed: although proposed in some candidate blocks, they are not included in the winning block. Approximately 30% of these delayed transactions are exclusive to a single losing builder, indicating that transaction routing materially affect inclusion outcomes. We further document substantial heterogeneity in execution quality: both the probability of successful execution and the execution price of users' swaps vary across candidate blocks. Finally, we study two arbitrage bots trading between decentralized (DEX) and centralized exchanges (CEX). We document intense competition for the same arbitrage opportunities and estimate that these bots trade USDC/WETH and USDT/WETH on centralized exchanges at prices approximately 2.8 basis points more favorable than contemporaneous Binance prices.","authors":["Andrea Canidio","Vabuk Pahari"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20394v1","updated":"2025-12-23T14:31:24Z","published":"2025-12-23T14:31:24Z","title":"Resilient Packet Forwarding: A Reinforcement Learning Approach to Routing in Gaussian Interconnected Networks with Clustered Faults","summary":"As Network-on-Chip (NoC) and Wireless Sensor Network architectures continue to scale, the topology of the underlying network becomes a critical factor in performance. Gaussian Interconnected Networks based on the arithmetic of Gaussian integers, offer attractive properties regarding diameter and symmetry. Despite their attractive theoretical properties, adaptive routing techniques in these networks are vulnerable to node and link faults, leading to rapid degradation in communication reliability. Node failures (particularly those following Gaussian distributions, such as thermal hotspots or physical damage clusters) pose severe challenges to traditional deterministic routing. This paper proposes a fault-aware Reinforcement Learning (RL) routing scheme tailored for Gaussian Interconnected Networks. By utilizing a PPO (Proximal Policy Optimization) agent with a specific reward structure designed to penalize fault proximity, the system dynamically learns to bypass faulty regions. We compare our proposed RL-based routing protocol against a greedy adaptive shortest-path routing algorithm. Experimental results demonstrate that the RL agent significantly outperforms the adaptive routing sustaining a Packet Delivery Ratio (PDR) of 0.95 at 40% fault density compared to 0.66 for the greedy. Furthermore, the RL approach exhibits effective delivery rates compared to the greedy adaptive routing, particularly under low network load of 20% at 0.57 vs. 0.43, showing greater proficiency in managing congestion, validating its efficacy in stochastic, fault-prone topologies","authors":["Mohammad Walid Charrwi","Zaid Hussain"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20363v1","updated":"2025-12-23T13:46:38Z","published":"2025-12-23T13:46:38Z","title":"Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning","summary":"Federated learning (FL) supports privacy-preserving, decentralized machine learning (ML) model training by keeping data on client devices. However, non-independent and identically distributed (non-IID) data across clients biases updates and degrades performance. To alleviate these issues, we propose Clust-PSI-PFL, a clustering-based personalized FL framework that uses the Population Stability Index (PSI) to quantify the level of non-IID data. We compute a weighted PSI metric, $WPSI^L$, which we show to be more informative than common non-IID metrics (Hellinger, Jensen-Shannon, and Earth Mover's distance). Using PSI features, we form distributionally homogeneous groups of clients via K-means++; the number of optimal clusters is chosen by a systematic silhouette-based procedure, typically yielding few clusters with modest overhead. Across six datasets (tabular, image, and text modalities), two partition protocols (Dirichlet with parameter $α$ and Similarity with parameter S), and multiple client sizes, Clust-PSI-PFL delivers up to 18% higher global accuracy than state-of-the-art baselines and markedly improves client fairness by a relative improvement of 37% under severe non-IID data. These results establish PSI-guided clustering as a principled, lightweight mechanism for robust PFL under label skew.","authors":["Daniel M. Jimenez-Gutierrez","Mehrdad Hassanzadeh","Aris Anagnostopoulos","Ioannis Chatzigiannakis","Andrea Vitaletti"],"pdf_url":"","comment":"Accepted for publication to the 40th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2026)"},{"id":"http://arxiv.org/abs/2512.20210v1","updated":"2025-12-23T10:03:47Z","published":"2025-12-23T10:03:47Z","title":"Predictive-LoRA: A Proactive and Fragmentation-Aware Serverless Inference System for LLMs","summary":"The serverless computing paradigm offers compelling advantages for deploying Large Language Model (LLM) inference services, including elastic scaling and pay-per-use billing. However, serving multiple fine-tuned LLMs via Low-Rank Adaptation (LoRA) in serverless environments faces critical challenges: reactive adapter loading causes significant cold start latency, and frequent adapter swapping leads to severe GPU memory fragmentation. In this paper, we present Predictive-LoRA (P-LoRA), a proactive and fragmentation-aware serverless inference system for LoRA-based LLMs. P-LoRA introduces two key innovations: (1) a lightweight LSTM-based traffic predictor that forecasts adapter demand and proactively prefetches hot adapters from host memory to GPU, reducing cold start latency by up to 68%; and (2) a page-based adapter memory management mechanism inspired by operating system virtual memory, which keeps GPU memory utilization above 87% even under heterogeneous adapter ranks. We evaluate P-LoRA using production-like workloads derived from the Azure Functions trace. Experimental results demonstrate that P-LoRA achieves 1.52x higher throughput than S-LoRA while reducing the average Time-To-First-Token (TTFT) by 35% under high concurrency scenarios.","authors":["Yinan Ni","Xiao Yang","Yuqi Tang","Zhimin Qiu","Chen Wang","Tingzhou Yuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16193v3","updated":"2025-12-23T09:31:34Z","published":"2025-11-20T10:00:03Z","title":"Fast LLM Post-training via Decoupled and Fastest-of-N Speculation","summary":"Rollout dominates the training time in large language model (LLM) post-training, where the trained model is used to generate tokens given a batch of prompts. This work, SpecActor, achieves fast rollout with speculative decoding that deploys a fast draft path to accelerate the unparallelizable generation, while the correctness is guaranteed by fast parallel verification of the outputs with the original model. SpecActor addresses two foundational challenges that hinder speculation efficiency: (1) a Decoupled speculation method that overcomes the computation inefficiency issue when executing speculative decoding with relative large per-worker batch size -- a common configuration in training but unfriendly to speculation, and (2) a Fastest-of-N speculation method that selects and combines different draft methods according to the rollout progress to approximate the optimal draft method even when the best one is unknown a priori. Extensive evaluations on production traces show that SpecActor accelerates mean rollout speed by 2.0--2.4x, with up to 2.7x speedup, over common post-training baselines. The results are consistent across both dense and MoE models and across different RL algorithms. Notably, SpecActor is 1.1--2.6x faster compared to vanilla speculative rollout in different traces. The accelerated rollout achieves 1.4--2.3x faster end-to-end training time.","authors":["Rongxin Cheng","Kai Zhou","Xingda Wei","Siyuan Liu","Mingcong Han","Mingjing Ai","Yeju Zhou","Baoquan Zhong","Wencong Xiao","Rong Chen","Haibo Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20184v1","updated":"2025-12-23T09:20:42Z","published":"2025-12-23T09:20:42Z","title":"Reaching Agreement Among Reasoning LLM Agents","summary":"Multi-agent systems have extended the capability of agentic AI. Instead of single inference passes, multiple agents perform collective reasoning to derive high quality answers. However, existing multi-agent orchestration relies on static heuristic workflows such as fixed loop limits and barrier synchronization. These ad-hoc approaches waste computational resources, incur high latency due to stragglers, and risk finalizing transient agreements. We argue that reliable multi-agent reasoning requires a formal foundation analogous to classical distributed consensus problem.\n  To that end, we propose a formal model of the multi-agent refinement problem. The model includes definitions of the correctness guarantees and formal semantics of agent reasoning. We then introduce Aegean, a consensus protocol designed for stochastic reasoning agents that solves multi-agent refinement. We implement the protocol in Aegean-Serve, a consensus-aware serving engine that performs incremental quorum detection across concurrent agent executions, enabling early termination when sufficient agents converge. Evaluation using four mathematical reasoning benchmarks shows that Aegean provides provable safety and liveness guarantees while reducing latency by 1.2--20$\\times$ compared to state-of-the-art baselines, maintaining answer quality within 2.5%. Consistent gains across both local GPU deployments and commercial API providers validate that consensus-based orchestration eliminates straggler delays without sacrificing correctness.","authors":["Chaoyi Ruan","Yiliang Wang","Ziji Shi","Jialin Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20178v1","updated":"2025-12-23T09:16:52Z","published":"2025-12-23T09:16:52Z","title":"SHIRO: Near-Optimal Communication Strategies for Distributed Sparse Matrix Multiplication","summary":"Distributed Sparse Matrix-Matrix Multiplication (SpMM) is a fundamental operation in numerous high-performance computing and deep learning applications. The major performance bottleneck in distributed SpMM lies in the substantial communication overhead, which limits both performance and scalability. In this paper, we identify and analyze sources of inefficient communication in existing distributed SpMM implementations at two levels and address these inefficiencies by proposing: (1) a fine-grained, sparsity-aware communication strategy that reduces communication overhead by exploiting the sparsity pattern of the sparse matrix, and (2) a hierarchical communication strategy that integrates the sparsity-aware strategy with the common two-tier network architectures in GPU-accelerated systems, to reduce redundant communication across slow network links. We implement these optimizations in a comprehensive distributed SpMM framework, \\method{}. Extensive evaluations on real-world datasets show that our framework demonstrates strong scalability up to 128 GPUs, achieving geometric mean speedups of 221.5$\\times$, 56.0$\\times$, 23.4$\\times$, and 8.8$\\times$ over four state-of-the-art baselines (CAGNET, SPA, BCL, and CoLa, respectively) at this scale.","authors":["Chen Zhuang","Lingqi Zhang","Benjamin Brock","Du Wu","Peng Chen","Toshio Endo","Satoshi Matsuoka","Mohamed Wahib"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2512.20163v1","updated":"2025-12-23T08:41:10Z","published":"2025-12-23T08:41:10Z","title":"Population Protocols Revisited: Parity and Beyond","summary":"For nearly two decades, population protocols have been extensively studied, yielding efficient solutions for central problems in distributed computing, including leader election, and majority computation, a predicate type in Presburger Arithmetic closely tied to population protocols. Surprisingly, no protocols have achieved both time- and space-efficiency for congruency predicates, such as parity computation, which are complementary in this arithmetic framework. This gap highlights a significant challenge in the field. To address this gap, we explore the parity problem, where agents are tasked with computing the parity of the given sub-population size. Then we extend the solution for parity to compute congruences modulo an arbitrary $m$.\n  Previous research on efficient population protocols has focused on protocols that minimise both stabilisation time and state utilisation for specific problems. In contrast, this work slightly relaxes this expectation, permitting protocols to place less emphasis on full optimisation and more on universality, robustness, and probabilistic guarantees. This allows us to propose a novel computing paradigm that integrates population weights (or simply weights), a robust clocking mechanism, and efficient anomaly detection coupled with a switching mechanism (which ensures slow but always correct solutions). This paradigm facilitates universal design of efficient multistage stable population protocols. Specifically, the first efficient parity and congruence protocols introduced here use both $O(\\log^3 n)$ states and achieve silent stabilisation in $O(\\log^3 n)$ time. We conclude by discussing the impact of implicit conversion between unary and binary representations enabled by the weight system, with applications to other problems, including the computation and representation of (sub-)population sizes.","authors":["Leszek Gąsieniec","Tytus Grodzicki","Tomasz Jurdziński","Jakub Kowalski","Grzegorz Stachowiak"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20064v1","updated":"2025-12-23T05:33:57Z","published":"2025-12-23T05:33:57Z","title":"FastMPS: Revisit Data Parallel in Large-scale Matrix Product State Sampling","summary":"Matrix Product State (MPS) is a versatile tensor network representation widely applied in quantum physics, quantum chemistry, and machine learning, etc. MPS sampling serves as a critical fundamental operation in these fields. As the problems become more complex, the scale of MPS is rapidly increasing. Traditional data parallelism is limited by memory and heavy I/O in large-scale MPS. Model parallelism that can handle large-scale MPS imposes rigid process bindings and lacks scalability. This work proposes Fast-MPS, a multi-level parallel framework for scalable MPS sampling. Our design combines data parallelism across samples with tensor parallelism along bond dimensions. We eliminate memory and I/O pressure through compression and overlapping, and revive data parallel in large-scale MPS sampling. We evaluate our approach on Gaussian Boson Sampling, a representative and demanding application. Fast-MPS achieves over 10x speedup compared to existing simulators, scales to thousands of processes, and enables simulations with 8,176 sites and bond dimension chi = 10^4, significantly outperforming the state of the art. Fast-MPS has demonstrated great potential in high-performance tensor network applications.","authors":["Yaojian Chen","Si-Qiu Gong","Lin Gan","Yanfei Liu","An Yang","Yinuo Wang","Chao-yang Lu","Guangwen Yang"],"pdf_url":"","comment":"12 pages, 13 figures"},{"id":"http://arxiv.org/abs/2512.20017v1","updated":"2025-12-23T03:17:04Z","published":"2025-12-23T03:17:04Z","title":"Scaling Point-based Differentiable Rendering for Large-scale Reconstruction","summary":"Point-based Differentiable Rendering (PBDR) enables high-fidelity 3D scene reconstruction, but scaling PBDR to high-resolution and large scenes requires efficient distributed training systems. Existing systems are tightly coupled to a specific PBDR method. And they suffer from severe communication overhead due to poor data locality. In this paper, we present Gaian, a general distributed training system for PBDR. Gaian provides a unified API expressive enough to support existing PBDR methods, while exposing rich data-access information, which Gaian leverages to optimize locality and reduce communication. We evaluated Gaian by implementing 4 PBDR algorithms. Our implementations achieve high performance and resource efficiency: across six datasets and up to 128 GPUs, it reduces communication by up to 91% and improves training throughput by 1.50x-3.71x.","authors":["Hexu Zhao","Xiaoteng Liu","Xiwen Min","Jianhao Huang","Youming Deng","Yanfei Li","Ang Li","Jinyang Li","Aurojit Panda"],"pdf_url":"","comment":"13 pages main text, plus appendix"},{"id":"http://arxiv.org/abs/2505.09343v2","updated":"2025-12-23T03:00:00Z","published":"2025-05-14T12:39:03Z","title":"Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures","summary":"The rapid scaling of large language models (LLMs) has unveiled critical limitations in current hardware architectures, including constraints in memory capacity, computational efficiency, and interconnection bandwidth. DeepSeek-V3, trained on 2,048 NVIDIA H800 GPUs, demonstrates how hardware-aware model co-design can effectively address these challenges, enabling cost-efficient training and inference at scale. This paper presents an in-depth analysis of the DeepSeek-V3/R1 model architecture and its AI infrastructure, highlighting key innovations such as Multi-head Latent Attention (MLA) for enhanced memory efficiency, Mixture of Experts (MoE) architectures for optimized computation-communication trade-offs, FP8 mixed-precision training to unlock the full potential of hardware capabilities, and a Multi-Plane Network Topology to minimize cluster-level network overhead. Building on the hardware bottlenecks encountered during DeepSeek-V3's development, we engage in a broader discussion with academic and industry peers on potential future hardware directions, including precise low-precision computation units, scale-up and scale-out convergence, and innovations in low-latency communication fabrics. These insights underscore the critical role of hardware and model co-design in meeting the escalating demands of AI workloads, offering a practical blueprint for innovation in next-generation AI systems.","authors":["Chenggang Zhao","Chengqi Deng","Chong Ruan","Damai Dai","Huazuo Gao","Jiashi Li","Liyue Zhang","Panpan Huang","Shangyan Zhou","Shirong Ma","Wenfeng Liang","Ying He","Yuqing Wang","Yuxuan Liu","Y. X. Wei"],"pdf_url":"","comment":"This is the author's version of the work. It is posted here for your personal use. Not for redistribution. The definitive version appeared as part of the Industry Track in Proceedings of the 52nd Annual International Symposium on Computer Architecture (ISCA '25)"},{"id":"http://arxiv.org/abs/2512.19972v1","updated":"2025-12-23T01:34:23Z","published":"2025-12-23T01:34:23Z","title":"Rethinking Knowledge Distillation in Collaborative Machine Learning: Memory, Knowledge, and Their Interactions","summary":"Collaborative learning has emerged as a key paradigm in large-scale intelligent systems, enabling distributed agents to cooperatively train their models while addressing their privacy concerns. Central to this paradigm is knowledge distillation (KD), a technique that facilitates efficient knowledge transfer among agents. However, the underlying mechanisms by which KD leverages memory and knowledge across agents remain underexplored. This paper aims to bridge this gap by offering a comprehensive review of KD in collaborative learning, with a focus on the roles of memory and knowledge. We define and categorize memory and knowledge within the KD process and explore their interrelationships, providing a clear understanding of how knowledge is extracted, stored, and shared in collaborative settings. We examine various collaborative learning patterns, including distributed, hierarchical, and decentralized structures, and provide insights into how memory and knowledge dynamics shape the effectiveness of KD in collaborative learning. Particularly, we emphasize task heterogeneity in distributed learning pattern covering federated learning (FL), multi-agent domain adaptation (MADA), federated multi-modal learning (FML), federated continual learning (FCL), federated multi-task learning (FMTL), and federated graph knowledge embedding (FKGE). Additionally, we highlight model heterogeneity, data heterogeneity, resource heterogeneity, and privacy concerns of these tasks. Our analysis categorizes existing work based on how they handle memory and knowledge. Finally, we discuss existing challenges and propose future directions for advancing KD techniques in the context of collaborative learning.","authors":["Pengchao Han","Xi Huang","Yi Fang","Guojun Han"],"pdf_url":"","comment":"Published in IEEE TNSE"},{"id":"http://arxiv.org/abs/2512.20795v1","updated":"2025-12-23T21:42:12Z","published":"2025-12-23T21:42:12Z","title":"RHAPSODY: Execution of Hybrid AI-HPC Workflows at Scale","summary":"Hybrid AI-HPC workflows combine large-scale simulation, training, high-throughput inference, and tightly coupled, agent-driven control within a single execution campaign. These workflows impose heterogeneous and often conflicting requirements on runtime systems, spanning MPI executables, persistent AI services, fine-grained tasks, and low-latency AI-HPC coupling. Existing systems typically address only subsets of these requirements, limiting their ability to support emerging AI-HPC applications at scale. We present RHAPSODY, a multi-runtime middleware that enables concurrent execution of heterogeneous AI-HPC workloads through uniform abstractions for tasks, services, resources, and execution policies. Rather than replacing existing runtimes, RHAPSODY composes and coordinates them, allowing simulation codes, inference services, and agentic workflows to coexist within a single job allocation on leadership-class HPC platforms. We evaluate RHAPSODY with Dragon and vLLM on multiple HPC systems using representative heterogeneous, inference-at-scale, and tightly coupled AI-HPC workflows. Our results show that RHAPSODY introduces minimal runtime overhead, sustains increasing heterogeneity at scale, achieves near-linear scaling for high-throughput inference workloads, and data- and control-efficient coupling between AI and HPC tasks in agentic workflows.","authors":["Aymen Alsaadi","Mason Hooten","Mariya Goliyad","Andre Merzky","Andrew Shao","Mikhail Titov","Tianle Wang","Yian Chen","Maria Kalantzi","Kent Lee","Andrew Park","Indira Pimpalkhare","Nick Radcliffe","Colin Wahl","Pete Mendygral","Matteo Turilli","Shantenu Jha"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20715v1","updated":"2025-12-23T19:25:02Z","published":"2025-12-23T19:25:02Z","title":"SoK: Speedy Secure Finality","summary":"While Ethereum has successfully achieved dynamic availability together with safety, a fundamental delay remains between transaction execution and immutable finality. In Ethereum's current Gasper protocol, this latency is on the order of 15 minutes, exposing the network to ex ante reorganization attacks, enabling MEV extraction, and limiting the efficiency of economic settlement. These limitations have motivated a growing body of work on Speedy Secure Finality (SSF), which aims to minimize confirmation latency without weakening formal security guarantees.\n  This paper surveys the state of the art in fast finality protocol design. We introduce the core theoretical primitives underlying this space, including reorganization resilience and the generalized sleepy model, and trace their development from Goldfish to RLMD-GHOST. We then analyze the communication and aggregation bottlenecks faced by single-slot finality protocols in large validator settings. Finally, we survey the 3-slot finality (3SF) protocol as a practical synthesis that balances fast finality with the engineering constraints of the Ethereum network.","authors":["Yash Saraswat","Abhimanyu Nag"],"pdf_url":"","comment":"26 pages"}],"Computation and Language":[{"id":"http://arxiv.org/abs/2512.20612v1","updated":"2025-12-23T18:58:25Z","published":"2025-12-23T18:58:25Z","title":"Making Large Language Models Efficient Dense Retrievers","summary":"Recent work has shown that directly fine-tuning large language models (LLMs) for dense retrieval yields strong performance, but their substantial parameter counts make them computationally inefficient. While prior studies have revealed significant layer redundancy in LLMs for generative tasks, it remains unclear whether similar redundancy exists when these models are adapted for retrieval tasks, which require encoding entire sequences into fixed representations rather than generating tokens iteratively. To this end, we conduct a comprehensive analysis of layer redundancy in LLM-based dense retrievers. We find that, in contrast to generative settings, MLP layers are substantially more prunable, while attention layers remain critical for semantic aggregation. Building on this insight, we propose EffiR, a framework for developing efficient retrievers that performs large-scale MLP compression through a coarse-to-fine strategy (coarse-grained depth reduction followed by fine-grained width reduction), combined with retrieval-specific fine-tuning. Across diverse BEIR datasets and LLM backbones, EffiR achieves substantial reductions in model size and inference cost while preserving the performance of full-size models.","authors":["Yibin Lei","Shwai He","Ang Li","Andrew Yates"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20604v1","updated":"2025-12-23T18:50:54Z","published":"2025-12-23T18:50:54Z","title":"MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts","summary":"We present MoE-DiffuSeq, a mixture of experts based framework for enhancing diffusion models in long document generation. Existing diffusion based text generation models, such as DiffuSeq, suffer from high computational cost and memory overhead when applied to extended sequences. To address these challenges, MoE-DiffuSeq integrates sparse attention with a mixture of experts architecture, enabling efficient and scalable long sequence modeling. Our approach introduces a customized sparse attention mechanism designed to reduce computational complexity while preserving text quality and coherence. In addition, we incorporate a soft absorbing state within the diffusion process to accelerate sequence reconstruction and improve generation precision. Extensive experiments demonstrate that MoE-DiffuSeq significantly improves training efficiency and sampling speed compared to existing diffusion models. These advantages are particularly effective for long document scenarios, including scientific article generation, code repository modeling, and long form dialogue generation. Benchmark results further show that MoE-DiffuSeq improves efficiency, speed, accuracy, and expressiveness, advancing the practical applicability of diffusion models for high quality long form text generation.","authors":["Alexandros Christoforos","Chadbourne Davis"],"pdf_url":"","comment":"Under submission"},{"id":"http://arxiv.org/abs/2512.20595v1","updated":"2025-12-23T18:43:05Z","published":"2025-12-23T18:43:05Z","title":"Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs","summary":"We introduce Cube Bench, a Rubik's-cube benchmark for evaluating spatial and sequential reasoning in multimodal large language models (MLLMs). The benchmark decomposes performance into five skills: (i) reconstructing cube faces from images and text, (ii) choosing the optimal next move, (iii) predicting the outcome of a candidate move without applying it, (iv) executing multi-step plans while recovering from mistakes, and (v) detecting and revising one's own errors. Using a shared set of scrambled cube states, identical prompts and parsers, and a single distance-to-solved metric, we compare recent MLLMs side by side as a function of scramble depth. Across seven MLLMs, accuracy drops sharply with depth; once a trajectory stalls or diverges, models rarely recover, and high face-reconstruction accuracy does not guarantee competent action selection or multi-step execution. A pronounced closed- vs open-source gap emerges: the strongest closed model leads on both single-step perception tasks and multi-step control tasks, while open-weight models cluster near chance on the hardest settings; yet even the best MLLM degrades at higher cube complexity. A simple self-correction via reflective thinking yields modest gains but can also introduce overthinking. Cube Bench offers a compact, reproducible probe of sequential spatial reasoning in MLLMs.","authors":["Dhruv Anand","Ehsan Shareghi"],"pdf_url":"","comment":"27 pages, 5 figures, 9 tables. Cube available at https://github.com/dana-23/cube-bench"},{"id":"http://arxiv.org/abs/2512.20586v1","updated":"2025-12-23T18:32:17Z","published":"2025-12-23T18:32:17Z","title":"Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent","summary":"Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the reasoning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.","authors":["Humza Nusrat","Luke Francisco","Bing Luo","Hassan Bagher-Ebadian","Joshua Kim","Karen Chin-Snyder","Salim Siddiqui","Mira Shah","Eric Mellon","Mohammad Ghassemi","Anthony Doemer","Benjamin Movsas","Kundan Thind"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20578v1","updated":"2025-12-23T18:21:32Z","published":"2025-12-23T18:21:32Z","title":"Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits","summary":"Large language models (LLMs) generate fluent and complex outputs but often fail to recognize their own mistakes and hallucinations. Existing approaches typically rely on external judges, multi-sample consistency, or text-based self-critique, which incur additional compute or correlate weakly with true correctness. We ask: can LLMs predict their own failures by inspecting internal states during inference? We introduce Gnosis, a lightweight self-awareness mechanism that enables frozen LLMs to perform intrinsic self-verification by decoding signals from hidden states and attention patterns. Gnosis passively observes internal traces, compresses them into fixed-budget descriptors, and predicts correctness with negligible inference cost, adding only ~5M parameters and operating independently of sequence length. Across math reasoning, open-domain question answering, and academic knowledge benchmarks, and over frozen backbones ranging from 1.7B to 20B parameters, Gnosis consistently outperforms strong internal baselines and large external judges in both accuracy and calibration. Moreover, it generalizes zero-shot to partial generations, enabling early detection of failing trajectories and compute-aware control. These results show that reliable correctness cues are intrinsic to generation process and can be extracted efficiently without external supervision.","authors":["Amirhosein Ghasemabadi","Di Niu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20569v1","updated":"2025-12-23T18:12:22Z","published":"2025-12-23T18:12:22Z","title":"Distilling to Hybrid Attention Models via KL-Guided Layer Selection","summary":"Distilling pretrained softmax attention Transformers into more efficient hybrid architectures that interleave softmax and linear attention layers is a promising approach for improving the inference efficiency of LLMs without requiring expensive pretraining from scratch. A critical factor in the conversion process is layer selection, i.e., deciding on which layers to convert to linear attention variants. This paper describes a simple and efficient recipe for layer selection that uses layer importance scores derived from a small amount of training on generic text data. Once the layers have been selected we use a recent pipeline for the distillation process itself \\citep[RADLADS;][]{goldstein2025radlads}, which consists of attention weight transfer, hidden state alignment, KL-based distribution matching, followed by a small amount of finetuning. We find that this approach is more effective than existing approaches for layer selection, including heuristics that uniformly interleave linear attentions based on a fixed ratio, as well as more involved approaches that rely on specialized diagnostic datasets.","authors":["Yanhong Li","Songlin Yang","Shawn Tan","Mayank Mishra","Rameswar Panda","Jiawei Zhou","Yoon Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20491v1","updated":"2025-12-23T16:32:27Z","published":"2025-12-23T16:32:27Z","title":"Step-DeepResearch Technical Report","summary":"As LLMs shift toward autonomous agents, Deep Research has emerged as a pivotal metric. However, existing academic benchmarks like BrowseComp often fail to meet real-world demands for open-ended research, which requires robust skills in intent recognition, long-horizon decision-making, and cross-source verification. To address this, we introduce Step-DeepResearch, a cost-effective, end-to-end agent. We propose a Data Synthesis Strategy Based on Atomic Capabilities to reinforce planning and report writing, combined with a progressive training path from agentic mid-training to SFT and RL. Enhanced by a Checklist-style Judger, this approach significantly improves robustness. Furthermore, to bridge the evaluation gap in the Chinese domain, we establish ADR-Bench for realistic deep research scenarios. Experimental results show that Step-DeepResearch (32B) scores 61.4% on Scale AI Research Rubrics. On ADR-Bench, it significantly outperforms comparable models and rivals SOTA closed-source models like OpenAI and Gemini DeepResearch. These findings prove that refined training enables medium-sized models to achieve expert-level capabilities at industry-leading cost-efficiency.","authors":["Chen Hu","Haikuo Du","Heng Wang","Lin Lin","Mingrui Chen","Peng Liu","Ruihang Miao","Tianchi Yue","Wang You","Wei Ji","Wei Yuan","Wenjin Deng","Xiaojian Yuan","Xiaoyun Zhang","Xiangyu Liu","Xikai Liu","Yanming Xu","Yicheng Cao","Yifei Zhang","Yongyao Wang","Yubo Shu","Yurong Zhang","Yuxiang Zhang","Zheng Gong","Zhichao Chang","Binyan Li","Dan Ma","Furong Jia","Hongyuan Wang","Jiayu Liu","Jing Bai","Junlan Liu","Manjiao Liu","Na Wang","Qiuping Wu","Qinxin Du","Shiwei Li","Wen Sun","Yifeng Gong","Yonglin Chen","Yuling Zhao","Yuxuan Lin","Ziqi Ren","Zixuan Wang","Aihu Zhang","Brian Li","Buyun Ma","Kang An","Li Xie","Mingliang Li","Pan Li","Shidong Yang","Xi Chen","Xiaojia Liu","Yuchu Luo","Yuan Song","YuanHao Ding","Yuanwei Liang","Zexi Li","Zhaoning Zhang","Zixin Zhang","Binxing Jiao","Daxin Jiang","Jiansheng Chen","Jing Li","Xiangyu Zhang","Yibo Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20481v1","updated":"2025-12-23T16:16:42Z","published":"2025-12-23T16:16:42Z","title":"Coherence in the brain unfolds across separable temporal regimes","summary":"Coherence in language requires the brain to satisfy two competing temporal demands: gradual accumulation of meaning across extended context and rapid reconfiguration of representations at event boundaries. Despite their centrality to language and thought, how these processes are implemented in the human brain during naturalistic listening remains unclear. Here, we tested whether these two processes can be captured by annotation-free drift and shift signals and whether their neural expression dissociates across large-scale cortical systems. These signals were derived from a large language model (LLM) and formalized contextual drift and event shifts directly from the narrative input. To enable high-precision voxelwise encoding models with stable parameter estimates, we densely sampled one healthy adult across more than 7 hours of listening to thirteen crime stories while collecting ultra high-field (7T) BOLD data. We then modeled the feature-informed hemodynamic response using a regularized encoding framework validated on independent stories. Drift predictions were prevalent in default-mode network hubs, whereas shift predictions were evident bilaterally in the primary auditory cortex and language association cortex. Furthermore, activity in default-mode and parietal networks was best explained by a signal capturing how meaning accumulates and gradually fades over the course of the narrative. Together, these findings show that coherence during language comprehension is implemented through dissociable neural regimes of slow contextual integration and rapid event-driven reconfiguration, offering a mechanistic entry point for understanding disturbances of language coherence in psychiatric disorders.","authors":["Davide Stauba","Finn Rabe","Akhil Misra","Yves Pauli","Roya Hüppi","Nils Lang","Lars Michels","Victoria Edkins","Sascha Frühholz","Iris Sommer","Wolfram Hinzen","Philipp Homan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20404v1","updated":"2025-12-23T14:48:42Z","published":"2025-12-23T14:48:42Z","title":"Sentiment-Aware Extractive and Abstractive Summarization for Unstructured Text Mining","summary":"With the rapid growth of unstructured data from social media, reviews, and forums, text mining has become essential in Information Systems (IS) for extracting actionable insights. Summarization can condense fragmented, emotion-rich posts, but existing methods-optimized for structured news-struggle with noisy, informal content. Emotional cues are critical for IS tasks such as brand monitoring and market analysis, yet few studies integrate sentiment modeling into summarization of short user-generated texts. We propose a sentiment-aware framework extending extractive (TextRank) and abstractive (UniLM) approaches by embedding sentiment signals into ranking and generation processes. This dual design improves the capture of emotional nuances and thematic relevance, producing concise, sentiment-enriched summaries that enhance timely interventions and strategic decision-making in dynamic online environments.","authors":["Junyi Liu","Stanley Kok"],"pdf_url":"","comment":"WITS 2025 (Workshop on Information Technologies and Systems 2025)"},{"id":"http://arxiv.org/abs/2512.20387v1","updated":"2025-12-23T14:22:26Z","published":"2025-12-23T14:22:26Z","title":"Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems","summary":"We propose a Vision-Language Simulation Model (VLSM) that unifies visual and textual understanding to synthesize executable FlexScript from layout sketches and natural-language prompts, enabling cross-modal reasoning for industrial simulation systems. To support this new paradigm, the study constructs the first large-scale dataset for generative digital twins, comprising over 120,000 prompt-sketch-code triplets that enable multimodal learning between textual descriptions, spatial structures, and simulation logic. In parallel, three novel evaluation metrics, Structural Validity Rate (SVR), Parameter Match Rate (PMR), and Execution Success Rate (ESR), are proposed specifically for this task to comprehensively evaluate structural integrity, parameter fidelity, and simulator executability. Through systematic ablation across vision encoders, connectors, and code-pretrained language backbones, the proposed models achieve near-perfect structural accuracy and high execution robustness. This work establishes a foundation for generative digital twins that integrate visual reasoning and language understanding into executable industrial simulation systems.","authors":["YuChe Hsu","AnJui Wang","TsaiChing Ni","YuanFu Yang"],"pdf_url":"","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2512.15328v2","updated":"2025-12-23T14:00:56Z","published":"2025-12-17T11:24:46Z","title":"Thematic Dispersion in Arabic Applied Linguistics: A Bibliometric Analysis using Brookes' Measure","summary":"This study applies Brookes' Measure of Categorical Dispersion (Δ) to analyze the thematic structure of contemporary Arabic Applied Linguistics research. Using a comprehensive, real-world dataset of 1,564 publications from 2019 to 2025, classified into eight core sub-disciplines, we calculate a dispersion index of Δ = 0.194. This remarkably low value indicates extreme thematic dispersion, revealing that the field is characterized by pronounced heterogeneity rather than concentration. The analysis identifies Computational Linguistics as a dominant but non-hegemonic force, coexisting with robust research in Sociolinguistics, Language Teaching, and other subfields. This study clarifies the correct application of Brookes' original formula, demonstrates its utility for field characterization, and provides a replicable bibliometric methodology for assessing disciplinary structure across domains.","authors":["Ayman Eddakrouri","Amani Ramadan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20352v1","updated":"2025-12-23T13:32:43Z","published":"2025-12-23T13:32:43Z","title":"Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation","summary":"Qualitative research faces a critical reliability challenge: traditional inter-rater agreement methods require multiple human coders, are time-intensive, and often yield moderate consistency. We present a multi-perspective validation framework for LLM-based thematic analysis that combines ensemble validation with dual reliability metrics: Cohen's Kappa ($κ$) for inter-rater agreement and cosine similarity for semantic consistency. Our framework enables configurable analysis parameters (1-6 seeds, temperature 0.0-2.0), supports custom prompt structures with variable substitution, and provides consensus theme extraction across any JSON format. As proof-of-concept, we evaluate three leading LLMs (Gemini 2.5 Pro, GPT-4o, Claude 3.5 Sonnet) on a psychedelic art therapy interview transcript, conducting six independent runs per model. Results demonstrate Gemini achieves highest reliability ($κ= 0.907$, cosine=95.3%), followed by GPT-4o ($κ= 0.853$, cosine=92.6%) and Claude ($κ= 0.842$, cosine=92.1%). All three models achieve a high agreement ($κ> 0.80$), validating the multi-run ensemble approach. The framework successfully extracts consensus themes across runs, with Gemini identifying 6 consensus themes (50-83% consistency), GPT-4o identifying 5 themes, and Claude 4 themes. Our open-source implementation provides researchers with transparent reliability metrics, flexible configuration, and structure-agnostic consensus extraction, establishing methodological foundations for reliable AI-assisted qualitative research.","authors":["Nilesh Jain","Seyi Adeyinka","Leor Roseman","Aza Allsop"],"pdf_url":"","comment":"11 pages, 1 figure, 3 tables"},{"id":"http://arxiv.org/abs/2512.20324v1","updated":"2025-12-23T12:48:05Z","published":"2025-12-23T12:48:05Z","title":"Can LLMs Solve My Grandma's Riddle? Evaluating Multilingual Large Language Models on Reasoning Traditional Bangla Tricky Riddles","summary":"Large Language Models (LLMs) show impressive performance on many NLP benchmarks, yet their ability to reason in figurative, culturally grounded, and low-resource settings remains underexplored. We address this gap for Bangla by introducing BanglaRiddleEval, a benchmark of 1,244 traditional Bangla riddles instantiated across four tasks (4,976 riddle-task artifacts in total). Using an LLM-based pipeline, we generate Chain-of-Thought explanations, semantically coherent distractors, and fine-grained ambiguity annotations, and evaluate a diverse suite of open-source and closed-source models under different prompting strategies. Models achieve moderate semantic overlap on generative QA but low correctness, MCQ accuracy peaks at only about 56% versus an 83% human baseline, and ambiguity resolution ranges from roughly 26% to 68%, with high-quality explanations confined to the strongest models. These results show that current LLMs capture some cues needed for Bangla riddle reasoning but remain far from human-level performance, establishing BanglaRiddleEval as a challenging new benchmark for low-resource figurative reasoning. All data, code, and evaluation scripts are available on GitHub: https://github.com/Labib1610/BanglaRiddleEval.","authors":["Nurul Labib Sayeedi","Md. Faiyaz Abdullah Sayeedi","Khushnur Binte Jahangir","Swakkhar Shatabda","Sarah Masud Preum"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.01564v2","updated":"2025-12-23T12:29:17Z","published":"2025-09-01T15:50:10Z","title":"Enhancing Uncertainty Estimation in LLMs with Expectation of Aggregated Internal Belief","summary":"Large Language Models (LLMs) have achieved remarkable success across a wide range of natural language tasks, but often exhibit overconfidence and generate plausible yet incorrect answers. This overconfidence, especially in models undergone Reinforcement Learning from Human Feedback (RLHF), poses significant challenges for reliable uncertainty estimation and safe deployment. In this paper, we propose EAGLE (Expectation of AGgregated internaL bEief), a novel self-evaluation-based calibration method that leverages the internal hidden states of LLMs to derive more accurate confidence scores. Instead of relying on the model's final output, our approach extracts internal beliefs from multiple intermediate layers during self-evaluation. By aggregating these layer-wise beliefs and calculating the expectation over the resulting confidence score distribution, EAGLE produces a refined confidence score that more faithfully reflects the model's internal certainty. Extensive experiments on diverse datasets and LLMs demonstrate that EAGLE significantly improves calibration performance over existing baselines. We also provide an in-depth analysis of EAGLE, including a layer-wise examination of uncertainty patterns, a study of the impact of self-evaluation prompts, and an analysis of the effect of self-evaluation score range.","authors":["Zeguan Xiao","Diyang Dou","Boya Xiong","Yun Chen","Guanhua Chen"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2512.20308v1","updated":"2025-12-23T12:22:25Z","published":"2025-12-23T12:22:25Z","title":"SpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision","summary":"The parallel advances in language modeling and speech representation learning have raised the prospect of learning language directly from speech without textual intermediates. This requires extracting semantic representations directly from speech. Our contributions are threefold. First, we introduce SpidR, a self-supervised speech representation model that efficiently learns representations with highly accessible phonetic information, which makes it particularly suited for textless spoken language modeling. It is trained on raw waveforms using a masked prediction objective combined with self-distillation and online clustering. The intermediate layers of the student model learn to predict assignments derived from the teacher's intermediate layers. This learning objective stabilizes the online clustering procedure compared to previous approaches, resulting in higher quality codebooks. SpidR outperforms wav2vec 2.0, HuBERT, WavLM, and DinoSR on downstream language modeling benchmarks (sWUGGY, sBLIMP, tSC). Second, we systematically evaluate across models and layers the correlation between speech unit quality (ABX, PNMI) and language modeling performance, validating these metrics as reliable proxies. Finally, SpidR significantly reduces pretraining time compared to HuBERT, requiring only one day of pretraining on 16 GPUs, instead of a week. This speedup is enabled by the pretraining method and an efficient codebase, which allows faster iteration and easier experimentation. We open-source the training code and model checkpoints at https://github.com/facebookresearch/spidr.","authors":["Maxime Poli","Mahi Luthra","Youssef Benchekroun","Yosuke Higuchi","Martin Gleize","Jiayi Shen","Robin Algayres","Yu-An Chung","Mido Assran","Juan Pino","Emmanuel Dupoux"],"pdf_url":"","comment":"30 pages, 16 figures"},{"id":"http://arxiv.org/abs/2512.20298v1","updated":"2025-12-23T12:05:01Z","published":"2025-12-23T12:05:01Z","title":"Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives","summary":"Growing reliance on LLMs for psychiatric self-assessment raises questions about their ability to interpret qualitative patient narratives. We present the first direct comparison between state-of-the-art LLMs and mental health professionals in diagnosing Borderline (BPD) and Narcissistic (NPD) Personality Disorders utilizing Polish-language first-person autobiographical accounts. We show that the top-performing Gemini Pro models surpassed human professionals in overall diagnostic accuracy by 21.91 percentage points (65.48% vs. 43.57%). While both models and human experts excelled at identifying BPD (F1 = 83.4 & F1 = 80.0, respectively), models severely underdiagnosed NPD (F1 = 6.7 vs. 50.0), showing a reluctance toward the value-laden term \"narcissism.\" Qualitatively, models provided confident, elaborate justifications focused on patterns and formal categories, while human experts remained concise and cautious, emphasizing the patient's sense of self and temporal experience. Our findings demonstrate that while LLMs are highly competent at interpreting complex first-person clinical data, they remain subject to critical reliability and bias issues.","authors":["Karolina Drożdż","Kacper Dudzic","Anna Sterna","Marcin Moskalewicz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20293v1","updated":"2025-12-23T12:01:32Z","published":"2025-12-23T12:01:32Z","title":"AprielGuard","summary":"Safeguarding large language models (LLMs) against unsafe or adversarial behavior is critical as they are increasingly deployed in conversational and agentic settings. Existing moderation tools often treat safety risks (e.g. toxicity, bias) and adversarial threats (e.g. prompt injections, jailbreaks) as separate problems, limiting their robustness and generalizability. We introduce AprielGuard, an 8B parameter safeguard model that unify these dimensions within a single taxonomy and learning framework. AprielGuard is trained on a diverse mix of open and synthetic data covering standalone prompts, multi-turn conversations, and agentic workflows, augmented with structured reasoning traces to improve interpretability. Across multiple public and proprietary benchmarks, AprielGuard achieves strong performance in detecting harmful content and adversarial manipulations, outperforming existing opensource guardrails such as Llama-Guard and Granite Guardian, particularly in multi-step and reasoning intensive scenarios. By releasing the model, we aim to advance transparent and reproducible research on reliable safeguards for LLMs.","authors":["Jaykumar Kasundra","Anjaneya Praharaj","Sourabh Surana","Lakshmi Sirisha Chodisetty","Sourav Sharma","Abhigya Verma","Abhishek Bhardwaj","Debasish Kanhar","Aakash Bhagat","Khalil Slimi","Seganrasan Subramanian","Sathwik Tejaswi Madhusudhan","Ranga Prasad Chenna","Srinivas Sunkara"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20292v1","updated":"2025-12-23T12:01:18Z","published":"2025-12-23T12:01:18Z","title":"SlideTailor: Personalized Presentation Slide Generation for Scientific Papers","summary":"Automatic presentation slide generation can greatly streamline content creation. However, since preferences of each user may vary, existing under-specified formulations often lead to suboptimal results that fail to align with individual user needs. We introduce a novel task that conditions paper-to-slides generation on user-specified preferences. We propose a human behavior-inspired agentic framework, SlideTailor, that progressively generates editable slides in a user-aligned manner. Instead of requiring users to write their preferences in detailed textual form, our system only asks for a paper-slides example pair and a visual template - natural and easy-to-provide artifacts that implicitly encode rich user preferences across content and visual style. Despite the implicit and unlabeled nature of these inputs, our framework effectively distills and generalizes the preferences to guide customized slide generation. We also introduce a novel chain-of-speech mechanism to align slide content with planned oral narration. Such a design significantly enhances the quality of generated slides and enables downstream applications like video presentations. To support this new task, we construct a benchmark dataset that captures diverse user preferences, with carefully designed interpretable metrics for robust evaluation. Extensive experiments demonstrate the effectiveness of our framework.","authors":["Wenzheng Zeng","Mingyu Ouyang","Langyuan Cui","Hwee Tou Ng"],"pdf_url":"","comment":"AAAI 2026 (with appendix)"},{"id":"http://arxiv.org/abs/2507.11662v2","updated":"2025-12-23T11:29:24Z","published":"2025-07-15T18:50:29Z","title":"Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification","summary":"Verifiers--functions assigning rewards to agent behavior--have been key for AI progress in domains like math and code. However, extending gains to domains without clear-cut success criteria (e.g., computer use) remains a challenge: while humans can recognize desired outcomes, translating this intuition into scalable rules is nontrivial. Multimodal Large Language Models (MLLMs) emerge as a promising solution, given their world knowledge, human-preference alignment, and reasoning skills. We evaluate MLLMs as verifiers across web navigation, computer use, and robotic manipulation, and identify a critical limitation: a strong tendency to over-validate agent behavior, a phenomenon we term agreement bias. This bias is pervasive across models, resilient to test-time scaling, and poses risks to existing methods relying on MLLM evaluations. We discuss methods to evaluate and improve MLLM verifiers and introduce Self-Grounded Verification (SGV), a lightweight method that harnesses MLLMs' own sampling mechanisms by modulating (un)conditional generation to better leverage their knowledge, alignment, and reasoning. SGV operates in two steps: first, the MLLM is elicited to generate broad priors about desired behavior, independent of the data under evaluation. Then, conditioned on self-generated priors, it reasons over and evaluates a candidate trajectory. SGV yields more human-aligned evaluations with gains of up to 25pp in failure detection, 14pp in accuracy, and benefits extending to downstream applications. In self-refinement and online supervision, SGV boosts task completion of a GUI specialist in OSWorld, a diffusion policy in robomimic, and a ReAct agent in VisualWebArena--setting a new state of the art, surpassing the previous best by 20pp. We release an updated version of VisualWebArena featuring more human-aligned evaluators, high-fidelity environment parallelism, and speedups of over 10x.","authors":["Moises Andrade","Joonhyuk Cha","Brandon Ho","Vriksha Srihari","Karmesh Yadav","Zsolt Kira"],"pdf_url":"","comment":"Our code, models, and data are publicly available at https://mshalimay.github.io/agreement-bias-sgv/"},{"id":"http://arxiv.org/abs/2512.19126v2","updated":"2025-12-23T11:15:52Z","published":"2025-12-22T08:07:00Z","title":"AWPO: Enhancing Tool-Use of Large Language Models through Explicit Integration of Reasoning Rewards","summary":"While reinforcement learning (RL) shows promise in training tool-use large language models (LLMs) using verifiable outcome rewards, existing methods largely overlook the potential of explicit reasoning rewards to bolster reasoning and tool utilization. Furthermore, natively combining reasoning and outcome rewards may yield suboptimal performance or conflict with the primary optimization objective. To address this, we propose advantage-weighted policy optimization (AWPO) -- a principled RL framework that effectively integrates explicit reasoning rewards to enhance tool-use capability. AWPO incorporates variance-aware gating and difficulty-aware weighting to adaptively modulate advantages from reasoning signals based on group-relative statistics, alongside a tailored clipping mechanism for stable optimization. Extensive experiments demonstrate that AWPO achieves state-of-the-art performance across standard tool-use benchmarks, significantly outperforming strong baselines and leading closed-source models in challenging multi-turn scenarios. Notably, with exceptional parameter efficiency, our 4B model surpasses Grok-4 by 16.0 percent in multi-turn accuracy while preserving generalization capability on the out-of-distribution MMLU-Pro benchmark.","authors":["Zihan Lin","Xiaohan Wang","Hexiong Yang","Jiajun Chai","Jie Cao","Guojun Yin","Wei Lin","Ran He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20204v1","updated":"2025-12-23T09:56:23Z","published":"2025-12-23T09:56:23Z","title":"Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings","summary":"Speech processing and translation technology have the potential to facilitate meetings of individuals who do not share any common language. To evaluate automatic systems for such a task, a versatile and realistic evaluation corpus is needed. Therefore, we create and present a corpus of cross-lingual dialogues between individuals without a common language who were facilitated by automatic simultaneous speech translation. The corpus consists of 5 hours of speech recordings with ASR and gold transcripts in 12 original languages and automatic and corrected translations into English. For the purposes of research into cross-lingual summarization, our corpus also includes written summaries (minutes) of the meetings.\n  Moreover, we propose automatic detection of misunderstandings. For an overview of this task and its complexity, we attempt to quantify misunderstandings in cross-lingual meetings. We annotate misunderstandings manually and also test the ability of current large language models to detect them automatically. The results show that the Gemini model is able to identify text spans with misunderstandings with recall of 77% and precision of 47%.","authors":["Marko Čechovič","Natália Komorníková","Dominik Macháček","Ondřej Bojar"],"pdf_url":"","comment":"12 pages, 2 figures, 6 tables, published as a conference paper in Text, Speech, and Dialogue 28th International Conference, TSD 2025, Erlangen, Germany, August 25-28, 2025, Proceedings, Part II. This version published here on arXiv.org is before review comments and seedings of the TSD conference staff"},{"id":"http://arxiv.org/abs/2510.03289v2","updated":"2025-12-23T09:36:38Z","published":"2025-09-29T12:07:09Z","title":"Why mask diffusion does not work","summary":"The main advantages of diffusion language models over autoregressive (AR) models lie in their ability to support parallel generation and bidirectional attention, enabling a more controllable generation process. In recent years, open-source mask diffusion language models have emerged, most of which are based on a variant known as absorbing diffusion. However, this paper demonstrates why mask diffusion faces inherent difficulties in achieving parallel generation and bidirectional attention. We also propose the most effective training and inference strategies for mask diffusion.","authors":["Haocheng Sun","Cynthia Xin Wen","Edward Hong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20182v1","updated":"2025-12-23T09:20:32Z","published":"2025-12-23T09:20:32Z","title":"FaithLens: Detecting and Explaining Faithfulness Hallucination","summary":"Recognizing whether outputs from large language models (LLMs) contain faithfulness hallucination is crucial for real-world applications, e.g., retrieval-augmented generation and summarization. In this paper, we introduce FaithLens, a cost-efficient and effective faithfulness hallucination detection model that can jointly provide binary predictions and corresponding explanations to improve trustworthiness. To achieve this, we first synthesize training data with explanations via advanced LLMs and apply a well-defined data filtering strategy to ensure label correctness, explanation quality, and data diversity. Subsequently, we fine-tune the model on these well-curated training data as a cold start and further optimize it with rule-based reinforcement learning, using rewards for both prediction correctness and explanation quality. Results on 12 diverse tasks show that the 8B-parameter FaithLens outperforms advanced models such as GPT-4.1 and o3. Also, FaithLens can produce high-quality explanations, delivering a distinctive balance of trustworthiness, efficiency, and effectiveness.","authors":["Shuzheng Si","Qingyi Wang","Haozhe Zhao","Yuzhuo Bai","Guanqiao Chen","Kangyang Luo","Gang Chen","Fanchao Qi","Minjia Zhang","Baobao Chang","Maosong Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20174v1","updated":"2025-12-23T09:14:16Z","published":"2025-12-23T09:14:16Z","title":"Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark","summary":"Document image retrieval (DIR) aims to retrieve document images from a gallery according to a given query. Existing DIR methods are primarily based on image queries that retrieve documents within the same coarse semantic category, e.g., newspapers or receipts. However, these methods struggle to effectively retrieve document images in real-world scenarios where textual queries with fine-grained semantics are usually provided. To bridge this gap, we introduce a new Natural Language-based Document Image Retrieval (NL-DIR) benchmark with corresponding evaluation metrics. In this work, natural language descriptions serve as semantically rich queries for the DIR task. The NL-DIR dataset contains 41K authentic document images, each paired with five high-quality, fine-grained semantic queries generated and evaluated through large language models in conjunction with manual verification. We perform zero-shot and fine-tuning evaluations of existing mainstream contrastive vision-language models and OCR-free visual document understanding (VDU) models. A two-stage retrieval method is further investigated for performance improvement while achieving both time and space efficiency. We hope the proposed NL-DIR benchmark can bring new opportunities and facilitate research for the VDU community. Datasets and codes will be publicly available at huggingface.co/datasets/nianbing/NL-DIR.","authors":["Hao Guo","Xugong Qin","Jun Jie Ou Yang","Peng Zhang","Gangyan Zeng","Yubo Li","Hailun Lin"],"pdf_url":"","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2512.20169v1","updated":"2025-12-23T08:56:49Z","published":"2025-12-23T08:56:49Z","title":"Learning to Reason in LLMs by Expectation Maximization","summary":"Large language models (LLMs) solve reasoning problems by first generating a rationale and then answering. We formalize reasoning as a latent variable model and derive an expectation-maximization (EM) objective for learning to reason. This view connects EM and modern reward-based optimization, and shows that the main challenge lies in designing a sampling distribution that generates rationales that justify correct answers. We instantiate and compare several sampling schemes: rejection sampling with a budget, self-taught reasoner (STaR), and prompt posterior sampling (PPS), which only keeps the rationalization stage of STaR. Our experiments on the ARC, MMLU, and OpenBookQA datasets with the Llama and Qwen models show that the sampling scheme can significantly affect the accuracy of learned reasoning models. Despite its simplicity, we observe that PPS outperforms the other sampling schemes.","authors":["Junghyun Lee","Branislav Kveton","Sunav Choudhary","Subhojyoti Mukherjee","Anup Rao","Ryan A. Rossi","Alexa Siu"],"pdf_url":"","comment":"12 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2506.09349v4","updated":"2025-12-23T08:50:59Z","published":"2025-06-11T02:57:22Z","title":"DrVoice: Parallel Speech-Text Voice Conversation Model via Dual-Resolution Speech Representations","summary":"Recent studies on end-to-end (E2E) speech generation with large language models (LLMs) have attracted significant community attention, with multiple works extending text-based LLMs to generate discrete speech tokens. Existing E2E approaches primarily fall into two categories: (1) Methods that generate discrete speech tokens independently without incorporating them into the LLM's autoregressive process, resulting in text generation being unaware of concurrent speech synthesis. (2) Models that generate interleaved or parallel speech-text tokens through joint autoregressive modeling, enabling mutual modality awareness during generation. This paper presents DrVoice, a parallel speech-text voice conversation model based on joint autoregressive modeling, featuring dual-resolution speech representations. Notably, while current methods utilize mainly 12.5Hz input audio representation, our proposed dual-resolution mechanism reduces the input frequency for the LLM to 5Hz, significantly reducing computational cost and alleviating the frequency discrepancy between speech and text tokens and in turn better exploiting LLMs' capabilities. Experimental results demonstrate that DrVoice-7B establishes new state-of-the-art (SOTA) on prominent speech benchmarks including OpenAudioBench, VoiceBench, UltraEval-Audio and Big Bench Audio, making it a leading open-source speech foundation model in ~7B models.","authors":["Chao-Hong Tan","Qian Chen","Wen Wang","Chong Deng","Qinglin Zhang","Luyao Cheng","Hai Yu","Xin Zhang","Xiang Lv","Tianyu Zhao","Chong Zhang","Yukun Ma","Yafeng Chen","Hui Wang","Jiaqing Liu","Xiangang Li","Jieping Ye"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2511.17004v3","updated":"2025-12-23T08:46:41Z","published":"2025-11-21T07:14:46Z","title":"Vision Language Models are Confused Tourists","summary":"Although the cultural dimension has been one of the key aspects in evaluating Vision-Language Models (VLMs), their ability to remain stable across diverse cultural inputs remains largely untested, despite being crucial to support diversity and multicultural societies. Existing evaluations often rely on benchmarks featuring only a singular cultural concept per image, overlooking scenarios where multiple, potentially unrelated cultural cues coexist. To address this gap, we introduce ConfusedTourist, a novel cultural adversarial robustness suite designed to assess VLMs' stability against perturbed geographical cues. Our experiments reveal a critical vulnerability, where accuracy drops heavily under simple image-stacking perturbations and even worsens with its image-generation-based variant. Interpretability analyses further show that these failures stem from systematic attention shifts toward distracting cues, diverting the model from its intended focus. These findings highlight a critical challenge: visual cultural concept mixing can substantially impair even state-of-the-art VLMs, underscoring the urgent need for more culturally robust multimodal understanding.","authors":["Patrick Amadeus Irawan","Ikhlasul Akmal Hanif","Muhammad Dehan Al Kautsar","Genta Indra Winata","Fajri Koto","Alham Fikri Aji"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20164v1","updated":"2025-12-23T08:42:09Z","published":"2025-12-23T08:42:09Z","title":"AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications","summary":"Large Language Models (LLMs) excel at text comprehension and generation, making them ideal for automated tasks like code review and content moderation. However, our research identifies a vulnerability: LLMs can be manipulated by \"adversarial instructions\" hidden in input data, such as resumes or code, causing them to deviate from their intended task. Notably, while defenses may exist for mature domains such as code review, they are often absent in other common applications such as resume screening and peer review. This paper introduces a benchmark to assess this vulnerability in resume screening, revealing attack success rates exceeding 80% for certain attack types. We evaluate two defense mechanisms: prompt-based defenses achieve 10.1% attack reduction with 12.5% false rejection increase, while our proposed FIDS (Foreign Instruction Detection through Separation) using LoRA adaptation achieves 15.4% attack reduction with 10.4% false rejection increase. The combined approach provides 26.3% attack reduction, demonstrating that training-time defenses outperform inference-time mitigations in both security and utility preservation.","authors":["Honglin Mu","Jinghao Liu","Kaiyang Wan","Rui Xing","Xiuying Chen","Timothy Baldwin","Wanxiang Che"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20156v1","updated":"2025-12-23T08:35:27Z","published":"2025-12-23T08:35:27Z","title":"Fun-Audio-Chat Technical Report","summary":"Recent advancements in joint speech-text models show great potential for seamless voice interactions. However, existing models face critical challenges: temporal resolution mismatch between speech tokens (25Hz) and text tokens (~3Hz) dilutes semantic information, incurs high computational costs, and causes catastrophic forgetting of text LLM knowledge. We introduce Fun-Audio-Chat, a Large Audio Language Model addressing these limitations via two innovations from our previous work DrVoice. First, Dual-Resolution Speech Representations (DRSR): the Shared LLM processes audio at efficient 5Hz (via token grouping), while the Speech Refined Head generates high-quality tokens at 25Hz, balancing efficiency (~50% GPU reduction) and quality. Second, Core-Cocktail Training, a two-stage fine-tuning with intermediate merging that mitigates catastrophic forgetting. We then apply Multi-Task DPO Training to enhance robustness, audio understanding, instruction-following and voice empathy. This multi-stage post-training enables Fun-Audio-Chat to retain text LLM knowledge while gaining powerful audio understanding, reasoning, and generation. Unlike recent LALMs requiring large-scale audio-text pre-training, Fun-Audio-Chat leverages pre-trained models and extensive post-training. Fun-Audio-Chat 8B and MoE 30B-A3B achieve competitive performance on Speech-to-Text and Speech-to-Speech tasks, ranking top among similar-scale models on Spoken QA benchmarks. They also achieve competitive to superior performance on Audio Understanding, Speech Function Calling, Instruction-Following and Voice Empathy. We develop Fun-Audio-Chat-Duplex, a full-duplex variant with strong performance on Spoken QA and full-duplex interactions. We open-source Fun-Audio-Chat-8B with training and inference code, and provide an interactive demo.","authors":["Qian Chen","Luyao Cheng","Chong Deng","Xiangang Li","Jiaqing Liu","Chao-Hong Tan","Wen Wang","Junhao Xu","Jieping Ye","Qinglin Zhang","Qiquan Zhang","Jingren Zhou"],"pdf_url":"","comment":"21 pages, https://github.com/FunAudioLLM/Fun-Audio-Chat"},{"id":"http://arxiv.org/abs/2506.05594v3","updated":"2025-12-23T08:31:59Z","published":"2025-06-05T21:12:51Z","title":"SoK: Are Watermarks in LLMs Ready for Deployment?","summary":"Large Language Models (LLMs) have transformed natural language processing, demonstrating impressive capabilities across diverse tasks. However, deploying these models introduces critical risks related to intellectual property violations and potential misuse, particularly as adversaries can imitate these models to steal services or generate misleading outputs. We specifically focus on model stealing attacks, as they are highly relevant to proprietary LLMs and pose a serious threat to their security, revenue, and ethical deployment. While various watermarking techniques have emerged to mitigate these risks, it remains unclear how far the community and industry have progressed in developing and deploying watermarks in LLMs.\n  To bridge this gap, we aim to develop a comprehensive systematization for watermarks in LLMs by 1) presenting a detailed taxonomy for watermarks in LLMs, 2) proposing a novel intellectual property classifier to explore the effectiveness and impacts of watermarks on LLMs under both attack and attack-free environments, 3) analyzing the limitations of existing watermarks in LLMs, and 4) discussing practical challenges and potential future directions for watermarks in LLMs. Through extensive experiments, we show that despite promising research outcomes and significant attention from leading companies and community to deploy watermarks, these techniques have yet to reach their full potential in real-world applications due to their unfavorable impacts on model utility of LLMs and downstream tasks. Our findings provide an insightful understanding of watermarks in LLMs, highlighting the need for practical watermarks solutions tailored to LLM deployment.","authors":["Kieu Dang","Phung Lai","NhatHai Phan","Yelong Shen","Ruoming Jin","Abdallah Khreishah","My T. Thai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.01457v4","updated":"2025-12-23T08:18:03Z","published":"2025-12-01T09:44:31Z","title":"Zero-Overhead Introspection for Adaptive Test-Time Compute","summary":"Large language models excel at reasoning but lack key aspects of introspection, including anticipating their own success and the computation required to achieve it. Humans use real-time introspection to decide how much effort to invest, when to make multiple attempts, when to stop, and when to signal success or failure. Without this, LLMs struggle to make intelligent meta-cognition decisions. Test-time scaling methods like Best-of-N drive up cost and latency by using a fixed budget of samples regardless of the marginal benefit of each one at any point in generation, and the absence of confidence signals can mislead people, prevent appropriate escalation to better tools, and undermine trustworthiness. Learned verifiers or reward models can provide confidence estimates, but do not enable adaptive inference and add substantial cost by requiring extra models or forward passes. We present ZIP-RC, which equips models with zero-overhead introspective predictions of reward and cost. At every token, ZIP-RC reuses reserved or unused logits in the same forward pass as next-token prediction to output a joint distribution over final reward and remaining length -- no extra models, architecture change, or inference overhead. This full joint distribution is used to compute a sampling utility which is the linear combination of the expected maximum reward, total compute, and latency of set of samples if generated to completion. During inference, we maximize this utility with meta-actions that determine which prefix of tokens to continue or initiate sampling from. On mixed-difficulty mathematical benchmarks, ZIP-RC improves accuracy by up to 12% over majority voting at equal or lower average cost, and traces smooth Pareto frontiers between quality, compute, and latency. By providing real-time reward-cost introspection, ZIP-RC enables adaptive, efficient reasoning.","authors":["Rohin Manvi","Joey Hong","Tim Seyde","Maxime Labonne","Mathias Lechner","Sergey Levine"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20145v1","updated":"2025-12-23T08:15:34Z","published":"2025-12-23T08:15:34Z","title":"Retrieval-augmented Prompt Learning for Pre-trained Foundation Models","summary":"The pre-trained foundation models (PFMs) have become essential for facilitating large-scale multimodal learning. Researchers have effectively employed the ``pre-train, prompt, and predict'' paradigm through prompt learning to induce improved few-shot performance. However, prompt learning approaches for PFMs still follow a parametric learning paradigm. As such, the stability of generalization in memorization and rote learning can be compromised. More specifically, conventional prompt learning might face difficulties in fully utilizing atypical instances and avoiding overfitting to shallow patterns with limited data during the process of fully-supervised training. To overcome these constraints, we present our approach, named RetroPrompt, which aims to achieve a balance between memorization and generalization by decoupling knowledge from mere memorization. Unlike traditional prompting methods, RetroPrompt leverages a publicly accessible knowledge base generated from the training data and incorporates a retrieval mechanism throughout the input, training, and inference stages. This enables the model to actively retrieve relevant contextual information from the corpus, thereby enhancing the available cues. We conduct comprehensive experiments on a variety of datasets across natural language processing and computer vision tasks to demonstrate the superior performance of our proposed approach, RetroPrompt, in both zero-shot and few-shot scenarios. Through detailed analysis of memorization patterns, we observe that RetroPrompt effectively reduces the reliance on rote memorization, leading to enhanced generalization.","authors":["Xiang Chen","Yixin Ou","Quan Feng","Lei Li","Piji Li","Haibo Ye","Sheng-Jun Huang","Shuofei Qiao","Shumin Deng","Huajun Chen","Ningyu Zhang"],"pdf_url":"","comment":"IEEE/ACM Transactions on Audio, Speech and Language Processing"},{"id":"http://arxiv.org/abs/2512.20144v1","updated":"2025-12-23T08:14:44Z","published":"2025-12-23T08:14:44Z","title":"Multi-hop Reasoning via Early Knowledge Alignment","summary":"Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for Large Language Models (LLMs) to address knowledge-intensive queries requiring domain-specific or up-to-date information. To handle complex multi-hop questions that are challenging for single-step retrieval, iterative RAG approaches incorporating reinforcement learning have been proposed. However, existing iterative RAG systems typically plan to decompose questions without leveraging information about the available retrieval corpus, leading to inefficient retrieval and reasoning chains that cascade into suboptimal performance. In this paper, we introduce Early Knowledge Alignment (EKA), a simple but effective module that aligns LLMs with retrieval set before planning in iterative RAG systems with contextually relevant retrieved knowledge. Extensive experiments on six standard RAG datasets demonstrate that by establishing a stronger reasoning foundation, EKA significantly improves retrieval precision, reduces cascading errors, and enhances both performance and efficiency. Our analysis from an entropy perspective demonstrate that incorporating early knowledge reduces unnecessary exploration during the reasoning process, enabling the model to focus more effectively on relevant information subsets. Moreover, EKA proves effective as a versatile, training-free inference strategy that scales seamlessly to large models. Generalization tests across diverse datasets and retrieval corpora confirm the robustness of our approach. Overall, EKA advances the state-of-the-art in iterative RAG systems while illuminating the critical interplay between structured reasoning and efficient exploration in reinforcement learning-augmented frameworks. The code is released at \\href{https://github.com/yxzwang/EarlyKnowledgeAlignment}{Github}.","authors":["Yuxin Wang","Shicheng Fang","Bo Wang","Qi Luo","Xuanjing Huang","Yining Zheng","Xipeng Qiu"],"pdf_url":"","comment":"16 pages"},{"id":"http://arxiv.org/abs/2512.18190v2","updated":"2025-12-23T08:10:47Z","published":"2025-12-20T03:27:11Z","title":"External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning","summary":"This paper proposes the External Hippocampus framework, which models language model reasoning from a cognitive dynamics perspective as the flow of information energy in semantic space. Unlike traditional weight-space optimization methods, this framework constructs topological cognitive maps through dimensionality reduction projection, enabling precise navigation and intervention of energy flow at test time while avoiding substantial computational requirements and demonstrating predictable intervention patterns. The method effectively addresses the cognitive deadlock problem in multi-step reasoning for small models. Experiments on models <=7B parameters show: map-guided methods achieve 81.20% accuracy on 500 challenging problems (relative baseline +16.80%), reduce reasoning time by >= 15x, with key findings revealing that reasoning stagnation manifests as \"Cognitive Vortex\" and low-entropy potential wells, while temperature perturbations effectively restart energy flow. The framework requires no additional training, possesses autonomous growth capability, and provides an efficient and controllable topological-aware solution for small model reasoning.","authors":["Jian Yan"],"pdf_url":"","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2509.23129v2","updated":"2025-12-23T07:56:48Z","published":"2025-09-27T05:24:51Z","title":"C$^2$GSPG: Confidence-calibrated Group Sequence Policy Gradient towards Self-aware Reasoning","summary":"Reinforcement Learning (RL) methods, exemplified by Group Relative Policy Optimization (GRPO) and its variants, play a central role in developing reasoning models. However, these methods often suffer from a critical overconfidence issue, which prevents them from achieving self-aware reasoning models. In this study, we propose a simple yet effective confidence-calibration group sequence policy gradient method, called C$^2$GSPG, which simultaneously enhances reasoning performance while suppressing overconfidence. In principle, we propose a Group Sequence Policy Gradient (GSPG) framework for learning reasoning models, which eliminates the token-level bias commonly appearing in GRPO and its variants. In this framework, we define the model confidence for each reasoning problem using the normalized sequence-level probability, and then apply a cross-entropy regularizer to calibrate the model confidence to the sequence's reward. We demonstrate that the confidence calibration regularizer and GSPG are collaborative for binary rewards, as their objectives always share the same gradient direction. For non-binary rewards, we apply nonlinear reward normalization and adaptive regularizer clipping, mitigating the potential conflict between the two objectives. Applying C$^2$GSPG to post-train large language models in logical and mathematical reasoning tasks, we show its superiority over state-of-the-art methods in both reasoning accuracy and confidence calibration. The code of C$^2$GSPG is available at https://github.com/HaotianLiu123/CCGSPG.","authors":["Haotian Liu","Shuo Wang","Hongteng Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20136v1","updated":"2025-12-23T07:54:03Z","published":"2025-12-23T07:54:03Z","title":"M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation","summary":"Retrieval-Augmented Generation (RAG) has recently been extended to multimodal settings, connecting multimodal large language models (MLLMs) with vast corpora of external knowledge such as multimodal knowledge graphs (MMKGs). Despite their recent success, multimodal RAG in the audio-visual domain remains challenging due to 1) limited modality coverage and multi-hop connectivity of existing MMKGs, and 2) retrieval based solely on similarity in a shared multimodal embedding space, which fails to filter out off-topic or redundant knowledge. To address these limitations, we propose M$^3$KG-RAG, a Multi-hop Multimodal Knowledge Graph-enhanced RAG that retrieves query-aligned audio-visual knowledge from MMKGs, improving reasoning depth and answer faithfulness in MLLMs. Specifically, we devise a lightweight multi-agent pipeline to construct multi-hop MMKG (M$^3$KG), which contains context-enriched triplets of multimodal entities, enabling modality-wise retrieval based on input queries. Furthermore, we introduce GRASP (Grounded Retrieval And Selective Pruning), which ensures precise entity grounding to the query, evaluates answer-supporting relevance, and prunes redundant context to retain only knowledge essential for response generation. Extensive experiments across diverse multimodal benchmarks demonstrate that M$^3$KG-RAG significantly enhances MLLMs' multimodal reasoning and grounding over existing approaches.","authors":["Hyeongcheol Park","Jiyoung Seo","Jaewon Mun","Hogun Park","Wonmin Byeon","Sung June Kim","Hyeonsoo Im","JeungSub Lee","Sangpil Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20111v1","updated":"2025-12-23T07:11:26Z","published":"2025-12-23T07:11:26Z","title":"ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language","summary":"As the length of sequential decision-making tasks increases, it becomes computationally impractical to keep full interaction histories in context. We introduce a general framework for LLM agents to maintain concise contexts through multi-step interaction: Acting through Belief Bottlenecks Expressed in Language (ABBEL), and methods to further improve ABBEL agents with RL post-training. ABBEL replaces long multi-step interaction history by a belief state, i.e., a natural language summary of what has been discovered about task-relevant unknowns. Under ABBEL, at each step the agent first updates a prior belief with the most recent observation from the environment to form a posterior belief, then uses only the posterior to select an action. We systematically evaluate frontier models under ABBEL across six diverse multi-step environments, finding that ABBEL supports generating interpretable beliefs while maintaining near-constant memory use over interaction steps. However, bottleneck approaches are generally prone to error propagation, which we observe causing inferior performance when compared to the full context setting due to errors in belief updating. Therefore, we train LLMs to generate and act on beliefs within the ABBEL framework via reinforcement learning (RL). We experiment with belief grading, to reward higher quality beliefs, as well as belief length penalties to reward more compressed beliefs. Our experiments demonstrate the ability of RL to improve ABBEL's performance beyond the full context setting, while using less memory than contemporaneous approaches.","authors":["Aly Lidayan","Jakob Bjorner","Satvik Golechha","Kartik Goyal","Alane Suhr"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.17266v3","updated":"2025-12-23T07:05:40Z","published":"2025-05-22T20:24:08Z","title":"Select2Reason: Efficient Instruction-Tuning Data Selection for Long-CoT Reasoning","summary":"A practical approach to activate long chain-of-thoughts reasoning ability in pre-trained large language models is to perform supervised fine-tuning on instruction datasets synthesized by strong Large Reasoning Models such as DeepSeek-R1, offering a cost-effective alternative to reinforcement learning. However, large-scale instruction sets with more than 100k samples incur significant training overhead, while effective strategies for automatic long-CoT instruction selection still remain unexplored. In this work, we propose Select2Reason, a novel and efficient instruction-tuning data selection framework for long-CoT reasoning. From the perspective of emergence of rethinking behaviors like self-correction and backtracking, we investigate common metrics that may determine the quality of long-CoT reasoning instructions. Select2Reason leverages a quantifier to estimate difficulty of question and jointly incorporates a reasoning trace length-based heuristic through a weighted scheme for ranking to prioritize high-utility examples. Empirical results on OpenR1-Math-220k demonstrate that fine-tuning LLM on only 10% of the data selected by Select2Reason achieves performance competitive with or superior to full-data tuning and open-source baseline OpenR1-Qwen-7B across three competition-level and six comprehensive mathematical benchmarks. Further experiments highlight the scalability in varying data size, efficiency during inference, and its adaptability to other instruction pools with minimal cost.","authors":["Cehao Yang","Xueyuan Lin","Xiaojun Wu","Chengjin Xu","Xuhui Jiang","Honghao Liu","Hui Xiong","Jian Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20097v1","updated":"2025-12-23T06:49:33Z","published":"2025-12-23T06:49:33Z","title":"A Novel Graph-Sequence Learning Model for Inductive Text Classification","summary":"Text classification plays an important role in various downstream text-related tasks, such as sentiment analysis, fake news detection, and public opinion analysis. Recently, text classification based on Graph Neural Networks (GNNs) has made significant progress due to their strong capabilities of structural relationship learning. However, these approaches still face two major limitations. First, these approaches fail to fully consider the diverse structural information across word pairs, e.g., co-occurrence, syntax, and semantics. Furthermore, they neglect sequence information in the text graph structure information learning module and can not classify texts with new words and relations. In this paper, we propose a Novel Graph-Sequence Learning Model for Inductive Text Classification (TextGSL) to address the previously mentioned issues. More specifically, we construct a single text-level graph for all words in each text and establish different edge types based on the diverse relationships between word pairs. Building upon this, we design an adaptive multi-edge message-passing paradigm to aggregate diverse structural information between word pairs. Additionally, sequential information among text data can be captured by the proposed TextGSL through the incorporation of Transformer layers. Therefore, TextGSL can learn more discriminative text representations. TextGSL has been comprehensively compared with several strong baselines. The experimental results on diverse benchmarking datasets demonstrate that TextGSL outperforms these baselines in terms of accuracy.","authors":["Zuo Wang","Ye Yuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20092v1","updated":"2025-12-23T06:37:29Z","published":"2025-12-23T06:37:29Z","title":"Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents","summary":"Temporal reasoning over long, multi-session dialogues is a critical capability for conversational agents. However, existing works and our pilot study have shown that as dialogue histories grow in length and accumulate noise, current long-context models struggle to accurately identify temporally pertinent information, significantly impairing reasoning performance. To address this, we introduce Memory-T1, a framework that learns a time-aware memory selection policy using reinforcement learning (RL). It employs a coarse-to-fine strategy, first pruning the dialogue history into a candidate set using temporal and relevance filters, followed by an RL agent that selects the precise evidence sessions. The RL training is guided by a multi-level reward function optimizing (i) answer accuracy, (ii) evidence grounding, and (iii) temporal consistency. In particular, the temporal consistency reward provides a dense signal by evaluating alignment with the query time scope at both the session-level (chronological proximity) and the utterance-level (chronological fidelity), enabling the agent to resolve subtle chronological ambiguities. On the Time-Dialog benchmark, Memory-T1 boosts a 7B model to an overall score of 67.0\\%, establishing a new state-of-the-art performance for open-source models and outperforming a 14B baseline by 10.2\\%. Ablation studies show temporal consistency and evidence grounding rewards jointly contribute to a 15.0\\% performance gain. Moreover, Memory-T1 maintains robustness up to 128k tokens, where baseline models collapse, proving effectiveness against noise in extensive dialogue histories. The code and datasets are publicly available at https://github.com/Elvin-Yiming-Du/Memory-T1/","authors":["Yiming Du","Baojun Wang","Yifan Xiang","Zhaowei Wang","Wenyu Huang","Boyang Xue","Bin Liang","Xingshan Zeng","Fei Mi","Haoli Bai","Lifeng Shang","Jeff Z. Pan","Yuxin Jiang","Kam-Fai Wong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19012v2","updated":"2025-12-23T06:23:22Z","published":"2025-12-22T04:03:01Z","title":"DramaBench: A Six-Dimensional Evaluation Framework for Drama Script Continuation","summary":"Drama script continuation requires models to maintain character consistency, advance plot coherently, and preserve dramatic structurecapabilities that existing benchmarks fail to evaluate comprehensively. We present DramaBench, the first large-scale benchmark for evaluating drama script continuation across six independent dimensions: Format Standards, Narrative Efficiency, Character Consistency, Emotional Depth, Logic Consistency, and Conflict Handling. Our framework combines rulebased analysis with LLM-based labeling and statistical metrics, ensuring objective and reproducible evaluation. We conduct comprehensive evaluation of 8 state-of-the-art language models on 1,103 scripts (8,824 evaluations total), with rigorous statistical significance testing (252 pairwise comparisons, 65.9% significant) and human validation (188 scripts, substantial agreement on 3/5 dimensions). Our ablation studies confirm all six dimensions capture independent quality aspects (mean | r | = 0.020). DramaBench provides actionable, dimensionspecific feedback for model improvement and establishes a rigorous standard for creative writing evaluation.","authors":["Shijian Ma","Yunqi Huang","Yan Lin"],"pdf_url":"","comment":"Project page: https://dramabench.pages.dev/"},{"id":"http://arxiv.org/abs/2512.20074v1","updated":"2025-12-23T05:58:47Z","published":"2025-12-23T05:58:47Z","title":"Reason2Decide: Rationale-Driven Multi-Task Learning","summary":"Despite the wide adoption of Large Language Models (LLM)s, clinical decision support systems face a critical challenge: achieving high predictive accuracy while generating explanations aligned with the predictions. Current approaches suffer from exposure bias leading to misaligned explanations. We propose Reason2Decide, a two-stage training framework that addresses key challenges in self-rationalization, including exposure bias and task separation. In Stage-1, our model is trained on rationale generation, while in Stage-2, we jointly train on label prediction and rationale generation, applying scheduled sampling to gradually transition from conditioning on gold labels to model predictions. We evaluate Reason2Decide on three medical datasets, including a proprietary triage dataset and public biomedical QA datasets. Across model sizes, Reason2Decide outperforms other fine-tuning baselines and some zero-shot LLMs in prediction (F1) and rationale fidelity (BERTScore, BLEU, LLM-as-a-Judge). In triage, Reason2Decide is rationale source-robust across LLM-generated, nurse-authored, and nurse-post-processed rationales. In our experiments, while using only LLM-generated rationales in Stage-1, Reason2Decide outperforms other fine-tuning variants. This indicates that LLM-generated rationales are suitable for pretraining models, reducing reliance on human annotations. Remarkably, Reason2Decide achieves these gains with models 40x smaller than contemporary foundation models, making clinical reasoning more accessible for resource-constrained deployments while still providing explainable decision support.","authors":["H M Quamran Hasan","Housam Khalifa Bashier","Jiayi Dai","Mi-Young Kim","Randy Goebel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.04944v2","updated":"2025-12-23T05:51:37Z","published":"2025-10-06T15:46:50Z","title":"On Structured State-Space Duality","summary":"Structured State-Space Duality (SSD) [Dao & Gu, ICML 2024] is an equivalence between a simple Structured State-Space Model (SSM) and a masked attention mechanism. In particular, a state-space model with a scalar-times-identity state matrix is equivalent to a masked self-attention with a $1$-semiseparable causal mask. Consequently, the same sequence transformation (model) has two algorithmic realizations: as a linear-time $O(T)$ recurrence or as a quadratic-time $O(T^2)$ attention. In this note, we formalize and generalize this duality: (i) we extend SSD from the scalar-identity case to general diagonal SSMs (diagonal state matrices); (ii) we show that these diagonal SSMs match the scalar case's training complexity lower bounds while supporting richer dynamics; (iii) we establish a necessary and sufficient condition under which an SSM is equivalent to $1$-semiseparable masked attention; and (iv) we show that such duality fails to extend to standard softmax attention due to rank explosion. Together, these results tighten bridge between recurrent SSMs and Transformers, and widen the design space for expressive yet efficient sequence models.","authors":["Jerry Yao-Chieh Hu","Xiwen Zhang","Ali ElSheikh","Weimin Wu","Han Liu"],"pdf_url":"","comment":"v2 fixed typos and added numerical results (Appendix B)"},{"id":"http://arxiv.org/abs/2408.02152v3","updated":"2025-12-23T05:50:45Z","published":"2024-08-04T22:00:34Z","title":"Generative Retrieval with Few-shot Indexing","summary":"Existing generative retrieval (GR) methods rely on training-based indexing, which fine-tunes a model to memorise associations between queries and the document identifiers (docids) of relevant documents. Training-based indexing suffers from high training costs, under-utilisation of pre-trained knowledge in large language models (LLMs), and limited adaptability to dynamic document corpora. To address the issues, we propose a few-shot indexing-based GR framework (Few-Shot GR). It has a few-shot indexing process without any training, where we prompt an LLM to generate docids for all documents in a corpus, ultimately creating a docid bank for the entire corpus. During retrieval, we feed a query to the same LLM and constrain it to generate a docid within the docid bank created during indexing, and then map the generated docid back to its corresponding document. Moreover, we devise few-shot indexing with one-to-many mapping to further enhance Few-Shot GR. Experiments show that Few-Shot GR achieves superior performance to state-of-the-art GR methods requiring heavy training.","authors":["Arian Askari","Chuan Meng","Mohammad Aliannejadi","Zhaochun Ren","Evangelos Kanoulas","Suzan Verberne"],"pdf_url":"","comment":"Accepted for publication at the 48th European Conference on Information Retrieval (ECIR 2026)"},{"id":"http://arxiv.org/abs/2509.16189v3","updated":"2025-12-23T05:18:37Z","published":"2025-09-19T17:49:25Z","title":"Latent learning: episodic memory complements parametric learning by enabling flexible reuse of experiences","summary":"When do machine learning systems fail to generalize, and what mechanisms could improve their generalization? Here, we draw inspiration from cognitive science to argue that one weakness of parametric machine learning systems is their failure to exhibit latent learning -- learning information that is not relevant to the task at hand, but that might be useful in a future task. We show how this perspective links failures ranging from the reversal curse in language modeling to new findings on agent-based navigation. We then highlight how cognitive science points to episodic memory as a potential part of the solution to these issues. Correspondingly, we show that a system with an oracle retrieval mechanism can use learning experiences more flexibly to generalize better across many of these challenges. We also identify some of the essential components for effectively using retrieval, including the importance of within-example in-context learning for acquiring the ability to use information across retrieved examples. In summary, our results illustrate one possible contributor to the relative data inefficiency of current machine learning systems compared to natural intelligence, and help to understand how retrieval methods can complement parametric learning to improve generalization. We close by discussing some of the links between these findings and prior results in cognitive science and neuroscience, and the broader implications.","authors":["Andrew Kyle Lampinen","Martin Engelcke","Yuxuan Li","Arslan Chaudhry","James L. McClelland"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.04826v3","updated":"2025-12-23T05:07:19Z","published":"2025-08-06T19:11:33Z","title":"Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History","summary":"Large language models require consistent behavioral patterns for safe deployment, yet there are indications of large variability that may lead to an instable expression of personality traits in these models. We present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive evaluation framework testing 25 open-source models (1B-685B parameters) across 2 million+ responses. Using traditional (BFI, SD3) and novel LLM-adapted personality questionnaires, we systematically vary model size, personas, reasoning modes, question order or paraphrasing, and conversation history. Our findings challenge fundamental assumptions: (1) Question reordering alone can introduce large shifts in personality measurements; (2) Scaling provides limited stability gains: even 400B+ models exhibit standard deviations >0.3 on 5-point scales; (3) Interventions expected to stabilize behavior, such as reasoning and inclusion of conversation history, can paradoxically increase variability; (4) Detailed persona instructions produce mixed effects, with misaligned personas showing significantly higher variability than the helpful assistant baseline; (5) The LLM-adapted questionnaires, despite their improved ecological validity, exhibit instability comparable to human-centric versions. This persistent instability across scales and mitigation strategies suggests that current LLMs lack the architectural foundations for genuine behavioral consistency. For safety-critical applications requiring predictable behavior, these findings indicate that current alignment strategies may be inadequate.","authors":["Tommaso Tosato","Saskia Helbling","Yorguin-Jose Mantilla-Ramos","Mahmood Hegazy","Alberto Tosato","David John Lemay","Irina Rish","Guillaume Dumas"],"pdf_url":"","comment":"Accepted at AAAI 2026, Track on AI Alignment"},{"id":"http://arxiv.org/abs/2511.06148v2","updated":"2025-12-23T04:52:15Z","published":"2025-11-08T21:58:26Z","title":"Large Language Models Develop Novel Social Biases Through Adaptive Exploration","summary":"As large language models (LLMs) are adopted into frameworks that grant them the capacity to make real decisions, it is increasingly important to ensure that they are unbiased. In this paper, we argue that the predominant approach of simply removing existing biases from models is not enough. Using a paradigm from the psychology literature, we demonstrate that LLMs can spontaneously develop novel social biases about artificial demographic groups even when no inherent differences exist. These biases result in highly stratified task allocations, which are less fair than assignments by human participants and are exacerbated by newer and larger models. In social science, emergent biases like these have been shown to result from exploration-exploitation trade-offs, where the decision-maker explores too little, allowing early observations to strongly influence impressions about entire demographic groups. To alleviate this effect, we examine a series of interventions targeting model inputs, problem structure, and explicit steering. We find that explicitly incentivizing exploration most robustly reduces stratification, highlighting the need for better multifaceted objectives to mitigate bias. These results reveal that LLMs are not merely passive mirrors of human social biases, but can actively create new ones from experience, raising urgent questions about how these systems will shape societies over time.","authors":["Addison J. Wu","Ryan Liu","Xuechunzi Bai","Thomas L. Griffiths"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.07890v3","updated":"2025-12-23T03:48:57Z","published":"2025-01-14T06:59:51Z","title":"GRAPHMOE: Amplifying Cognitive Depth of Mixture-of-Experts Network via Introducing Self-Rethinking Mechanism","summary":"Traditional Mixture-of-Experts (MoE) networks benefit from utilizing multiple smaller expert models as opposed to a single large network. However, these experts typically operate independently, leaving a question open about whether interconnecting these models could enhance the performance of MoE networks. In response, we introduce GRAPHMOE, a novel method aimed at augmenting the cognitive depth of language models via a self-rethinking mechanism constructed on Pseudo GraphMoE networks. GRAPHMOE employs a recurrent routing strategy to simulate iterative thinking steps, thereby facilitating the flow of information among expert nodes. We implement the GRAPHMOE architecture using Low-Rank Adaptation techniques (LoRA) and conduct extensive experiments on various benchmark datasets. The experimental results reveal that GRAPHMOE outperforms other LoRA based models, achieving state-of-the-art (SOTA) performance. Additionally, this study explores a novel recurrent routing strategy that may inspire further advancements in enhancing the reasoning capabilities of language models.","authors":["Bo Lv","Chen Tang","Zifan Zheng","Bohao Yang","Kun Zhao","Ning Liao","Xiaoxing Wang","Feiyu Xiong","Zhiyu Li","Nayu Liu","Jingchi Jiang"],"pdf_url":"","comment":"10 pages"},{"id":"http://arxiv.org/abs/2512.19682v2","updated":"2025-12-23T03:45:42Z","published":"2025-12-22T18:57:13Z","title":"GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators","summary":"Training capable Large Language Model (LLM) agents is critically bottlenecked by the high cost and static nature of real-world interaction data. We address this by introducing GenEnv, a framework that establishes a difficulty-aligned co-evolutionary game between an agent and a scalable, generative environment simulator. Unlike traditional methods that evolve models on static datasets, GenEnv instantiates a dataevolving: the simulator acts as a dynamic curriculum policy, continuously generating tasks specifically tailored to the agent's ``zone of proximal development''. This process is guided by a simple but effective $α$-Curriculum Reward, which aligns task difficulty with the agent's current capabilities. We evaluate GenEnv on five benchmarks, including API-Bank, ALFWorld, BFCL, Bamboogle, and TravelPlanner. Across these tasks, GenEnv improves agent performance by up to \\textbf{+40.3\\%} over 7B baselines and matches or exceeds the average performance of larger models. Compared to Gemini 2.5 Pro-based offline data augmentation, GenEnv achieves better performance while using 3.3$\\times$ less data. By shifting from static supervision to adaptive simulation, GenEnv provides a data-efficient pathway for scaling agent capabilities.","authors":["Jiacheng Guo","Ling Yang","Peter Chen","Qixin Xiao","Yinjie Wang","Xinzhe Juan","Jiahao Qiu","Ke Shen","Mengdi Wang"],"pdf_url":"","comment":"Our codes are available at https://github.com/Gen-Verse/GenEnv"},{"id":"http://arxiv.org/abs/2512.19455v2","updated":"2025-12-23T03:39:28Z","published":"2025-12-22T15:00:25Z","title":"SiamGPT: Quality-First Fine-Tuning for Stable Thai Text Generation","summary":"Open-weights large language models remain difficult to deploy for Thai due to unstable generation under complex instructions, despite strong English performance. To mitigate these limitations, We present SiamGPT-32B, an open-weights model based on Qwen3-32B, fine-tuned with a Quality-First strategy emphasizing curated supervision over data scale. The fine-tuning pipeline combines translated high-complexity English instruction data with a Thai-adapted AutoIF framework for instruction and linguistic constraints. Using supervised fine-tuning only, without continual pretraining or corpus expansion, SiamGPT-32B improves instruction adherence, multi-turn robustness, and linguistic stability. Evaluations on the SEA-HELM benchmark show that SiamGPT-32B achieves the strongest overall performance among similar-scale open-weights Thai models, with consistent gains in instruction following, multi-turn dialogue, and natural language understanding.","authors":["Thittipat Pairatsuppawat","Abhibhu Tachaapornchai","Paweekorn Kusolsomboon","Chutikan Chaiwong","Thodsaporn Chay-intr","Kobkrit Viriyayudhakorn","Nongnuch Ketui","Aslan B. Wong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.23066v3","updated":"2025-12-23T03:28:14Z","published":"2024-10-30T14:41:23Z","title":"Don't Pay Attention, PLANT It: Pretraining Attention via Learning-to-Rank","summary":"State-of-the-art Extreme Multi-Label Text Classification models rely on multi-label attention to focus on key tokens in input text, but learning good attention weights is challenging. We introduce PLANT - Pretrained and Leveraged Attention - a plug-and-play strategy for initializing attention. PLANT works by planting label-specific attention using a pretrained Learning-to-Rank model guided by mutual information gain. This architecture-agnostic approach integrates seamlessly with large language model backbones such as Mistral-7B, LLaMA3-8B, DeepSeek-V3, and Phi-3. PLANT outperforms state-of-the-art methods across tasks including ICD coding, legal topic classification, and content recommendation. Gains are especially pronounced in few-shot settings, with substantial improvements on rare labels. Ablation studies confirm that attention initialization is a key driver of these gains. For code and trained models, see https://github.com/debjyotiSRoy/xcube/tree/plant","authors":["Debjyoti Saha Roy","Byron C. Wallace","Javed A. Aslam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.15649v2","updated":"2025-12-23T03:03:58Z","published":"2025-12-17T17:58:35Z","title":"VTCBench: Can Vision-Language Models Understand Long Context with Vision-Text Compression?","summary":"The computational and memory overheads associated with expanding the context window of LLMs severely limit their scalability. A noteworthy solution is vision-text compression (VTC), exemplified by frameworks like DeepSeek-OCR and Glyph, which convert long texts into dense 2D visual representations, thereby achieving token compression ratios of 3x-20x. However, the impact of this high information density on the core long-context capabilities of vision-language models (VLMs) remains under-investigated. To address this gap, we introduce the first benchmark for VTC and systematically assess the performance of VLMs across three long-context understanding settings: VTC-Retrieval, which evaluates the model's ability to retrieve and aggregate information; VTC-Reasoning, which requires models to infer latent associations to locate facts with minimal lexical overlap; and VTC-Memory, which measures comprehensive question answering within long-term dialogue memory. Furthermore, we establish the VTCBench-Wild to simulate diverse input scenarios.We comprehensively evaluate leading open-source and proprietary models on our benchmarks. The results indicate that, despite being able to decode textual information (e.g., OCR) well, most VLMs exhibit a surprisingly poor long-context understanding ability with VTC-processed information, failing to capture long associations or dependencies in the context.This study provides a deep understanding of VTC and serves as a foundation for designing more efficient and scalable VLMs.","authors":["Hongbo Zhao","Meng Wang","Fei Zhu","Wenzhuo Liu","Bolin Ni","Fanhu Zeng","Gaofeng Meng","Zhaoxiang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19995v1","updated":"2025-12-23T02:44:25Z","published":"2025-12-23T02:44:25Z","title":"Schoenfeld's Anatomy of Mathematical Reasoning by Language Models","summary":"Large language models increasingly expose reasoning traces, yet their underlying cognitive structure and steps remain difficult to identify and analyze beyond surface-level statistics. We adopt Schoenfeld's Episode Theory as an inductive, intermediate-scale lens and introduce ThinkARM (Anatomy of Reasoning in Models), a scalable framework that explicitly abstracts reasoning traces into functional reasoning steps such as Analysis, Explore, Implement, Verify, etc. When applied to mathematical problem solving by diverse models, this abstraction reveals reproducible thinking dynamics and structural differences between reasoning and non-reasoning models, which are not apparent from token-level views. We further present two diagnostic case studies showing that exploration functions as a critical branching step associated with correctness, and that efficiency-oriented methods selectively suppress evaluative feedback steps rather than uniformly shortening responses. Together, our results demonstrate that episode-level representations make reasoning steps explicit, enabling systematic analysis of how reasoning is structured, stabilized, and altered in modern language models.","authors":["Ming Li","Chenrui Fan","Yize Cheng","Soheil Feizi","Tianyi Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.24347v3","updated":"2025-12-23T02:15:00Z","published":"2025-05-30T08:40:49Z","title":"Fewer Hallucinations, More Verification: A Three-Stage LLM-Based Framework for ASR Error Correction","summary":"Automatic Speech Recognition (ASR) error correction aims to correct recognition errors while preserving accurate text. Although traditional approaches demonstrate moderate effectiveness, LLMs offer a paradigm that eliminates the need for training and labeled data. However, directly using LLMs will encounter hallucinations problem, which may lead to the modification of the correct text. To address this problem, we propose the Reliable LLM Correction Framework (RLLM-CF), which consists of three stages: (1) error pre-detection, (2) chain-of-thought sub-tasks iterative correction, and (3) reasoning process verification. The advantage of our method is that it does not require additional information or fine-tuning of the model, and ensures the correctness of the LLM correction under multi-pass programming. Experiments on AISHELL-1, AISHELL-2, and Librispeech show that the GPT-4o model enhanced by our framework achieves 21%, 11%, 9%, and 11.4% relative reductions in CER/WER.","authors":["Yangui Fang","Baixu Chen","Jing Peng","Xu Li","Yu Xi","Chengwei Zhang","Guohui Zhong"],"pdf_url":"","comment":"This paper has been ACCEPTED for publication in ASRU"},{"id":"http://arxiv.org/abs/2506.05671v2","updated":"2025-12-23T02:11:59Z","published":"2025-06-06T01:34:29Z","title":"Low-Resource Domain Adaptation for Speech LLMs via Text-Only Fine-Tuning","summary":"Recent advances in automatic speech recognition (ASR) have combined speech encoders with large language models (LLMs) through projection, forming Speech LLMs with strong performance. However, adapting them to new domains remains challenging, especially in low-resource settings where paired speech-text data is scarce. We propose a text-only fine-tuning strategy for Speech LLMs using unpaired target-domain text without requiring additional audio. To preserve speech-text alignment, we introduce a real-time evaluation mechanism during fine-tuning. This enables effective domain adaptation while maintaining source-domain performance. Experiments on LibriSpeech, SlideSpeech, and Medical datasets show that our method achieves competitive recognition performance, with minimal degradation compared to full audio-text fine-tuning. It also improves generalization to new domains without catastrophic forgetting, highlighting the potential of text-only fine-tuning for low-resource domain adaptation of ASR.","authors":["Yangui Fang","Jing Peng","Xu Li","Yu Xi","Chengwei Zhang","Guohui Zhong","Kai Yu"],"pdf_url":"","comment":"This paper has been ACCEPTED for publication in ASRU"},{"id":"http://arxiv.org/abs/2512.19950v1","updated":"2025-12-23T00:41:48Z","published":"2025-12-23T00:41:48Z","title":"Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems","summary":"Large Language Models are increasingly used in conversational systems such as digital personal assistants, shaping how people interact with technology through language. While their responses often sound fluent and natural, they can also carry subtle tone biases such as sounding overly polite, cheerful, or cautious even when neutrality is expected. These tendencies can influence how users perceive trust, empathy, and fairness in dialogue. In this study, we explore tone bias as a hidden behavioral trait of large language models. The novelty of this research lies in the integration of controllable large language model based dialogue synthesis with tone classification models, enabling robust and ethical emotion recognition in personal assistant interactions. We created two synthetic dialogue datasets, one generated from neutral prompts and another explicitly guided to produce positive or negative tones. Surprisingly, even the neutral set showed consistent tonal skew, suggesting that bias may stem from the model's underlying conversational style. Using weak supervision through a pretrained DistilBERT model, we labeled tones and trained several classifiers to detect these patterns. Ensemble models achieved macro F1 scores up to 0.92, showing that tone bias is systematic, measurable, and relevant to designing fair and trustworthy conversational AI.","authors":["Heet Bodara","Md Masum Mushfiq","Isma Farah Siddiqui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20848v1","updated":"2025-12-23T23:54:32Z","published":"2025-12-23T23:54:32Z","title":"Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning","summary":"We present Nemotron 3 Nano 30B-A3B, a Mixture-of-Experts hybrid Mamba-Transformer language model. Nemotron 3 Nano was pretrained on 25 trillion text tokens, including more than 3 trillion new unique tokens over Nemotron 2, followed by supervised fine tuning and large-scale RL on diverse environments. Nemotron 3 Nano achieves better accuracy than our previous generation Nemotron 2 Nano while activating less than half of the parameters per forward pass. It achieves up to 3.3x higher inference throughput than similarly-sized open models like GPT-OSS-20B and Qwen3-30B-A3B-Thinking-2507, while also being more accurate on popular benchmarks. Nemotron 3 Nano demonstrates enhanced agentic, reasoning, and chat abilities and supports context lengths up to 1M tokens. We release both our pretrained Nemotron 3 Nano 30B-A3B Base and post-trained Nemotron 3 Nano 30B-A3B checkpoints on Hugging Face.","authors":[" NVIDIA"," :","Aaron Blakeman","Aaron Grattafiori","Aarti Basant","Abhibha Gupta","Abhinav Khattar","Adi Renduchintala","Aditya Vavre","Akanksha Shukla","Akhiad Bercovich","Aleksander Ficek","Aleksandr Shaposhnikov","Alex Kondratenko","Alexander Bukharin","Alexandre Milesi","Ali Taghibakhshi","Alisa Liu","Amelia Barton","Ameya Sunil Mahabaleshwarkar","Amir Klein","Amit Zuker","Amnon Geifman","Amy Shen","Anahita Bhiwandiwalla","Andrew Tao","Ann Guan","Anubhav Mandarwal","Arham Mehta","Ashwath Aithal","Ashwin Poojary","Asif Ahamed","Asma Kuriparambil Thekkumpate","Ayush Dattagupta","Banghua Zhu","Bardiya Sadeghi","Barnaby Simkin","Ben Lanir","Benedikt Schifferer","Besmira Nushi","Bilal Kartal","Bita Darvish Rouhani","Boris Ginsburg","Brandon Norick","Brandon Soubasis","Branislav Kisacanin","Brian Yu","Bryan Catanzaro","Carlo del Mundo","Chantal Hwang","Charles Wang","Cheng-Ping Hsieh","Chenghao Zhang","Chenhan Yu","Chetan Mungekar","Chintan Patel","Chris Alexiuk","Christopher Parisien","Collin Neale","Damon Mosk-Aoyama","Dan Su","Dane Corneil","Daniel Afrimi","Daniel Rohrer","Daniel Serebrenik","Daria Gitman","Daria Levy","Darko Stosic","David Mosallanezhad","Deepak Narayanan","Dhruv Nathawani","Dima Rekesh","Dina Yared","Divyanshu Kakwani","Dong Ahn","Duncan Riach","Dusan Stosic","Edgar Minasyan","Edward Lin","Eileen Long","Eileen Peters Long","Elena Lantz","Ellie Evans","Elliott Ning","Eric Chung","Eric Harper","Eric Tramel","Erick Galinkin","Erik Pounds","Evan Briones","Evelina Bakhturina","Faisal Ladhak","Fay Wang","Fei Jia","Felipe Soares","Feng Chen","Ferenc Galko","Frankie Siino","Gal Hubara Agam","Ganesh Ajjanagadde","Gantavya Bhatt","Gargi Prasad","George Armstrong","Gerald Shen","Gorkem Batmaz","Grigor Nalbandyan","Haifeng Qian","Harsh Sharma","Hayley Ross","Helen Ngo","Herman Sahota","Hexin Wang","Himanshu Soni","Hiren Upadhyay","Huizi Mao","Huy C Nguyen","Huy Q Nguyen","Iain Cunningham","Ido Shahaf","Igor Gitman","Ilya Loshchilov","Ivan Moshkov","Izzy Putterman","Jan Kautz","Jane Polak Scowcroft","Jared Casper","Jatin Mitra","Jeffrey Glick","Jenny Chen","Jesse Oliver","Jian Zhang","Jiaqi Zeng","Jie Lou","Jimmy Zhang","Jining Huang","Joey Conway","Joey Guman","John Kamalu","Johnny Greco","Jonathan Cohen","Joseph Jennings","Joyjit Daw","Julien Veron Vialard","Junkeun Yi","Jupinder Parmar","Kai Xu","Kan Zhu","Kari Briski","Katherine Cheung","Katherine Luna","Keshav Santhanam","Kevin Shih","Kezhi Kong","Khushi Bhardwaj","Krishna C. Puvvada","Krzysztof Pawelec","Kumar Anik","Lawrence McAfee","Laya Sleiman","Leon Derczynski","Li Ding","Lucas Liebenwein","Luis Vega","Maanu Grover","Maarten Van Segbroeck","Maer Rodrigues de Melo","Makesh Narsimhan Sreedhar","Manoj Kilaru","Maor Ashkenazi","Marc Romeijn","Mark Cai","Markus Kliegl","Maryam Moosaei","Matvei Novikov","Mehrzad Samadi","Melissa Corpuz","Mengru Wang","Meredith Price","Michael Boone","Michael Evans","Miguel Martinez","Mike Chrzanowski","Mohammad Shoeybi","Mostofa Patwary","Nabin Mulepati","Natalie Hereth","Nave Assaf","Negar Habibi","Neta Zmora","Netanel Haber","Nicola Sessions","Nidhi Bhatia","Nikhil Jukar","Nikki Pope","Nikolai Ludwig","Nima Tajbakhsh","Nirmal Juluru","Oleksii Hrinchuk","Oleksii Kuchaiev","Olivier Delalleau","Oluwatobi Olabiyi","Omer Ullman Argov","Ouye Xie","Parth Chadha","Pasha Shamis","Pavlo Molchanov","Pawel Morkisz","Peter Dykas","Peter Jin","Pinky Xu","Piotr Januszewski","Pranav Prashant Thombre","Prasoon Varshney","Pritam Gundecha","Qing Miao","Rabeeh Karimi Mahabadi","Ran El-Yaniv","Ran Zilberstein","Rasoul Shafipour","Rich Harang","Rick Izzo","Rima Shahbazyan","Rishabh Garg","Ritika Borkar","Ritu Gala","Riyad Islam","Roger Waleffe","Rohit Watve","Roi Koren","Ruoxi Zhang","Russell J. Hewett","Ryan Prenger","Ryan Timbrook","Sadegh Mahdavi","Sahil Modi","Samuel Kriman","Sanjay Kariyappa","Sanjeev Satheesh","Saori Kaji","Satish Pasumarthi","Sean Narentharen","Sean Narenthiran","Seonmyeong Bak","Sergey Kashirsky","Seth Poulos","Shahar Mor","Shanmugam Ramasamy","Shantanu Acharya","Shaona Ghosh","Sharath Turuvekere Sreenivas","Shelby Thomas","Shiqing Fan","Shreya Gopal","Shrimai Prabhumoye","Shubham Pachori","Shubham Toshniwal","Shuoyang Ding","Siddharth Singh","Simeng Sun","Smita Ithape","Somshubra Majumdar","Soumye Singhal","Stefania Alborghetti","Stephen Ge","Sugam Dipak Devare","Sumeet Kumar Barua","Suseella Panguluri","Suyog Gupta","Sweta Priyadarshi","Syeda Nahida Akter","Tan Bui","Teodor-Dumitru Ene","Terry Kong","Thanh Do","Tijmen Blankevoort","Tom Balough","Tomer Asida","Tomer Bar Natan","Tugrul Konuk","Twinkle Vashishth","Udi Karpas","Ushnish De","Vahid Noorozi","Vahid Noroozi","Venkat Srinivasan","Venmugil Elango","Vijay Korthikanti","Vitaly Kurin","Vitaly Lavrukhin","Wanli Jiang","Wasi Uddin Ahmad","Wei Du","Wei Ping","Wenfei Zhou","Will Jennings","William Zhang","Wojciech Prazuch","Xiaowei Ren","Yashaswi Karnati","Yejin Choi","Yev Meyer","Yi-Fu Wu","Yian Zhang","Ying Lin","Yonatan Geifman","Yonggan Fu","Yoshi Subara","Yoshi Suhara","Yubo Gao","Zach Moshe","Zhen Dong","Zihan Liu","Zijia Chen","Zijie Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.18839v3","updated":"2025-12-23T23:25:26Z","published":"2025-04-26T07:51:05Z","title":"Detect, Explain, Escalate: Sustainable Dialogue Breakdown Management for LLM Agents","summary":"Large Language Models (LLMs) have demonstrated substantial capabilities in conversational AI applications, yet their susceptibility to dialogue breakdowns poses significant challenges to deployment reliability and user trust. This paper introduces a \"Detect, Explain, Escalate\" framework to manage dialogue breakdowns in LLM-powered agents, emphasizing resource-efficient operation. Our approach integrates two key strategies: (1) We fine-tune a compact 8B-parameter model, augmented with teacher-generated reasoning traces, which serves as an efficient real-time breakdown detector and explainer. This model demonstrates robust classification and calibration on English and Japanese dialogues, and generalizes to the BETOLD dataset, improving accuracy by 7% over its baseline. (2) We systematically evaluate frontier LLMs using advanced prompting (few-shot, chain-of-thought, analogical reasoning) for high-fidelity breakdown assessment. These are integrated into an \"escalation\" architecture where our efficient detector defers to larger models only when necessary, substantially reducing operational costs and computational overhead. Our fine-tuned model and prompting strategies achieve state-of-the-art performance on DBDC5 and strong results on BETOLD, outperforming specialized classifiers on DBDC5 and narrowing the performance gap to larger proprietary models. The proposed monitor-escalate pipeline reduces inference costs by 54%, providing a cost-effective and interpretable solution for robust conversational AI in high-impact domains. Code and models will be publicly released.","authors":["Abdellah Ghassel","Xianzhi Li","Xiaodan Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20822v1","updated":"2025-12-23T22:52:24Z","published":"2025-12-23T22:52:24Z","title":"MediEval: A Unified Medical Benchmark for Patient-Contextual and Knowledge-Grounded Reasoning in LLMs","summary":"Large Language Models (LLMs) are increasingly applied to medicine, yet their adoption is limited by concerns over reliability and safety. Existing evaluations either test factual medical knowledge in isolation or assess patient-level reasoning without verifying correctness, leaving a critical gap. We introduce MediEval, a benchmark that links MIMIC-IV electronic health records (EHRs) to a unified knowledge base built from UMLS and other biomedical vocabularies. MediEval generates diverse factual and counterfactual medical statements within real patient contexts, enabling systematic evaluation across a 4-quadrant framework that jointly considers knowledge grounding and contextual consistency. Using this framework, we identify critical failure modes, including hallucinated support and truth inversion, that current proprietary, open-source, and domain-specific LLMs frequently exhibit. To address these risks, we propose Counterfactual Risk-Aware Fine-tuning (CoRFu), a DPO-based method with an asymmetric penalty targeting unsafe confusions. CoRFu improves by +16.4 macro-F1 points over the base model and eliminates truth inversion errors, demonstrating both higher accuracy and substantially greater safety.","authors":["Zhan Qu","Michael Färber"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20817v1","updated":"2025-12-23T22:33:54Z","published":"2025-12-23T22:33:54Z","title":"EssayCBM: Rubric-Aligned Concept Bottleneck Models for Transparent Essay Grading","summary":"Understanding how automated grading systems evaluate essays remains a significant challenge for educators and students, especially when large language models function as black boxes. We introduce EssayCBM, a rubric-aligned framework that prioritizes interpretability in essay assessment. Instead of predicting grades directly from text, EssayCBM evaluates eight writing concepts, such as Thesis Clarity and Evidence Use, through dedicated prediction heads on an encoder. These concept scores form a transparent bottleneck, and a lightweight network computes the final grade using only concepts. Instructors can adjust concept predictions and instantly view the updated grade, enabling accountable human-in-the-loop evaluation. EssayCBM matches black-box performance while offering actionable, concept-level feedback through an intuitive web interface.","authors":["Kumar Satvik Chaudhary","Chengshuai Zhao","Fan Zhang","Yung Hin Tse","Garima Agrawal","Yuli Deng","Huan Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20812v1","updated":"2025-12-23T22:22:18Z","published":"2025-12-23T22:22:18Z","title":"Semantic Deception: When Reasoning Models Can't Compute an Addition","summary":"Large language models (LLMs) are increasingly used in situations where human values are at stake, such as decision-making tasks that involve reasoning when performed by humans. We investigate the so-called reasoning capabilities of LLMs over novel symbolic representations by introducing an experimental framework that tests their ability to process and manipulate unfamiliar symbols. We introduce semantic deceptions: situations in which symbols carry misleading semantic associations due to their form, such as being embedded in specific contexts, designed to probe whether LLMs can maintain symbolic abstraction or whether they default to exploiting learned semantic associations. We redefine standard digits and mathematical operators using novel symbols, and task LLMs with solving simple calculations expressed in this altered notation. The objective is: (1) to assess LLMs' capacity for abstraction and manipulation of arbitrary symbol systems; (2) to evaluate their ability to resist misleading semantic cues that conflict with the task's symbolic logic. Through experiments with four LLMs we show that semantic cues can significantly deteriorate reasoning models' performance on very simple tasks. They reveal limitations in current LLMs' ability for symbolic manipulations and highlight a tendency to over-rely on surface-level semantics, suggesting that chain-of-thoughts may amplify reliance on statistical correlations. Even in situations where LLMs seem to correctly follow instructions, semantic cues still impact basic capabilities. These limitations raise ethical and societal concerns, undermining the widespread and pernicious tendency to attribute reasoning abilities to LLMs and suggesting how LLMs might fail, in particular in decision-making contexts where robust symbolic reasoning is essential and should not be compromised by residual semantic associations inherited from the model's training.","authors":["Nathaniël de Leeuw","Marceau Nahon","Mathis Reymond","Raja Chatila","Mehdi Khamassi"],"pdf_url":"","comment":"22 pages, 5 figures"},{"id":"http://arxiv.org/abs/2512.20796v1","updated":"2025-12-23T21:44:20Z","published":"2025-12-23T21:44:20Z","title":"Measuring Mechanistic Independence: Can Bias Be Removed Without Erasing Demographics?","summary":"We investigate how independent demographic bias mechanisms are from general demographic recognition in language models. Using a multi-task evaluation setup where demographics are associated with names, professions, and education levels, we measure whether models can be debiased while preserving demographic detection capabilities. We compare attribution-based and correlation-based methods for locating bias features. We find that targeted sparse autoencoder feature ablations in Gemma-2-9B reduce bias without degrading recognition performance: attribution-based ablations mitigate race and gender profession stereotypes while preserving name recognition accuracy, whereas correlation-based ablations are more effective for education bias. Qualitative analysis further reveals that removing attribution features in education tasks induces ``prior collapse'', thus increasing overall bias. This highlights the need for dimension-specific interventions. Overall, our results show that demographic bias arises from task-specific mechanisms rather than absolute demographic markers, and that mechanistic inference-time interventions can enable surgical debiasing without compromising core model capabilities.","authors":["Zhengyang Shan","Aaron Mueller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20794v1","updated":"2025-12-23T21:41:36Z","published":"2025-12-23T21:41:36Z","title":"Investigating Model Editing for Unlearning in Large Language Models","summary":"Machine unlearning aims to remove unwanted information from a model, but many methods are inefficient for LLMs with large numbers of parameters or fail to fully remove the intended information without degrading performance on knowledge that should be retained. Model editing algorithms solve a similar problem of changing information in models, but they focus on redirecting inputs to a new target rather than removing that information altogether. In this work, we explore the editing algorithms ROME, IKE, and WISE and design new editing targets for an unlearning setting. Through this investigation, we show that model editing approaches can exceed baseline unlearning methods in terms of quality of forgetting depending on the setting. Like traditional unlearning techniques, they struggle to encapsulate the scope of what is to be unlearned without damage to the overall model performance.","authors":["Shariqah Hossain","Lalana Kagal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.22615v2","updated":"2025-12-23T21:29:42Z","published":"2025-09-26T17:41:57Z","title":"GaussianVision: Vision-Language Alignment from Compressed Image Representations using 2D Gaussian Splatting","summary":"Modern vision language pipelines are driven by RGB vision encoders trained on massive image text corpora. While these pipelines have enabled impressive zero-shot capabilities and strong transfer across tasks, they still inherit two structural inefficiencies from the pixel domain: (i) transmitting dense RGB images from edge devices to the cloud is energy-intensive and costly, and (ii) patch-based tokenization explodes sequence length, stressing attention budgets and context limits. We explore 2D Gaussian Splatting (2DGS) as an alternative visual substrate for alignment: a compact, spatially adaptive representation that parameterizes images by a set of colored anisotropic Gaussians. We develop a scalable 2DGS pipeline with structured initialization, luminance-aware pruning, and batched CUDA kernels, achieving over 90x faster fitting and about 97% GPU utilization compared to prior implementations. We further adapt contrastive language-image pre-training (CLIP) to 2DGS by reusing a frozen RGB-based transformer backbone with a lightweight splat-aware input stem and a perceiver resampler, training only 9.7% to 13.8% of the total parameters. On a 12.8M dataset from DataComp, GS encoders yield competitive zero-shot performance on 38 datasets from the CLIP benchmark while compressing inputs 3x to 23.5x relative to pixels. Our results establish 2DGS as a viable multimodal substrate, pinpoint architectural bottlenecks, and open a path toward representations that are both semantically powerful and transmission-efficient for edge-cloud learning.","authors":["Yasmine Omri","Connor Ding","Tsachy Weissman","Thierry Tambe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20780v1","updated":"2025-12-23T21:29:09Z","published":"2025-12-23T21:29:09Z","title":"Large Language Models Approach Expert Pedagogical Quality in Math Tutoring but Differ in Instructional and Linguistic Profiles","summary":"Recent work has explored the use of large language models for generating tutoring responses in mathematics, yet it remains unclear how closely their instructional behavior aligns with expert human practice. We examine this question using a controlled, turn-level comparison in which expert human tutors, novice human tutors, and multiple large language models respond to the same set of math remediation conversation turns. We examine both instructional strategies and linguistic characteristics of tutoring responses, including restating and revoicing, pressing for accuracy, lexical diversity, readability, politeness, and agency. We find that large language models approach expert levels of perceived pedagogical quality on average but exhibit systematic differences in their instructional and linguistic profiles. In particular, large language models tend to underuse restating and revoicing strategies characteristic of expert human tutors, while producing longer, more lexically diverse, and more polite responses. Statistical analyses show that restating and revoicing, lexical diversity, and pressing for accuracy are positively associated with perceived pedagogical quality, whereas higher levels of agentic and polite language are negatively associated. Overall, recent large language models exhibit levels of perceived pedagogical quality comparable to expert human tutors, while relying on different instructional and linguistic strategies. These findings underscore the value of analyzing instructional strategies and linguistic characteristics when evaluating tutoring responses across human tutors and intelligent tutoring systems.","authors":["Ramatu Oiza Abdulsalam","Segun Aroyehun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.06303v2","updated":"2025-12-23T21:21:10Z","published":"2025-05-21T16:15:01Z","title":"Reward Is Enough: LLMs Are In-Context Reinforcement Learners","summary":"Reinforcement learning (RL) is a framework for solving sequential decision-making problems. In this work, we demonstrate that, surprisingly, RL emerges during the inference time of large language models (LLMs), a phenomenon we term in-context RL (ICRL). To reveal this capability, we introduce a simple multi-round prompting framework, we call ICRL prompting, for inference-time self-improvement. The goal of ICRL prompting is to guide LLMs to perform reinforcement learning during inference for self-improvement on a given task. After each response, the model receives numerical scalar feedback, denoted as a reward. In the next round, we prompt the LLM again together with a context that concatenates all prior responses and their associated rewards. We consistently observe that response quality improves as the context grows. In other words, the LLM can optimize scalar reward signals during inference, exhibiting behavior analogous to reinforcement learning. We evaluate ICRL prompting on Game of 24, creative writing, ScienceWorld, and Olympiad-level math competitions (AIME and HMMT), demonstrating significant improvements over baselines such as Self-Refine and Reflexion. Notably, even when the reward signals are generated by the same LLM, ICRL prompting still improves performance, highlighting a promising new paradigm for test-time scaling.","authors":["Kefan Song","Amir Moeini","Peng Wang","Lei Gong","Rohan Chandra","Yanjun Qi","Shangtong Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20773v1","updated":"2025-12-23T21:21:08Z","published":"2025-12-23T21:21:08Z","title":"Adversarial Training for Failure-Sensitive User Simulation in Mental Health Dialogue Optimization","summary":"Realistic user simulation is crucial for training and evaluating task-oriented dialogue (TOD) systems, yet creating simulators that accurately replicate human behavior remains challenging. A key property of effective simulators is their ability to expose failure modes of the systems they evaluate. We present an adversarial training framework that iteratively improves user simulator realism through a competitive dynamic between a generator (user simulator) and a discriminator. Applied to mental health support chatbots, our approach demonstrates that fine-tuned simulators dramatically outperform zero-shot base models at surfacing system issues, and adversarial training further enhances diversity, distributional alignment, and predictive validity. The resulting simulator achieves a strong correlation between simulated and real failure occurrence rates across diverse chatbot configurations while maintaining low distributional divergence of failure modes. Discriminator accuracy decreases drastically after three adversarial iterations, suggesting improved realism. These results provide evidence that adversarial training is a promising approach for creating realistic user simulators in mental health support TOD domains, enabling rapid, reliable, and cost-effective system evaluation before deployment.","authors":["Ziyi Zhu","Olivier Tieleman","Caitlin A. Stamatis","Luka Smyth","Thomas D. Hull","Daniel R. Cahn","Matteo Malgaroli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20760v1","updated":"2025-12-23T20:45:31Z","published":"2025-12-23T20:45:31Z","title":"Generalization of RLVR Using Causal Reasoning as a Testbed","summary":"Reinforcement learning with verifiable rewards (RLVR) has emerged as a promising paradigm for post-training large language models (LLMs) on complex reasoning tasks. Yet, the conditions under which RLVR yields robust generalization remain poorly understood. This paper provides an empirical study of RLVR generalization in the setting of probabilistic inference over causal graphical models. This setting offers two natural axes along which to examine generalization: (i) the level of the probabilistic query -- associational, interventional, or counterfactual -- and (ii) the structural complexity of the query, measured by the size of its relevant subgraph. We construct datasets of causal graphs and queries spanning these difficulty axes and fine-tune Qwen-2.5-Instruct models using RLVR or supervised fine-tuning (SFT). We vary both the model scale (3B-32B) and the query level included in training. We find that RLVR yields stronger within-level and across-level generalization than SFT, but only for specific combinations of model size and training query level. Further analysis shows that RLVR's effectiveness depends on the model's initial reasoning competence. With sufficient initial competence, RLVR improves an LLM's marginalization strategy and reduces errors in intermediate probability calculations, producing substantial accuracy gains, particularly on more complex queries. These findings show that RLVR can improve specific causal reasoning subskills, with its benefits emerging only when the model has sufficient initial competence.","authors":["Brian Lu","Hongyu Zhao","Shuo Sun","Hao Peng","Rui Ding","Hongyuan Mei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20757v1","updated":"2025-12-23T20:43:06Z","published":"2025-12-23T20:43:06Z","title":"TokSuite: Measuring the Impact of Tokenizer Choice on Language Model Behavior","summary":"Tokenizers provide the fundamental basis through which text is represented and processed by language models (LMs). Despite the importance of tokenization, its role in LM performance and behavior is poorly understood due to the challenge of measuring the impact of tokenization in isolation. To address this need, we present TokSuite, a collection of models and a benchmark that supports research into tokenization's influence on LMs. Specifically, we train fourteen models that use different tokenizers but are otherwise identical using the same architecture, dataset, training budget, and initialization. Additionally, we curate and release a new benchmark that specifically measures model performance subject to real-world perturbations that are likely to influence tokenization. Together, TokSuite allows robust decoupling of the influence of a model's tokenizer, supporting a series of novel findings that elucidate the respective benefits and shortcomings of a wide range of popular tokenizers.","authors":["Gül Sena Altıntaş","Malikeh Ehghaghi","Brian Lester","Fengyuan Liu","Wanru Zhao","Marco Ciccone","Colin Raffel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.16753v3","updated":"2025-12-23T20:35:30Z","published":"2025-08-22T19:13:21Z","title":"GAICo: A Deployed and Extensible Framework for Evaluating Diverse and Multimodal Generative AI Outputs","summary":"The rapid proliferation of Generative AI (GenAI) into diverse, high-stakes domains necessitates robust and reproducible evaluation methods. However, practitioners often resort to ad-hoc, non-standardized scripts, as common metrics are often unsuitable for specialized, structured outputs (e.g., automated plans, time-series) or holistic comparison across modalities (e.g., text, audio, and image). This fragmentation hinders comparability and slows AI system development. To address this challenge, we present GAICo (Generative AI Comparator): a deployed, open-source Python library that streamlines and standardizes GenAI output comparison. GAICo provides a unified, extensible framework supporting a comprehensive suite of reference-based metrics for unstructured text, specialized structured data formats, and multimedia (images, audio). Its architecture features a high-level API for rapid, end-to-end analysis, from multi-model comparison to visualization and reporting, alongside direct metric access for granular control. We demonstrate GAICo's utility through a detailed case study evaluating and debugging complex, multi-modal AI Travel Assistant pipelines. GAICo empowers AI researchers and developers to efficiently assess system performance, make evaluation reproducible, improve development velocity, and ultimately build more trustworthy AI systems, aligning with the goal of moving faster and safer in AI deployment. Since its release on PyPI in Jun 2025, the tool has been downloaded over 13K times, across versions, by Aug 2025, demonstrating growing community interest.","authors":["Nitin Gupta","Pallav Koppisetti","Kausik Lakkaraju","Biplav Srivastava"],"pdf_url":"","comment":"11 pages, 7 figures; accepted at IAAI/AAAI 2026; extended version"},{"id":"http://arxiv.org/abs/2512.14856v2","updated":"2025-12-23T20:01:24Z","published":"2025-12-16T19:19:34Z","title":"T5Gemma 2: Seeing, Reading, and Understanding Longer","summary":"We introduce T5Gemma 2, the next generation of the T5Gemma family of lightweight open encoder-decoder models, featuring strong multilingual, multimodal and long-context capabilities. T5Gemma 2 follows the adaptation recipe (via UL2) in T5Gemma -- adapting a pretrained decoder-only model into an encoder-decoder model, and extends it from text-only regime to multimodal based on the Gemma 3 models. We further propose two methods to improve the efficiency: tied word embedding that shares all embeddings across encoder and decoder, and merged attention that unifies decoder self- and cross-attention into a single joint module. Experiments demonstrate the generality of the adaptation strategy over architectures and modalities as well as the unique strength of the encoder-decoder architecture on long context modeling. Similar to T5Gemma, T5Gemma 2 yields comparable or better pretraining performance and significantly improved post-training performance than its Gemma 3 counterpart. We release the pretrained models (270M-270M, 1B-1B and 4B-4B) to the community for future research.","authors":["Biao Zhang","Paul Suganthan","Gaël Liu","Ilya Philippov","Sahil Dua","Ben Hora","Kat Black","Gus Martins","Omar Sanseviero","Shreya Pathak","Cassidy Hardin","Francesco Visin","Jiageng Zhang","Kathleen Kenealy","Qin Yin","Xiaodan Song","Olivier Lacombe","Armand Joulin","Tris Warkentin","Adam Roberts"],"pdf_url":"","comment":"technical report"},{"id":"http://arxiv.org/abs/2505.14582v3","updated":"2025-12-23T19:59:27Z","published":"2025-05-20T16:38:32Z","title":"Can Pruning Improve Reasoning? Revisiting Long-CoT Compression with Capability in Mind for Better Reasoning","summary":"Long chain-of-thought (Long-CoT) reasoning improves accuracy in LLMs, yet its verbose, self-reflective style often hinders effective distillation into small language models (SLMs). We revisit Long-CoT compression through the lens of capability alignment and ask: Can pruning improve reasoning? We propose Prune-on-Logic, a structure-aware framework that transforms Long-CoT into logic graphs and selectively prunes low-utility reasoning steps under self-verification constraints. Through systematic analysis across three pruning strategies targeting entire chains, core reasoning, and verification, we find that verification pruning consistently improves accuracy while reducing token usage, whereas pruning reasoning steps or indiscriminate pruning degrades performance. Our study reveals that effective pruning aligns supervision with model capacity rather than merely shortening inputs. Gains hold across tasks, model scales, and CoT capability, with larger models benefiting more from pruning due to richer but more redundant reasoning. Our empirical findings highlight pruning as a structural optimization strategy for aligning CoT reasoning with SLM capacity.","authors":["Shangziqi Zhao","Jiahao Yuan","Jinyang Wu","Zhenglin Wang","Guisong Yang","Usman Naseem"],"pdf_url":"","comment":"19 pages,6 figures"},{"id":"http://arxiv.org/abs/2512.20745v1","updated":"2025-12-23T19:57:49Z","published":"2025-12-23T19:57:49Z","title":"AgentMath: Empowering Mathematical Reasoning for Large Language Models via Tool-Augmented Agent","summary":"Large Reasoning Models (LRMs) like o3 and DeepSeek-R1 have achieved remarkable progress in natural language reasoning with long chain-of-thought. However, they remain computationally inefficient and struggle with accuracy when solving problems requiring complex mathematical operations. In this work, we present AgentMath, an agent framework that seamlessly integrates language models' reasoning capabilities with code interpreters' computational precision to efficiently tackle complex mathematical problems. Our approach introduces three key innovations: (1) An automated method that converts natural language chain-of-thought into structured tool-augmented trajectories, generating high-quality supervised fine-tuning (SFT) data to alleviate data scarcity; (2) A novel agentic reinforcement learning (RL) paradigm that dynamically interleaves natural language generation with real-time code execution. This enables models to autonomously learn optimal tool-use strategies through multi-round interactive feedback, while fostering emergent capabilities in code refinement and error correction; (3) An efficient training system incorporating innovative techniques, including request-level asynchronous rollout scheduling, agentic partial rollout, and prefix-aware weighted load balancing, achieving 4-5x speedup and making efficient RL training feasible on ultra-long sequences with scenarios with massive tool calls.Extensive evaluations show that AgentMath achieves state-of-the-art performance on challenging mathematical competition benchmarks including AIME24, AIME25, and HMMT25. Specifically, AgentMath-30B-A3B attains 90.6%, 86.4%, and 73.8% accuracy respectively, achieving advanced capabilities.These results validate the effectiveness of our approach and pave the way for building more sophisticated and scalable mathematical reasoning agents.","authors":["Haipeng Luo","Huawen Feng","Qingfeng Sun","Can Xu","Kai Zheng","Yufei Wang","Tao Yang","Han Hu","Yansong Tang","Di Wang"],"pdf_url":"","comment":"LLM, Mathematical Reasoning"},{"id":"http://arxiv.org/abs/2512.20724v1","updated":"2025-12-23T19:35:02Z","published":"2025-12-23T19:35:02Z","title":"SA-DiffuSeq: Addressing Computational and Scalability Challenges in Long-Document Generation with Sparse Attention","summary":"Diffusion based approaches to long form text generation suffer from prohibitive computational cost and memory overhead as sequence length increases. We introduce SA-DiffuSeq, a diffusion framework that integrates sparse attention to fundamentally improve scalability for long document modeling. By selectively allocating attention within the diffusion process, SA-DiffuSeq significantly reduces computational complexity while maintaining semantic coherence and generation quality. A key component of our method is a soft absorbing state tailored to sparse attention dynamics, which stabilizes diffusion trajectories and accelerates sequence reconstruction. This design improves sampling efficiency and enhances precision in long range dependency modeling. Extensive experiments demonstrate that SA-DiffuSeq consistently surpasses state of the art diffusion baselines in both training efficiency and sampling speed, with especially strong gains on extended sequences. These properties make SA-DiffuSeq well suited for demanding long form applications such as scientific writing, large scale code generation, and multi turn long context dialogue. Overall, our results indicate that incorporating structured sparsity into diffusion models is a promising direction for efficient and expressive long text generation.","authors":["Alexandros Christoforos","Chadbourne Davis"],"pdf_url":"","comment":"Under submission"}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2512.20423v1","updated":"2025-12-23T15:07:17Z","published":"2025-12-23T15:07:17Z","title":"Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit","summary":"The purpose of this project is to assess how well defenders can detect DNS-over-HTTPS (DoH) file exfiltration, and which evasion strategies can be used by attackers. While providing a reproducible toolkit to generate, intercept and analyze DoH exfiltration, and comparing Machine Learning vs threshold-based detection under adversarial scenarios. The originality of this project is the introduction of an end-to-end, containerized pipeline that generates configurable file exfiltration over DoH using several parameters (e.g., chunking, encoding, padding, resolver rotation). It allows for file reconstruction at the resolver side, while extracting flow-level features using a fork of DoHLyzer. The pipeline contains a prediction side, which allows the training of machine learning models based on public labelled datasets and then evaluates them side-by-side with threshold-based detection methods against malicious and evasive DNS-Over-HTTPS traffic. We train Random Forest, Gradient Boosting and Logistic Regression classifiers on a public DoH dataset and benchmark them against evasive DoH exfiltration scenarios. The toolkit orchestrates traffic generation, file capture, feature extraction, model training and analysis. The toolkit is then encapsulated into several Docker containers for easy setup and full reproducibility regardless of the platform it is run on. Future research regarding this project is directed at validating the results on mixed enterprise traffic, extending the protocol coverage to HTTP/3/QUIC request, adding a benign traffic generation, and working on real-time traffic evaluation. A key objective is to quantify when stealth constraints make DoH exfiltration uneconomical and unworthy for the attacker.","authors":["Adam Elaoumari"],"pdf_url":"","comment":"61 pages Advisor : Dr Darren Hurley-Smith"},{"id":"http://arxiv.org/abs/2410.23639v3","updated":"2025-12-23T14:49:59Z","published":"2024-10-31T05:21:46Z","title":"Integrating Brain-Computer Interface and Neuromorphic Computing for Human Digital Twins","summary":"The integration of immersive communication into a human-centric ecosystem has intensified the demand for sophisticated Human Digital Twins (HDTs) driven by multifaceted human data. However, the effective construction of HDTs faces significant challenges due to the heterogeneity of data collection devices, the high energy demands associated with processing intricate data, and concerns over the privacy of sensitive information. This work introduces a novel biologically-inspired (bio-inspired) HDT framework that leverages Brain-Computer Interface (BCI) sensor technology to capture brain signals as the data source for constructing HDT. By collecting and analyzing these signals, the framework not only minimizes device heterogeneity and enhances data collection efficiency, but also provides richer and more nuanced physiological and psychological data for constructing personalized HDTs. To this end, we further propose a bio-inspired neuromorphic computing learning model based on the Spiking Neural Network (SNN). This model utilizes discrete neural spikes to emulate the way of human brain processes information, thereby enhancing the system's ability to process data effectively while reducing energy consumption. Additionally, we integrate a Federated Learning (FL) strategy within the model to strengthen data privacy. We then conduct a case study to demonstrate the performance of our proposed twofold bio-inspired scheme. Finally, we present several challenges and promising directions for future research of HDTs driven by bio-inspired technologies.","authors":["Chen Shang","Jiadong Yu","Dinh Thai Hoang"],"pdf_url":"","comment":"7 pages, 3 figures,"},{"id":"http://arxiv.org/abs/2512.20275v1","updated":"2025-12-23T11:27:17Z","published":"2025-12-23T11:27:17Z","title":"Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks","summary":"As networks evolve toward 5G Standalone and 6G, operators face orchestration challenges that exceed the limits of static automation and Deep Reinforcement Learning. Although Large Language Model (LLM) agents offer a path toward intent-based networking, they introduce stochastic risks, including topology hallucinations and policy non-compliance. To mitigate this, we propose Graph-Symbolic Policy Enforcement and Control (G-SPEC), a neuro-symbolic framework that constrains probabilistic planning with deterministic verification. The architecture relies on a Governance Triad - a telecom-adapted agent (TSLAM-4B), a Network Knowledge Graph (NKG), and SHACL constraints. We evaluated G-SPEC on a simulated 450-node 5G Core, achieving zero safety violations and a 94.1% remediation success rate, significantly outperforming the 82.4% baseline. Ablation analysis indicates that NKG validation drives the majority of safety gains (68%), followed by SHACL policies (24%). Scalability tests on topologies ranging from 10K to 100K nodes demonstrate that validation latency scales as $O(k^{1.2})$ where $k$ is subgraph size. With a processing overhead of 142ms, G-SPEC is viable for SMO-layer operations.","authors":["Divya Vijay","Vignesh Ethiraj"],"pdf_url":"","comment":"15 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2510.26009v2","updated":"2025-12-23T11:17:31Z","published":"2025-10-29T22:41:40Z","title":"A Zero Added Loss Multiplexing (ZALM) Source Simulation","summary":"Zero Added Loss Multiplexing (ZALM) offers broadband, per channel heralded EPR pairs, with a rich parameter space that allows its performance to be tailored for specific applications. We present a modular ZALM simulator that demonstrates how design choices affect output rate and fidelity. Built in NetSquid with QSI controllers, it exposes 20+ tunable parameters, supports IDEAL and REALISTIC modes, and provides reusable components for Spontaneous Parametric Down Conversion (SPDC) sources, interference, Dense Wavelength Division Multiplexing (DWDM) filtering, fiber delay, active polarization gates, detectors, and lossy fiber. Physics based models capture Hong Ou Mandel (HOM) visibility, insertion loss, detector efficiency, gate errors, and attenuation. Using this tool, we map trade offs among fidelity, link distance, and entangled pairs per use, and show how SPDC bandwidth and DWDM grid spacing steer performance. Using the default configuration settings, average fidelity emains constant at 0.8 but the ebit rate decreases from 0.0175 at the source to 0.0 at 50 km; narrowing the SPDC degeneracy bandwidth increases the ebit rate significantly without affecting fidelity. The simulator enables codesign of source, filtering, and feedforward settings for specific quantum memories and integrates as a building block for end to end quantum network studies.","authors":["Jerry Horgan","Alexander Nico-Katz","Shelbi L. Jenkins","Ashley N. Tittelbaugh","Vivek Visan","Rohan Bali","Marco Ruffini","Boulat A. Bash","Daniel C. Kilper"],"pdf_url":"","comment":"7 pages, 7 figures"},{"id":"http://arxiv.org/abs/2512.20243v1","updated":"2025-12-23T10:53:32Z","published":"2025-12-23T10:53:32Z","title":"Post-Quantum Cryptography in the 5G Core","summary":"In this work, the conventional cryptographic algorithms used in the 5G Core are replaced with post-quantum alternatives and the practical impact of this transition is evaluated. Using a simulation environment, we model the registration and deregistration of varying numbers of user equipments (UEs) and measure the resulting effects on bandwidth consumption and latency.\n  Our results show that the deployment of post-quantum cryptographic algorithms has a measurable effect on performance, but that this effect is small, and perhaps more crucially, that the extra overhead needed in terms of computation and bandwidth does not have any substantial impact on the usability of the network and the efficiency of its network functions.\n  Overall the experimental results in this work corroborate earlier research: the 5G Core is technically able to support post-quantum cryptography without any inherent issues connected to the increased computational overhead or larger message size.","authors":["Thomas Attema","Bor de Kock","Sandesh Manganahalli Jayaprakash","Dimitrios Schoinianakis","Thom Sijpesteijn","Rintse van de Vlasakker"],"pdf_url":"","comment":"11 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2512.20186v1","updated":"2025-12-23T09:22:19Z","published":"2025-12-23T09:22:19Z","title":"Edge-Served Congestion Control for Wireless Multipath Transmission with a Transformer Agent","summary":"Multipath TCP is widely adopted to enhance connection quality-of-service by leveraging multiple network pathways on modern devices. However, the evolution of its core congestion control is hindered by the OS kernel, whose monolithic design imposes high development overhead and lacks the resource flexibility required for data-driven methods. Furthermore, inherent noise in network statistics induces a partial observability problem, which can mislead data-driven methods like Deep Reinforcement Learning. To bridge this gap, we propose Jazz, a system that re-architects multipath congestion control through a decoupled architecture that separates the decision-making ``brain'' from the in-kernel datapath, enabling it to operate on an external (edge) entity. At its core, Jazz employs a Transformer-based agent that processes sequences of historical observations to overcome the partial observability of single-step reinforcement learning. This allows it to learn and master fluctuating link conditions and intricate cross-path dependencies. Tested on a dual-band (5GHz/6GHz) Wi-Fi testbed, our implementation improves bandwidth efficiency by at least 2.85\\% over conventional methods and maintains 96.2\\% performance under 1\\% packet loss, validating this design as a practical blueprint for agile network intelligence.","authors":["Liang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20080v1","updated":"2025-12-23T06:26:20Z","published":"2025-12-23T06:26:20Z","title":"CBA: Communication-Bound-Aware Cross-Domain Resource Assignment for Pipeline-Parallel Distributed LLM Training in Dynamic Multi-DC Optical Networks","summary":"We propose a communication-bound-aware cross-domain resource assignment framework for pipeline-parallel distributed training over multi-datacenter optical networks, which lowers iteration time by 31.25% and reduces 13.20% blocking requests compared to baselines.","authors":["Dianxuan Fu","Xiaomin Liu","Yihao Zhang","Shikui Shen","Weisheng Hu","Qunbi Zhuge"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.17231v3","updated":"2025-12-23T05:48:23Z","published":"2024-12-23T02:58:12Z","title":"FedMeld: A Model-dispersal Federated Learning Framework for Space-ground Integrated Networks","summary":"To bridge the digital divide, space-ground integrated networks (SGINs) are expected to deliver artificial intelligence (AI) services to every corner of the world. One key mission of SGINs is to support federated learning (FL) at a global scale. However, existing space-ground integrated FL frameworks involve ground stations or costly inter-satellite links, entailing excessive training latency and communication costs. To overcome these limitations, we propose an infrastructure-free federated learning framework based on a model dispersal (FedMeld) strategy, which exploits periodic movement patterns and store-carry-forward capabilities of satellites to enable parameter mixing across large-scale geographical regions. We theoretically show that FedMeld leads to global model convergence and quantify the effects of round interval and mixing ratio between adjacent areas on its learning performance. Based on the theoretical results, we formulate a joint optimization problem to design the staleness control and mixing ratio (SC-MR) for minimizing the training loss. By decomposing the problem into sequential SC and MR subproblems without compromising the optimality, we derive the round interval solution in a closed form and the mixing ratio in a semi-closed form to achieve the optimal latency-accuracy tradeoff. Experiments using various datasets demonstrate that FedMeld achieves superior model accuracy while significantly reducing communication costs as compared with traditional FL schemes for SGINs.","authors":["Qian Chen","Xianhao Chen","Kaibin Huang"],"pdf_url":"","comment":"17 pages, 10 figures. This paper has been accepted by IEEE Transactions on Mobile Computing"},{"id":"http://arxiv.org/abs/2512.19964v1","updated":"2025-12-23T01:25:21Z","published":"2025-12-23T01:25:21Z","title":"VNF-Cache: An In-Network Key-Value Store Cache Based on Network Function Virtualization","summary":"With the exponential growth of the amount of data available on the Internet, optimizing the response time and resource usage for data access becomes essential. Caches are an effective solution that brings data closer to clients, eliminating repetitive requests to servers. This paper presents VNF-Cache, a caching service for geographically remote key-value databases. VNF-Cache is an NFV-COIN (Network Function Virtualization-Computing In The Network) service, a technology undergoing standardization by the IETF that enables the implementation of arbitrary services directly in the network. VNF-Cache intercepts network packets, processes, stores, and sends values directly to clients when possible. Through a proof-of-concept implementation and experiments conducted with geographically dispersed servers in Brazil, the United States, and Japan, significant reductions in response time and increases in the number of requests processed per second were observed.","authors":["Bruno E. Farias","José Flauzino","Elias P. Duarte"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20739v1","updated":"2025-12-23T19:50:13Z","published":"2025-12-23T19:50:13Z","title":"AI-Driven Green Cognitive Radio Networks for Sustainable 6G Communication","summary":"The 6G wireless aims at the Tb/s peak data rates are expected, a sub-millisecond latency, massive Internet of Things/vehicle connectivity, which requires sustainable access to audio over the air and energy-saving functionality. Cognitive Radio Networks CCNs help in alleviating the problem of spectrum scarcity, but classical sensing and allocation are still energy-consumption intensive, and sensitive to rapid spectrum variations. Our framework which centers on AI driven green CRN aims at integrating deep reinforcement learning (DRL) with transfer learning, energy harvesting (EH), reconfigurable intelligent surfaces (RIS) with other light-weight genetic refinement operations that optimally combine sensing timelines, transmit power, bandwidth distribution and RIS phase selection. Compared to two baselines, the utilization of MATLAB + NS-3 under dense loads, a traditional CRN with energy sensing under fixed policies, and a hybrid CRN with cooperative sensing under heuristic distribution of resource, there are (25-30%) fewer energy reserves used, sensing AUC greater than 0.90 and +6-13 p.p. higher PDR. The integrated framework is easily scalable to large IoT and vehicular applications, and it provides a feasible and sustainable roadmap to 6G CRNs.\n  Index Terms--Cognitive Radio Networks (CRNs), 6G, Green Communication, Energy Efficiency, Deep Reinforcement Learning (DRL), Spectrum Sensing, RIS, Energy Harvesting, QoS, IoT.","authors":["Anshul Sharma","Shujaatali Badami","Biky Chouhan","Pushpanjali Pandey","Brijeena Rana","Navneet Kaur"],"pdf_url":"","comment":"10 pages, 8 figures. Full research article with MATLAB and NS-3 simulations"},{"id":"http://arxiv.org/abs/2512.20733v1","updated":"2025-12-23T19:41:50Z","published":"2025-12-23T19:41:50Z","title":"Towards a Security Plane for 6G Ecosystems","summary":"6G networks promise to be the proper technology to support a wide deployment of highly demanding services, satisfying key users-related aspects such as extremely high quality, and persistent communications. However, there is no service to support if the network is not reliable enough. In this direction, it is with no doubt that security guarantees become a must. Traditional security approaches have focused on providing specific and attack-tailored solutions that will not properly meet the uncertainties driven by a technology yet under development and showing an attack surface not completely identified either. In this positioning paper we propose a softwarized solution, defining a Security Plane built on a top of programmable and adaptable set of live Security Functions under a proactive strategy. In addition, in order to address the inaccuracies driven by the predictive models a pre-assessment scenario is also considered ensuring that no action will be deployed if not previously verified. Although more efforts are required to develop this initiative, we think that such a shift paradigm is the only way to face security provisioning challenges in 6G ecosystems.","authors":["Xavi Masip-Bruin","Eva Rodríguez","Admela Jukan","Panos Trakadas"],"pdf_url":"","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2512.20618v1","updated":"2025-12-23T18:59:49Z","published":"2025-12-23T18:59:49Z","title":"LongVideoAgent: Multi-Agent Reasoning with Long Videos","summary":"Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We propose a multi-agent framework in which a master LLM coordinates a grounding agent to localize question-relevant segments and a vision agent to extract targeted textual observations. The master agent plans with a step limit, and is trained with reinforcement learning to encourage concise, correct, and efficient multi-agent cooperation. This design helps the master agent focus on relevant clips via grounding, complements subtitles with visual detail, and yields interpretable trajectories. On our proposed LongTVQA and LongTVQA+ which are episode-level datasets aggregated from TVQA/TVQA+, our multi-agent system significantly outperforms strong non-agent baselines. Experiments also show reinforcement learning further strengthens reasoning and planning for the trained agent. Code and data will be shared at https://longvideoagent.github.io/.","authors":["Runtao Liu","Ziyi Liu","Jiaqi Tang","Yue Ma","Renjie Pi","Jipeng Zhang","Qifeng Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20610v1","updated":"2025-12-23T18:57:53Z","published":"2025-12-23T18:57:53Z","title":"FedPOD: the deployable units of training for federated learning","summary":"This paper proposes FedPOD (Proportionally Orchestrated Derivative) for optimizing learning efficiency and communication cost in federated learning among multiple clients. Inspired by FedPIDAvg, we define a round-wise task for FedPOD to enhance training efficiency. FedPIDAvg achieved performance improvement by incorporating the training loss reduction for prediction entropy as weights using differential terms. Furthermore, by modeling data distribution with a Poisson distribution and using a PID controller, it reduced communication costs even in skewed data distribution. However, excluding participants classified as outliers based on the Poisson distribution can limit data utilization. Additionally, PID controller requires the same participants to be maintained throughout the federated learning process as it uses previous rounds' learning information in the current round. In our approach, FedPOD addresses these issues by including participants excluded as outliers, eliminating dependency on previous rounds' learning information, and applying a method for calculating validation loss at each round. In this challenge, FedPOD presents comparable performance to FedPIDAvg in metrics of Dice score, 0.78, 0.71 and 0.72 for WT, ET and TC in average, and projected convergence score, 0.74 in average. Furthermore, the concept of FedPOD draws inspiration from Kubernetes' smallest computing unit, POD, designed to be compatible with Kubernetes auto-scaling. Extending round-wise tasks of FedPOD to POD units allows flexible design by applying scale-out similar to Kubernetes' auto-scaling. This work demonstrated the potentials of FedPOD to enhance federated learning by improving efficiency, flexibility, and performance in metrics.","authors":["Daewoon Kim","Si Young Yie","Jae Sung Lee"],"pdf_url":"","comment":"12 pages, 12 figures, MICCAI"},{"id":"http://arxiv.org/abs/2512.20607v1","updated":"2025-12-23T18:55:30Z","published":"2025-12-23T18:55:30Z","title":"Saddle-to-Saddle Dynamics Explains A Simplicity Bias Across Neural Network Architectures","summary":"Neural networks trained with gradient descent often learn solutions of increasing complexity over time, a phenomenon known as simplicity bias. Despite being widely observed across architectures, existing theoretical treatments lack a unifying framework. We present a theoretical framework that explains a simplicity bias arising from saddle-to-saddle learning dynamics for a general class of neural networks, incorporating fully-connected, convolutional, and attention-based architectures. Here, simple means expressible with few hidden units, i.e., hidden neurons, convolutional kernels, or attention heads. Specifically, we show that linear networks learn solutions of increasing rank, ReLU networks learn solutions with an increasing number of kinks, convolutional networks learn solutions with an increasing number of convolutional kernels, and self-attention models learn solutions with an increasing number of attention heads. By analyzing fixed points, invariant manifolds, and dynamics of gradient descent learning, we show that saddle-to-saddle dynamics operates by iteratively evolving near an invariant manifold, approaching a saddle, and switching to another invariant manifold. Our analysis also illuminates the effects of data distribution and weight initialization on the duration and number of plateaus in learning, dissociating previously confounding factors. Overall, our theory offers a framework for understanding when and why gradient descent progressively learns increasingly complex solutions.","authors":["Yedi Zhang","Andrew Saxe","Peter E. Latham"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20605v1","updated":"2025-12-23T18:51:50Z","published":"2025-12-23T18:51:50Z","title":"Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning","summary":"Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token can result in highly inefficient learning, particularly when rewards are sparse. Here, we show that it is possible to overcome this problem by acting and exploring within the internal representations of an autoregressive model. Specifically, to discover temporally-abstract actions, we introduce a higher-order, non-causal sequence model whose outputs control the residual stream activations of a base autoregressive model. On grid world and MuJoCo-based tasks with hierarchical structure, we find that the higher-order model learns to compress long activation sequence chunks onto internal controllers. Critically, each controller executes a sequence of behaviorally meaningful actions that unfold over long timescales and are accompanied with a learned termination condition, such that composing multiple controllers over time leads to efficient exploration on novel tasks. We show that direct internal controller reinforcement, a process we term \"internal RL\", enables learning from sparse rewards in cases where standard RL finetuning fails. Our results demonstrate the benefits of latent action generation and reinforcement in autoregressive models, suggesting internal RL as a promising avenue for realizing hierarchical RL within foundation models.","authors":["Seijin Kobayashi","Yanick Schimpf","Maximilian Schlegel","Angelika Steger","Maciej Wolczyk","Johannes von Oswald","Nino Scherre","Kaitlin Maile","Guillaume Lajoie","Blake A. Richards","Rif A. Saurous","James Manyika","Blaise Agüera y Arcas","Alexander Meulemans","João Sacramento"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.08855v2","updated":"2025-12-23T18:50:53Z","published":"2025-12-09T17:48:28Z","title":"Reinforcement Learning From State and Temporal Differences","summary":"TD($λ$) with function approximation has proved empirically successful for some complex reinforcement learning problems. For linear approximation, TD($λ$) has been shown to minimise the squared error between the approximate value of each state and the true value. However, as far as policy is concerned, it is error in the relative ordering of states that is critical, rather than error in the state values. We illustrate this point, both in simple two-state and three-state systems in which TD($λ$)--starting from an optimal policy--converges to a sub-optimal policy, and also in backgammon. We then present a modified form of TD($λ$), called STD($λ$), in which function approximators are trained with respect to relative state values on binary decision problems. A theoretical analysis, including a proof of monotonic policy improvement for STD($λ$) in the context of the two-state system, is presented, along with a comparison with Bertsekas' differential training method [1]. This is followed by successful demonstrations of STD($λ$) on the two-state system and a variation on the well known acrobot problem.","authors":["Lex Weaver","Jonathan Baxter"],"pdf_url":"","comment":"Technical Report, Department of Computer Science, Australian National University, May 1999 New version uploaded 2025 after original source taken offline"},{"id":"http://arxiv.org/abs/2505.08961v2","updated":"2025-12-23T18:50:46Z","published":"2025-05-13T21:01:53Z","title":"Learning Informative Attention Weights for Person Re-Identification","summary":"Attention mechanisms have been widely used in deep learning, and recent efforts have been devoted to incorporating attention modules into deep neural networks (DNNs) for person Re-Identification (Re-ID) to enhance their discriminative feature learning capabilities. Existing attention modules, including self-attention and channel attention, learn attention weights that quantify the importance of feature tokens or feature channels. However, existing attention methods do not explicitly ensure that the attention weights are informative for predicting the identity of the person in the input image, and may consequently introduce noisy information from the input image. To address this issue, we propose a novel method termed Reduction of Information Bottleneck loss (RIB), motivated by the principle of the Information Bottleneck (IB). A novel distribution-free and efficient variational upper bound for the IB loss (IBB), which can be optimized by standard SGD, is derived and incorporated into the training loss of the RIB models. RIB is applied to DNNs with self-attention modules through a novel Differentiable Channel Selection Attention module, or DCS-Attention, that selects the most informative channels for computing attention weights, leading to competitive models termed RIB-DCS. RIB is also incorporated into DNNs with existing channel attention modules to promote the learning of informative channel attention weights, leading to models termed RIB-CA. Both RIB-DCS and RIB-CA are applied to fixed neural network backbones and learnable backbones with Differentiable Neural Architecture Search (DNAS). Extensive experiments on multiple person Re-ID benchmarks show that RIB significantly enhances the prediction accuracy of DNNs for person Re-ID, even for the occluded person Re-ID.","authors":["Yancheng Wang","Nebojsa Jojic","Yingzhen Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20582v1","updated":"2025-12-23T18:27:41Z","published":"2025-12-23T18:27:41Z","title":"Relu and softplus neural nets as zero-sum turn-based games","summary":"We show that the output of a ReLU neural network can be interpreted as the value of a zero-sum, turn-based, stopping game, which we call the ReLU net game. The game runs in the direction opposite to that of the network, and the input of the network serves as the terminal reward of the game. In fact, evaluating the network is the same as running the Shapley-Bellman backward recursion for the value of the game. Using the expression of the value of the game as an expected total payoff with respect to the path measure induced by the transition probabilities and a pair of optimal policies, we derive a discrete Feynman-Kac-type path-integral formula for the network output. This game-theoretic representation can be used to derive bounds on the output from bounds on the input, leveraging the monotonicity of Shapley operators, and to verify robustness properties using policies as certificates. Moreover, training the neural network becomes an inverse game problem: given pairs of terminal rewards and corresponding values, one seeks transition probabilities and rewards of a game that reproduces them. Finally, we show that a similar approach applies to neural networks with Softplus activation functions, where the ReLU net game is replaced by its entropic regularization.","authors":["Stephane Gaubert","Yiannis Vlassopoulos"],"pdf_url":"","comment":"24 pages, 2 figures"},{"id":"http://arxiv.org/abs/2303.16158v4","updated":"2025-12-23T18:23:14Z","published":"2023-03-25T03:06:43Z","title":"Behavioral Machine Learning? Regularization and Forecast Bias","summary":"Standard forecast efficiency tests interpret violations as evidence of behavioral bias. We show theoretically and empirically that rational forecasters using optimal regularization systematically violate these tests. Machine learning forecasts show near zero bias at one year horizon, but strong overreaction at two years, consistent with predictions from a model of regularization and measurement noise. We provide three complementary tests: experimental variation in regularization parameters, cross-sectional heterogeneity in firm signal quality, and quasi-experimental evidence from ML adoption around 2013. Technically trained analysts shift sharply toward overreaction post-2013. Our findings suggest reported violations may reflect statistical sophistication rather than cognitive failure.","authors":["Murray Z. Frank","Jing Gao","Keer Yang"],"pdf_url":"","comment":"stock analysts, machine learning, behavioral, overreaction"},{"id":"http://arxiv.org/abs/2512.20577v1","updated":"2025-12-23T18:21:24Z","published":"2025-12-23T18:21:24Z","title":"Improving ML Training Data with Gold-Standard Quality Metrics","summary":"Hand-tagged training data is essential to many machine learning tasks. However, training data quality control has received little attention in the literature, despite data quality varying considerably with the tagging exercise. We propose methods to evaluate and enhance the quality of hand-tagged training data using statistical approaches to measure tagging consistency and agreement. We show that agreement metrics give more reliable results if recorded over multiple iterations of tagging, where declining variance in such recordings is an indicator of increasing data quality. We also show one way a tagging project can collect high-quality training data without requiring multiple tags for every work item, and that a tagger burn-in period may not be sufficient for minimizing tagger errors.","authors":["Leslie Barrett","Michael W. Sherman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20576v1","updated":"2025-12-23T18:20:06Z","published":"2025-12-23T18:20:06Z","title":"Performative Policy Gradient: Optimality in Performative Reinforcement Learning","summary":"Post-deployment machine learning algorithms often influence the environments they act in, and thus shift the underlying dynamics that the standard reinforcement learning (RL) methods ignore. While designing optimal algorithms in this performative setting has recently been studied in supervised learning, the RL counterpart remains under-explored. In this paper, we prove the performative counterparts of the performance difference lemma and the policy gradient theorem in RL, and further introduce the Performative Policy Gradient algorithm (PePG). PePG is the first policy gradient algorithm designed to account for performativity in RL. Under softmax parametrisation, and also with and without entropy regularisation, we prove that PePG converges to performatively optimal policies, i.e. policies that remain optimal under the distribution shifts induced by themselves. Thus, PePG significantly extends the prior works in Performative RL that achieves performative stability but not optimality. Furthermore, our empirical analysis on standard performative RL environments validate that PePG outperforms standard policy gradient algorithms and the existing performative RL algorithms aiming for stability.","authors":["Debabrota Basu","Udvas Das","Brahim Driss","Uddalak Mukherjee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20573v1","updated":"2025-12-23T18:16:58Z","published":"2025-12-23T18:16:58Z","title":"Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs","summary":"Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM's speed from parallel decoding drastically lowers the risk of costly rejections, providing a practical mechanism to effectively realize the (elusive) lengthy drafts that lead to large speedups with speculative decoding. We present FailFast, a dLLM-based speculative decoding framework that realizes this approach by dynamically adapting its speculation length. It \"fails fast\" by spending minimal compute in hard-to-speculate regions to shrink speculation latency and \"wins big\" by aggressively extending draft lengths in easier regions to reduce verification latency (in many cases, speculating and accepting 70 tokens at a time!). Without any fine-tuning, FailFast delivers lossless acceleration of AR LLMs and achieves up to 4.9$\\times$ speedup over vanilla decoding, 1.7$\\times$ over the best naive dLLM drafter, and 1.4$\\times$ over EAGLE-3 across diverse models and workloads. We open-source FailFast at https://github.com/ruipeterpan/failfast.","authors":["Rui Pan","Zhuofu Chen","Ravi Netravali"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20563v1","updated":"2025-12-23T18:07:43Z","published":"2025-12-23T18:07:43Z","title":"LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving","summary":"Simulators can generate virtually unlimited driving data, yet imitation learning policies in simulation still struggle to achieve robust closed-loop performance. Motivated by this gap, we empirically study how misalignment between privileged expert demonstrations and sensor-based student observations can limit the effectiveness of imitation learning. More precisely, experts have significantly higher visibility (e.g., ignoring occlusions) and far lower uncertainty (e.g., knowing other vehicles' actions), making them difficult to imitate reliably. Furthermore, navigational intent (i.e., the route to follow) is under-specified in student models at test time via only a single target point. We demonstrate that these asymmetries can measurably limit driving performance in CARLA and offer practical interventions to address them. After careful modifications to narrow the gaps between expert and student, our TransFuser v6 (TFv6) student policy achieves a new state of the art on all major publicly available CARLA closed-loop benchmarks, reaching 95 DS on Bench2Drive and more than doubling prior performances on Longest6~v2 and Town13. Additionally, by integrating perception supervision from our dataset into a shared sim-to-real pipeline, we show consistent gains on the NAVSIM and Waymo Vision-Based End-to-End driving benchmarks. Our code, data, and models are publicly available at https://github.com/autonomousvision/lead.","authors":["Long Nguyen","Micha Fauth","Bernhard Jaeger","Daniel Dauner","Maximilian Igl","Andreas Geiger","Kashyap Chitta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20562v1","updated":"2025-12-23T18:05:55Z","published":"2025-12-23T18:05:55Z","title":"Shallow Neural Networks Learn Low-Degree Spherical Polynomials with Learnable Channel Attention","summary":"We study the problem of learning a low-degree spherical polynomial of degree $\\ell_0 = Θ(1) \\ge 1$ defined on the unit sphere in $\\RR^d$ by training an over-parameterized two-layer neural network (NN) with channel attention in this paper. Our main result is the significantly improved sample complexity for learning such low-degree polynomials. We show that, for any regression risk $\\eps \\in (0,1)$, a carefully designed two-layer NN with channel attention and finite width of $m \\ge Θ({n^4 \\log (2n/δ)}/{d^{2\\ell_0}})$ trained by the vanilla gradient descent (GD) requires the lowest sample complexity of $n \\asymp Θ(d^{\\ell_0}/\\eps)$ with probability $1-δ$ for every $δ\\in (0,1)$, in contrast with the representative sample complexity $Θ\\pth{d^{\\ell_0} \\max\\set{\\eps^{-2},\\log d}}$, where $n$ is the training daata size. Moreover, such sample complexity is not improvable since the trained network renders a sharp rate of the nonparametric regression risk of the order $Θ(d^{\\ell_0}/{n})$ with probability at least $1-δ$. On the other hand, the minimax optimal rate for the regression risk with a kernel of rank $Θ(d^{\\ell_0})$ is $Θ(d^{\\ell_0}/{n})$, so that the rate of the nonparametric regression risk of the network trained by GD is minimax optimal. The training of the two-layer NN with channel attention consists of two stages. In Stage 1, a provable learnable channel selection algorithm identifies the ground-truth channel number $\\ell_0$ from the initial $L \\ge \\ell_0$ channels in the first-layer activation, with high probability. This learnable selection is achieved by an efficient one-step GD update on both layers, enabling feature learning for low-degree polynomial targets. In Stage 2, the second layer is trained by standard GD using the activation function with the selected channels.","authors":["Yingzhen Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.13912v2","updated":"2025-12-23T18:00:52Z","published":"2025-11-17T21:06:52Z","title":"Compute-in-Memory Implementation of State Space Models for Event Sequence Processing","summary":"State space models (SSMs) have recently emerged as a powerful framework for long sequence processing, outperforming traditional methods on diverse benchmarks. Fundamentally, SSMs can generalize both recurrent and convolutional networks and have been shown to even capture key functions of biological systems. Here we report an approach to implement SSMs in energy-efficient compute-in-memory (CIM) hardware to achieve real-time, event-driven processing. Our work re-parameterizes the model to function with real-valued coefficients and shared decay constants, reducing the complexity of model mapping onto practical hardware systems. By leveraging device dynamics and diagonalized state transition parameters, the state evolution can be natively implemented in crossbar-based CIM systems combined with memristors exhibiting short-term memory effects. Through this algorithm and hardware co-design, we show the proposed system offers both high accuracy and high energy efficiency while supporting fully asynchronous processing for event-based vision and audio tasks.","authors":["Xiaoyu Zhang","Mingtao Hu","Sen Lu","Soohyeon Kim","Eric Yeu-Jer Lee","Yuyang Liu","Wei D. Lu"],"pdf_url":"","comment":"Xiaoyu Zhang and Mingtao Hu contributed equally to this work"},{"id":"http://arxiv.org/abs/2510.07191v2","updated":"2025-12-23T17:45:29Z","published":"2025-10-08T16:25:04Z","title":"Resolution scaling governs DINOv3 transfer performance in chest radiograph classification","summary":"Self-supervised learning (SSL) has advanced visual representation learning, but its value in chest radiography, a high-volume imaging modality with fine-grained findings, remains unclear. Meta's DINOv3 extends earlier SSL models through Gram-anchored self-distillation. Whether these design choices improve transfer learning for chest radiography has not been systematically tested. We benchmarked DINOv3 against DINOv2 and ImageNet initialization across seven datasets (n>814,000). Two representative backbones were evaluated: ViT-B/16 and ConvNeXt-B. Images were analyzed at 224x224, 512x512, and 1024x1024 pixels. We additionally assessed frozen features from a 7B model. The primary outcome was mean AUROC across labels. At 224x224, DINOv3 and DINOv2 achieved comparable performance on adult datasets. Increasing resolution to 512x512 yielded consistent improvements for DINOv3 over both DINOv2 and ImageNet. In contrast, results in pediatric cohort showed no differences across initializations. Across all settings, ConvNeXt-B outperformed ViT-B/16. Models using frozen DINOv3-7B features underperformed relative to fully finetuned 86-89M-parameter backbones, highlighting the importance of domain adaptation. Scaling to 1024x1024 did not further improve accuracy. Resolution-related gains were most evident for boundary-dependent and small focal abnormalities. In chest radiography, higher input resolution is critical for leveraging the benefits of modern self-supervised models. 512x512 pixels represent a practical upper limit where DINOv3-initialized ConvNeXt-B networks provide the strongest performance, while larger inputs offer minimal return on cost. Clinically, these findings support use of finetuned, mid-sized backbones at 512x512 for chest radiograph interpretation, with the greatest gains expected in detecting subtle or boundary-centered lesions relevant to emergency and critical care settings.","authors":["Soroosh Tayebi Arasteh","Mina Shaigan","Christiane Kuhl","Jakob Nikolas Kather","Sven Nebelung","Daniel Truhn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20533v1","updated":"2025-12-23T17:24:39Z","published":"2025-12-23T17:24:39Z","title":"Over-the-Air Goal-Oriented Communications","summary":"Goal-oriented communications offer an attractive alternative to the Shannon-based communication paradigm, where the data is never reconstructed at the Receiver (RX) side. Rather, focusing on the case of edge inference, the Transmitter (TX) and the RX cooperate to exchange features of the input data that will be used to predict an unseen attribute of them, leveraging information from collected data sets. This chapter demonstrates that the wireless channel can be used to perform computations over the data, when equipped with programmable metasurfaces. The end-to-end system of the TX, RX, and MS-based channel is treated as a single deep neural network which is trained through backpropagation to perform inference on unseen data. Using Stacked Intelligent Metasurfaces (SIM), it is shown that this Metasurfaces-Integrated Neural Network (MINN) can achieve performance comparable to fully digital neural networks under various system parameters and data sets. By offloading computations onto the channel itself, important benefits may be achieved in terms of energy consumption, arising from reduced computations at the transceivers and smaller transmission power required for successful inference.","authors":["Kyriakos Stylianopoulos","Paolo Di Lorenzo","George C. Alexandropoulos"],"pdf_url":"","comment":"35 pages, 9 figures. Book chapter"},{"id":"http://arxiv.org/abs/2512.20523v1","updated":"2025-12-23T17:14:14Z","published":"2025-12-23T17:14:14Z","title":"ScoreMatchingRiesz: Auto-DML with Infinitesimal Classification","summary":"This study proposes Riesz representer estimation methods based on score matching. The Riesz representer is a key component in debiased machine learning for constructing $\\sqrt{n}$-consistent and efficient estimators in causal inference and structural parameter estimation. To estimate the Riesz representer, direct approaches have garnered attention, such as Riesz regression and the covariate balancing propensity score. These approaches can also be interpreted as variants of direct density ratio estimation (DRE) in several applications such as average treatment effect estimation. In DRE, it is well known that flexible models can easily overfit the observed data due to the estimand and the form of the loss function. To address this issue, recent work has proposed modeling the density ratio as a product of multiple intermediate density ratios and estimating it using score-matching techniques, which are often used in the diffusion model literature. We extend score-matching-based DRE methods to Riesz representer estimation. Our proposed method not only mitigates overfitting but also provides insights for causal inference by bridging marginal effects and average policy effects through time score functions.","authors":["Masahiro Kato"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20514v1","updated":"2025-12-23T17:02:35Z","published":"2025-12-23T17:02:35Z","title":"Explainable time-series forecasting with sampling-free SHAP for Transformers","summary":"Time-series forecasts are essential for planning and decision-making in many domains. Explainability is key to building user trust and meeting transparency requirements. Shapley Additive Explanations (SHAP) is a popular explainable AI framework, but it lacks efficient implementations for time series and often assumes feature independence when sampling counterfactuals. We introduce SHAPformer, an accurate, fast and sampling-free explainable time-series forecasting model based on the Transformer architecture. It leverages attention manipulation to make predictions based on feature subsets. SHAPformer generates explanations in under one second, several orders of magnitude faster than the SHAP Permutation Explainer. On synthetic data with ground truth explanations, SHAPformer provides explanations that are true to the data. Applied to real-world electrical load data, it achieves competitive predictive performance and delivers meaningful local and global insights, such as identifying the past load as the key predictor and revealing a distinct model behavior during the Christmas period.","authors":["Matthias Hertel","Sebastian Pütz","Ralf Mikut","Veit Hagenmeyer","Benjamin Schäfer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20513v1","updated":"2025-12-23T17:02:17Z","published":"2025-12-23T17:02:17Z","title":"Recurrent Off-Policy Deep Reinforcement Learning Doesn't Have to be Slow","summary":"Recurrent off-policy deep reinforcement learning models achieve state-of-the-art performance but are often sidelined due to their high computational demands. In response, we introduce RISE (Recurrent Integration via Simplified Encodings), a novel approach that can leverage recurrent networks in any image-based off-policy RL setting without significant computational overheads via using both learnable and non-learnable encoder layers. When integrating RISE into leading non-recurrent off-policy RL algorithms, we observe a 35.6% human-normalized interquartile mean (IQM) performance improvement across the Atari benchmark. We analyze various implementation strategies to highlight the versatility and potential of our proposed framework.","authors":["Tyler Clark","Christine Evers","Jonathon Hare"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.09719v2","updated":"2025-12-23T16:32:05Z","published":"2025-09-09T22:16:24Z","title":"Spectral Bottleneck in Sinusoidal Representation Networks: Noise is All You Need","summary":"This work identifies and attempts to address a fundamental limitation of implicit neural representations with sinusoidal activation. The fitting error of SIRENs is highly sensitive to the target frequency content and to the choice of initialization. In extreme cases, this sensitivity leads to a spectral bottleneck that can result in a zero-valued output. This phenomenon is characterized by analyzing the evolution of activation spectra and the empirical neural tangent kernel (NTK) during the training process. An unfavorable distribution of energy across frequency modes was noted to give rise to this failure mode. Furthermore, the effect of Gaussian perturbations applied to the baseline uniformly initialized weights is examined, showing how these perturbations influence activation spectra and the NTK eigenbasis of SIREN. Overall, initialization emerges as a central factor governing the evolution of SIRENs, indicating the need for adaptive, target-aware strategies as the target length increases and fine-scale detail becomes essential. The proposed weight initialization scheme (WINNER) represents a simple ad hoc step in this direction and demonstrates that fitting accuracy can be significantly improved by modifying the spectral profile of network activations through a target-aware initialization. The approach achieves state-of-the-art performance on audio fitting tasks and yields notable improvements in image fitting tasks.","authors":["Hemanth Chandravamsi","Dhanush V. Shenoy","Itay Zinn","Ziv Chen","Shimon Pisnoy","Steven H. Frankel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.12833v2","updated":"2025-12-23T16:25:32Z","published":"2025-08-18T11:17:59Z","title":"Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG","summary":"On-device machine learning is often constrained by limited storage, particularly in continuous data collection scenarios. This paper presents an empirical study on storage-aware learning, focusing on the trade-off between data quantity and quality via compression. We demonstrate that naive strategies, such as uniform data dropping or one-size-fits-all compression, are suboptimal. Our findings further reveal that data samples exhibit varying sensitivities to compression, supporting the feasibility of a sample-wise adaptive compression strategy. These insights provide a foundation for developing a new class of storage-aware learning systems. The primary contribution of this work is the systematic characterization of this under-explored challenge, offering valuable insights that advance the understanding of storage-aware learning.","authors":["Kichang Lee","Songkuk Kim","JaeYeon Park","JeongGil Ko"],"pdf_url":"","comment":"6pages, 6figures"},{"id":"http://arxiv.org/abs/2401.09986v3","updated":"2025-12-23T16:22:09Z","published":"2024-01-18T14:02:23Z","title":"Improving Local Training in Federated Learning via Temperature Scaling","summary":"Federated learning is inherently hampered by data heterogeneity: non-i.i.d. training data over local clients. We propose a novel model training approach for federated learning, FLex&Chill, which exploits the Logit Chilling method. Through extensive evaluations, we demonstrate that, in the presence of non-i.i.d. data characteristics inherent in federated learning systems, this approach can expedite model convergence and improve inference accuracy. Quantitatively, from our experiments, we observe up to 6X improvement in the global federated learning model convergence time, and up to 3.37% improvement in inference accuracy.","authors":["Kichang Lee","Pei Zhang","Songkuk Kim","JeongGil Ko"],"pdf_url":"","comment":"56 pages"},{"id":"http://arxiv.org/abs/2506.09207v3","updated":"2025-12-23T16:20:49Z","published":"2025-06-10T19:57:35Z","title":"mLaSDI: Multi-stage latent space dynamics identification","summary":"Accurately solving partial differential equations (PDEs) is essential across many scientific disciplines. However, high-fidelity solvers can be computationally prohibitive, motivating the development of reduced-order models (ROMs). Recently, Latent Space Dynamics Identification (LaSDI) was proposed as a data-driven, non-intrusive ROM framework. LaSDI compresses the training data via an autoencoder and learns user-specified ordinary differential equations (ODEs), governing the latent dynamics, enabling rapid predictions for unseen parameters. While LaSDI has produced effective ROMs for numerous problems, the autoencoder must simultaneously reconstruct the training data and satisfy the imposed latent dynamics, which are often competing objectives that limit accuracy, particularly for complex or high-frequency phenomena. To address this limitation, we propose multi-stage Latent Space Dynamics Identification (mLaSDI). With mLaSDI, we train LaSDI sequentially in stages. After training the initial autoencoder, we train additional decoders which map the latent trajectories to residuals from previous stages. This staged residual learning, combined with periodic activation functions, enables recovery of high-frequency content without sacrificing interpretability of the latent dynamics. Numerical experiments on a multiscale oscillating system, unsteady wake flow, and the 1D-1V Vlasov equation demonstrate that mLaSDI achieves significantly lower reconstruction and prediction errors, often by an order of magnitude, while requiring less training time and reduced hyperparameter tuning compared to standard LaSDI.","authors":["William Anderson","Seung Whan Chung","Robert Stephany","Youngsoo Choi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20460v1","updated":"2025-12-23T15:55:10Z","published":"2025-12-23T15:55:10Z","title":"The Aligned Economic Index & The State Switching Model","summary":"A growing empirical literature suggests that equity-premium predictability is state dependent, with much of the forecasting power concentrated around recessionary periods \\parencite{Henkel2011,DanglHalling2012,Devpura2018}. I study U.S. stock return predictability across economic regimes and document strong evidence of time-varying expected returns across both expansionary and contractionary states. I contribute in two ways. First, I introduce a state-switching predictive regression in which the market state is defined in real time using the slope of the yield curve. Relative to the standard one-state predictive regression, the state-switching specification increases both in-sample and out-of-sample performance for the set of popular predictors considered by \\textcite{WelchGoyal2008}, improving the out-of-sample performance of most predictors in economically meaningful ways. Second, I propose a new aggregate predictor, the Aligned Economic Index, constructed via partial least squares (PLS). Under the state-switching model, the Aligned Economic Index exhibits statistically and economically significant predictive power in sample and out of sample, and it outperforms widely used benchmark predictors and alternative predictor-combination methods.","authors":["Ilias Aarab"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.22358v2","updated":"2025-12-23T15:51:07Z","published":"2025-09-26T13:53:56Z","title":"Stochastic activations","summary":"We introduce stochastic activations. This novel strategy randomly selects between several non-linear functions in the feed-forward layer of a large language model. In particular, we choose between SILU or RELU depending on a Bernoulli draw. This strategy circumvents the optimization problem associated with RELU, namely, the constant shape for negative inputs that prevents the gradient flow. We leverage this strategy in two ways:\n  (1) We use stochastic activations during pre-training and fine-tune the model with RELU, which is used at inference time to provide sparse latent vectors. This reduces the inference FLOPs and translates into a significant speedup in the CPU. Interestingly, this leads to much better results than training from scratch with the RELU activation function.\n  (2) We evaluate stochastic activations for generation. This strategy performs reasonably well: it is only slightly inferior to the best deterministic non-linearity, namely SILU combined with temperature scaling. This offers an alternative to existing strategies by providing a controlled way to increase the diversity of the generated text.","authors":["Maria Lomeli","Matthijs Douze","Gergely Szilvasy","Loic Cabannes","Jade Copet","Sainbayar Sukhbaatar","Jason Weston","Gabriel Synnaeve","Pierre-Emmanuel Mazaré","Hervé Jégou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20438v1","updated":"2025-12-23T15:27:28Z","published":"2025-12-23T15:27:28Z","title":"Machine Learning to Predict Digital Frustration from Clickstream Data","summary":"Many businesses depend on their mobile apps and websites, so user frustration while trying to complete a task on these channels can cause lost sales and complaints. In this research, I use clickstream data from a real e-commerce site to predict whether a session is frustrated or not. Frustration is defined using certain rules based on rage bursts, back and forth navigation (U turns), cart churn, search struggle, and long wandering sessions, and applies these rules to 5.4 million raw clickstream events (304,881 sessions). From each session, I build tabular features and train standard classifier models. I also use the full event sequence to train a discriminative LSTM classifier. XGBoost reaches about 90% accuracy, ROC AUC of 0.9579, while the LSTM performs best with about 91% accuracy and a ROC AUC of 0.9705. Finally, the research shows that with only the first 20 to 30 interactions, the LSTM already predicts frustration reliably.","authors":["Jibin Joseph"],"pdf_url":"","comment":"17 pages, 5 figures"},{"id":"http://arxiv.org/abs/2310.05805v3","updated":"2025-12-23T15:25:13Z","published":"2023-10-09T15:43:46Z","title":"Boosted Control Functions: Distribution generalization and invariance in confounded models","summary":"Modern machine learning methods and the availability of large-scale data have significantly advanced our ability to predict target quantities from large sets of covariates. However, these methods often struggle under distributional shifts, particularly in the presence of hidden confounding. While the impact of hidden confounding is well-studied in causal effect estimation, e.g., instrumental variables, its implications for prediction tasks under shifting distributions remain underexplored. This work addresses this gap by introducing a strong notion of invariance that, unlike existing weaker notions, allows for distribution generalization even in the presence of nonlinear, non-identifiable structural functions. Central to this framework is the Boosted Control Function (BCF), a novel, identifiable target of inference that satisfies the proposed strong invariance notion and is provably worst-case optimal under distributional shifts. The theoretical foundation of our work lies in Simultaneous Equation Models for Distribution Generalization (SIMDGs), which bridge machine learning with econometrics by describing data-generating processes under distributional shifts. To put these insights into practice, we propose the ControlTwicing algorithm to estimate the BCF using nonparametric machine-learning techniques and study its generalization performance on synthetic and real-world datasets compared to robust and empirical risk minimization approaches.","authors":["Nicola Gnecco","Jonas Peters","Sebastian Engelke","Niklas Pfister"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.07490v3","updated":"2025-12-23T15:22:53Z","published":"2025-12-08T12:17:40Z","title":"Efficient Low-Tubal-Rank Tensor Estimation via Alternating Preconditioned Gradient Descent","summary":"The problem of low-tubal-rank tensor estimation is a fundamental task with wide applications across high-dimensional signal processing, machine learning, and image science. Traditional approaches tackle such a problem by performing tensor singular value decomposition, which is computationally expensive and becomes infeasible for large-scale tensors. Recent approaches address this issue by factorizing the tensor into two smaller factor tensors and solving the resulting problem using gradient descent. However, this kind of approach requires an accurate estimate of the tensor rank, and when the rank is overestimated, the convergence of gradient descent and its variants slows down significantly or even diverges. To address this problem, we propose an Alternating Preconditioned Gradient Descent (APGD) algorithm, which accelerates convergence in the over-parameterized setting by adding a preconditioning term to the original gradient and updating these two factors alternately. Based on certain geometric assumptions on the objective function, we establish linear convergence guarantees for more general low-tubal-rank tensor estimation problems. Then we further analyze the specific cases of low-tubal-rank tensor factorization and low-tubal-rank tensor recovery. Our theoretical results show that APGD achieves linear convergence even under over-parameterization, and the convergence rate is independent of the tensor condition number. Extensive simulations on synthetic data are carried out to validate our theoretical assertions.","authors":["Zhiyu Liu","Zhi Han","Yandong Tang","Jun Fan","Yao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17586v2","updated":"2025-12-23T15:11:27Z","published":"2025-12-19T13:52:19Z","title":"Learning Safe Autonomous Driving Policies Using Predictive Safety Representations","summary":"Safe reinforcement learning (SafeRL) is a prominent paradigm for autonomous driving, where agents are required to optimize performance under strict safety requirements. This dual objective creates a fundamental tension, as overly conservative policies limit driving efficiency while aggressive exploration risks safety violations. The Safety Representations for Safer Policy Learning (SRPL) framework addresses this challenge by equipping agents with a predictive model of future constraint violations and has shown promise in controlled environments. This paper investigates whether SRPL extends to real-world autonomous driving scenarios. Systematic experiments on the Waymo Open Motion Dataset (WOMD) and NuPlan demonstrate that SRPL can improve the reward-safety tradeoff, achieving statistically significant improvements in success rate (effect sizes r = 0.65-0.86) and cost reduction (effect sizes r = 0.70-0.83), with p < 0.05 for observed improvements. However, its effectiveness depends on the underlying policy optimizer and the dataset distribution. The results further show that predictive safety representations play a critical role in improving robustness to observation noise. Additionally, in zero-shot cross-dataset evaluation, SRPL-augmented agents demonstrate improved generalization compared to non-SRPL methods. These findings collectively demonstrate the potential of predictive safety representations to strengthen SafeRL for autonomous driving.","authors":["Mahesh Keswani","Raunak Bhattacharyya"],"pdf_url":"","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2505.09710v3","updated":"2025-12-23T15:03:59Z","published":"2025-05-14T18:10:49Z","title":"Training Deep Morphological Neural Networks as Universal Approximators","summary":"We investigate deep morphological neural networks (DMNNs). We demonstrate that despite their inherent non-linearity, \"linear\" activations are essential for DMNNs. To preserve their inherent sparsity, we propose architectures that constraint the parameters of the \"linear\" activations: For the first (resp. second) architecture, we work under the constraint that the majority of parameters (resp. learnable parameters) should be part of morphological operations. We improve the generalization ability of our networks via residual connections and weight dropout. Our proposed networks can be successfully trained, and are more prunable than linear networks. To the best of our knowledge, we are the first to successfully train DMNNs under such constraints. Finally, we propose a hybrid network architecture combining linear and morphological layers, showing empirically that the inclusion of morphological layers significantly accelerates the convergence of gradient descent with large batches.","authors":["Konstantinos Fotopoulos","Petros Maragos"],"pdf_url":"","comment":"v3: Added acknowledgments"},{"id":"http://arxiv.org/abs/2512.20420v1","updated":"2025-12-23T15:02:12Z","published":"2025-12-23T15:02:12Z","title":"Simplifying Multi-Task Architectures Through Task-Specific Normalization","summary":"Multi-task learning (MTL) aims to leverage shared knowledge across tasks to improve generalization and parameter efficiency, yet balancing resources and mitigating interference remain open challenges. Architectural solutions often introduce elaborate task-specific modules or routing schemes, increasing complexity and overhead. In this work, we show that normalization layers alone are sufficient to address many of these challenges. Simply replacing shared normalization with task-specific variants already yields competitive performance, questioning the need for complex designs. Building on this insight, we propose Task-Specific Sigmoid Batch Normalization (TS$σ$BN), a lightweight mechanism that enables tasks to softly allocate network capacity while fully sharing feature extractors. TS$σ$BN improves stability across CNNs and Transformers, matching or exceeding performance on NYUv2, Cityscapes, CelebA, and PascalContext, while remaining highly parameter-efficient. Moreover, its learned gates provide a natural framework for analyzing MTL dynamics, offering interpretable insights into capacity allocation, filter specialization, and task relationships. Our findings suggest that complex MTL architectures may be unnecessary and that task-specific normalization offers a simple, interpretable, and efficient alternative.","authors":["Mihai Suteu","Ovidiu Serban"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20407v1","updated":"2025-12-23T14:55:08Z","published":"2025-12-23T14:55:08Z","title":"AUDRON: A Deep Learning Framework with Fused Acoustic Signatures for Drone Type Recognition","summary":"Unmanned aerial vehicles (UAVs), commonly known as drones, are increasingly used across diverse domains, including logistics, agriculture, surveillance, and defense. While these systems provide numerous benefits, their misuse raises safety and security concerns, making effective detection mechanisms essential. Acoustic sensing offers a low-cost and non-intrusive alternative to vision or radar-based detection, as drone propellers generate distinctive sound patterns. This study introduces AUDRON (AUdio-based Drone Recognition Network), a hybrid deep learning framework for drone sound detection, employing a combination of Mel-Frequency Cepstral Coefficients (MFCC), Short-Time Fourier Transform (STFT) spectrograms processed with convolutional neural networks (CNNs), recurrent layers for temporal modeling, and autoencoder-based representations. Feature-level fusion integrates complementary information before classification. Experimental evaluation demonstrates that AUDRON effectively differentiates drone acoustic signatures from background noise, achieving high accuracy while maintaining generalizability across varying conditions. AUDRON achieves 98.51 percent and 97.11 percent accuracy in binary and multiclass classification. The results highlight the advantage of combining multiple feature representations with deep learning for reliable acoustic drone detection, suggesting the framework's potential for deployment in security and surveillance applications where visual or radar sensing may be limited.","authors":["Rajdeep Chatterjee","Sudip Chakrabarty","Trishaani Acharjee","Deepanjali Mishra"],"pdf_url":"","comment":"Presented at the 2025 IEEE 22nd India Council International Conference (INDICON). 6 pages, 3 figures"},{"id":"http://arxiv.org/abs/2512.20403v1","updated":"2025-12-23T14:46:43Z","published":"2025-12-23T14:46:43Z","title":"BRIDGE: Budget-aware Reasoning via Intermediate Distillation with Guided Examples","summary":"Distilling knowledge from large proprietary models (e.g., GPT-4) to tiny deployable models (less than 1B parameters) faces a critical capacity-budget trap: the 1000x capacity gap between teachers and students prevents effective direct transfer, while API costs prohibit extensive data collection. We introduce BRIDGE (Budget-Aware Reasoning via Intermediate Distillation), a two-phase framework that resolves these constraints through strategic intermediation and budget asymmetry. In Phase 1, a mid-sized Teacher Assistant (TA; e.g., about 7B) learns from the black-box teacher on a strictly limited subset of data (e.g., 3-5%), selected via a zero-API-cost pipeline that balances entropic difficulty and semantic diversity using only local TA inference. In Phase 2, we exploit this asymmetry-teacher queries are expensive, whereas TA inference is free to amplify supervision: the refined TA generates synthetic rationales for the full dataset to train the tiny student. Crucially, we apply an instruction-tuning curriculum to establish behavioral alignment in the tiny student before transferring reasoning. Our theoretical analysis shows that BRIDGE yields tighter generalization bounds than direct distillation when data is abundant. Experiments across medical, legal, and financial benchmarks demonstrate consistent improvements: BRIDGE delivers student performance gains of 28-41%, closing the capability gap with proprietary teachers by 12-16% while using 10x fewer teacher queries. Notably, BRIDGE defies the conventional cost-performance frontier, surpassing direct distillation baselines that use 100% of the budget while consuming only 5% of the resources.","authors":["Xuan-An Le","Minh-Nam Tran","Son Nguyen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18689v2","updated":"2025-12-23T14:46:41Z","published":"2025-12-21T10:55:32Z","title":"Fusion of Multiscale Features Via Centralized Sparse-attention Network for EEG Decoding","summary":"Electroencephalography (EEG) signal decoding is a key technology that translates brain activity into executable commands, laying the foundation for direct brain-machine interfacing and intelligent interaction. To address the inherent spatiotemporal heterogeneity of EEG signals, this paper proposes a multi-branch parallel architecture, where each temporal scale is equipped with an independent spatial feature extraction module. To further enhance multi-branch feature fusion, we propose a Fusion of Multiscale Features via Centralized Sparse-attention Network (EEG-CSANet), a centralized sparse-attention network. It employs a main-auxiliary branch architecture, where the main branch models core spatiotemporal patterns via multiscale self-attention, and the auxiliary branch facilitates efficient local interactions through sparse cross-attention. Experimental results show that EEG-CSANet achieves state-of-the-art (SOTA) performance across five public datasets (BCIC-IV-2A, BCIC-IV-2B, HGD, SEED, and SEED-VIG), with accuracies of 88.54%, 91.09%, 99.43%, 96.03%, and 90.56%, respectively. Such performance demonstrates its strong adaptability and robustness across various EEG decoding tasks. Moreover, extensive ablation studies are conducted to enhance the interpretability of EEG-CSANet. In the future, we hope that EEG-CSANet could serve as a promising baseline model in the field of EEG signal decoding. The source code is publicly available at: https://github.com/Xiangrui-Cai/EEG-CSANet","authors":["Xiangrui Cai","Shaocheng Ma","Lei Cao","Jie Li","Tianyu Liu","Yilin Dong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20399v1","updated":"2025-12-23T14:40:08Z","published":"2025-12-23T14:40:08Z","title":"GeoTransolver: Learning Physics on Irregumar Domains Using Multi-scale Geometry Aware Physics Attention Transformer","summary":"We present GeoTransolver, a Multiscale Geometry-Aware Physics Attention Transformer for CAE that replaces standard attention with GALE, coupling physics-aware self-attention on learned state slices with cross-attention to a shared geometry/global/boundary-condition context computed from multi-scale ball queries (inspired by DoMINO) and reused in every block. Implemented and released in NVIDIA PhysicsNeMo, GeoTransolver persistently projects geometry, global and boundary condition parameters into physical state spaces to anchor latent computations to domain structure and operating regimes. We benchmark GeoTransolver on DrivAerML, Luminary SHIFT-SUV, and Luminary SHIFT-Wing, comparing against Domino, Transolver (as released in PhysicsNeMo), and literature-reported AB-UPT, and evaluate drag/lift R2 and Relative L1 errors for field variables. GeoTransolver delivers better accuracy, improved robustness to geometry/regime shifts, and favorable data efficiency; we include ablations on DrivAerML and qualitative results such as contour plots and design trends for the best GeoTransolver models. By unifying multiscale geometry-aware context with physics-based attention in a scalable transformer, GeoTransolver advances operator learning for high-fidelity surrogate modeling across complex, irregular domains and non-linear physical regimes.","authors":["Corey Adams","Rishikesh Ranade","Ram Cherukuri","Sanjay Choudhry"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20368v1","updated":"2025-12-23T13:53:53Z","published":"2025-12-23T13:53:53Z","title":"Avoiding the Price of Adaptivity: Inference in Linear Contextual Bandits via Stability","summary":"Statistical inference in contextual bandits is complicated by the adaptive, non-i.i.d. nature of the data. A growing body of work has shown that classical least-squares inference may fail under adaptive sampling, and that constructing valid confidence intervals for linear functionals of the model parameter typically requires paying an unavoidable inflation of order $\\sqrt{d \\log T}$. This phenomenon -- often referred to as the price of adaptivity -- highlights the inherent difficulty of reliable inference under general contextual bandit policies.\n  A key structural property that circumvents this limitation is the \\emph{stability} condition of Lai and Wei, which requires the empirical feature covariance to concentrate around a deterministic limit. When stability holds, the ordinary least-squares estimator satisfies a central limit theorem, and classical Wald-type confidence intervals -- designed for i.i.d. data -- become asymptotically valid even under adaptation, \\emph{without} incurring the $\\sqrt{d \\log T}$ price of adaptivity.\n  In this paper, we propose and analyze a penalized EXP4 algorithm for linear contextual bandits. Our first main result shows that this procedure satisfies the Lai--Wei stability condition and therefore admits valid Wald-type confidence intervals for linear functionals. Our second result establishes that the same algorithm achieves regret guarantees that are minimax optimal up to logarithmic factors, demonstrating that stability and statistical efficiency can coexist within a single contextual bandit method. Finally, we complement our theory with simulations illustrating the empirical normality of the resulting estimators and the sharpness of the corresponding confidence intervals.","authors":["Samya Praharaj","Koulik Khamaru"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20363v1","updated":"2025-12-23T13:46:38Z","published":"2025-12-23T13:46:38Z","title":"Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning","summary":"Federated learning (FL) supports privacy-preserving, decentralized machine learning (ML) model training by keeping data on client devices. However, non-independent and identically distributed (non-IID) data across clients biases updates and degrades performance. To alleviate these issues, we propose Clust-PSI-PFL, a clustering-based personalized FL framework that uses the Population Stability Index (PSI) to quantify the level of non-IID data. We compute a weighted PSI metric, $WPSI^L$, which we show to be more informative than common non-IID metrics (Hellinger, Jensen-Shannon, and Earth Mover's distance). Using PSI features, we form distributionally homogeneous groups of clients via K-means++; the number of optimal clusters is chosen by a systematic silhouette-based procedure, typically yielding few clusters with modest overhead. Across six datasets (tabular, image, and text modalities), two partition protocols (Dirichlet with parameter $α$ and Similarity with parameter S), and multiple client sizes, Clust-PSI-PFL delivers up to 18% higher global accuracy than state-of-the-art baselines and markedly improves client fairness by a relative improvement of 37% under severe non-IID data. These results establish PSI-guided clustering as a principled, lightweight mechanism for robust PFL under label skew.","authors":["Daniel M. Jimenez-Gutierrez","Mehrdad Hassanzadeh","Aris Anagnostopoulos","Ioannis Chatzigiannakis","Andrea Vitaletti"],"pdf_url":"","comment":"Accepted for publication to the 40th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2026)"},{"id":"http://arxiv.org/abs/2412.11800v3","updated":"2025-12-23T13:43:57Z","published":"2024-12-16T14:11:28Z","title":"Scalable Temporal Anomaly Causality Discovery in Large Systems: Achieving Computational Efficiency with Binary Anomaly Flag Data","summary":"Extracting anomaly causality facilitates diagnostics once monitoring systems detect system faults. Identifying anomaly causes in large systems involves investigating a broader set of monitoring variables across multiple subsystems. However, learning graphical causal models (GCMs) comes with a significant computational burden that restrains the applicability of most existing methods in real-time and large-scale deployments. In addition, modern monitoring applications for large systems often generate large amounts of binary alarm flags, and the distinct characteristics of binary anomaly data -- the meaning of state transition and data sparsity -- challenge existing causality learning mechanisms. This study proposes an anomaly causal discovery approach (AnomalyCD), addressing the accuracy and computational challenges of generating GCMs from temporal binary flag datasets. The AnomalyCD presents several strategies, such as anomaly data-aware causality testing, sparse data and prior link compression, and edge pruning adjustment approaches. We validate the performance of the approach on two datasets: monitoring sensor data from the readout-box system of the Compact Muon Solenoid experiment at CERN, and a public dataset from an information technology monitoring system. The results on temporal GCMs demonstrate a considerable reduction of computation overhead and a moderate enhancement of accuracy on the binary anomaly datasets Source code: https://github.com/muleina/AnomalyCD .","authors":["Mulugeta Weldezgina Asres","Christian Walter Omlin","The CMS-HCAL Collaboration"],"pdf_url":"","comment":"34 pages, 17 figures, 8 tables"},{"id":"http://arxiv.org/abs/2508.12029v3","updated":"2025-12-23T13:32:11Z","published":"2025-08-16T12:31:39Z","title":"BConformeR: A Conformer Based on Mutual Sampling for Unified Prediction of Continuous and Discontinuous Antibody Binding Sites","summary":"Accurate prediction of antibody-binding sites (epitopes) on antigens is crucial for vaccine design, immunodiagnostics, therapeutic antibody development, antibody engineering, research into autoimmune and allergic diseases, and advancing our understanding of immune responses. Despite in silico methods that have been proposed to predict both linear (continuous) and conformational (discontinuous) epitopes, they consistently underperform in predicting conformational epitopes. In this work, we propose Conformer-based models trained separately on AlphaFold-predicted structures and experimentally determined structures, leveraging convolutional neural networks (CNNs) to extract local features and Transformers to capture long-range dependencies within antigen sequences. Ablation studies demonstrate that CNN enhances the prediction of linear epitopes, and the Transformer module improves the prediction of conformational epitopes. Experimental results show that our model outperforms existing baselines in terms of MCC, ROC-AUC, PR-AUC, and F1 scores on both linear and conformational epitopes.","authors":["Zhangyu You","Jiahao Ma","Hongzong Li","Ye-Fan Hu","Jian-Dong Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20350v1","updated":"2025-12-23T13:31:21Z","published":"2025-12-23T13:31:21Z","title":"Field-Space Attention for Structure-Preserving Earth System Transformers","summary":"Accurate and physically consistent modeling of Earth system dynamics requires machine-learning architectures that operate directly on continuous geophysical fields and preserve their underlying geometric structure. Here we introduce Field-Space attention, a mechanism for Earth system Transformers that computes attention in the physical domain rather than in a learned latent space. By maintaining all intermediate representations as continuous fields on the sphere, the architecture enables interpretable internal states and facilitates the enforcement of scientific constraints. The model employs a fixed, non-learned multiscale decomposition and learns structure-preserving deformations of the input field, allowing coherent integration of coarse and fine-scale information while avoiding the optimization instabilities characteristic of standard single-scale Vision Transformers. Applied to global temperature super-resolution on a HEALPix grid, Field-Space Transformers converge more rapidly and stably than conventional Vision Transformers and U-Net baselines, while requiring substantially fewer parameters. The explicit preservation of field structure throughout the network allows physical and statistical priors to be embedded directly into the architecture, yielding improved fidelity and reliability in data-driven Earth system modeling. These results position Field-Space Attention as a compact, interpretable, and physically grounded building block for next-generation Earth system prediction and generative modeling frameworks.","authors":["Maximilian Witte","Johannes Meuer","Étienne Plésiat","Christopher Kadow"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.17454v2","updated":"2025-12-23T13:29:56Z","published":"2025-07-23T12:21:26Z","title":"C3RL: Rethinking the Combination of Channel-independence and Channel-mixing from Representation Learning","summary":"Multivariate time series forecasting has drawn increasing attention due to its practical importance. Existing approaches typically adopt either channel-mixing (CM) or channel-independence (CI) strategies. CM strategy can capture inter-variable dependencies but fails to discern variable-specific temporal patterns. CI strategy improves this aspect but fails to fully exploit cross-variable dependencies like CM. Hybrid strategies based on feature fusion offer limited generalization and interpretability. To address these issues, we propose C3RL, a novel representation learning framework that jointly models both CM and CI strategies. Motivated by contrastive learning in computer vision, C3RL treats the inputs of the two strategies as transposed views and builds a siamese network architecture: one strategy serves as the backbone, while the other complements it. By jointly optimizing contrastive and prediction losses with adaptive weighting, C3RL balances representation and forecasting performance. Extensive experiments on seven models show that C3RL boosts the best-case performance rate to 81.4% for models based on CI strategy and to 76.3% for models based on CM strategy, demonstrating strong generalization and effectiveness.","authors":["Shusen Ma","Yun-Bo Zhao","Yu Kang"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2512.20348v1","updated":"2025-12-23T13:29:26Z","published":"2025-12-23T13:29:26Z","title":"Physics-guided Neural Network-based Shaft Power Prediction for Vessels","summary":"Optimizing maritime operations, particularly fuel consumption for vessels, is crucial, considering its significant share in global trade. As fuel consumption is closely related to the shaft power of a vessel, predicting shaft power accurately is a crucial problem that requires careful consideration to minimize costs and emissions. Traditional approaches, which incorporate empirical formulas, often struggle to model dynamic conditions, such as sea conditions or fouling on vessels. In this paper, we present a hybrid, physics-guided neural network-based approach that utilizes empirical formulas within the network to combine the advantages of both neural networks and traditional techniques. We evaluate the presented method using data obtained from four similar-sized cargo vessels and compare the results with those of a baseline neural network and a traditional approach that employs empirical formulas. The experimental results demonstrate that the physics-guided neural network approach achieves lower mean absolute error, root mean square error, and mean absolute percentage error for all tested vessels compared to both the empirical formula-based method and the base neural network.","authors":["Dogan Altan","Hamza Haruna Mohammed","Glenn Terje Lines","Dusica Marijan","Arnbjørn Maressa"],"pdf_url":"","comment":"This work has been accepted for publication in the 11th Special Session on Intelligent Data Mining at IEEE BigData 2025. The final published version of this work will be available through IEEE"},{"id":"http://arxiv.org/abs/2512.20346v1","updated":"2025-12-23T13:28:15Z","published":"2025-12-23T13:28:15Z","title":"Inverse Autoregressive Flows for Zero Degree Calorimeter fast simulation","summary":"Physics-based machine learning blends traditional science with modern data-driven techniques. Rather than relying exclusively on empirical data or predefined equations, this methodology embeds domain knowledge directly into the learning process, resulting in models that are both more accurate and robust. We leverage this paradigm to accelerate simulations of the Zero Degree Calorimeter (ZDC) of the ALICE experiment at CERN. Our method introduces a novel loss function and an output variability-based scaling mechanism, which enhance the model's capability to accurately represent the spatial distribution and morphology of particle showers in detector outputs while mitigating the influence of rare artefacts on the training. Leveraging Normalizing Flows (NFs) in a teacher-student generative framework, we demonstrate that our approach not only outperforms classic data-driven model assimilation but also yields models that are 421 times faster than existing NF implementations in ZDC simulation literature.","authors":["Emilia Majerz","Witold Dzwinel","Jacek Kitowski"],"pdf_url":"","comment":"Presented as a poster at the Machine Learning and the Physical Sciences Workshop, 39th Conference on Neural Information Processing Systems (NeurIPS), 2025"},{"id":"http://arxiv.org/abs/2507.20993v2","updated":"2025-12-23T13:19:34Z","published":"2025-07-28T16:52:31Z","title":"Learning Treatment Policies From Multimodal Electronic Health Records","summary":"We study how to learn effective treatment policies from multimodal electronic health records (EHRs) that consist of tabular data and clinical text. These policies can help physicians make better treatment decisions and allocate healthcare resources more efficiently. Causal policy learning methods prioritize patients with the largest expected treatment benefit. Yet, existing estimators assume tabular covariates that satisfy strong causal assumptions, which are typically violated in the multimodal setting. As a result, predictive models of baseline risk are commonly used in practice to guide such decisions, as they extend naturally to multimodal data. However, such risk-based policies are not designed to identify which patients benefit most from treatment. We propose an extension of causal policy learning that uses expert-provided annotations during training to supervise treatment effect estimation, while using only multimodal representations as input during inference. We show that the proposed method achieves strong empirical performance across synthetic, semi-synthetic, and real-world EHR datasets, thereby offering practical insights into applying causal machine learning to realistic clinical data.","authors":["Henri Arno","Thomas Demeester"],"pdf_url":"","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2506.05831v3","updated":"2025-12-23T13:17:55Z","published":"2025-06-06T07:56:41Z","title":"Heartcare Suite: A Unified Multimodal ECG Suite for Dual Signal-Image Modeling and Understanding","summary":"Although electrocardiograms (ECG) play a dominant role in cardiovascular diagnosis and treatment, their intrinsic data forms and representational patterns pose significant challenges for medical multimodal large language models (Med-MLLMs) in achieving cross-modal semantic alignment. To address this gap, we propose Heartcare Suite, a unified ECG suite designed for dual signal-image modeling and understanding. (i) Heartcare-400K: We build a finegrained ECG instruction dataset on top of our data pipeline engine--HeartAgent--by integrating 12,170 high quality clinical ECG reports from top hospitals with open-source data; (ii) Heartcare-Bench: a systematic benchmark assessing performance of models in multi-perspective ECG understanding and cross-modal generalization, providing guidance for optimizing ECG comprehension models; (iii) HeartcareGPT: built upon a structure-aware discrete tokenizer Beat, we propose the DSPA (Dual Stream Projection Alignment) paradigm--a dual encoder projection alignment mechanism enabling joint optimizing and modeling native ECG signal-image within a shared feature space. Heartcare achieves consistent improvements across diverse ECG understanding tasks, validating both the effectiveness of the unified modeling paradigm and the necessity of a high-quality data pipeline, and establishing a methodological foundation for extending Med-MLLMs toward physiological signal domains. Our project is available at https://github.com/DCDmllm/Heartcare-Suite .","authors":["Yihan Xie","Sijing Li","Tianwei Lin","Zhuonan Wang","Chenglin Yang","Yu Zhong","Wenjie Yan","Wenqiao Zhang","Xiaogang Guo","Jun Xiao","Yueting Zhuang","Beng Chin Ooi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19253v2","updated":"2025-12-23T13:00:45Z","published":"2025-12-22T10:40:03Z","title":"Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study","summary":"We present the first comprehensive empirical study of machine unlearning (MU) in hybrid quantum-classical neural networks. While MU has been extensively explored in classical deep learning, its behavior within variational quantum circuits (VQCs) and quantum-augmented architectures remains largely unexplored. First, we adapt a broad suite of unlearning methods to quantum settings, including gradient-based, distillation-based, regularization-based and certified techniques. Second, we introduce two new unlearning strategies tailored to hybrid models. Experiments across Iris, MNIST, and Fashion-MNIST, under both subset removal and full-class deletion, reveal that quantum models can support effective unlearning, but outcomes depend strongly on circuit depth, entanglement structure, and task complexity. Shallow VQCs display high intrinsic stability with minimal memorization, whereas deeper hybrid models exhibit stronger trade-offs between utility, forgetting strength, and alignment with retrain oracle. We find that certain methods, e.g. EU-k, LCA, and Certified Unlearning, consistently provide the best balance across metrics. These findings establish baseline empirical insights into quantum machine unlearning and highlight the need for quantum-aware algorithms and theoretical guarantees, as quantum machine learning systems continue to expand in scale and capability. We publicly release our code at: https://github.com/CrivoiCarla/HQML.","authors":["Carla Crivoi","Radu Tudor Ionescu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20329v1","updated":"2025-12-23T12:57:27Z","published":"2025-12-23T12:57:27Z","title":"FedDPC : Handling Data Heterogeneity and Partial Client Participation in Federated Learning","summary":"Data heterogeneity is a significant challenge in modern federated learning (FL) as it creates variance in local model updates, causing the aggregated global model to shift away from the true global optimum. Partial client participation in FL further exacerbates this issue by skewing the aggregation of local models towards the data distribution of participating clients. This creates additional variance in the global model updates, causing the global model to converge away from the optima of the global objective. These variances lead to instability in FL training, which degrades global model performance and slows down FL training. While existing literature primarily focuses on addressing data heterogeneity, the impact of partial client participation has received less attention. In this paper, we propose FedDPC, a novel FL method, designed to improve FL training and global model performance by mitigating both data heterogeneity and partial client participation. FedDPC addresses these issues by projecting each local update onto the previous global update, thereby controlling variance in both local and global updates. To further accelerate FL training, FedDPC employs adaptive scaling for each local update before aggregation. Extensive experiments on image classification tasks with multiple heterogeneously partitioned datasets validate the effectiveness of FedDPC. The results demonstrate that FedDPC outperforms state-of-the-art FL algorithms by achieving faster reduction in training loss and improved test accuracy across communication rounds.","authors":["Mrinmay Sen","Subhrajit Nag"],"pdf_url":"","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2512.20328v1","updated":"2025-12-23T12:56:18Z","published":"2025-12-23T12:56:18Z","title":"Toward Explaining Large Language Models in Software Engineering Tasks","summary":"Recent progress in Large Language Models (LLMs) has substantially advanced the automation of software engineering (SE) tasks, enabling complex activities such as code generation and code summarization. However, the black-box nature of LLMs remains a major barrier to their adoption in high-stakes and safety-critical domains, where explainability and transparency are vital for trust, accountability, and effective human supervision. Despite increasing interest in explainable AI for software engineering, existing methods lack domain-specific explanations aligned with how practitioners reason about SE artifacts. To address this gap, we introduce FeatureSHAP, the first fully automated, model-agnostic explainability framework tailored to software engineering tasks. Based on Shapley values, FeatureSHAP attributes model outputs to high-level input features through systematic input perturbation and task-specific similarity comparisons, while remaining compatible with both open-source and proprietary LLMs. We evaluate FeatureSHAP on two bi-modal SE tasks: code generation and code summarization. The results show that FeatureSHAP assigns less importance to irrelevant input features and produces explanations with higher fidelity than baseline methods. A practitioner survey involving 37 participants shows that FeatureSHAP helps practitioners better interpret model outputs and make more informed decisions. Collectively, FeatureSHAP represents a meaningful step toward practical explainable AI in software engineering. FeatureSHAP is available at https://github.com/deviserlab/FeatureSHAP.","authors":["Antonio Vitale","Khai-Nguyen Nguyen","Denys Poshyvanyk","Rocco Oliveto","Simone Scalabrino","Antonio Mastropaolo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.13892v2","updated":"2025-12-23T12:54:15Z","published":"2025-12-15T20:50:54Z","title":"One Permutation Is All You Need: Fast, Reliable Variable Importance and Model Stress-Testing","summary":"Reliable estimation of feature contributions in machine learning models is essential for trust, transparency and regulatory compliance, especially when models are proprietary or otherwise operate as black boxes. While permutation-based methods are a standard tool for this task, classical implementations rely on repeated random permutations, introducing computational overhead and stochastic instability. In this paper, we show that by replacing multiple random permutations with a single, deterministic, and optimal permutation, we achieve a method that retains the core principles of permutation-based importance while being non-random, faster, and more stable. We validate this approach across nearly 200 scenarios, including real-world household finance and credit risk applications, demonstrating improved bias-variance tradeoffs and accuracy in challenging regimes such as small sample sizes, high dimensionality, and low signal-to-noise ratios. Finally, we introduce Systemic Variable Importance, a natural extension designed for model stress-testing that explicitly accounts for feature correlations. This framework provides a transparent way to quantify how shocks or perturbations propagate through correlated inputs, revealing dependencies that standard variable importance measures miss. Two real-world case studies demonstrate how this metric can be used to audit models for hidden reliance on protected attributes (e.g., gender or race), enabling regulators and practitioners to assess fairness and systemic risk in a principled and computationally efficient manner.","authors":["Albert Dorador"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20325v1","updated":"2025-12-23T12:49:44Z","published":"2025-12-23T12:49:44Z","title":"Top-K Exterior Power Persistent Homology: Algorithm, Structure, and Stability","summary":"Exterior powers play important roles in persistent homology in computational geometry. In the present paper we study the problem of extracting the $K$ longest intervals of the exterior-power layers of a tame persistence module. We prove a structural decomposition theorem that organizes the exterior-power layers into monotone per-anchor streams with explicit multiplicities, enabling a best-first algorithm. We also show that the Top-$K$ length vector is $2$-Lipschitz under bottleneck perturbations of the input barcode, and prove a comparison-model lower bound. Our experiments confirm the theory, showing speedups over full enumeration in high overlap cases. By enabling efficient extraction of the most prominent features, our approach makes higher-order persistence feasible for large datasets and thus broadly applicable to machine learning, data science, and scientific computing.","authors":["Yoshihiro Maruyama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.18092v6","updated":"2025-12-23T12:38:34Z","published":"2025-01-30T02:03:30Z","title":"Learning Provably Improves the Convergence of Gradient Descent","summary":"Learn to Optimize (L2O) trains deep neural network-based solvers for optimization, achieving success in accelerating convex problems and improving non-convex solutions. However, L2O lacks rigorous theoretical backing for its own training convergence, as existing analyses often use unrealistic assumptions -- a gap this work highlights empirically. We bridge this gap by proving the training convergence of L2O models that learn Gradient Descent (GD) hyperparameters for quadratic programming, leveraging the Neural Tangent Kernel (NTK) theory. We propose a deterministic initialization strategy to support our theoretical results and promote stable training over extended optimization horizons by mitigating gradient explosion. Our L2O framework demonstrates over 50% better optimality than GD and superior robustness over state-of-the-art L2O methods on synthetic datasets. The code of our method can be found from https://github.com/NetX-lab/MathL2OProof-Official.","authors":["Qingyu Song","Wei Lin","Hong Xu"],"pdf_url":"","comment":"48 pages, 11 figures, NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.18417v2","updated":"2025-12-23T12:33:25Z","published":"2025-11-23T12:07:45Z","title":"Categorical Equivariant Deep Learning: Category-Equivariant Neural Networks and Universal Approximation Theorems","summary":"We develop a theory of category-equivariant neural networks (CENNs) that unifies group/groupoid-equivariant networks, poset/lattice-equivariant networks, graph and sheaf neural networks. Equivariance is formulated as naturality in a topological category with Radon measures. Formulating linear and nonlinear layers in the categorical setup, we prove the equivariant universal approximation theorem in the general setting: the class of finite-depth CENNs is dense in the space of continuous equivariant transformations. We instantiate the framework for groups/groupoids, posets/lattices, graphs and cellular sheaves, deriving universal approximation theorems for them in a systematic manner. Categorical equivariant deep learning thus allows us to expand the horizons of equivariant deep learning beyond group actions, encompassing not only geometric symmetries but also contextual and compositional symmetries.","authors":["Yoshihiro Maruyama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20312v1","updated":"2025-12-23T12:30:37Z","published":"2025-12-23T12:30:37Z","title":"TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning","summary":"Tabular data serves as the backbone of modern data analysis and scientific research. While Large Language Models (LLMs) fine-tuned via Supervised Fine-Tuning (SFT) have significantly improved natural language interaction with such structured data, they often fall short in handling the complex, multi-step reasoning and robust code execution required for real-world table tasks. Reinforcement Learning (RL) offers a promising avenue to enhance these capabilities, yet its application in the tabular domain faces three critical hurdles: the scarcity of high-quality agentic trajectories with closed-loop code execution and environment feedback on diverse table structures, the extreme heterogeneity of feedback signals ranging from rigid SQL execution to open-ended data interpretation, and the risk of catastrophic forgetting of general knowledge during vertical specialization. To overcome these challenges and unlock advanced reasoning on complex tables, we introduce \\textbf{TableGPT-R1}, a specialized tabular model built on a systematic RL framework. Our approach integrates a comprehensive data engineering pipeline that synthesizes difficulty-stratified agentic trajectories for both supervised alignment and RL rollouts, a task-adaptive reward system that combines rule-based verification with a criteria-injected reward model and incorporates process-level step reward shaping with behavioral regularization, and a multi-stage training framework that progressively stabilizes reasoning before specializing in table-specific tasks. Extensive evaluations demonstrate that TableGPT-R1 achieves state-of-the-art performance on authoritative benchmarks, significantly outperforming baseline models while retaining robust general capabilities. Our model is available at https://huggingface.co/tablegpt/TableGPT-R1.","authors":["Saisai Yang","Qingyi Huang","Jing Yuan","Liangyu Zha","Kai Tang","Yuhang Yang","Ning Wang","Yucheng Wei","Liyao Li","Wentao Ye","Hao Chen","Tao Zhang","Junlin Zhou","Haobo Wang","Gang Chen","Junbo Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20311v1","updated":"2025-12-23T12:29:58Z","published":"2025-12-23T12:29:58Z","title":"Algorithm for Interpretable Graph Features via Motivic Persistent Cohomology","summary":"We present the Chromatic Persistence Algorithm (CPA), an event-driven method for computing persistent cohomological features of weighted graphs via graphic arrangements, a classical object in computational geometry. We establish rigorous complexity results: CPA is exponential in the worst case, fixed-parameter tractable in treewidth, and nearly linear for common graph families such as trees, cycles, and series-parallel graphs. Finally, we demonstrate its practical applicability through a controlled experiment on molecular-like graph structures.","authors":["Yoshihiro Maruyama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2212.04382v4","updated":"2025-12-23T12:28:30Z","published":"2022-12-08T16:23:42Z","title":"Structure of Classifier Boundaries: Case Study for a Naive Bayes Classifier","summary":"Classifiers assign complex input data points to one of a small number of output categories. For a Bayes classifier whose input space is a graph, we study the structure of the \\emph{boundary}, which comprises those points for which at least one neighbor is classified differently. The scientific setting is assignment of DNA reads produced by \\NGSs\\ to candidate source genomes. The boundary is both large and complicated in structure. We introduce a new measure of uncertainty, Neighbor Similarity, that compares the result for an input point to the distribution of results for its neighbors. This measure not only tracks two inherent uncertainty measures for the Bayes classifier, but also can be implemented for classifiers without inherent measures of uncertainty.","authors":["Alan F. Karr","Zac Bowen","Adam A. Porter","Regina Ruane"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20305v1","updated":"2025-12-23T12:16:06Z","published":"2025-12-23T12:16:06Z","title":"KAN-AFT: An Interpretable Nonlinear Survival Model Integrating Kolmogorov-Arnold Networks with Accelerated Failure Time Analysis","summary":"Survival analysis relies fundamentally on the semi-parametric Cox Proportional Hazards (CoxPH) model and the parametric Accelerated Failure Time (AFT) model. CoxPH assumes constant hazard ratios, often failing to capture real-world dynamics, while traditional AFT models are limited by rigid distributional assumptions. Although deep learning models like DeepAFT address these constraints by improving predictive accuracy and handling censoring, they inherit the significant challenge of black-box interpretability. The recent introduction of CoxKAN demonstrated the successful integration of Kolmogorov-Arnold Networks (KANs), a novel architecture that yields highly accurate and interpretable symbolic representations, within the CoxPH framework. Motivated by the interpretability gains of CoxKAN, we introduce KAN-AFT (Kolmogorov Arnold Network-based AFT), the first framework to apply KANs to the AFT model. KAN-AFT effectively models complex nonlinear relationships within the AFT framework. Our primary contributions include: (i) a principled AFT-KAN formulation, (ii) robust optimization strategies for right-censored observations (e.g., Buckley-James and IPCW), and (iii) an interpretability pipeline that converts the learned spline functions into closed-form symbolic equations for survival time. Empirical results on multiple datasets confirm that KAN-AFT achieves performance comparable to or better than DeepAFT, while uniquely providing transparent, symbolic models of the survival process.","authors":["Mebin Jose","Jisha Francis","Sudheesh Kumar Kattumannil"],"pdf_url":"","comment":"A new development in Survival Analysis based on the celebrated Kolmogorov-Arnold Networks (KANs)"},{"id":"http://arxiv.org/abs/2510.10078v3","updated":"2025-12-23T12:11:51Z","published":"2025-10-11T07:29:32Z","title":"Improving Speech Emotion Recognition with Mutual Information Regularized Generative Model","summary":"Lack of large, well-annotated emotional speech corpora continues to limit the performance and robustness of speech emotion recognition (SER), particularly as models grow more complex and the demand for multimodal systems increases. While generative data augmentation offers a promising solution, existing approaches often produce emotionally inconsistent samples due to oversimplified conditioning on categorical labels. This paper introduces a novel mutual-information-regularised generative framework that combines cross-modal alignment with feature-level synthesis. Building on an InfoGAN-style architecture, our method first learns a semantically aligned audio-text representation space using pre-trained transformers and contrastive objectives. A feature generator is then trained to produce emotion-aware audio features while employing mutual information as a quantitative regulariser to ensure strong dependency between generated features and their conditioning variables. We extend this approach to multimodal settings, enabling the generation of novel, paired (audio, text) features. Comprehensive evaluation on three benchmark datasets (IEMOCAP, MSP-IMPROV, MSP-Podcast) demonstrates that our framework consistently outperforms existing augmentation methods, achieving state-of-the-art performance with improvements of up to 2.6% in unimodal SER and 3.2% in multimodal emotion recognition. Most importantly, we demonstrate that mutual information functions as both a regulariser and a measurable metric for generative quality, offering a systematic approach to data augmentation in affective computing.","authors":["Chung-Soo Ahn","Rajib Rana","Sunil Sivadas","Carlos Busso","Jagath C. Rajapakse"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.14844v2","updated":"2025-12-23T12:08:33Z","published":"2025-09-18T11:10:24Z","title":"Non-Intrusive Parametrized-Background Data-Weak Reconstruction of Cardiac Displacement Fields from Sparse MRI-like Observations","summary":"Personalized cardiac diagnostics require accurate reconstruction of myocardial displacement fields from sparse clinical imaging data, yet current methods often demand intrusive access to computational models. In this work, we apply the non-intrusive Parametrized-Background Data-Weak (PBDW) approach to three-dimensional (3D) cardiac displacement field reconstruction from limited Magnetic Resonance Image (MRI)-like observations. Our implementation requires only solution snapshots -- no governing equations, assembly routines, or solver access -- enabling immediate deployment across commercial and research codes using different constitutive models. Additionally, we introduce two enhancements: an H-size minibatch worst-case Orthogonal Matching Pursuit (wOMP) algorithm that improves Sensor Selection (SS) computational efficiency while maintaining reconstruction accuracy, and memory optimization techniques exploiting block matrix structures in vectorial problems. We demonstrate the effectiveness of the method through validation on a 3D left ventricular model with simulated scar tissue. Starting with noise-free reconstruction, we systematically incorporate Gaussian noise and spatial sparsity mimicking realistic MRI acquisition protocols. Results show exceptional accuracy in noise-free conditions (relative L2 error of order O(1e-5)), robust performance with 10% noise (relative L2 error of order O(1e-2)), and effective reconstruction from sparse measurements (relative L2 error of order O(1e-2)). The online reconstruction achieves four-order-of-magnitude computational speed-up compared to full Finite Element (FE) simulations, with reconstruction times under one tenth of second for sparse scenarios, demonstrating significant potential for integration into clinical cardiac modeling workflows.","authors":["Francesco C. Mantegazza","Federica Caforio","Christoph Augustin","Matthias A. F. Gsell","Gundolf Haase","Elias Karabelas"],"pdf_url":"","comment":"42 pages, 12 figures, 6 tables"},{"id":"http://arxiv.org/abs/2512.20291v1","updated":"2025-12-23T12:00:10Z","published":"2025-12-23T12:00:10Z","title":"Mixture-of-Experts with Gradient Conflict-Driven Subspace Topology Pruning for Emergent Modularity","summary":"Mixture-of-Experts (MoE) architectures achieve parameter efficiency through conditional computation, yet contemporary designs suffer from two fundamental limitations: structural parameter isolation that causes catastrophic forgetting, and instruction-overfitting that degrades performance in instruction-free scenarios. We propose CDSP-MoE (Conflict-Driven Subspace Pruning MoE), a framework that addresses these issues through a paradigm shift from isolated expert containers to dynamic expert instantiation within a shared physical subspace. Grounded in the Universal Weight Subspace Hypothesis, CDSP-MoE maintains a super-complete parameter backbone where logical experts are carved out via learnable topology masks. Unlike prior work that uses gradient conflict for token reassignment or optimization surgery, we leverage it as a structural supervisory signal: a Lagged Gradient Game penalizes interfering connections in the shared manifold, enabling the topology to spontaneously prune conflicting pathways and evolve interpretable modular structures. Experimental results demonstrate that CDSP-MoE achieves robust content-driven routing without human-defined task labels, maintaining semantic specialization even under strict blind inference protocols where explicit instructions are absent. Code is available at: https://github.com/konodiodaaaaa1/Conflict-Driven-Subspace-Pruning-Mixture-of-Experts","authors":["Yuxing Gan","Ziyu Lei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.11662v2","updated":"2025-12-23T11:29:24Z","published":"2025-07-15T18:50:29Z","title":"Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification","summary":"Verifiers--functions assigning rewards to agent behavior--have been key for AI progress in domains like math and code. However, extending gains to domains without clear-cut success criteria (e.g., computer use) remains a challenge: while humans can recognize desired outcomes, translating this intuition into scalable rules is nontrivial. Multimodal Large Language Models (MLLMs) emerge as a promising solution, given their world knowledge, human-preference alignment, and reasoning skills. We evaluate MLLMs as verifiers across web navigation, computer use, and robotic manipulation, and identify a critical limitation: a strong tendency to over-validate agent behavior, a phenomenon we term agreement bias. This bias is pervasive across models, resilient to test-time scaling, and poses risks to existing methods relying on MLLM evaluations. We discuss methods to evaluate and improve MLLM verifiers and introduce Self-Grounded Verification (SGV), a lightweight method that harnesses MLLMs' own sampling mechanisms by modulating (un)conditional generation to better leverage their knowledge, alignment, and reasoning. SGV operates in two steps: first, the MLLM is elicited to generate broad priors about desired behavior, independent of the data under evaluation. Then, conditioned on self-generated priors, it reasons over and evaluates a candidate trajectory. SGV yields more human-aligned evaluations with gains of up to 25pp in failure detection, 14pp in accuracy, and benefits extending to downstream applications. In self-refinement and online supervision, SGV boosts task completion of a GUI specialist in OSWorld, a diffusion policy in robomimic, and a ReAct agent in VisualWebArena--setting a new state of the art, surpassing the previous best by 20pp. We release an updated version of VisualWebArena featuring more human-aligned evaluators, high-fidelity environment parallelism, and speedups of over 10x.","authors":["Moises Andrade","Joonhyuk Cha","Brandon Ho","Vriksha Srihari","Karmesh Yadav","Zsolt Kira"],"pdf_url":"","comment":"Our code, models, and data are publicly available at https://mshalimay.github.io/agreement-bias-sgv/"},{"id":"http://arxiv.org/abs/2512.20272v1","updated":"2025-12-23T11:25:22Z","published":"2025-12-23T11:25:22Z","title":"HGAN-SDEs: Learning Neural Stochastic Differential Equations with Hermite-Guided Adversarial Training","summary":"Neural Stochastic Differential Equations (Neural SDEs) provide a principled framework for modeling continuous-time stochastic processes and have been widely adopted in fields ranging from physics to finance. Recent advances suggest that Generative Adversarial Networks (GANs) offer a promising solution to learning the complex path distributions induced by SDEs. However, a critical bottleneck lies in designing a discriminator that faithfully captures temporal dependencies while remaining computationally efficient. Prior works have explored Neural Controlled Differential Equations (CDEs) as discriminators due to their ability to model continuous-time dynamics, but such architectures suffer from high computational costs and exacerbate the instability of adversarial training. To address these limitations, we introduce HGAN-SDEs, a novel GAN-based framework that leverages Neural Hermite functions to construct a structured and efficient discriminator. Hermite functions provide an expressive yet lightweight basis for approximating path-level dynamics, enabling both reduced runtime complexity and improved training stability. We establish the universal approximation property of our framework for a broad class of SDE-driven distributions and theoretically characterize its convergence behavior. Extensive empirical evaluations on synthetic and real-world systems demonstrate that HGAN-SDEs achieve superior sample quality and learning efficiency compared to existing generative models for SDEs","authors":["Yuanjian Xu","Yuan Shuai","Jianing Hao","Guang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20270v1","updated":"2025-12-23T11:24:45Z","published":"2025-12-23T11:24:45Z","title":"Optimality-Informed Neural Networks for Solving Parametric Optimization Problems","summary":"Many engineering tasks require solving families of nonlinear constrained optimization problems, parametrized in setting-specific variables. This is computationally demanding, particularly, if solutions have to be computed across strongly varying parameter values, e.g., in real-time control or for model-based design. Thus, we propose to learn the mapping from parameters to the primal optimal solutions and to their corresponding duals using neural networks, giving a dense estimation in contrast to gridded approaches. Our approach, Optimality-informed Neural Networks (OptINNs), combines (i) a KKT-residual loss that penalizes violations of the first-order optimality conditions under standard constraint qualifications assumptions, and (ii) problem-specific output activations that enforce simple inequality constraints (e.g., box-type/positivity) by construction. This design reduces data requirements, allows the prediction of dual variables, and improves feasibility and closeness to optimality compared to penalty-only training. Taking quadratic penalties as a baseline, since this approach has been previously proposed for the considered problem class in literature, our method simplifies hyperparameter tuning and attains tighter adherence to optimality conditions. We evaluate OptINNs on different nonlinear optimization problems ranging from low to high dimensions. On small problems, OptINNs match a quadratic-penalty baseline in primal accuracy while additionally predicting dual variables with low error. On larger problems, OptINNs achieve lower constraint violations and lower primal error compared to neural networks based on the quadratic-penalty method. These results suggest that embedding feasibility and optimality into the network architecture and loss can make learning-based surrogates more accurate, feasible, and data-efficient for parametric optimization.","authors":["Matthias K. Hoffmann","Amine Othmane","Kathrin Flaßkamp"],"pdf_url":"","comment":"Under review, 24 pages, 10 figures"},{"id":"http://arxiv.org/abs/2512.20268v1","updated":"2025-12-23T11:22:26Z","published":"2025-12-23T11:22:26Z","title":"DeepONet-accelerated Bayesian inversion for moving boundary problems","summary":"This work demonstrates that neural operator learning provides a powerful and flexible framework for building fast, accurate emulators of moving boundary systems, enabling their integration into digital twin platforms. To this end, a Deep Operator Network (DeepONet) architecture is employed to construct an efficient surrogate model for moving boundary problems in single-phase Darcy flow through porous media. The surrogate enables rapid and accurate approximation of complex flow dynamics and is coupled with an Ensemble Kalman Inversion (EKI) algorithm to solve Bayesian inverse problems.\n  The proposed inversion framework is demonstrated by estimating the permeability and porosity of fibre reinforcements for composite materials manufactured via the Resin Transfer Moulding (RTM) process. Using both synthetic and experimental in-process data, the DeepONet surrogate accelerates inversion by several orders of magnitude compared with full-model EKI. This computational efficiency enables real-time, accurate, high-resolution estimation of local variations in permeability, porosity, and other parameters, thereby supporting effective monitoring and control of RTM processes, as well as other applications involving moving boundary flows. Unlike prior approaches for RTM inversion that learn mesh-dependent mappings, the proposed neural operator generalises across spatial and temporal domains, enabling evaluation at arbitrary sensor configurations without retraining, and represents a significant step toward practical industrial deployment of digital twins.","authors":["Marco A. Iglesias","Michael. E. Causon","Mikhail Y. Matveev","Andreas Endruweit","Michael . V. Tretyakov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20249v1","updated":"2025-12-23T11:04:34Z","published":"2025-12-23T11:04:34Z","title":"Unified Multimodal Brain Decoding via Cross-Subject Soft-ROI Fusion","summary":"Multimodal brain decoding aims to reconstruct semantic information that is consistent with visual stimuli from brain activity signals such as fMRI, and then generate readable natural language descriptions. However, multimodal brain decoding still faces key challenges in cross-subject generalization and interpretability. We propose a BrainROI model and achieve leading-level results in brain-captioning evaluation on the NSD dataset. Under the cross-subject setting, compared with recent state-of-the-art methods and representative baselines, metrics such as BLEU-4 and CIDEr show clear improvements. Firstly, to address the heterogeneity of functional brain topology across subjects, we design a new fMRI encoder. We use multi-atlas soft functional parcellations (soft-ROI) as a shared space. We extend the discrete ROI Concatenation strategy in MINDLLM to a voxel-wise gated fusion mechanism (Voxel-gate). We also ensure consistent ROI mapping through global label alignment, which enhances cross-subject transferability. Secondly, to overcome the limitations of manual and black-box prompting methods in stability and transparency, we introduce an interpretable prompt optimization process. In a small-sample closed loop, we use a locally deployed Qwen model to iteratively generate and select human-readable prompts. This process improves the stability of prompt design and preserves an auditable optimization trajectory. Finally, we impose parameterized decoding constraints during inference to further improve the stability and quality of the generated descriptions.","authors":["Xuanyu Hu"],"pdf_url":"","comment":"15 pages, 2 figures, 4 tables. Submitted to ICPR 2026"},{"id":"http://arxiv.org/abs/2512.20233v1","updated":"2025-12-23T10:46:48Z","published":"2025-12-23T10:46:48Z","title":"How I Met Your Bias: Investigating Bias Amplification in Diffusion Models","summary":"Diffusion-based generative models demonstrate state-of-the-art performance across various image synthesis tasks, yet their tendency to replicate and amplify dataset biases remains poorly understood. Although previous research has viewed bias amplification as an inherent characteristic of diffusion models, this work provides the first analysis of how sampling algorithms and their hyperparameters influence bias amplification. We empirically demonstrate that samplers for diffusion models -- commonly optimized for sample quality and speed -- have a significant and measurable effect on bias amplification. Through controlled studies with models trained on Biased MNIST, Multi-Color MNIST and BFFHQ, and with Stable Diffusion, we show that sampling hyperparameters can induce both bias reduction and amplification, even when the trained model is fixed. Source code is available at https://github.com/How-I-met-your-bias/how_i_met_your_bias.","authors":["Nathan Roos","Ekaterina Iakovleva","Ani Gjergji","Vito Paolo Pastore","Enzo Tartaglione"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20232v1","updated":"2025-12-23T10:46:18Z","published":"2025-12-23T10:46:18Z","title":"Adaptive Multi-task Learning for Probabilistic Load Forecasting","summary":"Simultaneous load forecasting across multiple entities (e.g., regions, buildings) is crucial for the efficient, reliable, and cost-effective operation of power systems. Accurate load forecasting is a challenging problem due to the inherent uncertainties in load demand, dynamic changes in consumption patterns, and correlations among entities. Multi-task learning has emerged as a powerful machine learning approach that enables the simultaneous learning across multiple related problems. However, its application to load forecasting remains underexplored and is limited to offline learning-based methods, which cannot capture changes in consumption patterns. This paper presents an adaptive multi-task learning method for probabilistic load forecasting. The proposed method can dynamically adapt to changes in consumption patterns and correlations among entities. In addition, the techniques presented provide reliable probabilistic predictions for loads of multiples entities and assess load uncertainties. Specifically, the method is based on vectorvalued hidden Markov models and uses a recursive process to update the model parameters and provide predictions with the most recent parameters. The performance of the proposed method is evaluated using datasets that contain the load demand of multiple entities and exhibit diverse and dynamic consumption patterns. The experimental results show that the presented techniques outperform existing methods both in terms of forecasting performance and uncertainty assessment.","authors":["Onintze Zaballa","Verónica Álvarez","Santiago Mazuelas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.01498v2","updated":"2025-12-23T10:29:27Z","published":"2025-12-01T10:19:30Z","title":"No Trust Issues Here: A Technical Report on the Winning Solutions for the Rayan AI Contest","summary":"This report presents solutions to three machine learning challenges developed as part of the Rayan AI Contest: compositional image retrieval, zero-shot anomaly detection, and backdoored model detection. In compositional image retrieval, we developed a system that processes visual and textual inputs to retrieve relevant images, achieving 95.38% accuracy and ranking first with a clear margin over the second team. For zero-shot anomaly detection, we designed a model that identifies and localizes anomalies in images without prior exposure to abnormal examples, securing second place with a 73.14% score. In the backdoored model detection task, we proposed a method to detect hidden backdoor triggers in neural networks, reaching an accuracy of 78%, which placed our approach in second place. These results demonstrate the effectiveness of our methods in addressing key challenges related to retrieval, anomaly detection, and model security, with implications for real-world applications in industries such as healthcare, manufacturing, and cybersecurity. Code for all solutions is available online (https://github.com/safinal/rayan-ai-contest-solutions).","authors":["Ali Nafisi","Sina Asghari","Mohammad Saeed Arvenaghi","Hossein Shakibania"],"pdf_url":"","comment":"Code available at https://github.com/safinal/rayan-ai-contest-solutions"},{"id":"http://arxiv.org/abs/2512.20220v1","updated":"2025-12-23T10:20:11Z","published":"2025-12-23T10:20:11Z","title":"Generalisation in Multitask Fitted Q-Iteration and Offline Q-learning","summary":"We study offline multitask reinforcement learning in settings where multiple tasks share a low-rank representation of their action-value functions. In this regime, a learner is provided with fixed datasets collected from several related tasks, without access to further online interaction, and seeks to exploit shared structure to improve statistical efficiency and generalization. We analyze a multitask variant of fitted Q-iteration that jointly learns a shared representation and task-specific value functions via Bellman error minimization on offline data. Under standard realizability and coverage assumptions commonly used in offline reinforcement learning, we establish finite-sample generalization guarantees for the learned value functions. Our analysis explicitly characterizes how pooling data across tasks improves estimation accuracy, yielding a $1/\\sqrt{nT}$ dependence on the total number of samples across tasks, while retaining the usual dependence on the horizon and concentrability coefficients arising from distribution shift. In addition, we consider a downstream offline setting in which a new task shares the same underlying representation as the upstream tasks. We study how reusing the representation learned during the multitask phase affects value estimation for this new task, and show that it can reduce the effective complexity of downstream learning relative to learning from scratch. Together, our results clarify the role of shared representations in multitask offline Q-learning and provide theoretical insight into when and how multitask structure can improve generalization in model-free, value-based reinforcement learning.","authors":["Kausthubh Manda","Raghuram Bharadwaj Diddigi"],"pdf_url":"","comment":"18 pages (9 pages + Appendix and references), this is version 1"},{"id":"http://arxiv.org/abs/2410.06820v4","updated":"2025-12-23T10:16:53Z","published":"2024-10-09T12:28:32Z","title":"Learning a Neural Solver for Parametric PDE to Enhance Physics-Informed Methods","summary":"Physics-informed deep learning often faces optimization challenges due to the complexity of solving partial differential equations (PDEs), which involve exploring large solution spaces, require numerous iterations, and can lead to unstable training. These challenges arise particularly from the ill-conditioning of the optimization problem caused by the differential terms in the loss function. To address these issues, we propose learning a solver, i.e., solving PDEs using a physics-informed iterative algorithm trained on data. Our method learns to condition a gradient descent algorithm that automatically adapts to each PDE instance, significantly accelerating and stabilizing the optimization process and enabling faster convergence of physics-aware models. Furthermore, while traditional physics-informed methods solve for a single PDE instance, our approach extends to parametric PDEs. Specifically, we integrate the physical loss gradient with PDE parameters, allowing our method to solve over a distribution of PDE parameters, including coefficients, initial conditions, and boundary conditions. We demonstrate the effectiveness of our approach through empirical experiments on multiple datasets, comparing both training and test-time optimization performance. The code is available at https://github.com/2ailesB/neural-parametric-solver.","authors":["Lise Le Boudec","Emmanuel de Bezenac","Louis Serrano","Ramon Daniel Regueiro-Espino","Yuan Yin","Patrick Gallinari"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20218v1","updated":"2025-12-23T10:16:43Z","published":"2025-12-23T10:16:43Z","title":"Cost-TrustFL: Cost-Aware Hierarchical Federated Learning with Lightweight Reputation Evaluation across Multi-Cloud","summary":"Federated learning across multi-cloud environments faces critical challenges, including non-IID data distributions, malicious participant detection, and substantial cross-cloud communication costs (egress fees). Existing Byzantine-robust methods focus primarily on model accuracy while overlooking the economic implications of data transfer across cloud providers. This paper presents Cost-TrustFL, a hierarchical federated learning framework that jointly optimizes model performance and communication costs while providing robust defense against poisoning attacks. We propose a gradient-based approximate Shapley value computation method that reduces the complexity from exponential to linear, enabling lightweight reputation evaluation. Our cost-aware aggregation strategy prioritizes intra-cloud communication to minimize expensive cross-cloud data transfers. Experiments on CIFAR-10 and FEMNIST datasets demonstrate that Cost-TrustFL achieves 86.7% accuracy under 30% malicious clients while reducing communication costs by 32% compared to baseline methods. The framework maintains stable performance across varying non-IID degrees and attack intensities, making it practical for real-world multi-cloud deployments.","authors":["Jixiao Yang","Jinyu Chen","Zixiao Huang","Chengda Xu","Chi Zhang","Sijia Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.23593v3","updated":"2025-12-23T09:55:01Z","published":"2025-05-29T16:04:39Z","title":"Position: Federated Foundation Language Model Post-Training Should Focus on Open-Source Models","summary":"Post-training of foundation language models has emerged as a promising research domain in federated learning (FL) with the goal to enable privacy-preserving model improvements and adaptations to user's downstream tasks. Recent advances in this area adopt centralized post-training approaches that build upon black-box foundation language models where there is no access to model weights and architecture details. Although the use of black-box models has been successful in centralized post-training, their blind replication in FL raises several concerns. Our position is that using black-box models in FL contradicts the core principles of federation such as data privacy and autonomy. In this position paper, we critically analyze the usage of black-box models in federated post-training, and provide a detailed account of various aspects of openness and their implications for FL.","authors":["Nikita Agrawal","Simon Mertel","Ruben Mayer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.03289v2","updated":"2025-12-23T09:36:38Z","published":"2025-09-29T12:07:09Z","title":"Why mask diffusion does not work","summary":"The main advantages of diffusion language models over autoregressive (AR) models lie in their ability to support parallel generation and bidirectional attention, enabling a more controllable generation process. In recent years, open-source mask diffusion language models have emerged, most of which are based on a variant known as absorbing diffusion. However, this paper demonstrates why mask diffusion faces inherent difficulties in achieving parallel generation and bidirectional attention. We also propose the most effective training and inference strategies for mask diffusion.","authors":["Haocheng Sun","Cynthia Xin Wen","Edward Hong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.16066v3","updated":"2025-12-23T09:35:05Z","published":"2025-10-17T03:56:11Z","title":"Cash Flow Underwriting with Bank Transaction Data: Advancing MSME Financial Inclusion in Malaysia","summary":"Despite accounting for 96.1% of all businesses in Malaysia, access to financing remains one of the most persistent challenges faced by Micro, Small, and Medium Enterprises (MSMEs). Newly established businesses are often excluded from formal credit markets as traditional underwriting approaches rely heavily on credit bureau data. This study investigates the potential of bank statement data as an alternative data source for credit assessment to promote financial inclusion in emerging markets. First, we propose a cash flow-based underwriting pipeline where we utilise bank statement data for end-to-end data extraction and machine learning credit scoring. Second, we introduce a novel dataset of 611 loan applicants from a Malaysian lending institution. Third, we develop and evaluate credit scoring models based on application information and bank transaction-derived features. Empirical results show that the use of such data boosts the performance of all models on our dataset, which can improve credit scoring for new-to-lending MSMEs. Finally, we will release the anonymised bank transaction dataset to facilitate further research on MSME financial inclusion within Malaysia's emerging economy.","authors":["Chun Chet Ng","Wei Zeng Low","Jia Yu Lim","Yin Yin Boon"],"pdf_url":"","comment":"Accepted for oral presentation at the AI for Financial Inclusion, Risk Modeling and Resilience in Emerging Markets (FinRem) Workshop at ACM ICAIF 2025, Singapore. Accepted for poster presentation at the Agentic AI in Financial Services Workshop at AAAI 2026, Singapore"},{"id":"http://arxiv.org/abs/2508.06244v2","updated":"2025-12-23T09:18:27Z","published":"2025-08-08T11:56:13Z","title":"Membership Inference Attack with Partial Features","summary":"Machine learning models are vulnerable to membership inference attack, which can be used to determine whether a given sample appears in the training data. Most existing methods assume the attacker has full access to the features of the target sample. This assumption, however, does not hold in many real-world scenarios where only partial features are available, thereby limiting the applicability of these methods. In this work, we introduce Partial Feature Membership Inference (PFMI), a scenario where the adversary observes only partial features of each sample and aims to infer whether this observed subset was present in the training set. To address this problem, we propose MRAD (Memory-guided Reconstruction and Anomaly Detection), a two-stage attack framework that works in both white-box and black-box settings. In the first stage, MRAD leverages the latent memory of the target model to reconstruct the unknown features of the sample. We observe that when the known features are absent from the training set, the reconstructed sample deviates significantly from the true data distribution. Consequently, in the second stage, we use anomaly detection algorithms to measure the deviation between the reconstructed sample and the training data distribution, thereby determining whether the known features belong to a member of the training set. Empirical results demonstrate that MRAD is effective across various datasets, and maintains compatibility with off-the-shelf anomaly detection techniques. For example, on STL-10, our attack exceeds an AUC of around 0.75 even with 60% of the missing features.","authors":["Xurun Wang","Guangrui Liu","Xinjie Li","Haoyu He","Lin Yao","Zhongyun Hua","Weizhe Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20177v1","updated":"2025-12-23T09:16:44Z","published":"2025-12-23T09:16:44Z","title":"NeuralCrop: Combining physics and machine learning for improved crop yield predictions","summary":"Global gridded crop models (GGCMs) simulate daily crop growth by explicitly representing key biophysical processes and project end-of-season yield time series. They are a primary tool to quantify the impacts of climate change on agricultural productivity and assess associated risks for food security. Despite decades of development, state-of-the-art GGCMs still have substantial uncertainties in simulating complex biophysical processes due to limited process understanding. Recently, machine learning approaches trained on observational data have shown great potential in crop yield predictions. However, these models have not demonstrated improved performance over classical GGCMs and are not suitable for simulating crop yields under changing climate conditions due to problems in generalizing outside their training distributions. Here we introduce NeuralCrop, a hybrid GGCM that combines the strengths of an advanced process-based GGCM, resolving important processes explicitly, with data-driven machine learning components. The model is first trained to emulate a competitive GGCM before it is fine-tuned on observational data. We show that NeuralCrop outperforms state-of-the-art GGCMs across site-level and large-scale cropping regions. Across moisture conditions, NeuralCrop reproduces the interannual yield anomalies in European wheat regions and the US Corn Belt more accurately during the period from 2000 to 2019 with particularly strong improvements under drought extremes. When generalizing to conditions unseen during training, NeuralCrop continues to make robust projections, while pure machine learning models exhibit substantial performance degradation. Our results show that our hybrid crop modelling approach offers overall improved crop modeling and more reliable yield projections under climate change and intensifying extreme weather conditions.","authors":["Yunan Lin","Sebastian Bathiany","Maha Badri","Maximilian Gelbrecht","Philipp Hess","Brian Groenke","Jens Heinke","Christoph Müller","Niklas Boers"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19576v2","updated":"2025-12-23T09:09:53Z","published":"2025-12-22T17:00:25Z","title":"LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller","summary":"Attitude control is essential for many satellite missions. Classical controllers, however, are time-consuming to design and sensitive to model uncertainties and variations in operational boundary conditions. Deep Reinforcement Learning (DRL) offers a promising alternative by learning adaptive control strategies through autonomous interaction with a simulation environment. Overcoming the Sim2Real gap, which involves deploying an agent trained in simulation onto the real physical satellite, remains a significant challenge. In this work, we present the first successful in-orbit demonstration of an AI-based attitude controller for inertial pointing maneuvers. The controller was trained entirely in simulation and deployed to the InnoCube 3U nanosatellite, which was developed by the Julius-Maximilians-Universität Würzburg in cooperation with the Technische Universität Berlin, and launched in January 2025. We present the AI agent design, the methodology of the training procedure, the discrepancies between the simulation and the observed behavior of the real satellite, and a comparison of the AI-based attitude controller with the classical PD controller of InnoCube. Steady-state metrics confirm the robust performance of the AI-based controller during repeated in-orbit maneuvers.","authors":["Kirill Djebko","Tom Baumann","Erik Dilger","Frank Puppe","Sergio Montenegro"],"pdf_url":"","comment":"55 pages, 27 figures, 29 tables. The maneuver telemetry datasets generated and analyzed during this work are available in the GitHub repository under https://github.com/kdjebko/lelar-in-orbit-data"},{"id":"http://arxiv.org/abs/2512.20169v1","updated":"2025-12-23T08:56:49Z","published":"2025-12-23T08:56:49Z","title":"Learning to Reason in LLMs by Expectation Maximization","summary":"Large language models (LLMs) solve reasoning problems by first generating a rationale and then answering. We formalize reasoning as a latent variable model and derive an expectation-maximization (EM) objective for learning to reason. This view connects EM and modern reward-based optimization, and shows that the main challenge lies in designing a sampling distribution that generates rationales that justify correct answers. We instantiate and compare several sampling schemes: rejection sampling with a budget, self-taught reasoner (STaR), and prompt posterior sampling (PPS), which only keeps the rationalization stage of STaR. Our experiments on the ARC, MMLU, and OpenBookQA datasets with the Llama and Qwen models show that the sampling scheme can significantly affect the accuracy of learned reasoning models. Despite its simplicity, we observe that PPS outperforms the other sampling schemes.","authors":["Junghyun Lee","Branislav Kveton","Sunav Choudhary","Subhojyoti Mukherjee","Anup Rao","Ryan A. Rossi","Alexa Siu"],"pdf_url":"","comment":"12 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2512.20168v1","updated":"2025-12-23T08:53:36Z","published":"2025-12-23T08:53:36Z","title":"Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography","summary":"By integrating language understanding with perceptual modalities such as images, multimodal large language models (MLLMs) constitute a critical substrate for modern AI systems, particularly intelligent agents operating in open and interactive environments. However, their increasing accessibility also raises heightened risks of misuse, such as generating harmful or unsafe content. To mitigate these risks, alignment techniques are commonly applied to align model behavior with human values. Despite these efforts, recent studies have shown that jailbreak attacks can circumvent alignment and elicit unsafe outputs. Currently, most existing jailbreak methods are tailored for open-source models and exhibit limited effectiveness against commercial MLLM-integrated systems, which often employ additional filters. These filters can detect and prevent malicious input and output content, significantly reducing jailbreak threats. In this paper, we reveal that the success of these safety filters heavily relies on a critical assumption that malicious content must be explicitly visible in either the input or the output. This assumption, while often valid for traditional LLM-integrated systems, breaks down in MLLM-integrated systems, where attackers can leverage multiple modalities to conceal adversarial intent, leading to a false sense of security in existing MLLM-integrated systems. To challenge this assumption, we propose Odysseus, a novel jailbreak paradigm that introduces dual steganography to covertly embed malicious queries and responses into benign-looking images. Extensive experiments on benchmark datasets demonstrate that our Odysseus successfully jailbreaks several pioneering and realistic MLLM-integrated systems, achieving up to 99% attack success rate. It exposes a fundamental blind spot in existing defenses, and calls for rethinking cross-modal security in MLLM-integrated systems.","authors":["Songze Li","Jiameng Cheng","Yiming Li","Xiaojun Jia","Dacheng Tao"],"pdf_url":"","comment":"This paper is accepted by Network and Distributed System Security Symposium (NDSS) 2026"},{"id":"http://arxiv.org/abs/2510.23649v3","updated":"2025-12-23T08:47:31Z","published":"2025-10-25T11:43:27Z","title":"Efficient Low Rank Attention for Long-Context Inference in Large Language Models","summary":"As the length of input text increases, the key-value (KV) cache in LLMs imposes prohibitive GPU memory costs and limits long-context inference on resource constrained devices. Existing approaches, such as KV quantization and pruning, reduce memory usage but suffer from numerical precision loss or suboptimal retention of key-value pairs. In this work, Low Rank Query and Key attention (LRQK) is introduced, a two-stage framework that jointly decomposes full-precision query and key matrices into compact rank-\\(r\\) factors during the prefill stage, and then employs these low-dimensional projections to compute proxy attention scores in \\(\\mathcal{O}(lr)\\) time at each decode step. By selecting only the top-\\(k\\) tokens and a small fixed set of recent tokens, LRQK employs a mixed GPU-CPU cache with a hit-and-miss mechanism where only missing full-precision KV pairs are transferred, thereby preserving exact attention outputs while reducing CPU-GPU data movement. Extensive experiments on the RULER and LongBench benchmarks with LLaMA-3-8B and Qwen2.5-7B demonstrate that LRQK matches or surpasses leading sparse-attention methods in long context settings, while delivering significant memory savings with minimal accuracy loss. Our code is available at https://github.com/tenghuilee/LRQK.","authors":["Tenghui Li","Guoxu Zhou","Xuyang Zhao","Yuning Qiu","Qibin Zhao"],"pdf_url":"","comment":"https://neurips.cc/virtual/2025/loc/san-diego/poster/118451"},{"id":"http://arxiv.org/abs/2508.20295v2","updated":"2025-12-23T08:30:32Z","published":"2025-08-27T22:03:19Z","title":"FedReFT: Federated Representation Fine-Tuning with All-But-Me Aggregation","summary":"Parameter-efficient fine-tuning (PEFT) adapts large pre-trained models by updating only a small subset of parameters. Recently, Representation Fine-Tuning (ReFT) has emerged as an effective alternative. ReFT shifts the fine-tuning paradigm from updating model weights to directly manipulating hidden representations that capture rich semantic information, and outperforms state-of-the-art PEFTs in standalone settings. However, its application in Federated Learning (FL) remains challenging due to heterogeneity in clients' data distributions, model capacities, and computational resources. To address these challenges, we introduce Federated Representation Fine-Tuning (FedReFT), a novel approach to fine-tune clients' hidden representations. FedReFT applies sparse intervention layers to steer hidden representations directly, offering a lightweight and semantically rich fine-tuning alternative ideal for edge devices. However, representation-level updates are especially vulnerable to aggregation mismatch under different task heterogeneity, where naive averaging can corrupt semantic alignment. To mitigate this issue, we propose All-But-Me (ABM) aggregation, where each client receives the aggregated updates of others and partially incorporates them, enabling stable and personalized learning by balancing local focus with global knowledge. We further design an adaptive update strategy inspired by Test-Time Computing (TTC) to balance local and global contributions under heterogeneous conditions. FedReFT achieves state-of-the-art performance on commonsense reasoning, arithmetic reasoning, and GLUE benchmarks, while delivering 1-49 times higher parameter efficiency compared to leading LoRA-based methods.","authors":["Fatema Siddika","Md Anwar Hossen","J. Pablo Muñoz","Tanya Roosta","Anuj Sharma","Ali Jannesari"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.01457v4","updated":"2025-12-23T08:18:03Z","published":"2025-12-01T09:44:31Z","title":"Zero-Overhead Introspection for Adaptive Test-Time Compute","summary":"Large language models excel at reasoning but lack key aspects of introspection, including anticipating their own success and the computation required to achieve it. Humans use real-time introspection to decide how much effort to invest, when to make multiple attempts, when to stop, and when to signal success or failure. Without this, LLMs struggle to make intelligent meta-cognition decisions. Test-time scaling methods like Best-of-N drive up cost and latency by using a fixed budget of samples regardless of the marginal benefit of each one at any point in generation, and the absence of confidence signals can mislead people, prevent appropriate escalation to better tools, and undermine trustworthiness. Learned verifiers or reward models can provide confidence estimates, but do not enable adaptive inference and add substantial cost by requiring extra models or forward passes. We present ZIP-RC, which equips models with zero-overhead introspective predictions of reward and cost. At every token, ZIP-RC reuses reserved or unused logits in the same forward pass as next-token prediction to output a joint distribution over final reward and remaining length -- no extra models, architecture change, or inference overhead. This full joint distribution is used to compute a sampling utility which is the linear combination of the expected maximum reward, total compute, and latency of set of samples if generated to completion. During inference, we maximize this utility with meta-actions that determine which prefix of tokens to continue or initiate sampling from. On mixed-difficulty mathematical benchmarks, ZIP-RC improves accuracy by up to 12% over majority voting at equal or lower average cost, and traces smooth Pareto frontiers between quality, compute, and latency. By providing real-time reward-cost introspection, ZIP-RC enables adaptive, efficient reasoning.","authors":["Rohin Manvi","Joey Hong","Tim Seyde","Maxime Labonne","Mathias Lechner","Sergey Levine"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20145v1","updated":"2025-12-23T08:15:34Z","published":"2025-12-23T08:15:34Z","title":"Retrieval-augmented Prompt Learning for Pre-trained Foundation Models","summary":"The pre-trained foundation models (PFMs) have become essential for facilitating large-scale multimodal learning. Researchers have effectively employed the ``pre-train, prompt, and predict'' paradigm through prompt learning to induce improved few-shot performance. However, prompt learning approaches for PFMs still follow a parametric learning paradigm. As such, the stability of generalization in memorization and rote learning can be compromised. More specifically, conventional prompt learning might face difficulties in fully utilizing atypical instances and avoiding overfitting to shallow patterns with limited data during the process of fully-supervised training. To overcome these constraints, we present our approach, named RetroPrompt, which aims to achieve a balance between memorization and generalization by decoupling knowledge from mere memorization. Unlike traditional prompting methods, RetroPrompt leverages a publicly accessible knowledge base generated from the training data and incorporates a retrieval mechanism throughout the input, training, and inference stages. This enables the model to actively retrieve relevant contextual information from the corpus, thereby enhancing the available cues. We conduct comprehensive experiments on a variety of datasets across natural language processing and computer vision tasks to demonstrate the superior performance of our proposed approach, RetroPrompt, in both zero-shot and few-shot scenarios. Through detailed analysis of memorization patterns, we observe that RetroPrompt effectively reduces the reliance on rote memorization, leading to enhanced generalization.","authors":["Xiang Chen","Yixin Ou","Quan Feng","Lei Li","Piji Li","Haibo Ye","Sheng-Jun Huang","Shuofei Qiao","Shumin Deng","Huajun Chen","Ningyu Zhang"],"pdf_url":"","comment":"IEEE/ACM Transactions on Audio, Speech and Language Processing"},{"id":"http://arxiv.org/abs/2509.10825v3","updated":"2025-12-23T08:14:20Z","published":"2025-09-13T14:44:45Z","title":"ORACLE: Explaining Feature Interactions in Neural Networks with ANOVA","summary":"We introduce ORACLE, a framework for explaining neural networks on tabular data and scientific factorial designs. ORACLE summarizes a trained network's prediction surface with main effects and pairwise interactions by treating the network as a black-box response, discretizing the inputs onto a grid, and fitting an orthogonal factorial (ANOVA-style) surrogate -- the $L^2$ orthogonal projection of the model response onto a finite-dimensional factorial subspace. A simple centering and $μ$-rebalancing step then expresses this surrogate as main- and interaction-effect tables that remain faithful to the original model in the $L^2$ sense. The resulting grid-based interaction maps are easy to visualize, comparable across backbones, and directly aligned with classical design-of-experiments practice. On synthetic factorial benchmarks and low- to medium-dimensional tabular regression tasks, ORACLE more accurately recovers ground-truth interaction structure and hotspots than Monte Carlo SHAP-family interaction methods, as measured by ranking, localization, and cross-backbone stability. In latent image and text settings, ORACLE clarifies its scope: grid-based factorial surrogates are most effective when features admit an interpretable factorial structure, making ORACLE particularly well-suited to scientific and engineering workflows that require stable, DoE-style interaction summaries.","authors":["Dongseok Kim","Hyoungsun Choi","Mohamed Jismy Aashik Rasool","Gisung Oh"],"pdf_url":"","comment":"v3: Minor wording edits for clarity; no technical changes"},{"id":"http://arxiv.org/abs/2512.18190v2","updated":"2025-12-23T08:10:47Z","published":"2025-12-20T03:27:11Z","title":"External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning","summary":"This paper proposes the External Hippocampus framework, which models language model reasoning from a cognitive dynamics perspective as the flow of information energy in semantic space. Unlike traditional weight-space optimization methods, this framework constructs topological cognitive maps through dimensionality reduction projection, enabling precise navigation and intervention of energy flow at test time while avoiding substantial computational requirements and demonstrating predictable intervention patterns. The method effectively addresses the cognitive deadlock problem in multi-step reasoning for small models. Experiments on models <=7B parameters show: map-guided methods achieve 81.20% accuracy on 500 challenging problems (relative baseline +16.80%), reduce reasoning time by >= 15x, with key findings revealing that reasoning stagnation manifests as \"Cognitive Vortex\" and low-entropy potential wells, while temperature perturbations effectively restart energy flow. The framework requires no additional training, possesses autonomous growth capability, and provides an efficient and controllable topological-aware solution for small model reasoning.","authors":["Jian Yan"],"pdf_url":"","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2509.23129v2","updated":"2025-12-23T07:56:48Z","published":"2025-09-27T05:24:51Z","title":"C$^2$GSPG: Confidence-calibrated Group Sequence Policy Gradient towards Self-aware Reasoning","summary":"Reinforcement Learning (RL) methods, exemplified by Group Relative Policy Optimization (GRPO) and its variants, play a central role in developing reasoning models. However, these methods often suffer from a critical overconfidence issue, which prevents them from achieving self-aware reasoning models. In this study, we propose a simple yet effective confidence-calibration group sequence policy gradient method, called C$^2$GSPG, which simultaneously enhances reasoning performance while suppressing overconfidence. In principle, we propose a Group Sequence Policy Gradient (GSPG) framework for learning reasoning models, which eliminates the token-level bias commonly appearing in GRPO and its variants. In this framework, we define the model confidence for each reasoning problem using the normalized sequence-level probability, and then apply a cross-entropy regularizer to calibrate the model confidence to the sequence's reward. We demonstrate that the confidence calibration regularizer and GSPG are collaborative for binary rewards, as their objectives always share the same gradient direction. For non-binary rewards, we apply nonlinear reward normalization and adaptive regularizer clipping, mitigating the potential conflict between the two objectives. Applying C$^2$GSPG to post-train large language models in logical and mathematical reasoning tasks, we show its superiority over state-of-the-art methods in both reasoning accuracy and confidence calibration. The code of C$^2$GSPG is available at https://github.com/HaotianLiu123/CCGSPG.","authors":["Haotian Liu","Shuo Wang","Hongteng Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20115v1","updated":"2025-12-23T07:19:19Z","published":"2025-12-23T07:19:19Z","title":"Sample-Efficient Policy Constraint Offline Deep Reinforcement Learning based on Sample Filtering","summary":"Offline reinforcement learning (RL) aims to learn a policy that maximizes the expected return using a given static dataset of transitions. However, offline RL faces the distribution shift problem. The policy constraint offline RL method is proposed to solve the distribution shift problem. During the policy constraint offline RL training, it is important to ensure the difference between the learned policy and behavior policy within a given threshold. Thus, the learned policy heavily relies on the quality of the behavior policy. However, a problem exists in existing policy constraint methods: if the dataset contains many low-reward transitions, the learned will be contained with a suboptimal reference policy, leading to slow learning speed, low sample efficiency, and inferior performances. This paper shows that the sampling method in policy constraint offline RL that uses all the transitions in the dataset can be improved. A simple but efficient sample filtering method is proposed to improve the sample efficiency and the final performance. First, we evaluate the score of the transitions by average reward and average discounted reward of episodes in the dataset and extract the transition samples of high scores. Second, the high-score transition samples are used to train the offline RL algorithms. We verify the proposed method in a series of offline RL algorithms and benchmark tasks. Experimental results show that the proposed method outperforms baselines.","authors":["Yuanhao Chen","Qi Liu","Pengbin Chen","Zhongjian Qiao","Yanjie Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20111v1","updated":"2025-12-23T07:11:26Z","published":"2025-12-23T07:11:26Z","title":"ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language","summary":"As the length of sequential decision-making tasks increases, it becomes computationally impractical to keep full interaction histories in context. We introduce a general framework for LLM agents to maintain concise contexts through multi-step interaction: Acting through Belief Bottlenecks Expressed in Language (ABBEL), and methods to further improve ABBEL agents with RL post-training. ABBEL replaces long multi-step interaction history by a belief state, i.e., a natural language summary of what has been discovered about task-relevant unknowns. Under ABBEL, at each step the agent first updates a prior belief with the most recent observation from the environment to form a posterior belief, then uses only the posterior to select an action. We systematically evaluate frontier models under ABBEL across six diverse multi-step environments, finding that ABBEL supports generating interpretable beliefs while maintaining near-constant memory use over interaction steps. However, bottleneck approaches are generally prone to error propagation, which we observe causing inferior performance when compared to the full context setting due to errors in belief updating. Therefore, we train LLMs to generate and act on beliefs within the ABBEL framework via reinforcement learning (RL). We experiment with belief grading, to reward higher quality beliefs, as well as belief length penalties to reward more compressed beliefs. Our experiments demonstrate the ability of RL to improve ABBEL's performance beyond the full context setting, while using less memory than contemporaneous approaches.","authors":["Aly Lidayan","Jakob Bjorner","Satvik Golechha","Kartik Goyal","Alane Suhr"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2401.15894v3","updated":"2025-12-23T06:57:26Z","published":"2024-01-29T05:26:17Z","title":"Enhancing Topological Dependencies in Spatio-Temporal Graphs with Cycle Message Passing Blocks","summary":"Graph Neural Networks (GNNs) and Transformer-based models have been increasingly adopted to learn the complex vector representations of spatio-temporal graphs, capturing intricate spatio-temporal dependencies crucial for applications such as traffic datasets. Although many existing methods utilize multi-head attention mechanisms and message-passing neural networks (MPNNs) to capture both spatial and temporal relations, these approaches encode temporal and spatial relations independently, and reflect the graph's topological characteristics in a limited manner. In this work, we introduce the Cycle to Mixer (Cy2Mixer), a novel spatio-temporal GNN based on topological non-trivial invariants of spatio-temporal graphs with gated multi-layer perceptrons (gMLP). The Cy2Mixer is composed of three blocks based on MLPs: A temporal block for capturing temporal properties, a message-passing block for encapsulating spatial information, and a cycle message-passing block for enriching topological information through cyclic subgraphs. We bolster the effectiveness of Cy2Mixer with mathematical evidence emphasizing that our cycle message-passing block is capable of offering differentiated information to the deep learning model compared to the message-passing block. Furthermore, empirical evaluations substantiate the efficacy of the Cy2Mixer, demonstrating state-of-the-art performances across various spatio-temporal benchmark datasets. The source code is available at https://github.com/leemingo/cy2mixer.","authors":["Minho Lee","Yun Young Choi","Sun Woo Park","Seunghwan Lee","Joohwan Ko","Jaeyoung Hong"],"pdf_url":"","comment":"Proceedings of the Third Learning on Graphs Conference (LoG 2024)"},{"id":"http://arxiv.org/abs/2512.20096v1","updated":"2025-12-23T06:49:33Z","published":"2025-12-23T06:49:33Z","title":"Information-directed sampling for bandits: a primer","summary":"The Multi-Armed Bandit problem provides a fundamental framework for analyzing the tension between exploration and exploitation in sequential learning. This paper explores Information Directed Sampling (IDS) policies, a class of heuristics that balance immediate regret against information gain. We focus on the tractable environment of two-state Bernoulli bandits as a minimal model to rigorously compare heuristic strategies against the optimal policy. We extend the IDS framework to the discounted infinite-horizon setting by introducing a modified information measure and a tuning parameter to modulate the decision-making behavior. We examine two specific problem classes: symmetric bandits and the scenario involving one fair coin. In the symmetric case we show that IDS achieves bounded cumulative regret, whereas in the one-fair-coin scenario the IDS policy yields a regret that scales logarithmically with the horizon, in agreement with classical asymptotic lower bounds. This work serves as a pedagogical synthesis, aiming to bridge concepts from reinforcement learning and information theory for an audience of statistical physicists.","authors":["Annika Hirling","Giorgio Nicoletti","Antonio Celani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20094v1","updated":"2025-12-23T06:44:31Z","published":"2025-12-23T06:44:31Z","title":"Jensen-Shannon Divergence Message-Passing for Rich-Text Graph Representation Learning","summary":"In this paper, we investigate how the widely existing contextual and structural divergence may influence the representation learning in rich-text graphs. To this end, we propose Jensen-Shannon Divergence Message-Passing (JSDMP), a new learning paradigm for rich-text graph representation learning. Besides considering similarity regarding structure and text, JSDMP further captures their corresponding dissimilarity by Jensen-Shannon divergence. Similarity and dissimilarity are then jointly used to compute new message weights among text nodes, thus enabling representations to learn with contextual and structural information from truly correlated text nodes. With JSDMP, we propose two novel graph neural networks, namely Divergent message-passing graph convolutional network (DMPGCN) and Divergent message-passing Page-Rank graph neural networks (DMPPRG), for learning representations in rich-text graphs. DMPGCN and DMPPRG have been extensively texted on well-established rich-text datasets and compared with several state-of-the-art baselines. The experimental results show that DMPGCN and DMPPRG can outperform other baselines, demonstrating the effectiveness of the proposed Jensen-Shannon Divergence Message-Passing paradigm","authors":["Zuo Wang","Ye Yuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.09586v3","updated":"2025-12-23T06:43:03Z","published":"2025-11-12T12:56:25Z","title":"Environment Scaling for Interactive Agentic Experience Collection: A Survey","summary":"LLM-based agents can autonomously accomplish complex tasks across various domains. However, to further cultivate capabilities such as adaptive behavior and long-term decision-making, training on static datasets built from human-level knowledge is insufficient. These datasets are costly to construct and lack both dynamism and realism. A growing consensus is that agents should instead interact directly with environments and learn from experience through reinforcement learning. We formalize this iterative process as the Generation-Execution-Feedback (GEF) loop, where environments generate tasks to challenge agents, return observations in response to agents' actions during task execution, and provide evaluative feedback on rollouts for subsequent learning. Under this paradigm, environments function as indispensable producers of experiential data, highlighting the need to scale them toward greater complexity, realism, and interactivity. In this survey, we systematically review representative methods for environment scaling from a pioneering environment-centric perspective and organize them along the stages of the GEF loop, namely task generation, task execution, and feedback. We further analyze implementation frameworks, challenges, and applications, consolidating fragmented advances and outlining future research directions for agent intelligence.","authors":["Yuchen Huang","Sijia Li","Minghao Liu","Wei Liu","Shijue Huang","Zhiyuan Fan","Hou Pong Chan","Yi R. Fung"],"pdf_url":"","comment":"22 pages, 5 figures, SEA Workshop @ NeurIPS 2025"},{"id":"http://arxiv.org/abs/2108.03336v2","updated":"2025-12-23T06:30:15Z","published":"2021-08-06T23:52:30Z","title":"Estimating Graph Dimension with Cross-validated Eigenvalues","summary":"In applied multivariate statistics, estimating the number of latent dimensions or the number of clusters, $k$, is a fundamental and recurring problem. We study a sequence of statistics called \"cross-validated eigenvalues.\" Under a large class of random graph models, including both Poisson and Bernoulli edges, without parametric assumptions, we provide a $p$-value for each cross-validated eigenvalue. It tests the null hypothesis that the sample eigenvector is orthogonal to (i.e., uncorrelated with) the true latent dimensions. This approach naturally adapts to problems where some dimensions are not statistically detectable. In scenarios where all $k$ dimensions can be estimated, we show that our procedure consistently estimates $k$. In simulations and data example, the proposed estimator compares favorably to alternative approaches in both computational and statistical performance.","authors":["Fan Chen","Sebastien Roch","Karl Rohe","Shuqi Yu"],"pdf_url":"","comment":"63 pages, 12 figures"},{"id":"http://arxiv.org/abs/2512.20086v1","updated":"2025-12-23T06:28:12Z","published":"2025-12-23T06:28:12Z","title":"Spatio-Temporal Graphs Beyond Grids: Benchmark for Maritime Anomaly Detection","summary":"Spatio-temporal graph neural networks (ST-GNNs) have achieved notable success in structured domains such as road traffic and public transportation, where spatial entities can be naturally represented as fixed nodes. In contrast, many real-world systems including maritime traffic lack such fixed anchors, making the construction of spatio-temporal graphs a fundamental challenge. Anomaly detection in these non-grid environments is particularly difficult due to the absence of canonical reference points, the sparsity and irregularity of trajectories, and the fact that anomalies may manifest at multiple granularities. In this work, we introduce a novel benchmark dataset for anomaly detection in the maritime domain, extending the Open Maritime Traffic Analysis Dataset (OMTAD) into a benchmark tailored for graph-based anomaly detection. Our dataset enables systematic evaluation across three different granularities: node-level, edge-level, and graph-level anomalies. We plan to employ two specialized LLM-based agents: \\emph{Trajectory Synthesizer} and \\emph{Anomaly Injector} to construct richer interaction contexts and generate semantically meaningful anomalies. We expect this benchmark to promote reproducibility and to foster methodological advances in anomaly detection for non-grid spatio-temporal systems.","authors":["Jeehong Kim","Youngseok Hwang","Minchan Kim","Sungho Bae","Hyunwoo Park"],"pdf_url":"","comment":"Accepted at NeurIPS 2025 Workshop in AI for Science: The Reach and Limits of AI for Scientific Discovery"},{"id":"http://arxiv.org/abs/2512.20084v1","updated":"2025-12-23T06:27:30Z","published":"2025-12-23T06:27:30Z","title":"QE-Catalytic: A Graph-Language Multimodal Base Model for Relaxed-Energy Prediction in Catalytic Adsorption","summary":"Adsorption energy is a key descriptor of catalytic reactivity. It is fundamentally defined as the difference between the relaxed total energy of the adsorbate-surface system and that of an appropriate reference state; therefore, the accuracy of relaxed-energy prediction directly determines the reliability of machine-learning-driven catalyst screening. E(3)-equivariant graph neural networks (GNNs) can natively operate on three-dimensional atomic coordinates under periodic boundary conditions and have demonstrated strong performance on such tasks. In contrast, language-model-based approaches, while enabling human-readable textual descriptions and reducing reliance on explicit graph -- thereby broadening applicability -- remain insufficient in both adsorption-configuration energy prediction accuracy and in distinguishing ``the same system with different configurations,'' even with graph-assisted pretraining in the style of GAP-CATBERTa.\n  To this end, we propose QE-Catalytic, a multimodal framework that deeply couples a large language model (\\textbf{Q}wen) with an E(3)-equivariant graph Transformer (\\textbf{E}quiformer-V2), enabling unified support for adsorption-configuration property prediction and inverse design on complex catalytic surfaces. During prediction, QE-Catalytic jointly leverages three-dimensional structures and structured configuration text, and injects ``3D geometric information'' into the language channel via graph-text alignment, allowing it to function as a high-performance text-based predictor when precise coordinates are unavailable, while also autoregressively generating CIF files for target-energy-driven structure design and information completion. On OC20, QE-Catalytic reduces the MAE of relaxed adsorption energy from 0.713~eV to 0.486~eV, and consistently outperforms baseline models such as CatBERTa and GAP-CATBERTa across multiple evaluation protocols.","authors":["Yanjie Li","Jian Xu","Xueqing Chen","Lina Yu","Shiming Xiang","Weijun Li","Cheng-lin Liu"],"pdf_url":"","comment":"25 pages"},{"id":"http://arxiv.org/abs/2402.04536v3","updated":"2025-12-23T06:22:42Z","published":"2024-02-07T02:50:56Z","title":"Tactile-based Object Retrieval From Granular Media","summary":"We introduce GEOTACT, the first robotic system capable of grasping and retrieving objects of potentially unknown shapes buried in a granular environment. While important in many applications, ranging from mining and exploration to search and rescue, this type of interaction with granular media is difficult due to the uncertainty stemming from visual occlusion and noisy contact signals. To address these challenges, we use a learning method relying exclusively on touch feedback, trained end-to-end with simulated sensor noise. We show that our problem formulation leads to the natural emergence of learned pushing behaviors that the manipulator uses to reduce uncertainty and funnel the object to a stable grasp despite spurious and noisy tactile readings. We introduce a training curriculum that bootstraps learning in simulated granular environments, enabling zero-shot transfer to real hardware. Despite being trained only on seven objects with primitive shapes, our method is shown to successfully retrieve 35 different objects, including rigid, deformable, and articulated objects with complex shapes. Videos and additional information can be found at https://jxu.ai/geotact.","authors":["Jingxi Xu","Yinsen Jia","Dongxiao Yang","Patrick Meng","Xinyue Zhu","Zihan Guo","Shuran Song","Matei Ciocarlie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.08528v2","updated":"2025-12-23T06:18:57Z","published":"2025-05-13T13:01:38Z","title":"GradMix: Gradient-based Selective Mixup for Robust Data Augmentation in Class-Incremental Learning","summary":"In the context of continual learning, acquiring new knowledge while maintaining previous knowledge presents a significant challenge. Existing methods often use experience replay techniques that store a small portion of previous task data for training. In experience replay approaches, data augmentation has emerged as a promising strategy to further improve the model performance by mixing limited previous task data with sufficient current task data. However, we theoretically and empirically analyze that training with mixed samples from random sample pairs may harm the knowledge of previous tasks and cause greater catastrophic forgetting. We then propose GradMix, a robust data augmentation method specifically designed for mitigating catastrophic forgetting in class-incremental learning. GradMix performs gradient-based selective mixup using a class-based criterion that mixes only samples from helpful class pairs and not from detrimental class pairs for reducing catastrophic forgetting. Our experiments on various real datasets show that GradMix outperforms data augmentation baselines in accuracy by minimizing the forgetting of previous knowledge.","authors":["Minsu Kim","Seong-Hyeon Hwang","Steven Euijong Whang"],"pdf_url":"","comment":"Accepted to KDD 2026"},{"id":"http://arxiv.org/abs/2510.04944v2","updated":"2025-12-23T05:51:37Z","published":"2025-10-06T15:46:50Z","title":"On Structured State-Space Duality","summary":"Structured State-Space Duality (SSD) [Dao & Gu, ICML 2024] is an equivalence between a simple Structured State-Space Model (SSM) and a masked attention mechanism. In particular, a state-space model with a scalar-times-identity state matrix is equivalent to a masked self-attention with a $1$-semiseparable causal mask. Consequently, the same sequence transformation (model) has two algorithmic realizations: as a linear-time $O(T)$ recurrence or as a quadratic-time $O(T^2)$ attention. In this note, we formalize and generalize this duality: (i) we extend SSD from the scalar-identity case to general diagonal SSMs (diagonal state matrices); (ii) we show that these diagonal SSMs match the scalar case's training complexity lower bounds while supporting richer dynamics; (iii) we establish a necessary and sufficient condition under which an SSM is equivalent to $1$-semiseparable masked attention; and (iv) we show that such duality fails to extend to standard softmax attention due to rank explosion. Together, these results tighten bridge between recurrent SSMs and Transformers, and widen the design space for expressive yet efficient sequence models.","authors":["Jerry Yao-Chieh Hu","Xiwen Zhang","Ali ElSheikh","Weimin Wu","Han Liu"],"pdf_url":"","comment":"v2 fixed typos and added numerical results (Appendix B)"},{"id":"http://arxiv.org/abs/2408.02152v3","updated":"2025-12-23T05:50:45Z","published":"2024-08-04T22:00:34Z","title":"Generative Retrieval with Few-shot Indexing","summary":"Existing generative retrieval (GR) methods rely on training-based indexing, which fine-tunes a model to memorise associations between queries and the document identifiers (docids) of relevant documents. Training-based indexing suffers from high training costs, under-utilisation of pre-trained knowledge in large language models (LLMs), and limited adaptability to dynamic document corpora. To address the issues, we propose a few-shot indexing-based GR framework (Few-Shot GR). It has a few-shot indexing process without any training, where we prompt an LLM to generate docids for all documents in a corpus, ultimately creating a docid bank for the entire corpus. During retrieval, we feed a query to the same LLM and constrain it to generate a docid within the docid bank created during indexing, and then map the generated docid back to its corresponding document. Moreover, we devise few-shot indexing with one-to-many mapping to further enhance Few-Shot GR. Experiments show that Few-Shot GR achieves superior performance to state-of-the-art GR methods requiring heavy training.","authors":["Arian Askari","Chuan Meng","Mohammad Aliannejadi","Zhaochun Ren","Evangelos Kanoulas","Suzan Verberne"],"pdf_url":"","comment":"Accepted for publication at the 48th European Conference on Information Retrieval (ECIR 2026)"},{"id":"http://arxiv.org/abs/2412.17231v3","updated":"2025-12-23T05:48:23Z","published":"2024-12-23T02:58:12Z","title":"FedMeld: A Model-dispersal Federated Learning Framework for Space-ground Integrated Networks","summary":"To bridge the digital divide, space-ground integrated networks (SGINs) are expected to deliver artificial intelligence (AI) services to every corner of the world. One key mission of SGINs is to support federated learning (FL) at a global scale. However, existing space-ground integrated FL frameworks involve ground stations or costly inter-satellite links, entailing excessive training latency and communication costs. To overcome these limitations, we propose an infrastructure-free federated learning framework based on a model dispersal (FedMeld) strategy, which exploits periodic movement patterns and store-carry-forward capabilities of satellites to enable parameter mixing across large-scale geographical regions. We theoretically show that FedMeld leads to global model convergence and quantify the effects of round interval and mixing ratio between adjacent areas on its learning performance. Based on the theoretical results, we formulate a joint optimization problem to design the staleness control and mixing ratio (SC-MR) for minimizing the training loss. By decomposing the problem into sequential SC and MR subproblems without compromising the optimality, we derive the round interval solution in a closed form and the mixing ratio in a semi-closed form to achieve the optimal latency-accuracy tradeoff. Experiments using various datasets demonstrate that FedMeld achieves superior model accuracy while significantly reducing communication costs as compared with traditional FL schemes for SGINs.","authors":["Qian Chen","Xianhao Chen","Kaibin Huang"],"pdf_url":"","comment":"17 pages, 10 figures. This paper has been accepted by IEEE Transactions on Mobile Computing"},{"id":"http://arxiv.org/abs/2512.20063v1","updated":"2025-12-23T05:31:56Z","published":"2025-12-23T05:31:56Z","title":"PairFlow: Closed-Form Source-Target Coupling for Few-Step Generation in Discrete Flow Models","summary":"We introduce $\\texttt{PairFlow}$, a lightweight preprocessing step for training Discrete Flow Models (DFMs) to achieve few-step sampling without requiring a pretrained teacher. DFMs have recently emerged as a new class of generative models for discrete data, offering strong performance. However, they suffer from slow sampling due to their iterative nature. Existing acceleration methods largely depend on finetuning, which introduces substantial additional training overhead. $\\texttt{PairFlow}$ addresses this issue with a lightweight preprocessing step. Inspired by ReFlow and its extension to DFMs, we train DFMs from coupled samples of source and target distributions, without requiring any pretrained teacher. At the core of our approach is a closed-form inversion for DFMs, which allows efficient construction of paired source-target samples. Despite its extremely low cost, taking only up to 1.7% of the compute needed for full model training, $\\texttt{PairFlow}$ matches or even surpasses the performance of two-stage training involving finetuning. Furthermore, models trained with our framework provide stronger base models for subsequent distillation, yielding further acceleration after finetuning. Experiments on molecular data as well as binary and RGB images demonstrate the broad applicability and effectiveness of our approach.","authors":["Mingue Park","Jisung Hwang","Seungwoo Yoo","Kyeongmin Yeo","Minhyuk Sung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20059v1","updated":"2025-12-23T05:23:06Z","published":"2025-12-23T05:23:06Z","title":"DS-HGCN: A Dual-Stream Hypergraph Convolutional Network for Predicting Student Engagement via Social Contagion","summary":"Student engagement is a critical factor influencing academic success and learning outcomes. Accurately predicting student engagement is essential for optimizing teaching strategies and providing personalized interventions. However, most approaches focus on single-dimensional feature analysis and assessing engagement based on individual student factors. In this work, we propose a dual-stream multi-feature fusion model based on hypergraph convolutional networks (DS-HGCN), incorporating social contagion of student engagement. DS-HGCN enables accurate prediction of student engagement states by modeling multi-dimensional features and their propagation mechanisms between students. The framework constructs a hypergraph structure to encode engagement contagion among students and captures the emotional and behavioral differences and commonalities by multi-frequency signals. Furthermore, we introduce a hypergraph attention mechanism to dynamically weigh the influence of each student, accounting for individual differences in the propagation process. Extensive experiments on public benchmark datasets demonstrate that our proposed method achieves superior performance and significantly outperforms existing state-of-the-art approaches.","authors":["Ziyang Fan","Li Tao","Yi Wang","Jingwei Qu","Ying Wang","Fei Jiang"],"pdf_url":"","comment":"14pages,Accepted by MMM2026"},{"id":"http://arxiv.org/abs/2512.20058v1","updated":"2025-12-23T05:20:22Z","published":"2025-12-23T05:20:22Z","title":"Deep Eigenspace Network and Its Application to Parametric Non-selfadjoint Eigenvalue Problems","summary":"We consider operator learning for efficiently solving parametric non-selfadjoint eigenvalue problems. To overcome the spectral instability and mode switching inherent in non-selfadjoint operators, we introduce a hybrid framework that learns the stable invariant eigensubspace mapping rather than individual eigenfunctions. We proposed a Deep Eigenspace Network (DEN) architecture integrating Fourier Neural Operators, geometry-adaptive POD bases, and explicit banded cross-mode mixing mechanisms to capture complex spectral dependencies on unstructured meshes. We apply DEN to the parametric non-selfadjoint Steklov eigenvalue problem and provide theoretical proofs for the Lipschitz continuity of the eigensubspace with respect to the parameters. In addition, we derive error bounds for the reconstruction of the eigenspace. Numerical experiments validate DEN's high accuracy and zero-shot generalization capabilities across different discretizations.","authors":["H. Li","J. Sun","Z. Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.16189v3","updated":"2025-12-23T05:18:37Z","published":"2025-09-19T17:49:25Z","title":"Latent learning: episodic memory complements parametric learning by enabling flexible reuse of experiences","summary":"When do machine learning systems fail to generalize, and what mechanisms could improve their generalization? Here, we draw inspiration from cognitive science to argue that one weakness of parametric machine learning systems is their failure to exhibit latent learning -- learning information that is not relevant to the task at hand, but that might be useful in a future task. We show how this perspective links failures ranging from the reversal curse in language modeling to new findings on agent-based navigation. We then highlight how cognitive science points to episodic memory as a potential part of the solution to these issues. Correspondingly, we show that a system with an oracle retrieval mechanism can use learning experiences more flexibly to generalize better across many of these challenges. We also identify some of the essential components for effectively using retrieval, including the importance of within-example in-context learning for acquiring the ability to use information across retrieved examples. In summary, our results illustrate one possible contributor to the relative data inefficiency of current machine learning systems compared to natural intelligence, and help to understand how retrieval methods can complement parametric learning to improve generalization. We close by discussing some of the links between these findings and prior results in cognitive science and neuroscience, and the broader implications.","authors":["Andrew Kyle Lampinen","Martin Engelcke","Yuxuan Li","Arslan Chaudhry","James L. McClelland"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20053v1","updated":"2025-12-23T05:03:54Z","published":"2025-12-23T05:03:54Z","title":"An Optimal Policy for Learning Controllable Dynamics by Exploration","summary":"Controllable Markov chains describe the dynamics of sequential decision making tasks and are the central component in optimal control and reinforcement learning. In this work, we give the general form of an optimal policy for learning controllable dynamics in an unknown environment by exploring over a limited time horizon. This policy is simple to implement and efficient to compute, and allows an agent to ``learn by exploring\" as it maximizes its information gain in a greedy fashion by selecting controls from a constraint set that changes over time during exploration. We give a simple parameterization for the set of controls, and present an algorithm for finding an optimal policy. The reason for this policy is due to the existence of certain types of states that restrict control of the dynamics; such as transient states, absorbing states, and non-backtracking states. We show why the occurrence of these states makes a non-stationary policy essential for achieving optimal exploration. Six interesting examples of controllable dynamics are treated in detail. Policy optimality is demonstrated using counting arguments, comparing with suboptimal policies, and by making use of a sequential improvement property from dynamic programming.","authors":["Peter N. Loxley"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17052v2","updated":"2025-12-23T04:20:29Z","published":"2025-12-18T20:40:25Z","title":"Dynamic Tool Dependency Retrieval for Efficient Function Calling","summary":"Function calling agents powered by Large Language Models (LLMs) select external tools to automate complex tasks. On-device agents typically use a retrieval module to select relevant tools, improving performance and reducing context length. However, existing retrieval methods rely on static and limited inputs, failing to capture multi-step tool dependencies and evolving task context. This limitation often introduces irrelevant tools that mislead the agent, degrading efficiency and accuracy. We propose Dynamic Tool Dependency Retrieval (DTDR), a lightweight retrieval method that conditions on both the initial query and the evolving execution context. DTDR models tool dependencies from function calling demonstrations, enabling adaptive retrieval as plans unfold. We benchmark DTDR against state-of-the-art retrieval methods across multiple datasets and LLM backbones, evaluating retrieval precision, downstream task accuracy, and computational efficiency. Additionally, we explore strategies to integrate retrieved tools into prompts. Our results show that dynamic tool retrieval improves function calling success rates between $23\\%$ and $104\\%$ compared to state-of-the-art static retrievers.","authors":["Bhrij Patel","Davide Belli","Amir Jalalirad","Maximilian Arnold","Aleksandr Ermolov","Bence Major"],"pdf_url":"","comment":"18 pages, 5 figures, 6 tables"},{"id":"http://arxiv.org/abs/2512.20039v1","updated":"2025-12-23T04:14:56Z","published":"2025-12-23T04:14:56Z","title":"Optimal Anytime-Valid Tests for Composite Nulls","summary":"We consider the problem of designing optimal level-$α$ power-one tests for composite nulls. Given a parameter $α\\in (0,1)$ and a stream of $\\mathcal{X}$-valued observations $\\{X_n: n \\geq 1\\} \\overset{i.i.d.}{\\sim} P$, the goal is to design a level-$α$ power-one test $τ_α$ for the null $H_0: P \\in \\mathcal{P}_0 \\subset \\mathcal{P}(\\mathcal{X})$. Prior works have shown that any such $τ_α$ must satisfy $\\mathbb{E}_P[τ_α] \\geq \\tfrac{\\log(1/α)}{γ^*(P, \\mathcal{P}_0)}$, where $γ^*(P, \\mathcal{P}_0)$ is the so-called $\\mathrm{KL}_{\\inf}$ or minimum divergence of $P$ to the null class. In this paper, our objective is to develop and analyze constructive schemes that match this lower bound as $α\\downarrow 0$.\n  We first consider the finite-alphabet case~($|\\mathcal{X}| = m < \\infty$), and show that a test based on \\emph{universal} $e$-process~(formed by the ratio of a universal predictor and the running null MLE) is optimal in the above sense. The proof relies on a Donsker-Varadhan~(DV) based saddle-point representation of $\\mathrm{KL}_{\\inf}$, and an application of Sion's minimax theorem. This characterization motivates a general method for arbitrary $\\mathcal{X}$: construct an $e$-process based on the empirical solutions to the saddle-point representation over a sufficiently rich class of test functions. We give sufficient conditions for the optimality of this test for compact convex nulls, and verify them for Hölder smooth density models. We end the paper with a discussion on the computational aspects of implementing our proposed tests in some practical settings.","authors":["Shubhanshu Shekhar"],"pdf_url":"","comment":"24 pages, 1 figure"},{"id":"http://arxiv.org/abs/2504.11671v4","updated":"2025-12-23T04:02:12Z","published":"2025-04-16T00:02:28Z","title":"Computational Basis of LLM's Decision Making in Social Simulation","summary":"Large language models (LLMs) increasingly serve as human-like decision-making agents in social science and applied settings. These LLM-agents are typically assigned human-like characters and placed in real-life contexts. However, how these characters and contexts shape an LLM's behavior remains underexplored. This study proposes and tests methods for probing, quantifying, and modifying an LLM's internal representations in a Dictator Game, a classic behavioral experiment on fairness and prosocial behavior. We extract ``vectors of variable variations'' (e.g., ``male'' to ``female'') from the LLM's internal state. Manipulating these vectors during the model's inference can substantially alter how those variables relate to the model's decision-making. This approach offers a principled way to study and regulate how social concepts can be encoded and engineered within transformer-based models, with implications for alignment, debiasing, and designing AI agents for social simulations in both academic and commercial applications, strengthening sociological theory and measurement.","authors":["Ji Ma"],"pdf_url":"","comment":"Forthcoming: Sociological Methodology; USPTO patent pending"},{"id":"http://arxiv.org/abs/2512.20028v1","updated":"2025-12-23T03:44:49Z","published":"2025-12-23T03:44:49Z","title":"DecoKAN: Interpretable Decomposition for Forecasting Cryptocurrency Market Dynamics","summary":"Accurate and interpretable forecasting of multivariate time series is crucial for understanding the complex dynamics of cryptocurrency markets in digital asset systems. Advanced deep learning methodologies, particularly Transformer-based and MLP-based architectures, have achieved competitive predictive performance in cryptocurrency forecasting tasks. However, cryptocurrency data is inherently composed of long-term socio-economic trends and local high-frequency speculative oscillations. Existing deep learning-based 'black-box' models fail to effectively decouple these composite dynamics or provide the interpretability needed for trustworthy financial decision-making. To overcome these limitations, we propose DecoKAN, an interpretable forecasting framework that integrates multi-level Discrete Wavelet Transform (DWT) for decoupling and hierarchical signal decomposition with Kolmogorov-Arnold Network (KAN) mixers for transparent and interpretable nonlinear modeling. The DWT component decomposes complex cryptocurrency time series into distinct frequency components, enabling frequency-specific analysis, while KAN mixers provide intrinsically interpretable spline-based mappings within each decomposed subseries. Furthermore, interpretability is enhanced through a symbolic analysis pipeline involving sparsification, pruning, and symbolization, which produces concise analytical expressions offering symbolic representations of the learned patterns. Extensive experiments demonstrate that DecoKAN achieves the lowest average Mean Squared Error on all tested real-world cryptocurrency datasets (BTC, ETH, XMR), consistently outperforming a comprehensive suite of competitive state-of-the-art baselines. These results validate DecoKAN's potential to bridge the gap between predictive accuracy and model transparency, advancing trustworthy decision support within complex cryptocurrency markets.","authors":["Yuan Gao","Zhenguo Dong","Xuelong Wang","Zhiqiang Wang","Yong Zhang","Shaofan Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19025v2","updated":"2025-12-23T03:34:28Z","published":"2025-12-22T04:42:41Z","title":"The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation","summary":"Machine unlearning aims to remove specific data influences from trained models, a capability essential for adhering to copyright laws and ensuring AI safety. Current unlearning metrics typically measure success by monitoring the model's performance degradation on the specific unlearning dataset ($D_u$). We argue that for Large Language Models (LLMs), this evaluation paradigm is insufficient and potentially misleading. Many real-world uses of unlearning--motivated by copyright or safety--implicitly target not only verbatim content in $D_u$, but also behaviors influenced by the broader generalizations the model derived from it. We demonstrate that LLMs can pass standard unlearning evaluation and appear to have \"forgotten\" the target knowledge, while simultaneously retaining strong capabilities on content that is semantically adjacent to $D_u$. This phenomenon indicates that erasing exact sentences does not necessarily equate to removing the underlying knowledge. To address this gap, we propose Proximal Surrogate Generation (PSG), an automated stress-testing framework that generates a surrogate dataset, $\\tilde{D}_u$. This surrogate set is constructed to be semantically derived from $D_u$ yet sufficiently distinct in embedding space. By comparing unlearning metric scores between $D_u$ and $\\tilde{D}_u$, we can stress-test the reliability of the metric itself. Our extensive evaluation across three LLM families (Llama-3-8B, Qwen2.5-7B, and Zephyr-7B-$β$), three distinct datasets, and seven standard metrics reveals widespread inconsistencies. We find that current metrics frequently overestimate unlearning success, failing to detect retained knowledge exposed by our stress-test datasets.","authors":["Hengrui Jia","Taoran Li","Jonas Guan","Varun Chandrasekaran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20021v1","updated":"2025-12-23T03:31:35Z","published":"2025-12-23T03:31:35Z","title":"Gaussian Process Assisted Meta-learning for Image Classification and Object Detection Models","summary":"Collecting operationally realistic data to inform machine learning models can be costly. Before collecting new data, it is helpful to understand where a model is deficient. For example, object detectors trained on images of rare objects may not be good at identification in poorly represented conditions. We offer a way of informing subsequent data acquisition to maximize model performance by leveraging the toolkit of computer experiments and metadata describing the circumstances under which the training data was collected (e.g., season, time of day, location). We do this by evaluating the learner as the training data is varied according to its metadata. A Gaussian process (GP) surrogate fit to that response surface can inform new data acquisitions. This meta-learning approach offers improvements to learner performance as compared to data with randomly selected metadata, which we illustrate on both classic learning examples, and on a motivating application involving the collection of aerial images in search of airplanes.","authors":["Anna R. Flowers","Christopher T. Franck","Robert B. Gramacy","Justin A. Krometis"],"pdf_url":"","comment":"15 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.23066v3","updated":"2025-12-23T03:28:14Z","published":"2024-10-30T14:41:23Z","title":"Don't Pay Attention, PLANT It: Pretraining Attention via Learning-to-Rank","summary":"State-of-the-art Extreme Multi-Label Text Classification models rely on multi-label attention to focus on key tokens in input text, but learning good attention weights is challenging. We introduce PLANT - Pretrained and Leveraged Attention - a plug-and-play strategy for initializing attention. PLANT works by planting label-specific attention using a pretrained Learning-to-Rank model guided by mutual information gain. This architecture-agnostic approach integrates seamlessly with large language model backbones such as Mistral-7B, LLaMA3-8B, DeepSeek-V3, and Phi-3. PLANT outperforms state-of-the-art methods across tasks including ICD coding, legal topic classification, and content recommendation. Gains are especially pronounced in few-shot settings, with substantial improvements on rare labels. Ablation studies confirm that attention initialization is a key driver of these gains. For code and trained models, see https://github.com/debjyotiSRoy/xcube/tree/plant","authors":["Debjyoti Saha Roy","Byron C. Wallace","Javed A. Aslam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17902v2","updated":"2025-12-23T03:27:52Z","published":"2025-11-22T03:39:13Z","title":"Statistically-Guided Dual-Domain Meta-Learning with Adaptive Multi-Prototype Aggregation for Distributed Fiber Optic Sensing","summary":"Distributed Fiber Optic Sensing (DFOS) is promising for long-range perimeter security, yet practical deployment faces three key obstacles: severe cross-deployment domain shift, scarce or unavailable labels at new sites, and limited within-class coverage even in source deployments. We propose DUPLE, a prototype-based meta-learning framework tailored for cross-deployment DFOS recognition. The core idea is to jointly exploit complementary time- and frequency-domain cues and adapt class representations to sample-specific statistics: (i) a dual-domain learner constructs multi-prototype class representations to cover intra-class heterogeneity; (ii) a lightweight statistical guidance mechanism estimates the reliability of each domain from raw signal statistics; and (iii) a query-adaptive aggregation strategy selects and combines the most relevant prototypes for each query. Extensive experiments on two real-world cross-deployment benchmarks demonstrate consistent improvements over strong deep learning and meta-learning baselines, achieving more accurate and stable recognition under label-scarce target deployments.","authors":["Yifan He","Haodong Zhang","Qiuheng Song","Lin Lei","Zhenxuan Zeng","Haoyang He","Hongyan Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.15015v2","updated":"2025-12-23T03:19:42Z","published":"2025-05-21T01:35:56Z","title":"Multi-Scale Harmonic Encoding for Feature-Wise Graph Message Passing","summary":"Most Graph Neural Networks (GNNs) propagate messages by treating node embeddings as holistic feature vectors, implicitly assuming uniform relevance across feature dimensions. This limits their ability to selectively transmit informative components, especially when graph structures exhibit distinct frequency characteristics. We propose MSH-GNN (Multi-Scale Harmonic Graph Neural Network), a frequency-aware message passing framework that performs feature-wise adaptive propagation. Each node projects incoming messages onto node-conditioned feature subspaces derived from its own representation, enabling selective extraction of frequency-relevant components. Learnable multi-scale harmonic modulations further allow the model to capture both smooth and oscillatory structural patterns. A frequency-aware attention pooling mechanism is introduced for graph-level readout. We show that MSH-GNN admits an interpretation as a learnable Fourier-feature approximation of kernelized message functions and matches the expressive power of the 1-Weisfeiler-Lehman (1-WL) test. Extensive experiments on node- and graph-level benchmarks demonstrate consistent improvements over state-of-the-art methods, particularly in joint structure-frequency analysis tasks.","authors":["Longlong Li","Mengyang Zhao","Guanghui Wang","Cunquan Qu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20012v1","updated":"2025-12-23T03:10:09Z","published":"2025-12-23T03:10:09Z","title":"Reliable LLM-Based Edge-Cloud-Expert Cascades for Telecom Knowledge Systems","summary":"Large language models (LLMs) are emerging as key enablers of automation in domains such as telecommunications, assisting with tasks including troubleshooting, standards interpretation, and network optimization. However, their deployment in practice must balance inference cost, latency, and reliability. In this work, we study an edge-cloud-expert cascaded LLM-based knowledge system that supports decision-making through a question-and-answer pipeline. In it, an efficient edge model handles routine queries, a more capable cloud model addresses complex cases, and human experts are involved only when necessary. We define a misalignment-cost constrained optimization problem, aiming to minimize average processing cost, while guaranteeing alignment of automated answers with expert judgments. We propose a statistically rigorous threshold selection method based on multiple hypothesis testing (MHT) for a query processing mechanism based on knowledge and confidence tests. The approach provides finite-sample guarantees on misalignment risk. Experiments on the TeleQnA dataset -- a telecom-specific benchmark -- demonstrate that the proposed method achieves superior cost-efficiency compared to conventional cascaded baselines, while ensuring reliability at prescribed confidence levels.","authors":["Qiushuo Hou","Sangwoo Park","Matteo Zecchin","Yunlong Cai","Guanding Yu","Osvaldo Simeone","Tommaso Melodia"],"pdf_url":"","comment":"This paper has been submitted to a journal"},{"id":"http://arxiv.org/abs/2512.20007v1","updated":"2025-12-23T03:05:26Z","published":"2025-12-23T03:05:26Z","title":"Semiparametric KSD test: unifying score and distance-based approaches for goodness-of-fit testing","summary":"Goodness-of-fit (GoF) tests are fundamental for assessing model adequacy. Score-based tests are appealing because they require fitting the model only once under the null. However, extending them to powerful nonparametric alternatives is difficult due to the lack of suitable score functions. Through a class of exponentially tilted models, we show that the resulting score-based GoF tests are equivalent to the tests based on integral probability metrics (IPMs) indexed by a function class. When the class is rich, the test is universally consistent. This simple yet insightful perspective enables reinterpretation of classical distance-based testing procedures-including those based on Kolmogorov-Smirnov distance, Wasserstein-1 distance, and maximum mean discrepancy-as arising from score-based constructions. Building on this insight, we propose a new nonparametric score-based GoF test through a special class of IPM induced by kernelized Stein's function class, called semiparametric kernelized Stein discrepancy (SKSD) test. Compared with other nonparametric score-based tests, the SKSD test is computationally efficient and accommodates general nuisance-parameter estimators, supported by a generic parametric bootstrap procedure. The SKSD test is universally consistent and attains Pitman efficiency. Moreover, SKSD test provides simple GoF tests for models with intractable likelihoods but tractable scores with the help of Stein's identity and we use two popular models, kernel exponential family and conditional Gaussian models, to illustrate the power of our method. Our method achieves power comparable to task-specific normality tests such as Anderson-Darling and Lilliefors, despite being designed for general nonparametric alternatives.","authors":["Zhihan Huang","Ziang Niu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20006v1","updated":"2025-12-23T03:05:25Z","published":"2025-12-23T03:05:25Z","title":"Orthogonal Activation with Implicit Group-Aware Bias Learning for Class Imbalance","summary":"Class imbalance is a common challenge in machine learning and data mining, often leading to suboptimal performance in classifiers. While deep learning excels in feature extraction, its performance still deteriorates under imbalanced data. In this work, we propose a novel activation function, named OGAB, designed to alleviate class imbalance in deep learning classifiers. OGAB incorporates orthogonality and group-aware bias learning to enhance feature distinguishability in imbalanced scenarios without explicitly requiring label information. Our key insight is that activation functions can be used to introduce strong inductive biases that can address complex data challenges beyond traditional non-linearity. Our work demonstrates that orthogonal transformations can preserve information about minority classes by maintaining feature independence, thereby preventing the dominance of majority classes in the embedding space. Further, the proposed group-aware bias mechanism automatically identifies data clusters and adjusts embeddings to enhance class separability without the need for explicit supervision. Unlike existing approaches that address class imbalance through preprocessing data modifications or post-processing corrections, our proposed approach tackles class imbalance during the training phase at the embedding learning level, enabling direct integration with the learning process. We demonstrate the effectiveness of our solution on both real-world and synthetic imbalanced datasets, showing consistent performance improvements over both traditional and learnable activation functions.","authors":["Sukumar Kishanthan","Asela Hevapathige"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16334v3","updated":"2025-12-23T02:58:42Z","published":"2025-12-18T09:17:45Z","title":"Pretrained Battery Transformer (PBT): A battery life prediction foundation model","summary":"Early prediction of battery cycle life is essential for accelerating battery research, manufacturing, and deployment. Although machine learning methods have shown encouraging results, progress is hindered by data scarcity and heterogeneity arising from diverse aging conditions. In other fields, foundation models (FMs) trained on diverse datasets have achieved broad generalization through transfer learning, but no FMs have been reported for battery cycle life prediction yet. Here we present the Pretrained Battery Transformer (PBT), the first FM for battery life prediction, developed through domain-knowledge-encoded mixture-of-expert layers. Validated on the largest public battery life database, PBT learns transferable representations from 13 lithium-ion battery datasets, outperforming existing models by an average of 19.8%. With transfer learning, PBT achieves state-of-the-art performance across 15 diverse datasets encompassing various operating conditions, formation protocols, and chemistries. This work establishes a foundation model pathway for battery lifetime prediction, paving the way toward universal battery lifetime prediction systems.","authors":["Ruifeng Tan","Weixiang Hong","Jia Li","Jiaqiang Huang","Tong-Yi Zhang"],"pdf_url":"","comment":"5 figures in the main content"},{"id":"http://arxiv.org/abs/2512.20004v1","updated":"2025-12-23T02:57:33Z","published":"2025-12-23T02:57:33Z","title":"IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense","summary":"Since the Internet of Things (IoT) is widely adopted using Android applications, detecting malicious Android apps is essential. In recent years, Android graph-based deep learning research has proposed many approaches to extract relationships from applications as graphs to generate graph embeddings. First, we demonstrate the effectiveness of graph-based classification using a Graph Neural Network (GNN)-based classifier to generate API graph embeddings. The graph embeddings are combined with Permission and Intent features to train multiple machine learning and deep learning models for Android malware detection. The proposed classification approach achieves an accuracy of 98.33 percent on the CICMaldroid dataset and 98.68 percent on the Drebin dataset. However, graph-based deep learning models are vulnerable, as attackers can add fake relationships to evade detection by the classifier. Second, we propose a Generative Adversarial Network (GAN)-based attack algorithm named VGAE-MalGAN targeting graph-based GNN Android malware classifiers. The VGAE-MalGAN generator produces adversarial malware API graphs, while the VGAE-MalGAN substitute detector attempts to mimic the target detector. Experimental results show that VGAE-MalGAN can significantly reduce the detection rate of GNN-based malware classifiers. Although the model initially fails to detect adversarial malware, retraining with generated adversarial samples improves robustness and helps mitigate adversarial attacks.","authors":["Rahul Yumlembam","Biju Issac","Seibu Mary Jacob","Longzhi Yang"],"pdf_url":"","comment":"13 pages"},{"id":"http://arxiv.org/abs/2512.20003v1","updated":"2025-12-23T02:55:14Z","published":"2025-12-23T02:55:14Z","title":"Control Variate Score Matching for Diffusion Models","summary":"Diffusion models offer a robust framework for sampling from unnormalized probability densities, which requires accurately estimating the score of the noise-perturbed target distribution. While the standard Denoising Score Identity (DSI) relies on data samples, access to the target energy function enables an alternative formulation via the Target Score Identity (TSI). However, these estimators face a fundamental variance trade-off: DSI exhibits high variance in low-noise regimes, whereas TSI suffers from high variance at high noise levels. In this work, we reconcile these approaches by unifying both estimators within the principled framework of control variates. We introduce the Control Variate Score Identity (CVSI), deriving an optimal, time-dependent control coefficient that theoretically guarantees variance minimization across the entire noise spectrum. We demonstrate that CVSI serves as a robust, low-variance plug-in estimator that significantly enhances sample efficiency in both data-free sampler learning and inference-time diffusion sampling.","authors":["Khaled Kahouli","Romuald Elie","Klaus-Robert Müller","Quentin Berthet","Oliver T. Unke","Arnaud Doucet"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20002v1","updated":"2025-12-23T02:55:04Z","published":"2025-12-23T02:55:04Z","title":"LoFT-LLM: Low-Frequency Time-Series Forecasting with Large Language Models","summary":"Time-series forecasting in real-world applications such as finance and energy often faces challenges due to limited training data and complex, noisy temporal dynamics. Existing deep forecasting models typically supervise predictions using full-length temporal windows, which include substantial high-frequency noise and obscure long-term trends. Moreover, auxiliary variables containing rich domain-specific information are often underutilized, especially in few-shot settings. To address these challenges, we propose LoFT-LLM, a frequency-aware forecasting pipeline that integrates low-frequency learning with semantic calibration via a large language model (LLM). Firstly, a Patch Low-Frequency forecasting Module (PLFM) extracts stable low-frequency trends from localized spectral patches. Secondly, a residual learner then models high-frequency variations. Finally, a fine-tuned LLM refines the predictions by incorporating auxiliary context and domain knowledge through structured natural language prompts. Extensive experiments on financial and energy datasets demonstrate that LoFT-LLM significantly outperforms strong baselines under both full-data and few-shot regimes, delivering superior accuracy, robustness, and interpretability.","authors":["Jiacheng You","Jingcheng Yang","Yuhang Xie","Zhongxuan Wu","Xiucheng Li","Feng Li","Pengjie Wang","Jian Xu","Bo Zheng","Xinyang Chen"],"pdf_url":"","comment":"Accepted at KDD 2026. 9 pages"},{"id":"http://arxiv.org/abs/2412.06867v2","updated":"2025-12-23T02:53:15Z","published":"2024-12-09T09:37:54Z","title":"Lossless Model Compression via Joint Low-Rank Factorization Optimization","summary":"Low-rank factorization is a popular model compression technique that minimizes the error $δ$ between approximated and original weight matrices. Despite achieving performances close to the original models when $δ$ is optimized, a performance discrepancy remains due to the separate optimization processes for low-rank factorization and model performance, resulting in unavoidable losses. We address this issue by introducing a novel joint optimization strategy for lossless low-rank weight factorization, which, for the first time, enhances the model's performance beyond the original. Our approach begins with a theoretical analysis of the relationship between low-rank factorization and model optimization objectives, establishing a precise perturbation range for matrix factorization errors on model performance. This challenge is then reformulated as a numerical rank deficiency problem with inequality constraints and develop a joint objective that simultaneously addresses factorization error and model performance. Based on the above analysis, we propose two optimization algorithms: \\textbf{a lossless optimization algorithm} that maximizes model accuracy while ensuring compression, and \\textbf{a compact optimization algorithm} that minimizes model size while preserving performance. These algorithms do not require fine-tuning and can directly compress numerous deep models to achieve lossless results. Our methods demonstrate robust efficacy across various vision and language tasks. For example, the compressed model reduced by 70\\% on ResNext50 outperforms the original. Our code will be made public.","authors":["Boyang Zhang","Daning Cheng","Yunquan Zhang","Fangming Liu","Jiake Tian"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2502.15802v2","updated":"2025-12-23T02:46:06Z","published":"2025-02-19T06:12:43Z","title":"A General Error-Theoretical Analysis Framework for Constructing Compression Strategies","summary":"The exponential growth in parameter size and computational complexity of deep models poses significant challenges for efficient deployment. The core problem of existing compression methods is that different layers of the model have significant differences in their tolerance to compression levels. For instance, the first layer of a model can typically sustain a higher compression level compared to the last layer without compromising performance. Thus, the key challenge lies in how to allocate compression levels across layers in a way that minimizes performance loss while maximizing parameter reduction. To address this challenge, we propose a Compression Error Theory (CET) framework, designed to determine the optimal compression level for each layer. Taking quantization as an example, CET leverages differential expansion and algebraic geometry to reconstruct the quadratic form of quantization error as ellipsoids and hyperbolic paraboloids, and utilizes their geometric structures to define an error subspace. To identify the error subspace with minimal performance loss, by performing orthogonal decomposition of the geometric space, CET transforms the optimization process of the error subspace into a complementary problem. The final theoretical analysis shows that constructing the quantization subspace along the major axis results in minimal performance degradation. Through experimental verification of the theory, CET can greatly retain performance while compressing. Specifically, on the ResNet-34 model, CET achieves nearly 11$\\times$ parameter compression while even surpassing performance comparable to the original model.","authors":["Boyang Zhang","Daning Cheng","Yunquan Zhang","Meiqi Tu","Fangming Liu","Jiake Tian"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2507.09001v2","updated":"2025-12-23T02:45:24Z","published":"2025-07-11T20:08:07Z","title":"Surprisingly High Redundancy in Electronic Structure Data","summary":"Accurate prediction of electronic structure underpins advances in chemistry, materials science, and condensed matter physics. In recent years, Machine Learning (ML) has enabled the development of powerful surrogate models that can enable the prediction of the ground state electron density and related properties at a fraction of the computational cost of conventional first principles simulations. Such ML models typically rely on massive datasets generated through expensive Kohn-Sham Density Functional Theory calculations. A key reason for relying on such large datasets is the lack of prior knowledge about which portions of the data are essential, and which are redundant. This study reveals significant redundancies in electronic structure datasets across various material systems, including molecules, simple metals, and chemically complex alloys -- challenging the notion that extensive datasets are essential for accurate ML-based electronic structure predictions. We demonstrate that even random pruning can substantially reduce dataset size with minimal loss in predictive accuracy. Furthermore, a state-of-the-art coverage-based pruning strategy that selects data across all learning difficulties, retains chemical accuracy and model generalizability using up to 100-fold less data, while reducing training time by threefold or greater. By contrast, widely used importance-based pruning methods, which eliminate easy-to-learn data, can catastrophically fail at higher pruning factors due to significant reduction in data coverage. This heretofore unexplored high redundancy in electronic structure data holds the potential to identify a minimal, essential dataset representative of each material class.","authors":["Sazzad Hossain","Ponkrshnan Thiagarajan","Shashank Pathrudkar","Stephanie Taylor","Abhijeet S. Gangan","Amartya S. Banerjee","Susanta Ghosh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19995v1","updated":"2025-12-23T02:44:25Z","published":"2025-12-23T02:44:25Z","title":"Schoenfeld's Anatomy of Mathematical Reasoning by Language Models","summary":"Large language models increasingly expose reasoning traces, yet their underlying cognitive structure and steps remain difficult to identify and analyze beyond surface-level statistics. We adopt Schoenfeld's Episode Theory as an inductive, intermediate-scale lens and introduce ThinkARM (Anatomy of Reasoning in Models), a scalable framework that explicitly abstracts reasoning traces into functional reasoning steps such as Analysis, Explore, Implement, Verify, etc. When applied to mathematical problem solving by diverse models, this abstraction reveals reproducible thinking dynamics and structural differences between reasoning and non-reasoning models, which are not apparent from token-level views. We further present two diagnostic case studies showing that exploration functions as a critical branching step associated with correctness, and that efficiency-oriented methods selectively suppress evaluative feedback steps rather than uniformly shortening responses. Together, our results demonstrate that episode-level representations make reasoning steps explicit, enabling systematic analysis of how reasoning is structured, stabilized, and altered in modern language models.","authors":["Ming Li","Chenrui Fan","Yize Cheng","Soheil Feizi","Tianyi Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19991v1","updated":"2025-12-23T02:33:57Z","published":"2025-12-23T02:33:57Z","title":"Bloom Filter Encoding for Machine Learning","summary":"We present a method that uses the Bloom filter transform to preprocess data for machine learning. Each sample is encoded into a compact, privacy-preserving bit array. This reduces memory use and protects the original data while keeping enough structure for accurate classification. We test the method on six datasets: SMS Spam Collection, ECG200, Adult 50K, CDC Diabetes, MNIST, and Fashion MNIST. Four classifiers are used: Extreme Gradient Boosting, Deep Neural Networks, Convolutional Neural Networks, and Logistic Regression. Results show that models trained on Bloom filter encodings achieve accuracy similar to models trained on raw data or other transforms. At the same time, the method provides memory savings while enhancing privacy. These results suggest that the Bloom filter transform is an efficient preprocessing approach for diverse machine learning tasks.","authors":["John Cartmell","Mihaela Cardei","Ionut Cardei"],"pdf_url":"","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2512.19989v1","updated":"2025-12-23T02:30:50Z","published":"2025-12-23T02:30:50Z","title":"A Novel CNN Gradient Boosting Ensemble for Guava Disease Detection","summary":"As a significant agricultural country, Bangladesh utilizes its fertile land for guava cultivation and dedicated labor to boost its economic development. In a nation like Bangladesh, enhancing guava production and agricultural practices plays a crucial role in its economy. Anthracnose and fruit fly infection can lower the quality and productivity of guava, a crucial tropical fruit. Expert systems that detect diseases early can reduce losses and safeguard the harvest. Images of guava fruits classified into the Healthy, Fruit Flies, and Anthracnose classes are included in the Guava Fruit Disease Dataset 2024 (GFDD24), which comes from plantations in Rajshahi and Pabna, Bangladesh. This study aims to create models using CNN alongside traditional machine learning techniques that can effectively identify guava diseases in locally cultivated varieties in Bangladesh. In order to achieve the highest classification accuracy of approximately 99.99% for the guava dataset, we propose utilizing ensemble models that combine CNNML with Gradient Boosting Machine. In general, the CNN-ML cascade framework exhibits strong, high-accuracy guava disease detection that is appropriate for real-time agricultural monitoring systems.","authors":["Tamim Ahasan Rijon","Yeasin Arafath"],"pdf_url":"","comment":"Accepted at IEEE ICCIT 2025. This is the author accepted manuscript"},{"id":"http://arxiv.org/abs/2412.06865v2","updated":"2025-12-23T02:30:32Z","published":"2024-12-09T08:50:28Z","title":"FP=xINT:Representing Neural Networks via Low-Bit Series Basis Functions","summary":"Post-Training Quantization (PTQ) converts pre-trained Full-Precision (FP) models into quantized versions without training. While existing methods reduce size and computational costs, they also significantly degrade performance and quantization efficiency at extremely low settings due to quantization noise. We introduce a deep model series expansion framework to address this issue, enabling rapid and accurate approximation of unquantized models without calibration sets or fine-tuning. This is the first use of series expansion for neural network quantization. Specifically, our method expands the FP model into multiple low-bit basis models. To ensure accurate quantization, we develop low-bit basis model expansions at different granularities (tensor, layer, model), and theoretically confirm their convergence to the dense model, thus restoring FP model accuracy. Additionally, we design AbelianAdd/Mul operations between isomorphic models in the low-bit expansion, forming an Abelian group to ensure operation parallelism and commutativity. The experiments show that our algorithm achieves state-of-the-art performance in low-bit settings; for example, 4-bit quantization of ResNet-50 surpasses the original accuracy, reaching 77.03%. The code will be made public.","authors":["Boyang Zhang","Daning Cheng","Yunquan Zhang","Jiake Tian","Jing Li","Fangming Liu"],"pdf_url":"","comment":"AAAI2026"},{"id":"http://arxiv.org/abs/2512.01801v3","updated":"2025-12-23T02:23:42Z","published":"2025-12-01T15:33:59Z","title":"GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation","summary":"We present GR-RL, a robotic learning framework that turns a generalist vision-language-action (VLA) policy into a highly capable specialist for long-horizon dexterous manipulation. Assuming the optimality of human demonstrations is core to existing VLA policies. However, we claim that in highly dexterous and precise manipulation tasks, human demonstrations are noisy and suboptimal. GR-RL proposes a multi-stage training pipeline that filters, augments, and reinforces the demonstrations by reinforcement learning. First, GR-RL learns a vision-language-conditioned task progress, filters the demonstration trajectories, and only keeps the transitions that contribute positively to the progress. Specifically, we show that by directly applying offline RL with sparse reward, the resulting $Q$-values can be treated as a robust progress function. Next, we introduce morphological symmetry augmentation that greatly improves the generalization and performance of GR-RL. Lastly, to better align the VLA policy with its deployment behaviors for high-precision control, we perform online RL by learning a latent space noise predictor. With this pipeline, GR-RL is, to our knowledge, the first learning-based policy that can autonomously lace up a shoe by threading shoelaces through multiple eyelets with an 83.3% success rate, a task requiring long-horizon reasoning, millimeter-level precision, and compliant soft-body interaction. We hope GR-RL provides a step toward enabling generalist robot foundation models to specialize into reliable real-world experts.","authors":["Yunfei Li","Xiao Ma","Jiafeng Xu","Yu Cui","Zhongren Cui","Zhigang Han","Liqun Huang","Tao Kong","Yuxiao Liu","Hao Niu","Wanli Peng","Jingchao Qiao","Zeyu Ren","Haixin Shi","Zhi Su","Jiawen Tian","Yuyang Xiao","Shenyu Zhang","Liwei Zheng","Hang Li","Yonghui Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19986v1","updated":"2025-12-23T02:22:53Z","published":"2025-12-23T02:22:53Z","title":"Covariance-Aware Simplex Projection for Cardinality-Constrained Portfolio Optimization","summary":"Metaheuristic algorithms for cardinality-constrained portfolio optimization require repair operators to map infeasible candidates onto the feasible region. Standard Euclidean projection treats assets as independent and can ignore the covariance structure that governs portfolio risk, potentially producing less diversified portfolios. This paper introduces Covariance-Aware Simplex Projection (CASP), a two-stage repair operator that (i) selects a target number of assets using volatility-normalized scores and (ii) projects the candidate weights using a covariance-aware geometry aligned with tracking-error risk. This provides a portfolio-theoretic foundation for using a covariance-induced distance in repair operators. On S&P 500 data (2020-2024), CASP-Basic delivers materially lower portfolio variance than standard Euclidean repair without relying on return estimates, with improvements that are robust across assets and statistically significant. Ablation results indicate that volatility-normalized selection drives most of the variance reduction, while the covariance-aware projection provides an additional, consistent improvement. We further show that optional return-aware extensions can improve Sharpe ratios, and out-of-sample tests confirm that gains transfer to realized performance. CASP integrates as a drop-in replacement for Euclidean projection in metaheuristic portfolio optimizers.","authors":["Nikolaos Iliopoulos"],"pdf_url":"","comment":"9 pages, 3 figures, 5 tables"},{"id":"http://arxiv.org/abs/2512.16251v2","updated":"2025-12-23T02:11:19Z","published":"2025-12-18T07:05:25Z","title":"Interpretable Deep Learning for Stock Returns: A Consensus-Bottleneck Asset Pricing Model","summary":"We introduce the Consensus-Bottleneck Asset Pricing Model (CB-APM), a partially interpretable neural network that replicates the reasoning processes of sell-side analysts by capturing how dispersed investor beliefs are compressed into asset prices through a consensus formation process. By modeling this \"bottleneck\" to summarize firm- and macro-level information, CB-APM not only predicts future risk premiums of U.S. equities but also links belief aggregation to expected returns in a structurally interpretable manner. The model improves long-horizon return forecasts and outperforms standard deep learning approaches in both predictive accuracy and explanatory power. Comprehensive portfolio analyses show that CB-APM's out-of-sample predictions translate into economically meaningful payoffs, with monotonic return differentials and stable long-short performance across regularization settings. Empirically, CB-APM leverages consensus as a regularizer to amplify long-horizon predictability and yields interpretable consensus-based components that clarify how information is priced in returns. Moreover, regression and Gibbons-Ross-Shanken (GRS)-based pricing diagnostics reveal that the learned consensus representations capture priced variation only partially spanned by traditional factor models, demonstrating that CB-APM uncovers belief-driven structure in expected returns beyond the canonical factor space. Overall, CB-APM provides an interpretable and empirically grounded framework for understanding belief-driven return dynamics.","authors":["Bong-Gyu Jang","Younwoo Jeong","Changeun Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.06580v4","updated":"2025-12-23T01:41:33Z","published":"2025-09-08T11:49:52Z","title":"AI for Scientific Discovery is a Social Problem","summary":"Artificial intelligence (AI) is increasingly applied to scientific research, but its benefits remain unevenly distributed across communities and disciplines. While technical challenges such as limited data, fragmented standards, and unequal access to computational resources exist, social and institutional factors are often the primary constraints. Narratives emphasizing autonomous \"AI scientists,\" under-recognition of data and infrastructure work, misaligned incentives, and gaps between domain experts and machine learning researchers all limit the impact of AI on scientific discovery. This paper highlights four interconnected challenges: community coordination, misalignment of research priorities with upstream needs, data fragmentation, and infrastructure inequities. We argue that addressing these challenges requires not only technical innovation but also intentional efforts in community-building, cross-disciplinary education, shared benchmarks, and accessible infrastructure. We call for reframing AI for science as a collective social project, where sustainable collaboration and equitable participation are treated as prerequisites for technical progress","authors":["Georgia Channing","Avijit Ghosh"],"pdf_url":"","comment":"Both authors contributed equally"},{"id":"http://arxiv.org/abs/2512.19970v1","updated":"2025-12-23T01:32:32Z","published":"2025-12-23T01:32:32Z","title":"Spatio-Temporal Graph Neural Networks for Dairy Farm Sustainability Forecasting and Counterfactual Policy Analysis","summary":"This study introduces a novel data-driven framework and the first-ever county-scale application of Spatio-Temporal Graph Neural Networks (STGNN) to forecast composite sustainability indices from herd-level operational records. The methodology employs a novel, end-to-end pipeline utilizing a Variational Autoencoder (VAE) to augment Irish Cattle Breeding Federation (ICBF) datasets, preserving joint distributions while mitigating sparsity. A first-ever pillar-based scoring formulation is derived via Principal Component Analysis, identifying Reproductive Efficiency, Genetic Management, Herd Health, and Herd Management, to construct weighted composite indices. These indices are modelled using a novel STGNN architecture that explicitly encodes geographic dependencies and non-linear temporal dynamics to generate multi-year forecasts for 2026-2030.","authors":["Surya Jayakumar","Kieran Sullivan","John McLaughlin","Christine O'Meara","Indrakshi Dey"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.25535v2","updated":"2025-12-23T01:30:53Z","published":"2025-09-29T21:44:00Z","title":"Meta-Router: Bridging Gold-standard and Preference-based Evaluations in Large Language Model Routing","summary":"In language tasks that require extensive human--model interaction, deploying a single \"best\" model for every query can be expensive. To reduce inference cost while preserving the quality of the responses, a large language model (LLM) router selects the most appropriate model from a pool of candidates for each query. A central challenge to training a high-quality router is the scarcity of reliable supervision. Gold-standard data (e.g., expert-verified labels or rubric-based scores) provide accurate quality evaluations of LLM responses but are costly and difficult to scale. In contrast, preference-based data, collected via crowdsourcing or LLM-as-a-judge systems, are cheaper and more scalable, yet often biased in reflecting the true quality of responses. We cast the problem of LLM router training with combined gold-standard and preference-based data into a causal inference framework by viewing the response evaluation mechanism as the treatment assignment. This perspective further reveals that the bias in preference-based data corresponds to the well-known causal estimand: the conditional average treatment effect. Based on this new perspective, we develop an integrative causal router training framework that corrects preference-data bias, address imbalances between two data sources, and improve routing robustness and efficiency. Numerical experiments demonstrate that our approach delivers more accurate routing and improves the trade-off between cost and quality.","authors":["Yichi Zhang","Fangzheng Xie","Shu Yang","Chong Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.18345v2","updated":"2025-12-23T01:23:23Z","published":"2025-05-23T20:03:36Z","title":"Diffusion Self-Weighted Guidance for Offline Reinforcement Learning","summary":"Offline reinforcement learning (RL) recovers the optimal policy $π$ given historical observations of an agent. In practice, $π$ is modeled as a weighted version of the agent's behavior policy $μ$, using a weight function $w$ working as a critic of the agent's behavior. Though recent approaches to offline RL based on diffusion models have exhibited promising results, the computation of the required scores is challenging due to their dependence on the unknown $w$. In this work, we alleviate this issue by constructing a diffusion over both the actions and the weights. With the proposed setting, the required scores are directly obtained from the diffusion model without learning extra networks. Our main conceptual contribution is a novel guidance method, where guidance (which is a function of $w$) comes from the same diffusion model, therefore, our proposal is termed Self-Weighted Guidance (SWG). We show that SWG generates samples from the desired distribution on toy examples and performs on par with state-of-the-art methods on D4RL's challenging environments, while maintaining a streamlined training pipeline. We further validate SWG through ablation studies on weight formulations and scalability.","authors":["Augusto Tagle","Javier Ruiz-del-Solar","Felipe Tobar"],"pdf_url":"","comment":"Published in Transactions on Machine Learning Research (TMLR). 21 pages, 6 figures"},{"id":"http://arxiv.org/abs/2512.10229v3","updated":"2025-12-23T01:17:01Z","published":"2025-12-11T02:25:27Z","title":"Adaptive Information Routing for Multimodal Time Series Forecasting","summary":"Time series forecasting is a critical task for artificial intelligence with numerous real-world applications. Traditional approaches primarily rely on historical time series data to predict the future values. However, in practical scenarios, this is often insufficient for accurate predictions due to the limited information available. To address this challenge, multimodal time series forecasting methods which incorporate additional data modalities, mainly text data, alongside time series data have been explored. In this work, we introduce the Adaptive Information Routing (AIR) framework, a novel approach for multimodal time series forecasting. Unlike existing methods that treat text data on par with time series data as interchangeable auxiliary features for forecasting, AIR leverages text information to dynamically guide the time series model by controlling how and to what extent multivariate time series information should be combined. We also present a text-refinement pipeline that employs a large language model to convert raw text data into a form suitable for multimodal forecasting, and we introduce a benchmark that facilitates multimodal forecasting experiments based on this pipeline. Experiment results with the real world market data such as crude oil price and exchange rates demonstrate that AIR effectively modulates the behavior of the time series model using textual inputs, significantly enhancing forecasting accuracy in various time series forecasting tasks.","authors":["Jun Seo","Hyeokjun Choe","Seohui Bae","Soyeon Park","Wonbin Ahn","Taeyoon Lim","Junhyeok Kang","Sangjun Han","Jaehoon Lee","Dongwan Kang","Minjae Kim","Sungdong Yoo","Soonyoung Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19941v1","updated":"2025-12-23T00:18:23Z","published":"2025-12-23T00:18:23Z","title":"Block-Recurrent Dynamics in Vision Transformers","summary":"As Vision Transformers (ViTs) become standard vision backbones, a mechanistic account of their computational phenomenology is essential. Despite architectural cues that hint at dynamical structure, there is no settled framework that interprets Transformer depth as a well-characterized flow. In this work, we introduce the Block-Recurrent Hypothesis (BRH), arguing that trained ViTs admit a block-recurrent depth structure such that the computation of the original $L$ blocks can be accurately rewritten using only $k \\ll L$ distinct blocks applied recurrently. Across diverse ViTs, between-layer representational similarity matrices suggest few contiguous phases. To determine whether these phases reflect genuinely reusable computation, we train block-recurrent surrogates of pretrained ViTs: Recurrent Approximations to Phase-structured TransfORmers (Raptor). In small-scale, we demonstrate that stochastic depth and training promote recurrent structure and subsequently correlate with our ability to accurately fit Raptor. We then provide an empirical existence proof for BRH by training a Raptor model to recover $96\\%$ of DINOv2 ImageNet-1k linear probe accuracy in only 2 blocks at equivalent computational cost. Finally, we leverage our hypothesis to develop a program of Dynamical Interpretability. We find i) directional convergence into class-dependent angular basins with self-correcting trajectories under small perturbations, ii) token-specific dynamics, where cls executes sharp late reorientations while patch tokens exhibit strong late-stage coherence toward their mean direction, and iii) a collapse to low rank updates in late depth, consistent with convergence to low-dimensional attractors. Altogether, we find a compact recurrent program emerges along ViT depth, pointing to a low-complexity normative solution that enables these models to be studied through principled dynamical systems analysis.","authors":["Mozes Jacobs","Thomas Fel","Richard Hakim","Alessandra Brondetta","Demba Ba","T. Andy Keller"],"pdf_url":"","comment":"25 pages, 15 figures"},{"id":"http://arxiv.org/abs/2512.20848v1","updated":"2025-12-23T23:54:32Z","published":"2025-12-23T23:54:32Z","title":"Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning","summary":"We present Nemotron 3 Nano 30B-A3B, a Mixture-of-Experts hybrid Mamba-Transformer language model. Nemotron 3 Nano was pretrained on 25 trillion text tokens, including more than 3 trillion new unique tokens over Nemotron 2, followed by supervised fine tuning and large-scale RL on diverse environments. Nemotron 3 Nano achieves better accuracy than our previous generation Nemotron 2 Nano while activating less than half of the parameters per forward pass. It achieves up to 3.3x higher inference throughput than similarly-sized open models like GPT-OSS-20B and Qwen3-30B-A3B-Thinking-2507, while also being more accurate on popular benchmarks. Nemotron 3 Nano demonstrates enhanced agentic, reasoning, and chat abilities and supports context lengths up to 1M tokens. We release both our pretrained Nemotron 3 Nano 30B-A3B Base and post-trained Nemotron 3 Nano 30B-A3B checkpoints on Hugging Face.","authors":[" NVIDIA"," :","Aaron Blakeman","Aaron Grattafiori","Aarti Basant","Abhibha Gupta","Abhinav Khattar","Adi Renduchintala","Aditya Vavre","Akanksha Shukla","Akhiad Bercovich","Aleksander Ficek","Aleksandr Shaposhnikov","Alex Kondratenko","Alexander Bukharin","Alexandre Milesi","Ali Taghibakhshi","Alisa Liu","Amelia Barton","Ameya Sunil Mahabaleshwarkar","Amir Klein","Amit Zuker","Amnon Geifman","Amy Shen","Anahita Bhiwandiwalla","Andrew Tao","Ann Guan","Anubhav Mandarwal","Arham Mehta","Ashwath Aithal","Ashwin Poojary","Asif Ahamed","Asma Kuriparambil Thekkumpate","Ayush Dattagupta","Banghua Zhu","Bardiya Sadeghi","Barnaby Simkin","Ben Lanir","Benedikt Schifferer","Besmira Nushi","Bilal Kartal","Bita Darvish Rouhani","Boris Ginsburg","Brandon Norick","Brandon Soubasis","Branislav Kisacanin","Brian Yu","Bryan Catanzaro","Carlo del Mundo","Chantal Hwang","Charles Wang","Cheng-Ping Hsieh","Chenghao Zhang","Chenhan Yu","Chetan Mungekar","Chintan Patel","Chris Alexiuk","Christopher Parisien","Collin Neale","Damon Mosk-Aoyama","Dan Su","Dane Corneil","Daniel Afrimi","Daniel Rohrer","Daniel Serebrenik","Daria Gitman","Daria Levy","Darko Stosic","David Mosallanezhad","Deepak Narayanan","Dhruv Nathawani","Dima Rekesh","Dina Yared","Divyanshu Kakwani","Dong Ahn","Duncan Riach","Dusan Stosic","Edgar Minasyan","Edward Lin","Eileen Long","Eileen Peters Long","Elena Lantz","Ellie Evans","Elliott Ning","Eric Chung","Eric Harper","Eric Tramel","Erick Galinkin","Erik Pounds","Evan Briones","Evelina Bakhturina","Faisal Ladhak","Fay Wang","Fei Jia","Felipe Soares","Feng Chen","Ferenc Galko","Frankie Siino","Gal Hubara Agam","Ganesh Ajjanagadde","Gantavya Bhatt","Gargi Prasad","George Armstrong","Gerald Shen","Gorkem Batmaz","Grigor Nalbandyan","Haifeng Qian","Harsh Sharma","Hayley Ross","Helen Ngo","Herman Sahota","Hexin Wang","Himanshu Soni","Hiren Upadhyay","Huizi Mao","Huy C Nguyen","Huy Q Nguyen","Iain Cunningham","Ido Shahaf","Igor Gitman","Ilya Loshchilov","Ivan Moshkov","Izzy Putterman","Jan Kautz","Jane Polak Scowcroft","Jared Casper","Jatin Mitra","Jeffrey Glick","Jenny Chen","Jesse Oliver","Jian Zhang","Jiaqi Zeng","Jie Lou","Jimmy Zhang","Jining Huang","Joey Conway","Joey Guman","John Kamalu","Johnny Greco","Jonathan Cohen","Joseph Jennings","Joyjit Daw","Julien Veron Vialard","Junkeun Yi","Jupinder Parmar","Kai Xu","Kan Zhu","Kari Briski","Katherine Cheung","Katherine Luna","Keshav Santhanam","Kevin Shih","Kezhi Kong","Khushi Bhardwaj","Krishna C. Puvvada","Krzysztof Pawelec","Kumar Anik","Lawrence McAfee","Laya Sleiman","Leon Derczynski","Li Ding","Lucas Liebenwein","Luis Vega","Maanu Grover","Maarten Van Segbroeck","Maer Rodrigues de Melo","Makesh Narsimhan Sreedhar","Manoj Kilaru","Maor Ashkenazi","Marc Romeijn","Mark Cai","Markus Kliegl","Maryam Moosaei","Matvei Novikov","Mehrzad Samadi","Melissa Corpuz","Mengru Wang","Meredith Price","Michael Boone","Michael Evans","Miguel Martinez","Mike Chrzanowski","Mohammad Shoeybi","Mostofa Patwary","Nabin Mulepati","Natalie Hereth","Nave Assaf","Negar Habibi","Neta Zmora","Netanel Haber","Nicola Sessions","Nidhi Bhatia","Nikhil Jukar","Nikki Pope","Nikolai Ludwig","Nima Tajbakhsh","Nirmal Juluru","Oleksii Hrinchuk","Oleksii Kuchaiev","Olivier Delalleau","Oluwatobi Olabiyi","Omer Ullman Argov","Ouye Xie","Parth Chadha","Pasha Shamis","Pavlo Molchanov","Pawel Morkisz","Peter Dykas","Peter Jin","Pinky Xu","Piotr Januszewski","Pranav Prashant Thombre","Prasoon Varshney","Pritam Gundecha","Qing Miao","Rabeeh Karimi Mahabadi","Ran El-Yaniv","Ran Zilberstein","Rasoul Shafipour","Rich Harang","Rick Izzo","Rima Shahbazyan","Rishabh Garg","Ritika Borkar","Ritu Gala","Riyad Islam","Roger Waleffe","Rohit Watve","Roi Koren","Ruoxi Zhang","Russell J. Hewett","Ryan Prenger","Ryan Timbrook","Sadegh Mahdavi","Sahil Modi","Samuel Kriman","Sanjay Kariyappa","Sanjeev Satheesh","Saori Kaji","Satish Pasumarthi","Sean Narentharen","Sean Narenthiran","Seonmyeong Bak","Sergey Kashirsky","Seth Poulos","Shahar Mor","Shanmugam Ramasamy","Shantanu Acharya","Shaona Ghosh","Sharath Turuvekere Sreenivas","Shelby Thomas","Shiqing Fan","Shreya Gopal","Shrimai Prabhumoye","Shubham Pachori","Shubham Toshniwal","Shuoyang Ding","Siddharth Singh","Simeng Sun","Smita Ithape","Somshubra Majumdar","Soumye Singhal","Stefania Alborghetti","Stephen Ge","Sugam Dipak Devare","Sumeet Kumar Barua","Suseella Panguluri","Suyog Gupta","Sweta Priyadarshi","Syeda Nahida Akter","Tan Bui","Teodor-Dumitru Ene","Terry Kong","Thanh Do","Tijmen Blankevoort","Tom Balough","Tomer Asida","Tomer Bar Natan","Tugrul Konuk","Twinkle Vashishth","Udi Karpas","Ushnish De","Vahid Noorozi","Vahid Noroozi","Venkat Srinivasan","Venmugil Elango","Vijay Korthikanti","Vitaly Kurin","Vitaly Lavrukhin","Wanli Jiang","Wasi Uddin Ahmad","Wei Du","Wei Ping","Wenfei Zhou","Will Jennings","William Zhang","Wojciech Prazuch","Xiaowei Ren","Yashaswi Karnati","Yejin Choi","Yev Meyer","Yi-Fu Wu","Yian Zhang","Ying Lin","Yonatan Geifman","Yonggan Fu","Yoshi Subara","Yoshi Suhara","Yubo Gao","Zach Moshe","Zhen Dong","Zihan Liu","Zijia Chen","Zijie Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.17836v4","updated":"2025-12-23T23:38:19Z","published":"2025-04-24T17:48:03Z","title":"Learning Enhanced Ensemble Filters","summary":"The filtering distribution in hidden Markov models evolves according to the law of a mean-field model in state-observation space. The ensemble Kalman filter (EnKF) approximates this mean-field model with an ensemble of interacting particles, employing a Gaussian ansatz for the joint distribution of the state and observation at each observation time. These methods are robust, but the Gaussian ansatz limits accuracy. Here this shortcoming is addressed by using machine learning to map the joint predicted state and observation to the updated state estimate. The derivation of methods from a mean field formulation of the true filtering distribution suggests a single parametrization of the algorithm that can be deployed at different ensemble sizes. And we use a mean field formulation of the ensemble Kalman filter as an inductive bias for our architecture.\n  To develop this perspective, in which the mean-field limit of the algorithm and finite interacting ensemble particle approximations share a common set of parameters, a novel form of neural operator is introduced, taking probability distributions as input: a measure neural mapping (MNM). A MNM is used to design a novel approach to filtering, the MNM-enhanced ensemble filter (MNMEF), which is defined in both the mean-field limit and for interacting ensemble particle approximations. The ensemble approach uses empirical measures as input to the MNM and is implemented using the set transformer, which is invariant to ensemble permutation and allows for different ensemble sizes. In practice fine-tuning of a small number of parameters, for specific ensemble sizes, further enhances the accuracy of the scheme. The promise of the approach is demonstrated by its superior root-mean-square-error performance relative to leading methods in filtering the Lorenz '96 and Kuramoto-Sivashinsky models.","authors":["Eviatar Bach","Ricardo Baptista","Edoardo Calvello","Bohan Chen","Andrew Stuart"],"pdf_url":"","comment":"Accepted by the Journal of Computational Physics"},{"id":"http://arxiv.org/abs/2512.20833v1","updated":"2025-12-23T23:15:10Z","published":"2025-12-23T23:15:10Z","title":"CHAMMI-75: pre-training multi-channel models with heterogeneous microscopy images","summary":"Quantifying cell morphology using images and machine learning has proven to be a powerful tool to study the response of cells to treatments. However, models used to quantify cellular morphology are typically trained with a single microscopy imaging type. This results in specialized models that cannot be reused across biological studies because the technical specifications do not match (e.g., different number of channels), or because the target experimental conditions are out of distribution. Here, we present CHAMMI-75, an open access dataset of heterogeneous, multi-channel microscopy images from 75 diverse biological studies. We curated this resource from publicly available sources to investigate cellular morphology models that are channel-adaptive and can process any microscopy image type. Our experiments show that training with CHAMMI-75 can improve performance in multi-channel bioimaging tasks primarily because of its high diversity in microscopy modalities. This work paves the way to create the next generation of cellular morphology models for biological studies.","authors":["Vidit Agrawal","John Peters","Tyler N. Thompson","Mohammad Vali Sanian","Chau Pham","Nikita Moshkov","Arshad Kazi","Aditya Pillai","Jack Freeman","Byunguk Kang","Samouil L. Farhi","Ernest Fraenkel","Ron Stewart","Lassi Paavolainen","Bryan A. Plummer","Juan C. Caicedo"],"pdf_url":"","comment":"47 Pages, 23 Figures, 26 Tables"},{"id":"http://arxiv.org/abs/2512.20831v1","updated":"2025-12-23T23:12:53Z","published":"2025-12-23T23:12:53Z","title":"Context-Sensitive Abstractions for Reinforcement Learning with Parameterized Actions","summary":"Real-world sequential decision-making often involves parameterized action spaces that require both, decisions regarding discrete actions and decisions about continuous action parameters governing how an action is executed. Existing approaches exhibit severe limitations in this setting -- planning methods demand hand-crafted action models, and standard reinforcement learning (RL) algorithms are designed for either discrete or continuous actions but not both, and the few RL methods that handle parameterized actions typically rely on domain-specific engineering and fail to exploit the latent structure of these spaces. This paper extends the scope of RL algorithms to long-horizon, sparse-reward settings with parameterized actions by enabling agents to autonomously learn both state and action abstractions online. We introduce algorithms that progressively refine these abstractions during learning, increasing fine-grained detail in the critical regions of the state-action space where greater resolution improves performance. Across several continuous-state, parameterized-action domains, our abstraction-driven approach enables TD($λ$) to achieve markedly higher sample efficiency than state-of-the-art baselines.","authors":["Rashmeet Kaur Nayyar","Naman Shah","Siddharth Srivastava"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20821v1","updated":"2025-12-23T22:46:06Z","published":"2025-12-23T22:46:06Z","title":"Defending against adversarial attacks using mixture of experts","summary":"Machine learning is a powerful tool enabling full automation of a huge number of tasks without explicit programming. Despite recent progress of machine learning in different domains, these models have shown vulnerabilities when they are exposed to adversarial threats. Adversarial threats aim to hinder the machine learning models from satisfying their objectives. They can create adversarial perturbations, which are imperceptible to humans' eyes but have the ability to cause misclassification during inference. Moreover, they can poison the training data to harm the model's performance or they can query the model to steal its sensitive information. In this paper, we propose a defense system, which devises an adversarial training module within mixture-of-experts architecture to enhance its robustness against adversarial threats. In our proposed defense system, we use nine pre-trained experts with ResNet-18 as their backbone. During end-to-end training, the parameters of expert models and gating mechanism are jointly updated allowing further optimization of the experts. Our proposed defense system outperforms state-of-the-art defense systems and plain classifiers, which use a more complex architecture than our model's backbone.","authors":["Mohammad Meymani","Roozbeh Razavi-Far"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20814v1","updated":"2025-12-23T22:25:11Z","published":"2025-12-23T22:25:11Z","title":"FedMPDD: Communication-Efficient Federated Learning with Privacy Preservation Attributes via Projected Directional Derivative","summary":"This paper introduces \\texttt{FedMPDD} (\\textbf{Fed}erated Learning via \\textbf{M}ulti-\\textbf{P}rojected \\textbf{D}irectional \\textbf{D}erivatives), a novel algorithm that simultaneously optimizes bandwidth utilization and enhances privacy in Federated Learning. The core idea of \\texttt{FedMPDD} is to encode each client's high-dimensional gradient by computing its directional derivatives along multiple random vectors. This compresses the gradient into a much smaller message, significantly reducing uplink communication costs from $\\mathcal{O}(d)$ to $\\mathcal{O}(m)$, where $m \\ll d$. The server then decodes the aggregated information by projecting it back onto the same random vectors. Our key insight is that averaging multiple projections overcomes the dimension-dependent convergence limitations of a single projection. We provide a rigorous theoretical analysis, establishing that \\texttt{FedMPDD} converges at a rate of $\\mathcal{O}(1/\\sqrt{K})$, matching the performance of FedSGD. Furthermore, we demonstrate that our method provides some inherent privacy against gradient inversion attacks due to the geometric properties of low-rank projections, offering a tunable privacy-utility trade-off controlled by the number of projections. Extensive experiments on benchmark datasets validate our theory and demonstrates our results.","authors":["Mohammadreza Rostami","Solmaz S. Kia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20813v1","updated":"2025-12-23T22:23:23Z","published":"2025-12-23T22:23:23Z","title":"GraphFire-X: Physics-Informed Graph Attention Networks and Structural Gradient Boosting for Building-Scale Wildfire Preparedness at the Wildland-Urban Interface","summary":"As wildfires increasingly evolve into urban conflagrations, traditional risk models that treat structures as isolated assets fail to capture the non-linear contagion dynamics characteristic of the wildland urban interface (WUI). This research bridges the gap between mechanistic physics and data driven learning by establishing a novel dual specialist ensemble framework that disentangles vulnerability into two distinct vectors, environmental contagion and structural fragility. The architecture integrates two specialized predictive streams, an environmental specialist, implemented as a graph neural network (GNN) that operationalizes the community as a directed contagion graph weighted by physics informed convection, radiation, and ember probabilities, and enriched with high dimensional Google AlphaEarth Foundation embeddings, and a Structural Specialist, implemented via XGBoost to isolate granular asset level resilience. Applied to the 2025 Eaton Fire, the framework reveals a critical dichotomy in risk drivers. The GNN demonstrates that neighborhood scale environmental pressure overwhelmingly dominates intrinsic structural features in defining propagation pathways, while the XGBoost model identifies eaves as the primary micro scale ingress vector. By synthesizing these divergent signals through logistic stacking, the ensemble achieves robust classification and generates a diagnostic risk topology. This capability empowers decision makers to move beyond binary loss prediction and precisely target mitigation prioritizing vegetation management for high connectivity clusters and structural hardening for architecturally vulnerable nodes thereby operationalizing a proactive, data driven approach to community resilience.","authors":["Miguel Esparza","Vamshi Battal","Ali Mostafavi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20811v1","updated":"2025-12-23T22:20:34Z","published":"2025-12-23T22:20:34Z","title":"Weighted MCC: A Robust Measure of Multiclass Classifier Performance for Observations with Individual Weights","summary":"Several performance measures are used to evaluate binary and multiclass classification tasks.\n  But individual observations may often have distinct weights, and none of these measures are sensitive to such varying weights.\n  We propose a new weighted Pearson-Matthews Correlation Coefficient (MCC) for binary classification as well as weighted versions of related multiclass measures. The weighted MCC varies between $-1$ and $1$. But crucially, the weighted MCC values are higher for classifiers that perform better on highly weighted observations, and hence is able to distinguish them from classifiers that have a similar overall performance and ones that perform better on the lowly weighted observations.\n  Furthermore, we prove that the weighted measures are robust with respect to the choice of weights in a precise manner:\n  if the weights are changed by at most $ε$, the value of the weighted measure changes at most by a factor of $ε$ in the binary case\n  and by a factor of $ε^2$ in the multiclass case.\n  Our computations demonstrate that the weighted measures clearly identify classifiers that perform better on higher weighted observations, while the unweighted measures remain completely indifferent to the choices of weights.","authors":["Rommel Cortez","Bala Krishnamoorthy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.13868v2","updated":"2025-12-23T21:56:57Z","published":"2025-12-15T19:56:39Z","title":"Safe Online Control-Informed Learning","summary":"This paper proposes a Safe Online Control-Informed Learning framework for safety-critical autonomous systems. The framework unifies optimal control, parameter estimation, and safety constraints into an online learning process. It employs an extended Kalman filter to incrementally update system parameters in real time, enabling robust and data-efficient adaptation under uncertainty. A softplus barrier function enforces constraint satisfaction during learning and control while eliminating the dependence on high-quality initial guesses. Theoretical analysis establishes convergence and safety guarantees, and the framework's effectiveness is demonstrated on cart-pole and robot-arm systems.","authors":["Tianyu Zhou","Zihao Liang","Zehui Lu","Shaoshuai Mou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.17228v2","updated":"2025-12-23T21:35:27Z","published":"2024-12-23T02:44:35Z","title":"MatchMiner-AI: An Open-Source Solution for Cancer Clinical Trial Matching","summary":"Clinical trials drive improvements in cancer treatments and outcomes. However, most adults with cancer do not participate in trials, and trials often fail to enroll enough patients to answer their scientific questions. Artificial intelligence could accelerate identification of appropriate clinical trials for patients, but data restrictions have precluded sharing AI models trained on patient records. Here, we describe the development and evaluation of the open-source MatchMiner-AI platform, trained on synthetic data, for clinical trial searching and ranking. It focuses on matching patients to potential trials based on core criteria describing clinical \"spaces,\" or target populations. The pipeline includes modules to extract key elements of the history from a patient's longitudinal electronic health record, rapidly rank candidate trial-patient matches based on embeddings in vector space, and reason about whether a candidate match represents an appropriate clinical consideration. Another module predicts whether the patient meets common exclusion criteria across clinical trials, such as end-organ dysfunction. Training code is available at https://github.com/dfci/matchminer-ai-training . Examples of inference code are at https://github.com/dfci/matchminer-ai-inference . To facilitate deployment across contexts, demonstration apps, all synthetic data, as well as patient/trial embedding, cross-encoding/match classification, and generative reasoning models are available at https://huggingface.co/ksg-dfci .","authors":["Jennifer Altreuter","Pavel Trukhanov","Morgan A. Paul","Michael J. Hassett","Irbaz B. Riaz","Muhammad Umar Afzal","Arshad A. Mohammed","Sarah Sammons","James Lindsay","Emily Mallaber","Harry R. Klein","Gufran Gungor","Matthew Galvin","Michael Deletto","Stephen C. Van Nostrand","James Provencher","Joyce Yu","Naeem Tahir","Jonathan Wischhusen","Olga Kozyreva","Taylor Ortiz","Hande Tuncer","Jad El Masri","Alys Malcolm","Tali Mazor","Ethan Cerami","Kenneth L. Kehl"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20785v1","updated":"2025-12-23T21:33:11Z","published":"2025-12-23T21:33:11Z","title":"Symbolic regression for defect interactions in 2D materials","summary":"Machine learning models have become firmly established across all scientific fields. Extracting features from data and making inferences based on them with neural network models often yields high accuracy; however, this approach has several drawbacks. Symbolic regression is a powerful technique for discovering analytical equations that describe data, providing interpretable and generalizable models capable of predicting unseen data. Symbolic regression methods have gained new momentum with the advancement of neural network technologies and offer several advantages, the main one being the interpretability of results. In this work, we examined the application of the deep symbolic regression algorithm SEGVAE to determine the properties of two-dimensional materials with defects. Comparing the results with state-of-the-art graph neural network-based methods shows comparable or, in some cases, even identical outcomes. We also discuss the applicability of this class of methods in natural sciences.","authors":["Mikhail Lazarev","Andrey Ustyuzhanin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20783v1","updated":"2025-12-23T21:30:05Z","published":"2025-12-23T21:30:05Z","title":"NULLBUS: Multimodal Mixed-Supervision for Breast Ultrasound Segmentation via Nullable Global-Local Prompts","summary":"Breast ultrasound (BUS) segmentation provides lesion boundaries essential for computer-aided diagnosis and treatment planning. While promptable methods can improve segmentation performance and tumor delineation when text or spatial prompts are available, many public BUS datasets lack reliable metadata or reports, constraining training to small multimodal subsets and reducing robustness. We propose NullBUS, a multimodal mixed-supervision framework that learns from images with and without prompts in a single model. To handle missing text, we introduce nullable prompts, implemented as learnable null embeddings with presence masks, enabling fallback to image-only evidence when metadata are absent and the use of text when present. Evaluated on a unified pool of three public BUS datasets, NullBUS achieves a mean IoU of 0.8568 and a mean Dice of 0.9103, demonstrating state-of-the-art performance under mixed prompt availability.","authors":["Raja Mallina","Bryar Shareef"],"pdf_url":"","comment":"5 pages, 2 figures, and 4 tables"},{"id":"http://arxiv.org/abs/2512.20777v1","updated":"2025-12-23T21:25:40Z","published":"2025-12-23T21:25:40Z","title":"Improving Matrix Exponential for Generative AI Flows: A Taylor-Based Approach Beyond Paterson--Stockmeyer","summary":"The matrix exponential is a fundamental operator in scientific computing and system simulation, with applications ranging from control theory and quantum mechanics to modern generative machine learning. While Padé approximants combined with scaling and squaring have long served as the standard, recent Taylor-based methods, which utilize polynomial evaluation schemes that surpass the classical Paterson--Stockmeyer technique, offer superior accuracy and reduced computational complexity. This paper presents an optimized Taylor-based algorithm for the matrix exponential, specifically designed for the high-throughput requirements of generative AI flows. We provide a rigorous error analysis and develop a dynamic selection strategy for the Taylor order and scaling factor to minimize computational effort under a prescribed error tolerance. Extensive numerical experiments demonstrate that our approach provides significant acceleration and maintains high numerical stability compared to existing state-of-the-art implementations. These results establish the proposed method as a highly efficient tool for large-scale generative modeling.","authors":["Jorge Sastre","Daniel Faronbi","José Miguel Alonso","Peter Traver","Javier Ibáñez","Nuria Lloret"],"pdf_url":"","comment":"41 pages, 35 figures"},{"id":"http://arxiv.org/abs/2506.06303v2","updated":"2025-12-23T21:21:10Z","published":"2025-05-21T16:15:01Z","title":"Reward Is Enough: LLMs Are In-Context Reinforcement Learners","summary":"Reinforcement learning (RL) is a framework for solving sequential decision-making problems. In this work, we demonstrate that, surprisingly, RL emerges during the inference time of large language models (LLMs), a phenomenon we term in-context RL (ICRL). To reveal this capability, we introduce a simple multi-round prompting framework, we call ICRL prompting, for inference-time self-improvement. The goal of ICRL prompting is to guide LLMs to perform reinforcement learning during inference for self-improvement on a given task. After each response, the model receives numerical scalar feedback, denoted as a reward. In the next round, we prompt the LLM again together with a context that concatenates all prior responses and their associated rewards. We consistently observe that response quality improves as the context grows. In other words, the LLM can optimize scalar reward signals during inference, exhibiting behavior analogous to reinforcement learning. We evaluate ICRL prompting on Game of 24, creative writing, ScienceWorld, and Olympiad-level math competitions (AIME and HMMT), demonstrating significant improvements over baselines such as Self-Refine and Reflexion. Notably, even when the reward signals are generated by the same LLM, ICRL prompting still improves performance, highlighting a promising new paradigm for test-time scaling.","authors":["Kefan Song","Amir Moeini","Peng Wang","Lei Gong","Rohan Chandra","Yanjun Qi","Shangtong Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20762v1","updated":"2025-12-23T20:49:05Z","published":"2025-12-23T20:49:05Z","title":"Subgroup Discovery with the Cox Model","summary":"We study the problem of subgroup discovery for survival analysis, where the goal is to find an interpretable subset of the data on which a Cox model is highly accurate. Our work is the first to study this particular subgroup problem, for which we make several contributions.\n  Subgroup discovery methods generally require a \"quality function\" in order to sift through and select the most advantageous subgroups. We first examine why existing natural choices for quality functions are insufficient to solve the subgroup discovery problem for the Cox model. To address the shortcomings of existing metrics, we introduce two technical innovations: the *expected prediction entropy (EPE)*, a novel metric for evaluating survival models which predict a hazard function; and the *conditional rank statistics (CRS)*, a statistical object which quantifies the deviation of an individual point to the distribution of survival times in an existing subgroup. We study the EPE and CRS theoretically and show that they can solve many of the problems with existing metrics.\n  We introduce a total of eight algorithms for the Cox subgroup discovery problem. The main algorithm is able to take advantage of both the EPE and the CRS, allowing us to give theoretical correctness results for this algorithm in a well-specified setting. We evaluate all of the proposed methods empirically on both synthetic and real data. The experiments confirm our theory, showing that our contributions allow for the recovery of a ground-truth subgroup in well-specified cases, as well as leading to better model fit compared to naively fitting the Cox model to the whole dataset in practical settings. Lastly, we conduct a case study on jet engine simulation data from NASA. The discovered subgroups uncover known nonlinearities/homogeneity in the data, and which suggest design choices which have been mirrored in practice.","authors":["Zachary Izzo","Iain Melvin"],"pdf_url":"","comment":"43 pages, 2 figures"},{"id":"http://arxiv.org/abs/2512.20761v1","updated":"2025-12-23T20:48:11Z","published":"2025-12-23T20:48:11Z","title":"TS-Arena Technical Report -- A Pre-registered Live Forecasting Platform","summary":"While Time Series Foundation Models (TSFMs) offer transformative capabilities for forecasting, they simultaneously risk triggering a fundamental evaluation crisis. This crisis is driven by information leakage due to overlapping training and test sets across different models, as well as the illegitimate transfer of global patterns to test data. While the ability to learn shared temporal dynamics represents a primary strength of these models, their evaluation on historical archives often permits the exploitation of observed global shocks, which violates the independence required for valid benchmarking. We introduce TS-Arena, a platform that restores the operational integrity of forecasting by treating the genuinely unknown future as the definitive test environment. By implementing a pre-registration mechanism on live data streams, the platform ensures that evaluation targets remain physically non-existent during inference, thereby enforcing a strict global temporal split. This methodology establishes a moving temporal frontier that prevents historical contamination and provides an authentic assessment of model generalization. Initially applied within the energy sector, TS-Arena provides a sustainable infrastructure for comparing foundation models under real-world constraints. A prototype of the platform is available at https://huggingface.co/spaces/DAG-UPB/TS-Arena.","authors":["Marcel Meyer","Sascha Kaltenpoth","Kevin Zalipski","Henrik Albers","Oliver Müller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20760v1","updated":"2025-12-23T20:45:31Z","published":"2025-12-23T20:45:31Z","title":"Generalization of RLVR Using Causal Reasoning as a Testbed","summary":"Reinforcement learning with verifiable rewards (RLVR) has emerged as a promising paradigm for post-training large language models (LLMs) on complex reasoning tasks. Yet, the conditions under which RLVR yields robust generalization remain poorly understood. This paper provides an empirical study of RLVR generalization in the setting of probabilistic inference over causal graphical models. This setting offers two natural axes along which to examine generalization: (i) the level of the probabilistic query -- associational, interventional, or counterfactual -- and (ii) the structural complexity of the query, measured by the size of its relevant subgraph. We construct datasets of causal graphs and queries spanning these difficulty axes and fine-tune Qwen-2.5-Instruct models using RLVR or supervised fine-tuning (SFT). We vary both the model scale (3B-32B) and the query level included in training. We find that RLVR yields stronger within-level and across-level generalization than SFT, but only for specific combinations of model size and training query level. Further analysis shows that RLVR's effectiveness depends on the model's initial reasoning competence. With sufficient initial competence, RLVR improves an LLM's marginalization strategy and reduces errors in intermediate probability calculations, producing substantial accuracy gains, particularly on more complex queries. These findings show that RLVR can improve specific causal reasoning subskills, with its benefits emerging only when the model has sufficient initial competence.","authors":["Brian Lu","Hongyu Zhao","Shuo Sun","Hao Peng","Rui Ding","Hongyuan Mei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20757v1","updated":"2025-12-23T20:43:06Z","published":"2025-12-23T20:43:06Z","title":"TokSuite: Measuring the Impact of Tokenizer Choice on Language Model Behavior","summary":"Tokenizers provide the fundamental basis through which text is represented and processed by language models (LMs). Despite the importance of tokenization, its role in LM performance and behavior is poorly understood due to the challenge of measuring the impact of tokenization in isolation. To address this need, we present TokSuite, a collection of models and a benchmark that supports research into tokenization's influence on LMs. Specifically, we train fourteen models that use different tokenizers but are otherwise identical using the same architecture, dataset, training budget, and initialization. Additionally, we curate and release a new benchmark that specifically measures model performance subject to real-world perturbations that are likely to influence tokenization. Together, TokSuite allows robust decoupling of the influence of a model's tokenizer, supporting a series of novel findings that elucidate the respective benefits and shortcomings of a wide range of popular tokenizers.","authors":["Gül Sena Altıntaş","Malikeh Ehghaghi","Brian Lester","Fengyuan Liu","Wanru Zhao","Marco Ciccone","Colin Raffel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20755v1","updated":"2025-12-23T20:36:54Z","published":"2025-12-23T20:36:54Z","title":"Bridging Efficiency and Safety: Formal Verification of Neural Networks with Early Exits","summary":"Ensuring the safety and efficiency of AI systems is a central goal of modern research. Formal verification provides guarantees of neural network robustness, while early exits improve inference efficiency by enabling intermediate predictions. Yet verifying networks with early exits introduces new challenges due to their conditional execution paths. In this work, we define a robustness property tailored to early exit architectures and show how off-the-shelf solvers can be used to assess it. We present a baseline algorithm, enhanced with an early stopping strategy and heuristic optimizations that maintain soundness and completeness. Experiments on multiple benchmarks validate our framework's effectiveness and demonstrate the performance gains of the improved algorithm. Alongside the natural inference acceleration provided by early exits, we show that they also enhance verifiability, enabling more queries to be solved in less time compared to standard networks. Together with a robustness analysis, we show how these metrics can help users navigate the inherent trade-off between accuracy and efficiency.","authors":["Yizhak Yisrael Elboher","Avraham Raviv","Amihay Elboher","Zhouxing Shi","Omri Azencot","Hillel Kugler","Guy Katz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.11785v3","updated":"2025-12-23T20:21:51Z","published":"2025-05-17T01:51:28Z","title":"Improving Coverage in Combined Prediction Sets with Weighted p-values","summary":"Conformal prediction quantifies the uncertainty of machine learning models by augmenting point predictions with valid prediction sets. For complex scenarios involving multiple trials, models, or data sources, conformal prediction sets can be aggregated to create a prediction set that captures the overall uncertainty, often improving precision. However, aggregating multiple prediction sets with individual $1-α$ coverage inevitably weakens the overall guarantee, typically resulting in $1-2α$ worst-case coverage. In this work, we propose a framework for the weighted aggregation of prediction sets, where weights are assigned to each prediction set based on their contribution. Our framework offers flexible control over how the sets are aggregated, achieving tighter coverage bounds that interpolate between the $1-2α$ guarantee of the combined models and the $1-α$ guarantee of an individual model depending on the distribution of weights. Importantly, our framework generalizes to data-dependent weights, as we derive a procedure for weighted aggregation that maintains finite-sample validity even when the weights depend on the data. This extension makes our framework broadly applicable to settings where weights are learned, such as mixture-of-experts (MoE), and we demonstrate through experiments in the MoE setting that our methods achieve adaptive coverage.","authors":["Gina Wong","Drew Prinster","Suchi Saria","Rama Chellappa","Anqi Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20749v1","updated":"2025-12-23T20:12:01Z","published":"2025-12-23T20:12:01Z","title":"Stabilizing Multimodal Autoencoders: A Theoretical and Empirical Analysis of Fusion Strategies","summary":"In recent years, the development of multimodal autoencoders has gained significant attention due to their potential to handle multimodal complex data types and improve model performance. Understanding the stability and robustness of these models is crucial for optimizing their training, architecture, and real-world applicability. This paper presents an analysis of Lipschitz properties in multimodal autoencoders, combining both theoretical insights and empirical validation to enhance the training stability of these models. We begin by deriving the theoretical Lipschitz constants for aggregation methods within the multimodal autoencoder framework. We then introduce a regularized attention-based fusion method, developed based on our theoretical analysis, which demonstrates improved stability and performance during training. Through a series of experiments, we empirically validate our theoretical findings by estimating the Lipschitz constants across multiple trials and fusion strategies. Our results demonstrate that our proposed fusion function not only aligns with theoretical predictions but also outperforms existing strategies in terms of consistency, convergence speed, and accuracy. This work provides a solid theoretical foundation for understanding fusion in multimodal autoencoders and contributes a solution for enhancing their performance.","authors":["Diyar Altinses","Andreas Schwung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20747v1","updated":"2025-12-23T20:07:37Z","published":"2025-12-23T20:07:37Z","title":"A Physics Informed Neural Network For Deriving MHD State Vectors From Global Active Regions Observations","summary":"Solar active regions (ARs) do not appear randomly but cluster along longitudinally warped toroidal bands ('toroids') that encode information about magnetic structures in the tachocline, where global-scale organization likely originates. Global MagnetoHydroDynamic Shallow-Water Tachocline (MHD-SWT) models have shown potential to simulate such toroids, matching observations qualitatively. For week-scale early prediction of flare-producing AR emergence, forward-integration of these toroids is necessary. This requires model initialization with a dynamically self-consistent MHD state-vector that includes magnetic, flow fields, and shell-thickness variations. However, synoptic magnetograms provide only geometric shape of toroids, not the state-vector needed to initialize MHD-SWT models. To address this challenging task, we develop PINNBARDS, a novel Physics-Informed Neural Network (PINN)-Based AR Distribution Simulator, that uses observational toroids and MHD-SWT equations to derive initial state-vector. Using Feb-14-2024 SDO/HMI synoptic map, we show that PINN converges to physically consistent, predominantly antisymmetric toroids, matching observed ones. Although surface data provides north and south toroids' central latitudes, and their latitudinal widths, they cannot determine tachocline field strengths, connected to AR emergence. We explore here solutions across a broad parameter range, finding hydrodynamically-dominated structures for weak fields (~2 kG) and overly rigid behavior for strong fields (~100 kG). We obtain best agreement with observations for 20-30 kG toroidal fields, and ~10 degree bandwidth, consistent with low-order longitudinal mode excitation. To our knowledge, PINNBARDS serves as the first method for reconstructing state-vectors for hidden tachocline magnetic structures from surface patterns; potentially leading to weeks ahead prediction of flare-producing AR-emergence.","authors":["Subhamoy Chatterjee","Mausumi Dikpati"],"pdf_url":"","comment":"25 pages, 12 figures, accepted for publication in The Astrophysical Journal"},{"id":"http://arxiv.org/abs/2512.20746v1","updated":"2025-12-23T20:00:34Z","published":"2025-12-23T20:00:34Z","title":"TrashDet: Iterative Neural Architecture Search for Efficient Waste Detection","summary":"This paper addresses trash detection on the TACO dataset under strict TinyML constraints using an iterative hardware-aware neural architecture search framework targeting edge and IoT devices. The proposed method constructs a Once-for-All-style ResDets supernet and performs iterative evolutionary search that alternates between backbone and neck/head optimization, supported by a population passthrough mechanism and an accuracy predictor to reduce search cost and improve stability. This framework yields a family of deployment-ready detectors, termed TrashDets. On a five-class TACO subset (paper, plastic, bottle, can, cigarette), the strongest variant, TrashDet-l, achieves 19.5 mAP50 with 30.5M parameters, improving accuracy by up to 3.6 mAP50 over prior detectors while using substantially fewer parameters. The TrashDet family spans 1.2M to 30.5M parameters with mAP50 values between 11.4 and 19.5, providing scalable detector options for diverse TinyML deployment budgets on resource-constrained hardware. On the MAX78002 microcontroller with the TrashNet dataset, two specialized variants, TrashDet-ResNet and TrashDet-MBNet, jointly dominate the ai87-fpndetector baseline, with TrashDet-ResNet achieving 7525~$μ$J energy per inference at 26.7 ms latency and 37.45 FPS, and TrashDet-MBNet improving mAP50 by 10.2%; together they reduce energy consumption by up to 88%, latency by up to 78%, and average power by up to 53% compared to existing TinyML detectors.","authors":["Tony Tran","Bin Hu"],"pdf_url":"","comment":"10 pages. The paper has been accepted by the WACV 2026 workshop"},{"id":"http://arxiv.org/abs/2512.20745v1","updated":"2025-12-23T19:57:49Z","published":"2025-12-23T19:57:49Z","title":"AgentMath: Empowering Mathematical Reasoning for Large Language Models via Tool-Augmented Agent","summary":"Large Reasoning Models (LRMs) like o3 and DeepSeek-R1 have achieved remarkable progress in natural language reasoning with long chain-of-thought. However, they remain computationally inefficient and struggle with accuracy when solving problems requiring complex mathematical operations. In this work, we present AgentMath, an agent framework that seamlessly integrates language models' reasoning capabilities with code interpreters' computational precision to efficiently tackle complex mathematical problems. Our approach introduces three key innovations: (1) An automated method that converts natural language chain-of-thought into structured tool-augmented trajectories, generating high-quality supervised fine-tuning (SFT) data to alleviate data scarcity; (2) A novel agentic reinforcement learning (RL) paradigm that dynamically interleaves natural language generation with real-time code execution. This enables models to autonomously learn optimal tool-use strategies through multi-round interactive feedback, while fostering emergent capabilities in code refinement and error correction; (3) An efficient training system incorporating innovative techniques, including request-level asynchronous rollout scheduling, agentic partial rollout, and prefix-aware weighted load balancing, achieving 4-5x speedup and making efficient RL training feasible on ultra-long sequences with scenarios with massive tool calls.Extensive evaluations show that AgentMath achieves state-of-the-art performance on challenging mathematical competition benchmarks including AIME24, AIME25, and HMMT25. Specifically, AgentMath-30B-A3B attains 90.6%, 86.4%, and 73.8% accuracy respectively, achieving advanced capabilities.These results validate the effectiveness of our approach and pave the way for building more sophisticated and scalable mathematical reasoning agents.","authors":["Haipeng Luo","Huawen Feng","Qingfeng Sun","Can Xu","Kai Zheng","Yufei Wang","Tao Yang","Han Hu","Yansong Tang","Di Wang"],"pdf_url":"","comment":"LLM, Mathematical Reasoning"},{"id":"http://arxiv.org/abs/2507.01020v2","updated":"2025-12-23T19:52:29Z","published":"2025-04-18T08:38:56Z","title":"AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models","summary":"Large Language Models (LLMs) continue to exhibit vulnerabilities to jailbreaking attacks: carefully crafted malicious inputs intended to circumvent safety guardrails and elicit harmful responses. As such, we present AutoAdv, a novel framework that automates adversarial prompt generation to systematically evaluate and expose vulnerabilities in LLM safety mechanisms. Our approach leverages a parametric attacker LLM to produce semantically disguised malicious prompts through strategic rewriting techniques, specialized system prompts, and optimized hyperparameter configurations. The primary contribution of our work is a dynamic, multi-turn attack methodology that analyzes failed jailbreak attempts and iteratively generates refined follow-up prompts, leveraging techniques such as roleplaying, misdirection, and contextual manipulation. We quantitatively evaluate attack success rate (ASR) using the StrongREJECT (arXiv:2402.10260 [cs.CL]) framework across sequential interaction turns. Through extensive empirical evaluation of state-of-the-art models--including ChatGPT, Llama, and DeepSeek--we reveal significant vulnerabilities, with our automated attacks achieving jailbreak success rates of up to 86% for harmful content generation. Our findings reveal that current safety mechanisms remain susceptible to sophisticated multi-turn attacks, emphasizing the urgent need for more robust defense strategies.","authors":["Aashray Reddy","Andrew Zagula","Nicholas Saban"],"pdf_url":"","comment":"We encountered issues with the paper being hosted under my personal account, so we republished it under a different account associated with a university email, which makes updates and management easier. As a result, this version is a duplicate of arXiv:2511.02376"},{"id":"http://arxiv.org/abs/2512.20739v1","updated":"2025-12-23T19:50:13Z","published":"2025-12-23T19:50:13Z","title":"AI-Driven Green Cognitive Radio Networks for Sustainable 6G Communication","summary":"The 6G wireless aims at the Tb/s peak data rates are expected, a sub-millisecond latency, massive Internet of Things/vehicle connectivity, which requires sustainable access to audio over the air and energy-saving functionality. Cognitive Radio Networks CCNs help in alleviating the problem of spectrum scarcity, but classical sensing and allocation are still energy-consumption intensive, and sensitive to rapid spectrum variations. Our framework which centers on AI driven green CRN aims at integrating deep reinforcement learning (DRL) with transfer learning, energy harvesting (EH), reconfigurable intelligent surfaces (RIS) with other light-weight genetic refinement operations that optimally combine sensing timelines, transmit power, bandwidth distribution and RIS phase selection. Compared to two baselines, the utilization of MATLAB + NS-3 under dense loads, a traditional CRN with energy sensing under fixed policies, and a hybrid CRN with cooperative sensing under heuristic distribution of resource, there are (25-30%) fewer energy reserves used, sensing AUC greater than 0.90 and +6-13 p.p. higher PDR. The integrated framework is easily scalable to large IoT and vehicular applications, and it provides a feasible and sustainable roadmap to 6G CRNs.\n  Index Terms--Cognitive Radio Networks (CRNs), 6G, Green Communication, Energy Efficiency, Deep Reinforcement Learning (DRL), Spectrum Sensing, RIS, Energy Harvesting, QoS, IoT.","authors":["Anshul Sharma","Shujaatali Badami","Biky Chouhan","Pushpanjali Pandey","Brijeena Rana","Navneet Kaur"],"pdf_url":"","comment":"10 pages, 8 figures. Full research article with MATLAB and NS-3 simulations"},{"id":"http://arxiv.org/abs/2504.16172v3","updated":"2025-12-23T19:47:25Z","published":"2025-04-22T18:01:45Z","title":"Physics-Informed Inference Time Scaling for Solving High-Dimensional PDE via Defect Correction","summary":"Solving high-dimensional partial differential equations (PDEs) is a critical challenge where modern data-driven solvers often lack reliability and rigorous error guarantees. We introduce Simulation-Calibrated Scientific Machine Learning (SCaSML), a framework that systematically improves pre-trained PDE solvers at inference time without any retraining. Our core idea is to use defect correction method that derive a new PDE, termed Structural-preserving Law of Defect, that precisely describes the error of a given surrogate model. Since it retains the structure of the original problem, we can solve it efficiently with traditional stochastic simulators and correct the initial machine-learned solution. We prove that SCaSML achieves a faster convergence rate, with a final error bounded by the product of the surrogate and simulation errors. On challenging PDEs up to 160 dimensions, SCaSML reduces the error of various surrogate models, including PINNs and Gaussian Processes, by 20-80%. Code of SCaSML is available at https://github.com/Francis-Fan-create/SCaSML.","authors":["Zexi Fan","Yan Sun","Shihao Yang","Yiping Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20732v1","updated":"2025-12-23T19:40:51Z","published":"2025-12-23T19:40:51Z","title":"FEM-Bench: A Structured Scientific Reasoning Benchmark for Evaluating Code-Generating LLMs","summary":"As LLMs advance their reasoning capabilities about the physical world, the absence of rigorous benchmarks for evaluating their ability to generate scientifically valid physical models has become a critical gap. Computational mechanics, which develops and applies mathematical models and numerical methods to predict the behavior of physical systems under forces, deformation, and constraints, provides an ideal foundation for structured scientific reasoning evaluation. Problems follow clear mathematical structure, enforce strict physical and numerical constraints, and support objective verification. The discipline requires constructing explicit models of physical systems and reasoning about geometry, spatial relationships, and material behavior, connecting directly to emerging AI goals in physical reasoning and world modeling. We introduce FEM-Bench, a computational mechanics benchmark designed to evaluate the ability of LLMs to generate correct finite element method (FEM) and related code. FEM-Bench 2025 contains a suite of introductory but nontrivial tasks aligned with material from a first graduate course on computational mechanics. These tasks capture essential numerical and physical modeling challenges while representing only a small fraction of the complexity present in the discipline. Despite their simplicity, state-of-the-art LLMs do not reliably solve all of them. In a five attempt run, the best performing model at function writing, Gemini 3 Pro, completed 30/33 tasks at least once and 26/33 tasks all five times. The best performing model at unit test writing, GPT-5, had an Average Joint Success Rate of 73.8%. Other popular models showed broad performance variation. FEM-Bench establishes a structured foundation for evaluating AI-generated scientific code, and future iterations will incorporate increasingly sophisticated tasks to track progress as models evolve.","authors":["Saeed Mohammadzadeh","Erfan Hamdi","Joel Shor","Emma Lejeune"],"pdf_url":"","comment":"40 pages, 5 figures, 6 tables, 7 listings"},{"id":"http://arxiv.org/abs/2512.20712v1","updated":"2025-12-23T19:19:45Z","published":"2025-12-23T19:19:45Z","title":"Real-World Adversarial Attacks on RF-Based Drone Detectors","summary":"Radio frequency (RF) based systems are increasingly used to detect drones by analyzing their RF signal patterns, converting them into spectrogram images which are processed by object detection models. Existing RF attacks against image based models alter digital features, making over-the-air (OTA) implementation difficult due to the challenge of converting digital perturbations to transmittable waveforms that may introduce synchronization errors and interference, and encounter hardware limitations. We present the first physical attack on RF image based drone detectors, optimizing class-specific universal complex baseband (I/Q) perturbation waveforms that are transmitted alongside legitimate communications. We evaluated the attack using RF recordings and OTA experiments with four types of drones. Our results show that modest, structured I/Q perturbations are compatible with standard RF chains and reliably reduce target drone detection while preserving detection of legitimate drones.","authors":["Omer Gazit","Yael Itzhakev","Yuval Elovici","Asaf Shabtai"],"pdf_url":"","comment":null}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2512.20571v1","updated":"2025-12-23T18:16:24Z","published":"2025-12-23T18:16:24Z","title":"Composing Mini Oscilloscope on Embedded Systems","summary":"In this paper, our goal is to reproduce the basic functionalities of a regular oscilloscope, using the Nuvoton NUC-140 embedded systems development platform as the front-end and display method. A custom-built daughter board connects the NUC-140 to a variety of peripherals, including two BNC scope-probe connections, an external nine-button keypad, and a calibration signal. The LCD of the NUC-140 development board serves as the waveform display. From the experimental results, it is demonstrated that our proposed system became a very competent debugging tool. It implements 90% of the features we typically use on original oscilloscopes, including: automatic, edge-triggered, and single modes; waveform visualization using vertical and horizontal scaling; probe calibration.","authors":["Brennan Romero","D. G. Perera"],"pdf_url":"","comment":"22 pages, 11 figures"},{"id":"http://arxiv.org/abs/2512.20495v1","updated":"2025-12-23T16:42:14Z","published":"2025-12-23T16:42:14Z","title":"Nebula: Enable City-Scale 3D Gaussian Splatting in Virtual Reality via Collaborative Rendering and Accelerated Stereo Rasterization","summary":"3D Gaussian splatting (3DGS) has drawn significant attention in the architectural community recently. However, current architectural designs often overlook the 3DGS scalability, making them fragile for extremely large-scale 3DGS. Meanwhile, the VR bandwidth requirement makes it impossible to deliver high-fidelity and smooth VR content from the cloud.\n  We present Nebula, a coherent acceleration framework for large-scale 3DGS collaborative rendering. Instead of streaming videos, Nebula streams intermediate results after the LoD search, reducing 1925% data communication between the cloud and the client. To further enhance the motion-to-photon experience, we introduce a temporal-aware LoD search in the cloud that tames the irregular memory access and reduces redundant data access by exploiting temporal coherence across frames. On the client side, we propose a novel stereo rasterization that enables two eyes to share most computations during the stereo rendering with bit-accurate quality. With minimal hardware augmentations, Nebula achieves 2.7$\\times$ motion-to-photon speedup and reduces 1925% bandwidth over lossy video streaming.","authors":["He Zhu","Zheng Liu","Xingyang Li","Anbang Wu","Jieru Zhao","Fangxin Liu","Yiming Gan","Jingwen Leng","Yu Feng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20198v1","updated":"2025-12-23T09:43:32Z","published":"2025-12-23T09:43:32Z","title":"Designing Spatial Architectures for Sparse Attention: STAR Accelerator via Cross-Stage Tiling","summary":"Large language models (LLMs) rely on self-attention for contextual understanding, demanding high-throughput inference and large-scale token parallelism (LTPP). Existing dynamic sparsity accelerators falter under LTPP scenarios due to stage-isolated optimizations. Revisiting the end-to-end sparsity acceleration flow, we identify an overlooked opportunity: cross-stage coordination can substantially reduce redundant computation and memory access. We propose STAR, a cross-stage compute- and memory-efficient algorithm-hardware co-design tailored for Transformer inference under LTPP. STAR introduces a leading-zero-based sparsity prediction using log-domain add-only operations to minimize prediction overhead. It further employs distributed sorting and a sorted updating FlashAttention mechanism, guided by a coordinated tiling strategy that enables fine-grained stage interaction for improved memory efficiency and latency. These optimizations are supported by a dedicated STAR accelerator architecture, achieving up to 9.2$\\times$ speedup and 71.2$\\times$ energy efficiency over A100, and surpassing SOTA accelerators by up to 16.1$\\times$ energy and 27.1$\\times$ area efficiency gains. Further, we deploy STAR onto a multi-core spatial architecture, optimizing dataflow and execution orchestration for ultra-long sequence processing. Architectural evaluation shows that, compared to the baseline design, Spatial-STAR achieves a 20.1$\\times$ throughput improvement.","authors":["Huizheng Wang","Taiquan Wei","Hongbin Wang","Zichuan Wang","Xinru Tang","Zhiheng Yue","Shaojun Wei","Yang Hu","Shouyi Yin"],"pdf_url":"","comment":"Accepted for publication in IEEE Transactions on Computers"},{"id":"http://arxiv.org/abs/2512.17814v2","updated":"2025-12-23T08:00:41Z","published":"2025-12-19T17:19:08Z","title":"LLM-based Behaviour Driven Development for Hardware Design","summary":"Test and verification are essential activities in hardware and system design, but their complexity grows significantly with increasing system sizes. While Behavior Driven Development (BDD) has proven effective in software engineering, it is not yet well established in hardware design, and its practical use remains limited. One contributing factor is the manual effort required to derive precise behavioral scenarios from textual specifications.\n  Recent advances in Large Language Models (LLMs) offer new opportunities to automate this step. In this paper, we investigate the use of LLM-based techniques to support BDD in the context of hardware design.","authors":["Rolf Drechsler","Qian Liu"],"pdf_url":"","comment":"7 pages, keynote given at 2nd International Symposium on Artificial Intelligence and Internet of Things (AIIoT-25), December 22-24th, 2025"},{"id":"http://arxiv.org/abs/2512.20073v1","updated":"2025-12-23T05:55:55Z","published":"2025-12-23T05:55:55Z","title":"3D Stack In-Sensor-Computing (3DS-ISC): Accelerating Time-Surface Construction for Neuromorphic Event Cameras","summary":"This work proposes a 3D Stack In-Sensor-Computing (3DS-ISC) architecture for efficient event-based vision processing. A real-time normalization method using an exponential decay function is introduced to construct the time-surface, reducing hardware usage while preserving temporal information. The circuit design utilizes the leakage characterization of Dynamic Random Access Memory(DRAM) for timestamp normalization. Custom interdigitated metal-oxide-metal capacitor (MOMCAP) is used to store the charge and low leakage switch (LL switch) is used to extend the effective charge storage time. The 3DS-ISC architecture integrates sensing, memory, and computation to overcome the memory wall problem, reducing power, latency, and reducing area by 69x, 2.2x and 1.9x, respectively, compared with its 2D counterpart. Moreover, compared to works using a 16-bit SRAM to store timestamps, the ISC analog array can reduce power consumption by three orders of magnitude. In real computer vision (CV) tasks, we applied the spatial-temporal correlation filter (STCF) for denoise, and 3D-ISC achieved almost equivalent accuracy compared to the digital implementation using high precision timestamps. As for the image classification, time-surface constructed by 3D-ISC is used as the input of GoogleNet, achieving 99% on N-MNIST, 85% on N-Caltech101, 78% on CIFAR10-DVS, and 97% on DVS128 Gesture, comparable with state-of-the-art results on each dataset. Additionally, the 3D-ISC method is also applied to image reconstruction using the DAVIS240C dataset, achieving the highest average SSIM (0.62) among three methods. This work establishes a foundation for real-time, resource-efficient event-based processing and points to future integration of advanced computational circuits for broader applications.","authors":["Hongyang Shang","Shuai Dong","Ye Ke","Arindam Basu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.09343v2","updated":"2025-12-23T03:00:00Z","published":"2025-05-14T12:39:03Z","title":"Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures","summary":"The rapid scaling of large language models (LLMs) has unveiled critical limitations in current hardware architectures, including constraints in memory capacity, computational efficiency, and interconnection bandwidth. DeepSeek-V3, trained on 2,048 NVIDIA H800 GPUs, demonstrates how hardware-aware model co-design can effectively address these challenges, enabling cost-efficient training and inference at scale. This paper presents an in-depth analysis of the DeepSeek-V3/R1 model architecture and its AI infrastructure, highlighting key innovations such as Multi-head Latent Attention (MLA) for enhanced memory efficiency, Mixture of Experts (MoE) architectures for optimized computation-communication trade-offs, FP8 mixed-precision training to unlock the full potential of hardware capabilities, and a Multi-Plane Network Topology to minimize cluster-level network overhead. Building on the hardware bottlenecks encountered during DeepSeek-V3's development, we engage in a broader discussion with academic and industry peers on potential future hardware directions, including precise low-precision computation units, scale-up and scale-out convergence, and innovations in low-latency communication fabrics. These insights underscore the critical role of hardware and model co-design in meeting the escalating demands of AI workloads, offering a practical blueprint for innovation in next-generation AI systems.","authors":["Chenggang Zhao","Chengqi Deng","Chong Ruan","Damai Dai","Huazuo Gao","Jiashi Li","Liyue Zhang","Panpan Huang","Shangyan Zhou","Shirong Ma","Wenfeng Liang","Ying He","Yuqing Wang","Yuxuan Liu","Y. X. Wei"],"pdf_url":"","comment":"This is the author's version of the work. It is posted here for your personal use. Not for redistribution. The definitive version appeared as part of the Industry Track in Proceedings of the 52nd Annual International Symposium on Computer Architecture (ISCA '25)"},{"id":"http://arxiv.org/abs/2512.20823v1","updated":"2025-12-23T22:53:47Z","published":"2025-12-23T22:53:47Z","title":"NotSoTiny: A Large, Living Benchmark for RTL Code Generation","summary":"LLMs have shown early promise in generating RTL code, yet evaluating their capabilities in realistic setups remains a challenge. So far, RTL benchmarks have been limited in scale, skewed toward trivial designs, offering minimal verification rigor, and remaining vulnerable to data contamination. To overcome these limitations and to push the field forward, this paper introduces NotSoTiny, a benchmark that assesses LLM on the generation of structurally rich and context-aware RTL. Built from hundreds of actual hardware designs produced by the Tiny Tapeout community, our automated pipeline removes duplicates, verifies correctness and periodically incorporates new designs to mitigate contamination, matching Tiny Tapeout release schedule. Evaluation results show that NotSoTiny tasks are more challenging than prior benchmarks, emphasizing its effectiveness in overcoming current limitations of LLMs applied to hardware design, and in guiding the improvement of such promising technology.","authors":["Razine Moundir Ghorab","Emanuele Parisi","Cristian Gutierrez","Miquel Alberti-Binimelis","Miquel Moreto","Dario Garcia-Gasulla","Gokcen Kestor"],"pdf_url":"","comment":"9 pages, 5 figures"}],"Software Engineering":[{"id":"http://arxiv.org/abs/2512.20482v1","updated":"2025-12-23T16:18:39Z","published":"2025-12-23T16:18:39Z","title":"SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization","summary":"Maintaining large-scale, multilingual codebases hinges on accurately localizing issues, which requires mapping natural-language error descriptions to the relevant functions that need to be modified. However, existing ranking approaches are often Python-centric and perform a single-pass search over the codebase. This work introduces SweRank+, a framework that couples SweRankMulti, a cross-lingual code ranking tool, with SweRankAgent, an agentic search setup, for iterative, multi-turn reasoning over the code repository. SweRankMulti comprises a code embedding retriever and a listwise LLM reranker, and is trained using a carefully curated large-scale issue localization dataset spanning multiple popular programming languages. SweRankAgent adopts an agentic search loop that moves beyond single-shot localization with a memory buffer to reason and accumulate relevant localization candidates over multiple turns. Our experiments on issue localization benchmarks spanning various languages demonstrate new state-of-the-art performance with SweRankMulti, while SweRankAgent further improves localization over single-pass ranking.","authors":["Revanth Gangi Reddy","Ye Liu","Wenting Zhao","JaeHyeok Doo","Tarun Suresh","Daniel Lee","Caiming Xiong","Yingbo Zhou","Semih Yavuz","Shafiq Joty"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21878v2","updated":"2025-12-23T15:17:24Z","published":"2025-11-26T19:53:46Z","title":"Advancing Automated In-Isolation Validation in Repository-Level Code Translation","summary":"Repository-level code translation aims to migrate entire repositories across programming languages while preserving functionality automatically. Despite advancements in repository-level code translation, validating the translations remains challenging. This paper proposes TRAM, which combines context-aware type resolution with mock-based in-isolation validation to achieve high-quality translations between programming languages. Prior to translation, TRAM retrieves API documentation and contextual code information for each variable type in the source language. It then prompts a large language model (LLM) with retrieved contextual information to resolve type mappings across languages with precise semantic interpretations. Using the automatically constructed type mapping, TRAM employs a custom serialization/deserialization workflow that automatically constructs equivalent mock objects in the target language. This enables each method fragment to be validated in isolation, without the high cost of using agents for translation validation, or the heavy manual effort required by existing approaches that rely on language interoperability. TRAM demonstrates state-of-the-art performance in Java-to-Python translation, underscoring the effectiveness of its integration of RAG-based type resolution with reliable in-isolation validation.","authors":["Kaiyao Ke","Ali Reza Ibrahimzada","Rangeet Pan","Saurabh Sinha","Reyhaneh Jabbarvand"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20402v1","updated":"2025-12-23T14:43:03Z","published":"2025-12-23T14:43:03Z","title":"iblock: Accurate and Scalable Bitcoin Simulations with OMNeT++","summary":"This paper proposes iblock, a comprehensive C++ library for Bitcoin simulation, designed for OMNeT++. iblock offers superior efficiency and scalability with respect to state-of-the-art simulators, which are typically written in high-level languages. Moreover, the possible integration with other OMNeT++ libraries allows highly detailed simulations. We measure iblock's performance against a state-of-the-art blockchain simulator, proving that it is more efficient at the same level of simulation detail. We also validate iblock by using it to simulate different scenarios such as the normal Bitcoin operation and the selfish mine attack, showing that simulation results are coherent with theoretical expectations.","authors":["Niccolò Scatena","Pericle Perazzo","Giovanni Nardini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20396v1","updated":"2025-12-23T14:33:31Z","published":"2025-12-23T14:33:31Z","title":"Symmaries: Automatic Inference of Formal Security Summaries for Java Programs","summary":"We introduce a scalable, modular, and sound approach for automatically constructing formal security specifications for Java bytecode programs in the form of method summaries. A summary provides an abstract representation of a method's security behavior, consisting of the conditions under which the method can be securely invoked, together with specifications of information flows and aliasing updates. Such summaries can be consumed by static code analysis tools and also help developers understand the behavior of code segments, such as libraries, in order to evaluate their security implications when reused in applications. Our approach is implemented in a tool called Symmaries, which automates the generation of security summaries. We applied Symmaries to Java API libraries to extract their security specifications and to large real-world applications to evaluate its scalability. Our results show that the tool successfully scales to analyze applications with hundreds of thousands of lines of code, and that Symmaries achieves a promising precision depending on the heap model used. We prove the soundness of our approach in terms of guaranteeing termination-insensitive non-interference.","authors":["Narges Khakpour","Nicolas Berthier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20381v1","updated":"2025-12-23T14:12:02Z","published":"2025-12-23T14:12:02Z","title":"Identifying Appropriately-Sized Services with Deep Reinforcement Learning","summary":"Service-based architecture (SBA) has gained attention in industry and academia as a means to modernize legacy systems. It refers to a design style that enables systems to be developed as suites of small, loosely coupled, and autonomous components (services) that encapsulate functionality and communicate via language-agnostic APIs. However, defining appropriately sized services that capture cohesive subsets of system functionality remains challenging. Existing work often relies on the availability of documentation, access to project personnel, or a priori knowledge of the target number of services, assumptions that do not hold in many real-world scenarios. Our work addresses these limitations using a deep reinforcement learning-based approach to identify appropriately sized services directly from implementation artifacts. We present Rake, a reinforcement learning-based technique that leverages available system documentation and source code to guide service decomposition at the level of implementation methods. Rake does not require specific documentation or access to project personnel and is language-agnostic. It also supports a customizable objective function that balances modularization quality and business capability alignment, i.e., the degree to which a service covers the targeted business capability. We applied Rake to four open-source legacy projects and compared it with two state-of-the-art techniques. On average, Rake achieved 7-14 percent higher modularization quality and 18-22 percent stronger business capability alignment. Our results further show that optimizing solely for business context can degrade decomposition quality in tightly coupled systems, highlighting the need for balanced objectives.","authors":["Syeda Tasnim Fabiha","Saad Shafiq","Wesley Klewerton Guez Assunção","Nenad Medvidović"],"pdf_url":"","comment":"22 pages, 6 figures"},{"id":"http://arxiv.org/abs/2512.20345v1","updated":"2025-12-23T13:27:05Z","published":"2025-12-23T13:27:05Z","title":"A Comprehensive Study of Bugs in Modern Distributed Deep Learning Systems","summary":"In today's data-driven era, deep learning is vital for processing massive datasets, yet single-device training is constrained by computational and memory limits. Distributed deep learning overcomes these challenges by leveraging multiple GPUs or machines in parallel. While general-purpose frameworks (e.g., TensorFlow and PyTorch) provide distributed capabilities, these are often add-on features that demand significant manual effort for advanced parallelism, underscoring the need for specialized frameworks. This study conducts the first large-scale empirical analysis of practitioner challenges in dedicated distributed frameworks. We examine 849 real-world issues from DeepSpeed, Megatron-LM, and Colossal-AI and construct a taxonomy of 34 bug symptoms, 28 root causes, and 6 fix patterns. Crucially, we establish explicit mappings between symptoms, causes, and fixes across distributed training stages, enabling a systematic understanding of how issues emerge and are resolved. Our results show that 45.1\\% of bug symptoms are unique to distributed frameworks, with setup failures, memory issues, and performance anomalies being the most prevalent. Moreover, 95\\% of issues in the communication setup stage occur exclusively in distributed contexts. We also find over 60\\% of cases can be resolved through version and dependency management, and distributed feature, API, and communication tuning. Based on these findings, we provide actionable implications.","authors":["Xiaoxue Ma","Wanwei Zhan","Jiale Chen","Yishu Li","Jacky Keung","Federica Sarro"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20334v1","updated":"2025-12-23T13:08:19Z","published":"2025-12-23T13:08:19Z","title":"Comment Traps: How Defective Commented-out Code Augment Defects in AI-Assisted Code Generation","summary":"With the rapid development of large language models in code generation, AI-powered editors such as GitHub Copilot and Cursor are revolutionizing software development practices. At the same time, studies have identified potential defects in the generated code. Previous research has predominantly examined how code context influences the generation of defective code, often overlooking the impact of defects within commented-out code (CO code). AI coding assistants' interpretation of CO code in prompts affects the code they generate.\n  This study evaluates how AI coding assistants, GitHub Copilot and Cursor, are influenced by defective CO code. The experimental results show that defective CO code in the context causes AI coding assistants to generate more defective code, reaching up to 58.17 percent. Our findings further demonstrate that the tools do not simply copy the defective code from the context. Instead, they actively reason to complete incomplete defect patterns and continue to produce defective code despite distractions such as incorrect indentation or tags. Even with explicit instructions to ignore the defective CO code, the reduction in defects does not exceed 21.84 percent. These findings underscore the need for improved robustness and security measures in AI coding assistants.","authors":["Yuan Huang","Yukang Zhou","Xiangping Chen","Zibin Zheng"],"pdf_url":"","comment":"This paper has been accepted by FSE 2026 (ACM International Conference on the Foundations of Software Engineering). This is a preprint version and may differ from the final published version"},{"id":"http://arxiv.org/abs/2512.20328v1","updated":"2025-12-23T12:56:18Z","published":"2025-12-23T12:56:18Z","title":"Toward Explaining Large Language Models in Software Engineering Tasks","summary":"Recent progress in Large Language Models (LLMs) has substantially advanced the automation of software engineering (SE) tasks, enabling complex activities such as code generation and code summarization. However, the black-box nature of LLMs remains a major barrier to their adoption in high-stakes and safety-critical domains, where explainability and transparency are vital for trust, accountability, and effective human supervision. Despite increasing interest in explainable AI for software engineering, existing methods lack domain-specific explanations aligned with how practitioners reason about SE artifacts. To address this gap, we introduce FeatureSHAP, the first fully automated, model-agnostic explainability framework tailored to software engineering tasks. Based on Shapley values, FeatureSHAP attributes model outputs to high-level input features through systematic input perturbation and task-specific similarity comparisons, while remaining compatible with both open-source and proprietary LLMs. We evaluate FeatureSHAP on two bi-modal SE tasks: code generation and code summarization. The results show that FeatureSHAP assigns less importance to irrelevant input features and produces explanations with higher fidelity than baseline methods. A practitioner survey involving 37 participants shows that FeatureSHAP helps practitioners better interpret model outputs and make more informed decisions. Collectively, FeatureSHAP represents a meaningful step toward practical explainable AI in software engineering. FeatureSHAP is available at https://github.com/deviserlab/FeatureSHAP.","authors":["Antonio Vitale","Khai-Nguyen Nguyen","Denys Poshyvanyk","Rocco Oliveto","Simone Scalabrino","Antonio Mastropaolo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20279v1","updated":"2025-12-23T11:35:30Z","published":"2025-12-23T11:35:30Z","title":"Auditing Reproducibility in Non-Targeted Analysis: 103 LC/GC--HRMS Tools Reveal Temporal Divergence Between Openness and Operability","summary":"In 2008, melamine in infant formula forced laboratories across three continents to verify a compound they had never monitored. Non-targeted analysis using LC/GC-HRMS handles these cases. But when findings trigger regulatory action, reproducibility becomes operational: can an independent laboratory repeat the analysis and reach the same conclusion?\n  We assessed 103 tools (2004-2025) against six pillars drawn from FAIR and BP4NTA principles: laboratory validation (C1), data availability (C2), code availability (C3), standardised formats (C4), knowledge integration (C5), and portable implementation (C6). Health contributed 51 tools, Pharma 31, and Chemistry 21.\n  Nine in ten tools shared data (C2, 90/103, 87%). Fewer than four in ten supported portable implementations (C6, 40/103, 39%). Validation and portability rarely appeared together (C1+C6, 18/103, 17%). Over twenty-one years, openness climbed from 56% to 86% while operability dropped from 55% to 43%. No tool addressed food safety.\n  Journal data-sharing policies increased what authors share but not what reviewers can run. Tools became easier to find but harder to execute. Strengthening C1, C4, and C6 would turn documented artifacts into workflows that external laboratories can replay.","authors":["Sarah Alsubaie","Sakhaa Alsaedi","Xin Gao"],"pdf_url":"","comment":"26 pages, 6 figures, submitted to Journal of Cheminformatics"},{"id":"http://arxiv.org/abs/2512.20245v1","updated":"2025-12-23T10:55:32Z","published":"2025-12-23T10:55:32Z","title":"Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds","summary":"The memory of contemporary Large Language Models is bound by a physical paradox: as they learn, they fill up. The linear accumulation (O(N)) of Key-Value states treats context as a warehouse of static artifacts, eventually forcing a destructive choice between amnesia and latency. We challenge this discrete orthodoxy, proposing that long-term memory is not the storage of items, but the persistence of a trajectory. We introduce Phonetic Trajectory Memory (PTM), a neuro-symbolic architecture that encodes language not as a sequence of tensors, but as a continuous path on an ergodic manifold governed by irrational rotation matrices. By decoupling the navigation (an invariant O(1) geometric signal) from the reconstruction (a probabilistic generative act), PTM achieves a compression magnitude of greater than 3,000x relative to dense caches. We demonstrate that retrieval becomes a process of resonance: the phonetic trace stabilizes the model against hallucination via \"Signal Consensus\" mechanism, securing up to approximately 92% factual accuracy. While this aggressive abstraction alters generative texture, it unlocks immediate access latency (approximately 34ms) independent of depth. Our results suggest that infinite context does not require infinite silicon; it requires treating memory not as data to be stored, but as a reconstructive process acting on a conserved, undying physical signal.","authors":["Tarik Houichime","Abdelghani Souhar","Younes El Amrani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18261v2","updated":"2025-12-23T10:10:18Z","published":"2025-12-20T07:58:35Z","title":"Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective","summary":"Artificial Intelligence (AI) has revolutionized software development, particularly by automating repetitive tasks and improving developer productivity. While these advancements are well-documented, the use of AI-powered tools for Software Vulnerability Management (SVM), such as vulnerability detection and repair, remains underexplored in industry settings. To bridge this gap, our study aims to determine the extent of the adoption of AI-powered tools for SVM, identify barriers and facilitators to the use, and gather insights to help improve the tools to meet industry needs better. We conducted a survey study involving 60 practitioners from diverse industry sectors across 27 countries. The survey incorporates both quantitative and qualitative questions to analyze the adoption trends, assess tool strengths, identify practical challenges, and uncover opportunities for improvement. Our findings indicate that AI-powered tools are used throughout the SVM life cycle, with 69% of users reporting satisfaction with their current use. Practitioners value these tools for their speed, coverage, and accessibility. However, concerns about false positives, missing context, and trust issues remain prevalent. We observe a socio-technical adoption pattern in which AI outputs are filtered through human oversight and organizational governance. To support safe and effective use of AI for SVM, we recommend improvements in explainability, contextual awareness, integration workflows, and validation practices. We assert that these findings can offer practical guidance for practitioners, tool developers, and researchers seeking to enhance secure software development through the use of AI.","authors":["M. Mehdi Kholoosi","Triet Huynh Minh Le","M. Ali Babar"],"pdf_url":"","comment":"Accepted at the 48th IEEE/ACM International Conference on Software Engineering (ICSE 2026) - Research Track"},{"id":"http://arxiv.org/abs/2512.20203v1","updated":"2025-12-23T09:54:22Z","published":"2025-12-23T09:54:22Z","title":"Well Begun is Half Done: Location-Aware and Trace-Guided Iterative Automated Vulnerability Repair","summary":"The advances of large language models (LLMs) have paved the way for automated software vulnerability repair approaches, which iteratively refine the patch until it becomes plausible. Nevertheless, existing LLM-based vulnerability repair approaches face notable limitations: 1) they ignore the concern of locations that need to be patched and focus solely on the repair content. 2) they lack quality assessment for generated candidate patches in the iterative process.\n  To tackle the two limitations, we propose \\sysname, an LLM-based approach that provides information about where should be patched first. Furthermore, \\sysname improves the iterative repair strategy by assessing the quality of test-failing patches and selecting the best patch for the next iteration. We introduce two dimensions to assess the quality of patches: whether they introduce new vulnerabilities and the taint statement coverage. We evaluated \\sysname on a real-world C/C++ vulnerability repair dataset VulnLoc+, which contains 40 vulnerabilities and their Proofs-of-Vulnerability. The experimental results demonstrate that \\sysname exhibits substantial improvements compared with the Neural Machine Translation-based, Program Analysis-based, and LLM-based state-of-the-art vulnerability repair approaches. Specifically, \\sysname is able to generate 27 plausible patches, which is comparable to or even 8 to 22 more plausible patches than the baselines. In terms of correct patch generation, \\sysname repairs 8 to 13 additional vulnerabilities compared with existing approaches.","authors":["Zhenlei Ye","Xiaobing Sun","Sicong Cao","Lili Bo","Bin Li"],"pdf_url":"","comment":"Accepted by ICSE 2026"},{"id":"http://arxiv.org/abs/2510.04711v2","updated":"2025-12-23T09:28:44Z","published":"2025-10-06T11:30:03Z","title":"Rethinking the Evaluation of Microservice RCA with a Fault Propagation-Aware Benchmark","summary":"While cloud-native microservice architectures have revolutionized software development, their inherent operational complexity makes failure Root Cause Analysis (RCA) a critical yet challenging task. Numerous data-driven RCA models have been proposed to address this challenge. However, we find that the benchmarks used to evaluate these models are often too simple to reflect real-world scenarios. Our preliminary study reveals that simple rule-based methods can achieve performance comparable to or even surpassing state-of-the-art (SOTA) models on four widely used public benchmarks. This finding suggests that the oversimplification of existing benchmarks might lead to an overestimation of the performance of RCA methods. To further investigate the oversimplification issue, we conduct a systematic analysis of popular public RCA benchmarks, identifying key limitations in their fault injection strategies, call graph structures, and telemetry signal patterns. Based on these insights, we propose an automated framework for generating more challenging and comprehensive benchmarks that include complex fault propagation scenarios. Our new dataset contains 1,430 validated failure cases from 9,152 fault injections, covering 25 fault types across 6 categories, dynamic workloads, and hierarchical ground-truth labels that map failures from services down to code-level causes. Crucially, to ensure the failure cases are relevant to IT operations, each case is validated to have a discernible impact on user-facing SLIs. Our re-evaluation of 11 SOTA models on this new benchmark shows that they achieve low Top@1 accuracies, averaging 0.21, with the best-performing model reaching merely 0.37, and execution times escalating from seconds to hours.","authors":["Aoyang Fang","Songhan Zhang","Yifan Yang","Haotong Wu","Junjielong Xu","Xuyang Wang","Rui Wang","Manyi Wang","Qisheng Lu","Pinjia He"],"pdf_url":"","comment":"directly accepted by FSE'26, 87/920. project page: https://operationspai.github.io/revisiting-rca-evaluation/; dataset: https://doi.org/10.5281/zenodo.17105974"},{"id":"http://arxiv.org/abs/2512.20159v1","updated":"2025-12-23T08:39:22Z","published":"2025-12-23T08:39:22Z","title":"AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration","summary":"Large language models (LLMs) have been increasingly deployed in real-world software engineering, fostering the development of code evaluation metrics to study the quality of LLM-generated code. Conventional rule-based metrics merely score programs based on their surface-level similarities with reference programs instead of analyzing functionality and code quality in depth. To address this limitation, researchers have developed LLM-as-a-judge metrics, prompting LLMs to evaluate and score code, and curated various code evaluation benchmarks to validate their effectiveness. However, these benchmarks suffer from critical limitations, hindering reliable assessments of evaluation capability: Some feature coarse-grained binary labels, which reduce rich code behavior to a single bit of information, obscuring subtle errors. Others propose fine-grained but subjective, vaguely-defined evaluation criteria, introducing unreliability in manually-annotated scores, which is the ground-truth they rely on. Furthermore, they often use uncontrolled data synthesis methods, leading to unbalanced score distributions that poorly represent real-world code generation scenarios.\n  To curate a diverse benchmark with programs of well-balanced distributions across various quality levels and streamline the manual annotation procedure, we propose AXIOM, a novel perturbation-based framework for synthesizing code evaluation benchmarks at scale. It reframes program scores as the refinement effort needed for deployment, consisting of two stages: (1) Rule-guided perturbation, which prompts LLMs to apply sequences of predefined perturbation rules to existing high-quality programs to modify their functionality and code quality, enabling us to precisely control each program's target score to achieve balanced score distributions. (2) Multisource quality calibration, which first selects a subset of...","authors":["Ruiqi Wang","Xinchen Wang","Cuiyun Gao","Chun Yong Chong","Xin Xia","Qing Liao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17814v2","updated":"2025-12-23T08:00:41Z","published":"2025-12-19T17:19:08Z","title":"LLM-based Behaviour Driven Development for Hardware Design","summary":"Test and verification are essential activities in hardware and system design, but their complexity grows significantly with increasing system sizes. While Behavior Driven Development (BDD) has proven effective in software engineering, it is not yet well established in hardware design, and its practical use remains limited. One contributing factor is the manual effort required to derive precise behavioral scenarios from textual specifications.\n  Recent advances in Large Language Models (LLMs) offer new opportunities to automate this step. In this paper, we investigate the use of LLM-based techniques to support BDD in the context of hardware design.","authors":["Rolf Drechsler","Qian Liu"],"pdf_url":"","comment":"7 pages, keynote given at 2nd International Symposium on Artificial Intelligence and Internet of Things (AIIoT-25), December 22-24th, 2025"},{"id":"http://arxiv.org/abs/2510.06187v3","updated":"2025-12-23T07:41:07Z","published":"2025-10-07T17:46:33Z","title":"Automated Program Repair of Uncompilable Student Code","summary":"A significant portion of student programming submissions in CS1 learning environments are uncompilable, limiting their use in student modeling and downstream knowledge tracing. Traditional modeling pipelines often exclude these cases, discarding observations of student learning. This study investigates automated program repair as a strategy to recover uncompilable code while preserving students' structural intent for use in student modeling. Within this framework, we assess large language models (LLMs) as repair agents under high- and low-context prompting conditions. Repairs were evaluated for compilability, edit distance, and preservation of students' original structure and logic. While all models produced compilable repairs, they differed in how well they preserve students' control flow and code structure, affecting their pedagogical utility. By recovering uncompilable submissions, this work enables richer and more comprehensive analyses of learners' coding processes and development over time.","authors":["Griffin Pitts","Aum Pandya","Darsh Rank","Tirth Bhatt","Muntasir Hoq","Bita Akram"],"pdf_url":"","comment":"In Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2 (SIGCSE TS 2026)"},{"id":"http://arxiv.org/abs/2512.20083v1","updated":"2025-12-23T06:27:18Z","published":"2025-12-23T06:27:18Z","title":"Detecting Non-Optimal Decisions of Embodied Agents via Diversity-Guided Metamorphic Testing","summary":"As embodied agents advance toward real-world deployment, ensuring optimal decisions becomes critical for resource-constrained applications. Current evaluation methods focus primarily on functional correctness, overlooking the non-functional optimality of generated plans. This gap can lead to significant performance degradation and resource waste. We identify and formalize the problem of Non-optimal Decisions (NoDs), where agents complete tasks successfully but inefficiently. We present NoD-DGMT, a systematic framework for detecting NoDs in embodied agent task planning via diversity-guided metamorphic testing. Our key insight is that optimal planners should exhibit invariant behavioral properties under specific transformations. We design four novel metamorphic relations capturing fundamental optimality properties: position detour suboptimality, action optimality completeness, condition refinement monotonicity, and scene perturbation invariance. To maximize detection efficiency, we introduce a diversity-guided selection strategy that actively selects test cases exploring different violation categories, avoiding redundant evaluations while ensuring comprehensive diversity coverage. Extensive experiments on the AI2-THOR simulator with four state-of-the-art planning models demonstrate that NoD-DGMT achieves violation detection rates of 31.9% on average, with our diversity-guided filter improving rates by 4.3% and diversity scores by 3.3 on average. NoD-DGMT significantly outperforms six baseline methods, with 16.8% relative improvement over the best baseline, and demonstrates consistent superiority across different model architectures and task complexities.","authors":["Wenzhao Wu","Yahui Tang","Mingfei Cheng","Wenbing Tang","Yuan Zhou","Yang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19997v1","updated":"2025-12-23T02:45:36Z","published":"2025-12-23T02:45:36Z","title":"BacAlarm: Mining and Simulating Composite API Traffic to Prevent Broken Access Control Violations","summary":"Broken Access Control (BAC) violations, which consistently rank among the top five security risks in the OWASP API Security Top 10, refer to unauthorized access attempts arising from BAC vulnerabilities, whose successful exploitation can impose significant risks on exposed application programming interfaces (APIs). In recent years, learning-based methods have demonstrated promising prospects in detecting various types of malicious activities. However, in real-network operation and maintenance scenarios, leveraging learning-based methods for BAC detection faces two critical challenges. Firstly, under the RESTful API design principles, most systems omit recording composite traffic for performance, and together with ethical and legal bans on directly testing real-world systems, this leads to a critical shortage of training data for detecting BAC violations. Secondly, common malicious behaviors such as SQL injection typically generate individual access traffic that is inherently anomalous. In contrast, BAC is usually composed of multiple correlated access requests that appear normal when examined in isolation. To tackle these problems, we introduce \\BAC, an approach for establishing a BAC violation detection model by generating and utilizing API traffic data. The \\BAC consists of an API Traffic Generator and a BAC Detector. Experimental results show that \\BAC outperforms current state-of-the-art invariant-based and learning-based methods with the $\\text{F}_1$ and MCC improving by 21.2\\% and 24.1\\%.","authors":["Yanjing Yang","He Zhang","Bohan Liu","Jinwei Xu","Jinghao Hu","Liming Dong","Zhewen Mao","Dongxue Pan"],"pdf_url":"","comment":"The full version of this work consists of 15 pages and has been submitted to IEEE Transactions on Software Engineering (TSE)"},{"id":"http://arxiv.org/abs/2512.19980v1","updated":"2025-12-23T02:04:13Z","published":"2025-12-23T02:04:13Z","title":"Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?","summary":"Code language models excel on code intelligence tasks, yet their internal interpretability is underexplored. Existing neuron interpretability techniques from NLP are suboptimal for source code due to programming languages formal, hierarchical, and executable nature. We empirically investigate code LLMs at the neuron level, localizing language-specific neurons (selectively responsive to one language) and concept layers (feed-forward layers encoding language-agnostic code representations). We analyze Llama-3.1-8B and Qwen2.5-Coder-32B on multilingual inputs in C++, Java, Python, Go, and JavaScript, measuring neuron selectivity and layerwise contributions during generation. We find (1) neurons specialized for individual languages alongside a universal subset supporting general-purpose generation; and (2) lower layers mainly encode language-specific syntax, while middle layers capture semantic abstractions shared across languages, emerging as concept layers. We demonstrate utility on three tasks: neuron-guided fine-tuning for code generation, clone detection via concept-layer embeddings, and concept-layer-guided transfer for code summarization, each yielding consistent gains in multilingual settings.","authors":["Zhe Yin","Xiaodong Gu","Beijun Shen"],"pdf_url":"","comment":"Accepted by FSE2026"},{"id":"http://arxiv.org/abs/2406.03839v6","updated":"2025-12-23T01:41:38Z","published":"2024-06-06T08:15:12Z","title":"PCART: Automated Repair of Python API Parameter Compatibility Issues","summary":"In modern software development, Python third-party libraries play a critical role, especially in fields like deep learning and scientific computing. However, API parameters in these libraries often change during evolution, leading to compatibility issues for client applications reliant on specific versions. Python's flexible parameter-passing mechanism further complicates this, as different passing methods can result in different API compatibility. Currently, no tool can automatically detect and repair Python API parameter compatibility issues. To fill this gap, we introduce PCART, the first solution to fully automate the process of API extraction, code instrumentation, API mapping establishment, compatibility assessment, repair, and validation. PCART handles various types of Python API parameter compatibility issues, including parameter addition, removal, renaming, reordering, and the conversion of positional to keyword parameters. To evaluate PCART, we construct PCBENCH, a large-scale benchmark comprising 47,478 test cases mutated from 844 parameter-changed APIs across 33 popular Python libraries. Evaluation results demonstrate that PCART is both effective and efficient, significantly outperforming existing tools (MLCatchUp and Relancer) and the large language model ChatGPT (GPT-4o), achieving an F1-score of 96.51% in detecting API parameter compatibility issues and a repair precision of 91.97%. Further evaluation on 30 real-world Python projects from GitHub confirms PCART's practicality. We believe PCART can significantly reduce the time programmers spend maintaining Python API updates and advance the automation of Python API compatibility issue repair.","authors":["Shuai Zhang","Guanping Xiao","Jun Wang","Huashan Lei","Gangqiang He","Yepang Liu","Zheng Zheng"],"pdf_url":"","comment":"Accepted by IEEE Transactions on Software Engineering"},{"id":"http://arxiv.org/abs/2406.15596v3","updated":"2025-12-23T01:14:43Z","published":"2024-06-21T18:53:52Z","title":"DiVerify: Hardening Identity-Based Software Signing with Diverse-Context Scopes","summary":"Identity-based code signing enables software developers to digitally sign their code using cryptographic keys. This key is then linked to an identity (e.g., through an identity provider), allowing signers to verify both the code's origin and integrity. However, this code-identity binding is only as trustworthy as the mechanisms enforcing it. State-of-the-art identity-based code signing schemes present a major shortcoming: these schemes fail to provide verifiable information about the context in which a signature is generated. This verifiability is crucial given that modern attackers have subverted long-established security assumptions, namely, that the identity provider ecosystem, as well as signing software itself, is trusted.\n  To address these issues, this paper introduces a diverse identity verification framework, DiVerify, that distributes identity-based verification across multiple entities and enforces stronger guarantees about the signing context. DiVerify makes it possible to provide end-to-end verifiability of not only a signer's identity (via multiple such signals), but also a signer's software stack (e.g., to verify no malware is present on a system at the time of signing). DiVerify is aimed at deployability, and leverages a meta-protocol to gather various trust signals and a binding mechanism to address the aforementioned, novel software supply chain attack vectors. We evaluate DiVerify's performance and confirm it is cheap to deploy and non-intrusive to developers: it only incurs a few kilobytes of additional storage (less than 0.4 percent of the average package size in widely used ecosystems like PyPI), and signing completes in under 100ms on a server-grade deployment.","authors":["Chinenye Okafor","James C. Davis","Santiago Torres-Arias"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19958v1","updated":"2025-12-23T01:10:25Z","published":"2025-12-23T01:10:25Z","title":"Towards Analysing Invoices and Receipts with Amazon Textract","summary":"This paper presents an evaluation of the AWS Textract in the context of extracting data from receipts. We analyse Textract functionalities using a dataset that includes receipts of varied formats and conditions. Our analysis provided a qualitative view of Textract strengths and limitations. While the receipts totals were consistently detected, we also observed typical issues and irregularities that were often influenced by image quality and layout. Based on the analysis of the observations, we propose mitigation strategies.","authors":["Sneha Oommen","Gabby Sanchez","Cassandra T. Britto","Di Wang","Jordan Chiou","Maria Spichkova"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20732v1","updated":"2025-12-23T19:40:51Z","published":"2025-12-23T19:40:51Z","title":"FEM-Bench: A Structured Scientific Reasoning Benchmark for Evaluating Code-Generating LLMs","summary":"As LLMs advance their reasoning capabilities about the physical world, the absence of rigorous benchmarks for evaluating their ability to generate scientifically valid physical models has become a critical gap. Computational mechanics, which develops and applies mathematical models and numerical methods to predict the behavior of physical systems under forces, deformation, and constraints, provides an ideal foundation for structured scientific reasoning evaluation. Problems follow clear mathematical structure, enforce strict physical and numerical constraints, and support objective verification. The discipline requires constructing explicit models of physical systems and reasoning about geometry, spatial relationships, and material behavior, connecting directly to emerging AI goals in physical reasoning and world modeling. We introduce FEM-Bench, a computational mechanics benchmark designed to evaluate the ability of LLMs to generate correct finite element method (FEM) and related code. FEM-Bench 2025 contains a suite of introductory but nontrivial tasks aligned with material from a first graduate course on computational mechanics. These tasks capture essential numerical and physical modeling challenges while representing only a small fraction of the complexity present in the discipline. Despite their simplicity, state-of-the-art LLMs do not reliably solve all of them. In a five attempt run, the best performing model at function writing, Gemini 3 Pro, completed 30/33 tasks at least once and 26/33 tasks all five times. The best performing model at unit test writing, GPT-5, had an Average Joint Success Rate of 73.8%. Other popular models showed broad performance variation. FEM-Bench establishes a structured foundation for evaluating AI-generated scientific code, and future iterations will incorporate increasingly sophisticated tasks to track progress as models evolve.","authors":["Saeed Mohammadzadeh","Erfan Hamdi","Joel Shor","Emma Lejeune"],"pdf_url":"","comment":"40 pages, 5 figures, 6 tables, 7 listings"},{"id":"http://arxiv.org/abs/2512.18470v2","updated":"2025-12-23T19:29:43Z","published":"2025-12-20T19:08:15Z","title":"SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios","summary":"Existing benchmarks for AI coding agents focus on isolated, single-issue tasks such as fixing a bug or implementing a small feature. However, real-world software engineering is fundamentally a long-horizon endeavor: developers must interpret high-level requirements, plan coordinated changes across many files, and evolve codebases over multiple iterations while preserving existing functionality. We introduce SWE-EVO, a benchmark that evaluates agents on this long-horizon software evolution challenge. Constructed from release notes and version histories of seven mature open-source Python projects, Tool comprises 48 evolution tasks that require agents to implement multi-step modifications spanning an average of 21 files, validated against comprehensive test suites averaging 874 tests per instance. Experiments with state-of-the-art models reveal a striking capability gap: even GPT-5 with OpenHands achieves only a 21 percent resolution rate on Tool, compared to 65 percent on the single-issue SWE-Bench Verified. This demonstrates that current agents struggle with sustained, multi-file reasoning. We also propose Fix Rate, a fine-grained metric that captures partial progress toward solving these complex, long-horizon tasks.","authors":["Minh V. T. Thai","Tue Le","Dung Nguyen Manh","Huy Phan Nhat","Nghi D. Q. Bui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20703v1","updated":"2025-12-23T19:05:18Z","published":"2025-12-23T19:05:18Z","title":"Process Analytics -- Data-driven Business Process Management","summary":"Data-driven analysis of business processes has a long tradition in research. However, recently the term of process mining is mostly used when referring to data-driven process analysis. As a consequence, awareness for the many facets of process analysis is decreasing. In particular, while an increasing focus is put onto technical aspects of the analysis, human and organisational concerns remain under the radar. Following the socio-technical perspective of information systems research, we propose a new perspective onto data-driven process analysis that combines the process of analysis with the organisation and its stakeholders. This paper conceptualises the term process analytics and its various dimensions by following both an inductive and deductive approach. The results are discussed by contrasting them to a real-life case study from a large company implementing data-driven process analysis and automation.","authors":["Matthias Stierle","Karsten Kraume","Martin Matzner"],"pdf_url":"","comment":null}],"Performance":[{"id":"http://arxiv.org/abs/2512.20243v1","updated":"2025-12-23T10:53:32Z","published":"2025-12-23T10:53:32Z","title":"Post-Quantum Cryptography in the 5G Core","summary":"In this work, the conventional cryptographic algorithms used in the 5G Core are replaced with post-quantum alternatives and the practical impact of this transition is evaluated. Using a simulation environment, we model the registration and deregistration of varying numbers of user equipments (UEs) and measure the resulting effects on bandwidth consumption and latency.\n  Our results show that the deployment of post-quantum cryptographic algorithms has a measurable effect on performance, but that this effect is small, and perhaps more crucially, that the extra overhead needed in terms of computation and bandwidth does not have any substantial impact on the usability of the network and the efficiency of its network functions.\n  Overall the experimental results in this work corroborate earlier research: the 5G Core is technically able to support post-quantum cryptography without any inherent issues connected to the increased computational overhead or larger message size.","authors":["Thomas Attema","Bor de Kock","Sandesh Manganahalli Jayaprakash","Dimitrios Schoinianakis","Thom Sijpesteijn","Rintse van de Vlasakker"],"pdf_url":"","comment":"11 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2512.20178v1","updated":"2025-12-23T09:16:52Z","published":"2025-12-23T09:16:52Z","title":"SHIRO: Near-Optimal Communication Strategies for Distributed Sparse Matrix Multiplication","summary":"Distributed Sparse Matrix-Matrix Multiplication (SpMM) is a fundamental operation in numerous high-performance computing and deep learning applications. The major performance bottleneck in distributed SpMM lies in the substantial communication overhead, which limits both performance and scalability. In this paper, we identify and analyze sources of inefficient communication in existing distributed SpMM implementations at two levels and address these inefficiencies by proposing: (1) a fine-grained, sparsity-aware communication strategy that reduces communication overhead by exploiting the sparsity pattern of the sparse matrix, and (2) a hierarchical communication strategy that integrates the sparsity-aware strategy with the common two-tier network architectures in GPU-accelerated systems, to reduce redundant communication across slow network links. We implement these optimizations in a comprehensive distributed SpMM framework, \\method{}. Extensive evaluations on real-world datasets show that our framework demonstrates strong scalability up to 128 GPUs, achieving geometric mean speedups of 221.5$\\times$, 56.0$\\times$, 23.4$\\times$, and 8.8$\\times$ over four state-of-the-art baselines (CAGNET, SPA, BCL, and CoLa, respectively) at this scale.","authors":["Chen Zhuang","Lingqi Zhang","Benjamin Brock","Du Wu","Peng Chen","Toshio Endo","Satoshi Matsuoka","Mohamed Wahib"],"pdf_url":"","comment":"Under Review"}],"Programming Languages":[{"id":"http://arxiv.org/abs/2507.18885v4","updated":"2025-12-23T17:57:57Z","published":"2025-07-25T02:04:56Z","title":"A Minimalist Proof Language for Neural Theorem Proving over Isabelle/HOL","summary":"Neural Theorem Proving (NTP) employs LLMs to automate formal proofs in proof assistants. While LLMs have achieved relatively remarkable success in informal reasoning tasks using natural languages, the transition to mechanized formal theorem proving presents persistent challenges. Mechanized proof languages often contain many syntactic constructs and diverse, specialized proof tactics, which facilitate expert use but have no direct counterpart in informal mathematical proofs. These prover-specific idioms represent an additional burden for LLM-based NTPs that might be otherwise successful in generating informal proofs. Seeking to bridge this gap between formal proof construction and informal reasoning, in order to better facilitate NTP, this work approaches these challenges from a language design perspective. We look at common reasoning patterns in informal proofs and in existing mechanized proofs, and design Minilang -- a minimalist proof language that captures these reasoning patterns. In contrast to proof languages (informal and formal) that often feature a large collection of operations with unclear semantic boundaries, Minilang is deliberately kept minimalist -- its core design comprises only 10 operations, each with clear semantic distinctions. We further develop a rule-based translator from Isabelle's language (Isar) to Minilang, translating ~340K existing proofs with an ~85% success rate. Using this translated corpus, we finetune two LLMs to compare machine learning performance on Minilang versus the original Isar. Experiments show Minilang benefits the two LLMs by improving the pass@1 success rate on the PISA benchmark by up to 20/29 percentage points in comparison to the Isar-based LLMs w/wo Sledgehammer. The pass@1 rate reaches 69.1%, exceeding the prior work Baldur's pass@64 (65.7%); the pass@8 rate reaches 79.2%, exceeding the SOTA on PISA (71.0%) achieved by Magnushammer.","authors":["Qiyuan Xu","Renxi Wang","Peixin Wang","Haonan Li","Conrad Watt"],"pdf_url":"","comment":"Accepted in OOPSLA'26"},{"id":"http://arxiv.org/abs/2511.21878v2","updated":"2025-12-23T15:17:24Z","published":"2025-11-26T19:53:46Z","title":"Advancing Automated In-Isolation Validation in Repository-Level Code Translation","summary":"Repository-level code translation aims to migrate entire repositories across programming languages while preserving functionality automatically. Despite advancements in repository-level code translation, validating the translations remains challenging. This paper proposes TRAM, which combines context-aware type resolution with mock-based in-isolation validation to achieve high-quality translations between programming languages. Prior to translation, TRAM retrieves API documentation and contextual code information for each variable type in the source language. It then prompts a large language model (LLM) with retrieved contextual information to resolve type mappings across languages with precise semantic interpretations. Using the automatically constructed type mapping, TRAM employs a custom serialization/deserialization workflow that automatically constructs equivalent mock objects in the target language. This enables each method fragment to be validated in isolation, without the high cost of using agents for translation validation, or the heavy manual effort required by existing approaches that rely on language interoperability. TRAM demonstrates state-of-the-art performance in Java-to-Python translation, underscoring the effectiveness of its integration of RAG-based type resolution with reliable in-isolation validation.","authors":["Kaiyao Ke","Ali Reza Ibrahimzada","Rangeet Pan","Saurabh Sinha","Reyhaneh Jabbarvand"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20396v1","updated":"2025-12-23T14:33:31Z","published":"2025-12-23T14:33:31Z","title":"Symmaries: Automatic Inference of Formal Security Summaries for Java Programs","summary":"We introduce a scalable, modular, and sound approach for automatically constructing formal security specifications for Java bytecode programs in the form of method summaries. A summary provides an abstract representation of a method's security behavior, consisting of the conditions under which the method can be securely invoked, together with specifications of information flows and aliasing updates. Such summaries can be consumed by static code analysis tools and also help developers understand the behavior of code segments, such as libraries, in order to evaluate their security implications when reused in applications. Our approach is implemented in a tool called Symmaries, which automates the generation of security summaries. We applied Symmaries to Java API libraries to extract their security specifications and to large real-world applications to evaluate its scalability. Our results show that the tool successfully scales to analyze applications with hundreds of thousands of lines of code, and that Symmaries achieves a promising precision depending on the heap model used. We prove the soundness of our approach in terms of guaranteeing termination-insensitive non-interference.","authors":["Narges Khakpour","Nicolas Berthier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20214v1","updated":"2025-12-23T10:15:28Z","published":"2025-12-23T10:15:28Z","title":"Error Localization, Certificates, and Hints for Probabilistic Program Verification via Slicing (Extended Version)","summary":"This paper focuses on effective user diagnostics generated during the deductive verification of probabilistic programs. Our key principle is based on providing slices for (1) error reporting, (2) proof simplification, and (3) preserving successful verification results. By formally defining these different notions on HeyVL, an existing quantitative intermediate verification language (IVL), our concepts (and implementation) can be used to obtain diagnostics for a range of probabilistic programming languages. Slicing for error reporting is a novel notion of error localization for quantitative assertions. We demonstrate slicing-based diagnostics on a variety of proof rules such as quantitative versions of the specification statement and invariant-based loop rules, and formally prove the correctness of specialized error messages and verification hints.\n  We implemented our user diagnostics into the deductive verifier Caesar. Our novel implementation -- called \\emph{Brutus} -- can search for slices which do or do not verify, corresponding to each of the three diagnostic notions. For error reporting (1), it exploits a binary search-based algorithm that minimizes error-witnessing slices. To solve for slices that verify (2 and 3), we empirically compare different algorithms based on unsatisfiable cores, minimal unsatisfiable subset enumeration, and a direct SMT encoding of the slicing problem. Our empirical evaluation of Brutus on existing and new benchmarks shows that we can find slices that are both small and informative.","authors":["Philipp Schröer","Darion Haase","Joost-Pieter Katoen"],"pdf_url":"","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2512.20618v1","updated":"2025-12-23T18:59:49Z","published":"2025-12-23T18:59:49Z","title":"LongVideoAgent: Multi-Agent Reasoning with Long Videos","summary":"Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We propose a multi-agent framework in which a master LLM coordinates a grounding agent to localize question-relevant segments and a vision agent to extract targeted textual observations. The master agent plans with a step limit, and is trained with reinforcement learning to encourage concise, correct, and efficient multi-agent cooperation. This design helps the master agent focus on relevant clips via grounding, complements subtitles with visual detail, and yields interpretable trajectories. On our proposed LongTVQA and LongTVQA+ which are episode-level datasets aggregated from TVQA/TVQA+, our multi-agent system significantly outperforms strong non-agent baselines. Experiments also show reinforcement learning further strengthens reasoning and planning for the trained agent. Code and data will be shared at https://longvideoagent.github.io/.","authors":["Runtao Liu","Ziyi Liu","Jiaqi Tang","Yue Ma","Renjie Pi","Jipeng Zhang","Qifeng Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20605v1","updated":"2025-12-23T18:51:50Z","published":"2025-12-23T18:51:50Z","title":"Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning","summary":"Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token can result in highly inefficient learning, particularly when rewards are sparse. Here, we show that it is possible to overcome this problem by acting and exploring within the internal representations of an autoregressive model. Specifically, to discover temporally-abstract actions, we introduce a higher-order, non-causal sequence model whose outputs control the residual stream activations of a base autoregressive model. On grid world and MuJoCo-based tasks with hierarchical structure, we find that the higher-order model learns to compress long activation sequence chunks onto internal controllers. Critically, each controller executes a sequence of behaviorally meaningful actions that unfold over long timescales and are accompanied with a learned termination condition, such that composing multiple controllers over time leads to efficient exploration on novel tasks. We show that direct internal controller reinforcement, a process we term \"internal RL\", enables learning from sparse rewards in cases where standard RL finetuning fails. Our results demonstrate the benefits of latent action generation and reinforcement in autoregressive models, suggesting internal RL as a promising avenue for realizing hierarchical RL within foundation models.","authors":["Seijin Kobayashi","Yanick Schimpf","Maximilian Schlegel","Angelika Steger","Maciej Wolczyk","Johannes von Oswald","Nino Scherre","Kaitlin Maile","Guillaume Lajoie","Blake A. Richards","Rif A. Saurous","James Manyika","Blaise Agüera y Arcas","Alexander Meulemans","João Sacramento"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20595v1","updated":"2025-12-23T18:43:05Z","published":"2025-12-23T18:43:05Z","title":"Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs","summary":"We introduce Cube Bench, a Rubik's-cube benchmark for evaluating spatial and sequential reasoning in multimodal large language models (MLLMs). The benchmark decomposes performance into five skills: (i) reconstructing cube faces from images and text, (ii) choosing the optimal next move, (iii) predicting the outcome of a candidate move without applying it, (iv) executing multi-step plans while recovering from mistakes, and (v) detecting and revising one's own errors. Using a shared set of scrambled cube states, identical prompts and parsers, and a single distance-to-solved metric, we compare recent MLLMs side by side as a function of scramble depth. Across seven MLLMs, accuracy drops sharply with depth; once a trajectory stalls or diverges, models rarely recover, and high face-reconstruction accuracy does not guarantee competent action selection or multi-step execution. A pronounced closed- vs open-source gap emerges: the strongest closed model leads on both single-step perception tasks and multi-step control tasks, while open-weight models cluster near chance on the hardest settings; yet even the best MLLM degrades at higher cube complexity. A simple self-correction via reflective thinking yields modest gains but can also introduce overthinking. Cube Bench offers a compact, reproducible probe of sequential spatial reasoning in MLLMs.","authors":["Dhruv Anand","Ehsan Shareghi"],"pdf_url":"","comment":"27 pages, 5 figures, 9 tables. Cube available at https://github.com/dana-23/cube-bench"},{"id":"http://arxiv.org/abs/2512.20589v1","updated":"2025-12-23T18:36:07Z","published":"2025-12-23T18:36:07Z","title":"Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information","summary":"As systems engineering (SE) objectives evolve from design and operation of monolithic systems to complex System of Systems (SoS), the discipline of Mission Engineering (ME) has emerged which is increasingly being accepted as a new line of thinking for the SE community. Moreover, mission environments are uncertain, dynamic, and mission outcomes are a direct function of how the mission assets will interact with this environment. This proves static architectures brittle and calls for analytically rigorous approaches for ME. To that end, this paper proposes an intelligent mission coordination methodology that integrates digital mission models with Reinforcement Learning (RL), that specifically addresses the need for adaptive task allocation and reconfiguration. More specifically, we are leveraging a Digital Engineering (DE) based infrastructure that is composed of a high-fidelity digital mission model and agent-based simulation; and then we formulate the mission tactics management problem as a Markov Decision Process (MDP), and employ an RL agent trained via Proximal Policy Optimization. By leveraging the simulation as a sandbox, we map the system states to actions, refining the policy based on realized mission outcomes. The utility of the RL-based intelligent mission coordinator is demonstrated through an aerial firefighting case study. Our findings indicate that the RL-based intelligent mission coordinator not only surpasses baseline performance but also significantly reduces the variability in mission performance. Thus, this study serves as a proof of concept demonstrating that DE-enabled mission simulations combined with advanced analytical tools offer a mission-agnostic framework for improving ME practice; which can be extended to more complicated fleet design and selection problems in the future from a mission-first perspective.","authors":["İbrahim Oğuz Çetinkaya","Sajad Khodadadian","Taylan G. Topçu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20586v1","updated":"2025-12-23T18:32:17Z","published":"2025-12-23T18:32:17Z","title":"Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent","summary":"Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the reasoning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.","authors":["Humza Nusrat","Luke Francisco","Bing Luo","Hassan Bagher-Ebadian","Joshua Kim","Karen Chin-Snyder","Salim Siddiqui","Mira Shah","Eric Mellon","Mohammad Ghassemi","Anthony Doemer","Benjamin Movsas","Kundan Thind"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20576v1","updated":"2025-12-23T18:20:06Z","published":"2025-12-23T18:20:06Z","title":"Performative Policy Gradient: Optimality in Performative Reinforcement Learning","summary":"Post-deployment machine learning algorithms often influence the environments they act in, and thus shift the underlying dynamics that the standard reinforcement learning (RL) methods ignore. While designing optimal algorithms in this performative setting has recently been studied in supervised learning, the RL counterpart remains under-explored. In this paper, we prove the performative counterparts of the performance difference lemma and the policy gradient theorem in RL, and further introduce the Performative Policy Gradient algorithm (PePG). PePG is the first policy gradient algorithm designed to account for performativity in RL. Under softmax parametrisation, and also with and without entropy regularisation, we prove that PePG converges to performatively optimal policies, i.e. policies that remain optimal under the distribution shifts induced by themselves. Thus, PePG significantly extends the prior works in Performative RL that achieves performative stability but not optimality. Furthermore, our empirical analysis on standard performative RL environments validate that PePG outperforms standard policy gradient algorithms and the existing performative RL algorithms aiming for stability.","authors":["Debabrota Basu","Udvas Das","Brahim Driss","Uddalak Mukherjee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20573v1","updated":"2025-12-23T18:16:58Z","published":"2025-12-23T18:16:58Z","title":"Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs","summary":"Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM's speed from parallel decoding drastically lowers the risk of costly rejections, providing a practical mechanism to effectively realize the (elusive) lengthy drafts that lead to large speedups with speculative decoding. We present FailFast, a dLLM-based speculative decoding framework that realizes this approach by dynamically adapting its speculation length. It \"fails fast\" by spending minimal compute in hard-to-speculate regions to shrink speculation latency and \"wins big\" by aggressively extending draft lengths in easier regions to reduce verification latency (in many cases, speculating and accepting 70 tokens at a time!). Without any fine-tuning, FailFast delivers lossless acceleration of AR LLMs and achieves up to 4.9$\\times$ speedup over vanilla decoding, 1.7$\\times$ over the best naive dLLM drafter, and 1.4$\\times$ over EAGLE-3 across diverse models and workloads. We open-source FailFast at https://github.com/ruipeterpan/failfast.","authors":["Rui Pan","Zhuofu Chen","Ravi Netravali"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20569v1","updated":"2025-12-23T18:12:22Z","published":"2025-12-23T18:12:22Z","title":"Distilling to Hybrid Attention Models via KL-Guided Layer Selection","summary":"Distilling pretrained softmax attention Transformers into more efficient hybrid architectures that interleave softmax and linear attention layers is a promising approach for improving the inference efficiency of LLMs without requiring expensive pretraining from scratch. A critical factor in the conversion process is layer selection, i.e., deciding on which layers to convert to linear attention variants. This paper describes a simple and efficient recipe for layer selection that uses layer importance scores derived from a small amount of training on generic text data. Once the layers have been selected we use a recent pipeline for the distillation process itself \\citep[RADLADS;][]{goldstein2025radlads}, which consists of attention weight transfer, hidden state alignment, KL-based distribution matching, followed by a small amount of finetuning. We find that this approach is more effective than existing approaches for layer selection, including heuristics that uniformly interleave linear attentions based on a fixed ratio, as well as more involved approaches that rely on specialized diagnostic datasets.","authors":["Yanhong Li","Songlin Yang","Shawn Tan","Mayank Mishra","Rameswar Panda","Jiawei Zhou","Yoon Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.18218v4","updated":"2025-12-23T18:09:51Z","published":"2025-09-21T22:34:00Z","title":"Similarity Field Theory: A Mathematical Framework for Intelligence","summary":"We posit that persisting and transforming similarity relations form the structural basis of any comprehensible dynamic system. This paper introduces Similarity Field Theory, a mathematical framework that formalizes the principles governing similarity values among entities and their evolution. We define: (1) a similarity field $S: U \\times U \\to [0,1]$ over a universe of entities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed relational field (asymmetry and non-transitivity are allowed); (2) the evolution of a system through a sequence $Z_p=(X_p,S^{(p)})$ indexed by $p=0,1,2,\\ldots$; (3) concepts $K$ as entities that induce fibers $F_α(K)={E\\in U \\mid S(E,K)\\ge α}$, i.e., superlevel sets of the unary map $S_K(E):=S(E,K)$; and (4) a generative operator $G$ that produces new entities. Within this framework, we formalize a generative definition of intelligence: an operator $G$ is intelligent with respect to a concept $K$ if, given a system containing entities belonging to the fiber of $K$, it generates new entities that also belong to that fiber. Similarity Field Theory thus offers a foundational language for characterizing, comparing, and constructing intelligent systems. At a high level, this framework reframes intelligence and interpretability as geometric problems on similarity fields--preserving and composing level-set fibers--rather than purely statistical ones. We prove two theorems: (i) asymmetry blocks mutual inclusion; and (ii) stability implies either an anchor coordinate or asymptotic confinement to the target level (up to arbitrarily small tolerance). Together, these results constrain similarity-field evolution and motivate an interpretive lens that can be applied to large language models.","authors":["Kei-Sing Ng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20563v1","updated":"2025-12-23T18:07:43Z","published":"2025-12-23T18:07:43Z","title":"LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving","summary":"Simulators can generate virtually unlimited driving data, yet imitation learning policies in simulation still struggle to achieve robust closed-loop performance. Motivated by this gap, we empirically study how misalignment between privileged expert demonstrations and sensor-based student observations can limit the effectiveness of imitation learning. More precisely, experts have significantly higher visibility (e.g., ignoring occlusions) and far lower uncertainty (e.g., knowing other vehicles' actions), making them difficult to imitate reliably. Furthermore, navigational intent (i.e., the route to follow) is under-specified in student models at test time via only a single target point. We demonstrate that these asymmetries can measurably limit driving performance in CARLA and offer practical interventions to address them. After careful modifications to narrow the gaps between expert and student, our TransFuser v6 (TFv6) student policy achieves a new state of the art on all major publicly available CARLA closed-loop benchmarks, reaching 95 DS on Bench2Drive and more than doubling prior performances on Longest6~v2 and Town13. Additionally, by integrating perception supervision from our dataset into a shared sim-to-real pipeline, we show consistent gains on the NAVSIM and Waymo Vision-Based End-to-End driving benchmarks. Our code, data, and models are publicly available at https://github.com/autonomousvision/lead.","authors":["Long Nguyen","Micha Fauth","Bernhard Jaeger","Daniel Dauner","Maximilian Igl","Andreas Geiger","Kashyap Chitta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.13912v2","updated":"2025-12-23T18:00:52Z","published":"2025-11-17T21:06:52Z","title":"Compute-in-Memory Implementation of State Space Models for Event Sequence Processing","summary":"State space models (SSMs) have recently emerged as a powerful framework for long sequence processing, outperforming traditional methods on diverse benchmarks. Fundamentally, SSMs can generalize both recurrent and convolutional networks and have been shown to even capture key functions of biological systems. Here we report an approach to implement SSMs in energy-efficient compute-in-memory (CIM) hardware to achieve real-time, event-driven processing. Our work re-parameterizes the model to function with real-valued coefficients and shared decay constants, reducing the complexity of model mapping onto practical hardware systems. By leveraging device dynamics and diagonalized state transition parameters, the state evolution can be natively implemented in crossbar-based CIM systems combined with memristors exhibiting short-term memory effects. Through this algorithm and hardware co-design, we show the proposed system offers both high accuracy and high energy efficiency while supporting fully asynchronous processing for event-based vision and audio tasks.","authors":["Xiaoyu Zhang","Mingtao Hu","Sen Lu","Soohyeon Kim","Eric Yeu-Jer Lee","Yuyang Liu","Wei D. Lu"],"pdf_url":"","comment":"Xiaoyu Zhang and Mingtao Hu contributed equally to this work"},{"id":"http://arxiv.org/abs/2510.07191v2","updated":"2025-12-23T17:45:29Z","published":"2025-10-08T16:25:04Z","title":"Resolution scaling governs DINOv3 transfer performance in chest radiograph classification","summary":"Self-supervised learning (SSL) has advanced visual representation learning, but its value in chest radiography, a high-volume imaging modality with fine-grained findings, remains unclear. Meta's DINOv3 extends earlier SSL models through Gram-anchored self-distillation. Whether these design choices improve transfer learning for chest radiography has not been systematically tested. We benchmarked DINOv3 against DINOv2 and ImageNet initialization across seven datasets (n>814,000). Two representative backbones were evaluated: ViT-B/16 and ConvNeXt-B. Images were analyzed at 224x224, 512x512, and 1024x1024 pixels. We additionally assessed frozen features from a 7B model. The primary outcome was mean AUROC across labels. At 224x224, DINOv3 and DINOv2 achieved comparable performance on adult datasets. Increasing resolution to 512x512 yielded consistent improvements for DINOv3 over both DINOv2 and ImageNet. In contrast, results in pediatric cohort showed no differences across initializations. Across all settings, ConvNeXt-B outperformed ViT-B/16. Models using frozen DINOv3-7B features underperformed relative to fully finetuned 86-89M-parameter backbones, highlighting the importance of domain adaptation. Scaling to 1024x1024 did not further improve accuracy. Resolution-related gains were most evident for boundary-dependent and small focal abnormalities. In chest radiography, higher input resolution is critical for leveraging the benefits of modern self-supervised models. 512x512 pixels represent a practical upper limit where DINOv3-initialized ConvNeXt-B networks provide the strongest performance, while larger inputs offer minimal return on cost. Clinically, these findings support use of finetuned, mid-sized backbones at 512x512 for chest radiograph interpretation, with the greatest gains expected in detecting subtle or boundary-centered lesions relevant to emergency and critical care settings.","authors":["Soroosh Tayebi Arasteh","Mina Shaigan","Christiane Kuhl","Jakob Nikolas Kather","Sven Nebelung","Daniel Truhn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20548v1","updated":"2025-12-23T17:42:16Z","published":"2025-12-23T17:42:16Z","title":"Advancing Multimodal Teacher Sentiment Analysis:The Large-Scale T-MED Dataset & The Effective AAM-TSA Model","summary":"Teachers' emotional states are critical in educational scenarios, profoundly impacting teaching efficacy, student engagement, and learning achievements. However, existing studies often fail to accurately capture teachers' emotions due to the performative nature and overlook the critical impact of instructional information on emotional expression.In this paper, we systematically investigate teacher sentiment analysis by building both the dataset and the model accordingly. We construct the first large-scale teacher multimodal sentiment analysis dataset, T-MED.To ensure labeling accuracy and efficiency, we employ a human-machine collaborative labeling process.The T-MED dataset includes 14,938 instances of teacher emotional data from 250 real classrooms across 11 subjects ranging from K-12 to higher education, integrating multimodal text, audio, video, and instructional information.Furthermore, we propose a novel asymmetric attention-based multimodal teacher sentiment analysis model, AAM-TSA.AAM-TSA introduces an asymmetric attention mechanism and hierarchical gating unit to enable differentiated cross-modal feature fusion and precise emotional classification. Experimental results demonstrate that AAM-TSA significantly outperforms existing state-of-the-art methods in terms of accuracy and interpretability on the T-MED dataset.","authors":["Zhiyi Duan","Xiangren Wang","Hongyu Yuan","Qianli Xing"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20520v1","updated":"2025-12-23T17:08:31Z","published":"2025-12-23T17:08:31Z","title":"Benchmarking LLMs for Predictive Applications in the Intensive Care Units","summary":"With the advent of LLMs, various tasks across the natural language processing domain have been transformed. However, their application in predictive tasks remains less researched. This study compares large language models, including GatorTron-Base (trained on clinical data), Llama 8B, and Mistral 7B, against models like BioBERT, DocBERT, BioClinicalBERT, Word2Vec, and Doc2Vec, setting benchmarks for predicting Shock in critically ill patients. Timely prediction of shock can enable early interventions, thus improving patient outcomes. Text data from 17,294 ICU stays of patients in the MIMIC III database were scored for length of stay > 24 hours and shock index (SI) > 0.7 to yield 355 and 87 patients with normal and abnormal SI-index, respectively. Both focal and cross-entropy losses were used during finetuning to address class imbalances. Our findings indicate that while GatorTron Base achieved the highest weighted recall of 80.5%, the overall performance metrics were comparable between SLMs and LLMs. This suggests that LLMs are not inherently superior to SLMs in predicting future clinical events despite their strong performance on text-based tasks. To achieve meaningful clinical outcomes, future efforts in training LLMs should prioritize developing models capable of predicting clinical trajectories rather than focusing on simpler tasks such as named entity recognition or phenotyping.","authors":["Chehak Malhotra","Mehak Gopal","Akshaya Devadiga","Pradeep Singh","Ridam Pal","Ritwik Kashyap","Tavpritesh Sethi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.15735v3","updated":"2025-12-23T17:06:16Z","published":"2025-12-05T22:52:22Z","title":"Deep Reinforcement Learning Optimization for Uncertain Nonlinear Systems via Event-Triggered Robust Adaptive Dynamic Programming","summary":"This work proposes a unified control architecture that couples a Reinforcement Learning (RL)-driven controller with a disturbance-rejection Extended State Observer (ESO), complemented by an Event-Triggered Mechanism (ETM) to limit unnecessary computations. The ESO is utilized to estimate the system states and the lumped disturbance in real time, forming the foundation for effective disturbance compensation. To obtain near-optimal behavior without an accurate system description, a value-iteration-based Adaptive Dynamic Programming (ADP) method is adopted for policy approximation. The inclusion of the ETM ensures that parameter updates of the learning module are executed only when the state deviation surpasses a predefined bound, thereby preventing excessive learning activity and substantially reducing computational load. A Lyapunov-oriented analysis is used to characterize the stability properties of the resulting closed-loop system. Numerical experiments further confirm that the developed approach maintains strong control performance and disturbance tolerance, while achieving a significant reduction in sampling and processing effort compared with standard time-triggered ADP schemes.","authors":["Ningwei Bai","Chi Pui Chan","Qichen Yin","Tengyang Gong","Yunda Yan","Zezhi Tang"],"pdf_url":"","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2507.05495v2","updated":"2025-12-23T16:43:12Z","published":"2025-07-07T21:35:09Z","title":"Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents","summary":"Effectively evaluating deep research agents that autonomously search the web, analyze information, and generate reports remains a major challenge, particularly when it comes to assessing long reports and giving detailed feedback on their intermediate steps. To address these gaps, we introduce Deep Research Comparator, a platform that offers a holistic framework for deep research agent hosting, side-by-side comparison, fine-grained human feedback collection, and ranking calculation. Given a user query, our platform displays the final reports from two different agents along with their intermediate steps during generation. Annotators can evaluate the overall quality of final reports based on side-by-side comparison, and also provide detailed feedback separately by assessing intermediate steps or specific text spans within the final report. Furthermore, we develop Simple Deepresearch, an end-to-end agent scaffold. This scaffold serves as a baseline that facilitates the easy integration of various large language models to transform them into deep research agents for evaluation. To demonstrate the platform's utility for deep research agent development, we have collected real user preference data from 17 annotators on three deep research agents. A demo video of our platform can be found at https://www.youtube.com/watch?v=g4d2dnbdseg.","authors":["Prahaladh Chandrahasan","Jiahe Jin","Zhihan Zhang","Tevin Wang","Andy Tang","Lucy Mo","Morteza Ziyadi","Leonardo F. R. Ribeiro","Zimeng Qiu","Markus Dreyer","Akari Asai","Chenyan Xiong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.12833v2","updated":"2025-12-23T16:25:32Z","published":"2025-08-18T11:17:59Z","title":"Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG","summary":"On-device machine learning is often constrained by limited storage, particularly in continuous data collection scenarios. This paper presents an empirical study on storage-aware learning, focusing on the trade-off between data quantity and quality via compression. We demonstrate that naive strategies, such as uniform data dropping or one-size-fits-all compression, are suboptimal. Our findings further reveal that data samples exhibit varying sensitivities to compression, supporting the feasibility of a sample-wise adaptive compression strategy. These insights provide a foundation for developing a new class of storage-aware learning systems. The primary contribution of this work is the systematic characterization of this under-explored challenge, offering valuable insights that advance the understanding of storage-aware learning.","authors":["Kichang Lee","Songkuk Kim","JaeYeon Park","JeongGil Ko"],"pdf_url":"","comment":"6pages, 6figures"},{"id":"http://arxiv.org/abs/2401.09986v3","updated":"2025-12-23T16:22:09Z","published":"2024-01-18T14:02:23Z","title":"Improving Local Training in Federated Learning via Temperature Scaling","summary":"Federated learning is inherently hampered by data heterogeneity: non-i.i.d. training data over local clients. We propose a novel model training approach for federated learning, FLex&Chill, which exploits the Logit Chilling method. Through extensive evaluations, we demonstrate that, in the presence of non-i.i.d. data characteristics inherent in federated learning systems, this approach can expedite model convergence and improve inference accuracy. Quantitatively, from our experiments, we observe up to 6X improvement in the global federated learning model convergence time, and up to 3.37% improvement in inference accuracy.","authors":["Kichang Lee","Pei Zhang","Songkuk Kim","JeongGil Ko"],"pdf_url":"","comment":"56 pages"},{"id":"http://arxiv.org/abs/2512.20482v1","updated":"2025-12-23T16:18:39Z","published":"2025-12-23T16:18:39Z","title":"SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization","summary":"Maintaining large-scale, multilingual codebases hinges on accurately localizing issues, which requires mapping natural-language error descriptions to the relevant functions that need to be modified. However, existing ranking approaches are often Python-centric and perform a single-pass search over the codebase. This work introduces SweRank+, a framework that couples SweRankMulti, a cross-lingual code ranking tool, with SweRankAgent, an agentic search setup, for iterative, multi-turn reasoning over the code repository. SweRankMulti comprises a code embedding retriever and a listwise LLM reranker, and is trained using a carefully curated large-scale issue localization dataset spanning multiple popular programming languages. SweRankAgent adopts an agentic search loop that moves beyond single-shot localization with a memory buffer to reason and accumulate relevant localization candidates over multiple turns. Our experiments on issue localization benchmarks spanning various languages demonstrate new state-of-the-art performance with SweRankMulti, while SweRankAgent further improves localization over single-pass ranking.","authors":["Revanth Gangi Reddy","Ye Liu","Wenting Zhao","JaeHyeok Doo","Tarun Suresh","Daniel Lee","Caiming Xiong","Yingbo Zhou","Semih Yavuz","Shafiq Joty"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20469v1","updated":"2025-12-23T16:04:41Z","published":"2025-12-23T16:04:41Z","title":"Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale","summary":"AI agents are emerging as a practical way to run multi-step scientific workflows that interleave reasoning with tool use and verification, pointing to a shift from isolated AI-assisted steps toward \\emph{agentic science at scale}. This shift is increasingly feasible, as scientific tools and models can be invoked through stable interfaces and verified with recorded execution traces, and increasingly necessary, as AI accelerates scientific output and stresses the peer-review and publication pipeline, raising the bar for traceability and credible evaluation.\n  However, scaling agentic science remains difficult: workflows are hard to observe and reproduce; many tools and laboratory systems are not agent-ready; execution is hard to trace and govern; and prototype AI Scientist systems are often bespoke, limiting reuse and systematic improvement from real workflow signals.\n  We argue that scaling agentic science requires an infrastructure-and-ecosystem approach, instantiated in Bohrium+SciMaster. Bohrium acts as a managed, traceable hub for AI4S assets -- akin to a HuggingFace of AI for Science -- that turns diverse scientific data, software, compute, and laboratory systems into agent-ready capabilities. SciMaster orchestrates these capabilities into long-horizon scientific workflows, on which scientific agents can be composed and executed. Between infrastructure and orchestration, a \\emph{scientific intelligence substrate} organizes reusable models, knowledge, and components into executable building blocks for workflow reasoning and action, enabling composition, auditability, and improvement through use.\n  We demonstrate this stack with eleven representative master agents in real workflows, achieving orders-of-magnitude reductions in end-to-end scientific cycle time and generating execution-grounded signals from real workloads at multi-million scale.","authors":["Linfeng Zhang","Siheng Chen","Yuzhu Cai","Jingyi Chai","Junhan Chang","Kun Chen","Zhi X. Chen","Zhaohan Ding","Yuwen Du","Yuanpeng Gao","Yuan Gao","Jing Gao","Zhifeng Gao","Qiangqiang Gu","Yanhui Hong","Yuan Huang","Xi Fang","Xiaohong Ji","Guolin Ke","Zixing Lei","Xinyu Li","Yongge Li","Ruoxue Liao","Hang Lin","Xiaolu Lin","Yuxiang Liu","Xinzijian Liu","Zexi Liu","Jintan Lu","Tingjia Miao","Haohui Que","Weijie Sun","Yanfeng Wang","Bingyang Wu","Tianju Xue","Rui Ye","Jinzhe Zeng","Duo Zhang","Jiahui Zhang","Linfeng Zhang","Tianhan Zhang","Wenchang Zhang","Yuzhi Zhang","Zezhong Zhang","Hang Zheng","Hui Zhou","Tong Zhu","Xinyu Zhu","Qingguo Zhou","Weinan E"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.09312v4","updated":"2025-12-23T15:52:27Z","published":"2025-09-11T09:55:50Z","title":"Explaining Tournament Solutions with Minimal Supports","summary":"Tournaments are widely used models to represent pairwise dominance between candidates, alternatives, or teams. We study the problem of providing certified explanations for why a candidate appears among the winners under various tournament rules. To this end, we identify minimal supports, minimal sub-tournaments in which the candidate is guaranteed to win regardless of how the rest of the tournament is completed (that is, the candidate is a necessary winner of the sub-tournament). This notion corresponds to an abductive explanation for the question,\"Why does the winner win the tournament?\", a central concept in formal explainable AI. We focus on common tournament solutions: the top cycle, the uncovered set, the Copeland rule, the Borda rule, the maximin rule, and the weighted uncovered set. For each rule we determine the size of the smallest minimal supports, and we present polynomial-time algorithms to compute them for all solutions except for the weighted uncovered set, for which the problem is NP-complete. Finally, we show how minimal supports can serve to produce compact, certified, and intuitive explanations for tournament solutions.","authors":["Clément Contet","Umberto Grandi","Jérôme Mengin"],"pdf_url":"","comment":"This paper is the extended version of Contet, Grandi, and Mengin. 2026. Explaining Tournament Solutions with Minimal Supports. In Proceedings of the 40th AAAI Conference on Artificial Intelligence"},{"id":"http://arxiv.org/abs/2509.22358v2","updated":"2025-12-23T15:51:07Z","published":"2025-09-26T13:53:56Z","title":"Stochastic activations","summary":"We introduce stochastic activations. This novel strategy randomly selects between several non-linear functions in the feed-forward layer of a large language model. In particular, we choose between SILU or RELU depending on a Bernoulli draw. This strategy circumvents the optimization problem associated with RELU, namely, the constant shape for negative inputs that prevents the gradient flow. We leverage this strategy in two ways:\n  (1) We use stochastic activations during pre-training and fine-tune the model with RELU, which is used at inference time to provide sparse latent vectors. This reduces the inference FLOPs and translates into a significant speedup in the CPU. Interestingly, this leads to much better results than training from scratch with the RELU activation function.\n  (2) We evaluate stochastic activations for generation. This strategy performs reasonably well: it is only slightly inferior to the best deterministic non-linearity, namely SILU combined with temperature scaling. This offers an alternative to existing strategies by providing a controlled way to increase the diversity of the generated text.","authors":["Maria Lomeli","Matthijs Douze","Gergely Szilvasy","Loic Cabannes","Jade Copet","Sainbayar Sukhbaatar","Jason Weston","Gabriel Synnaeve","Pierre-Emmanuel Mazaré","Hervé Jégou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20436v1","updated":"2025-12-23T15:24:31Z","published":"2025-12-23T15:24:31Z","title":"Dual-Encoder Transformer-Based Multimodal Learning for Ischemic Stroke Lesion Segmentation Using Diffusion MRI","summary":"Accurate segmentation of ischemic stroke lesions from diffusion magnetic resonance imaging (MRI) is essential for clinical decision-making and outcome assessment. Diffusion-Weighted Imaging (DWI) and Apparent Diffusion Coefficient (ADC) scans provide complementary information on acute and sub-acute ischemic changes; however, automated lesion delineation remains challenging due to variability in lesion appearance.\n  In this work, we study ischemic stroke lesion segmentation using multimodal diffusion MRI from the ISLES 2022 dataset. Several state-of-the-art convolutional and transformer-based architectures, including U-Net variants, Swin-UNet, and TransUNet, are benchmarked. Based on performance, a dual-encoder TransUNet architecture is proposed to learn modality-specific representations from DWI and ADC inputs. To incorporate spatial context, adjacent slice information is integrated using a three-slice input configuration.\n  All models are trained under a unified framework and evaluated using the Dice Similarity Coefficient (DSC). Results show that transformer-based models outperform convolutional baselines, and the proposed dual-encoder TransUNet achieves the best performance, reaching a Dice score of 85.4% on the test set. The proposed framework offers a robust solution for automated ischemic stroke lesion segmentation from diffusion MRI.","authors":["Muhammad Usman","Azka Rehman","Muhammad Mutti Ur Rehman","Abd Ur Rehman","Muhammad Umar Farooq"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.02824v2","updated":"2025-12-23T15:15:42Z","published":"2025-05-05T17:51:55Z","title":"Towards Dataset Copyright Evasion Attack against Personalized Text-to-Image Diffusion Models","summary":"Text-to-image (T2I) diffusion models enable high-quality image generation conditioned on textual prompts. However, fine-tuning these pre-trained models for personalization raises concerns about unauthorized dataset usage. To address this issue, dataset ownership verification (DOV) has recently been proposed, which embeds watermarks into fine-tuning datasets via backdoor techniques. These watermarks remain dormant on benign samples but produce owner-specified outputs when triggered. Despite its promise, the robustness of DOV against copyright evasion attacks (CEA) remains unexplored. In this paper, we investigate how adversaries can circumvent these mechanisms, enabling models trained on watermarked datasets to bypass ownership verification. We begin by analyzing the limitations of potential attacks achieved by backdoor removal, including TPD and T2IShield. In practice, TPD suffers from inconsistent effectiveness due to randomness, while T2IShield fails when watermarks are embedded as local image patches. To this end, we introduce CEAT2I, the first CEA specifically targeting DOV in T2I diffusion models. CEAT2I consists of three stages: (1) motivated by the observation that T2I models converge faster on watermarked samples with respect to intermediate features rather than training loss, we reliably detect watermarked samples; (2) we iteratively ablate tokens from the prompts of detected samples and monitor feature shifts to identify trigger tokens; and (3) we apply a closed-form concept erasure method to remove the injected watermarks. Extensive experiments demonstrate that CEAT2I effectively evades state-of-the-art DOV mechanisms while preserving model performance. The code is available at https://github.com/csyufei/CEAT2I.","authors":["Kuofeng Gao","Yufei Zhu","Yiming Li","Jiawang Bai","Yong Yang","Zhifeng Li","Shu-Tao Xia"],"pdf_url":"","comment":"Accepted by IEEE Transactions on Information Forensics and Security"},{"id":"http://arxiv.org/abs/2512.20423v1","updated":"2025-12-23T15:07:17Z","published":"2025-12-23T15:07:17Z","title":"Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit","summary":"The purpose of this project is to assess how well defenders can detect DNS-over-HTTPS (DoH) file exfiltration, and which evasion strategies can be used by attackers. While providing a reproducible toolkit to generate, intercept and analyze DoH exfiltration, and comparing Machine Learning vs threshold-based detection under adversarial scenarios. The originality of this project is the introduction of an end-to-end, containerized pipeline that generates configurable file exfiltration over DoH using several parameters (e.g., chunking, encoding, padding, resolver rotation). It allows for file reconstruction at the resolver side, while extracting flow-level features using a fork of DoHLyzer. The pipeline contains a prediction side, which allows the training of machine learning models based on public labelled datasets and then evaluates them side-by-side with threshold-based detection methods against malicious and evasive DNS-Over-HTTPS traffic. We train Random Forest, Gradient Boosting and Logistic Regression classifiers on a public DoH dataset and benchmark them against evasive DoH exfiltration scenarios. The toolkit orchestrates traffic generation, file capture, feature extraction, model training and analysis. The toolkit is then encapsulated into several Docker containers for easy setup and full reproducibility regardless of the platform it is run on. Future research regarding this project is directed at validating the results on mixed enterprise traffic, extending the protocol coverage to HTTP/3/QUIC request, adding a benign traffic generation, and working on real-time traffic evaluation. A key objective is to quantify when stealth constraints make DoH exfiltration uneconomical and unworthy for the attacker.","authors":["Adam Elaoumari"],"pdf_url":"","comment":"61 pages Advisor : Dr Darren Hurley-Smith"},{"id":"http://arxiv.org/abs/2512.16531v3","updated":"2025-12-23T15:02:39Z","published":"2025-12-18T13:40:33Z","title":"Scaling Laws for Energy Efficiency of Local LLMs","summary":"Deploying local large language models and vision-language models on edge devices requires balancing accuracy with constrained computational and energy budgets. Although graphics processors dominate modern artificial-intelligence deployment, most consumer hardware--including laptops, desktops, industrial controllers, and embedded systems--relies on central processing units. Despite this, the computational laws governing central-processing-unit-only inference for local language and vision-language workloads remain largely unexplored. We systematically benchmark large language and vision-language models on two representative central-processing-unit tiers widely used for local inference: a MacBook Pro M2, reflecting mainstream laptop-class deployment, and a Raspberry Pi 5, representing constrained, low-power embedded settings. Using a unified methodology based on continuous sampling of processor and memory usage together with area-under-curve integration, we characterize how computational load scales with input text length for language models and with image resolution for vision-language models. We uncover two empirical scaling laws: (1) computational cost for language-model inference scales approximately linearly with token length; and (2) vision-language models exhibit a preprocessing-driven \"resolution knee\", where compute remains constant above an internal resolution clamp and decreases sharply below it. Beyond these laws, we show that quantum-inspired compression reduces processor and memory usage by up to 71.9% and energy consumption by up to 62%, while preserving or improving semantic accuracy. These results provide a systematic quantification of multimodal central-processing-unit-only scaling for local language and vision-language workloads, and they identify model compression and input-resolution preprocessing as effective, low-cost levers for sustainable edge inference.","authors":["Ander Alvarez","Alessandro Genuardi","Nilotpal Sinha","Antonio Tiene","Mikail Okyay","Bakbergen Ryskulov","David Montero","Samuel Mugel","Román Orús"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20420v1","updated":"2025-12-23T15:02:12Z","published":"2025-12-23T15:02:12Z","title":"Simplifying Multi-Task Architectures Through Task-Specific Normalization","summary":"Multi-task learning (MTL) aims to leverage shared knowledge across tasks to improve generalization and parameter efficiency, yet balancing resources and mitigating interference remain open challenges. Architectural solutions often introduce elaborate task-specific modules or routing schemes, increasing complexity and overhead. In this work, we show that normalization layers alone are sufficient to address many of these challenges. Simply replacing shared normalization with task-specific variants already yields competitive performance, questioning the need for complex designs. Building on this insight, we propose Task-Specific Sigmoid Batch Normalization (TS$σ$BN), a lightweight mechanism that enables tasks to softly allocate network capacity while fully sharing feature extractors. TS$σ$BN improves stability across CNNs and Transformers, matching or exceeding performance on NYUv2, Cityscapes, CelebA, and PascalContext, while remaining highly parameter-efficient. Moreover, its learned gates provide a natural framework for analyzing MTL dynamics, offering interpretable insights into capacity allocation, filter specialization, and task relationships. Our findings suggest that complex MTL architectures may be unnecessary and that task-specific normalization offers a simple, interpretable, and efficient alternative.","authors":["Mihai Suteu","Ovidiu Serban"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.12289v2","updated":"2025-12-23T15:02:02Z","published":"2025-01-21T16:59:13Z","title":"Regressor-Guided Generative Image Editing Balances User Emotions to Reduce Time Spent Online","summary":"Internet overuse is a widespread phenomenon in today's digital society. Existing interventions, such as time limits or grayscaling, often rely on restrictive controls that provoke psychological reactance and are frequently circumvented. Building on prior work showing that emotional responses mediate the relationship between content consumption and online engagement, we investigate whether regulating the emotional impact of images can reduce online use in a non-coercive manner. We introduce and systematically analyze three regressor-guided image-editing approaches: (i) global optimization of emotion-related image attributes, (ii) optimization in a style latent space, and (iii) a diffusion-based method using classifier and classifier-free guidance. While the first two approaches modify low-level visual features (e.g., contrast, color), the diffusion-based method enables higher-level changes (e.g., adjusting clothing, facial features). Results from a controlled image-rating study and a social media experiment show that diffusion-based edits balance emotional responses and are associated with lower usage duration while preserving visual quality.","authors":["Christoph Gebhardt","Robin Willardt","Seyedmorteza Sadat","Chih-Wei Ning","Andreas Brombach","Jie Song","Otmar Hilliges","Christian Holz"],"pdf_url":"","comment":"44 pages, 22 figures"},{"id":"http://arxiv.org/abs/2512.20409v1","updated":"2025-12-23T14:55:53Z","published":"2025-12-23T14:55:53Z","title":"DETACH : Decomposed Spatio-Temporal Alignment for Exocentric Video and Ambient Sensors with Staged Learning","summary":"Aligning egocentric video with wearable sensors have shown promise for human action recognition, but face practical limitations in user discomfort, privacy concerns, and scalability. We explore exocentric video with ambient sensors as a non-intrusive, scalable alternative. While prior egocentric-wearable works predominantly adopt Global Alignment by encoding entire sequences into unified representations, this approach fails in exocentric-ambient settings due to two problems: (P1) inability to capture local details such as subtle motions, and (P2) over-reliance on modality-invariant temporal patterns, causing misalignment between actions sharing similar temporal patterns with different spatio-semantic contexts. To resolve these problems, we propose DETACH, a decomposed spatio-temporal framework. This explicit decomposition preserves local details, while our novel sensor-spatial features discovered via online clustering provide semantic grounding for context-aware alignment. To align the decomposed features, our two-stage approach establishes spatial correspondence through mutual supervision, then performs temporal alignment via a spatial-temporal weighted contrastive loss that adaptively handles easy negatives, hard negatives, and false negatives. Comprehensive experiments with downstream tasks on Opportunity++ and HWU-USP datasets demonstrate substantial improvements over adapted egocentric-wearable baselines.","authors":["Junho Yoon","Jaemo Jung","Hyunju Kim","Dongman Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20407v1","updated":"2025-12-23T14:55:08Z","published":"2025-12-23T14:55:08Z","title":"AUDRON: A Deep Learning Framework with Fused Acoustic Signatures for Drone Type Recognition","summary":"Unmanned aerial vehicles (UAVs), commonly known as drones, are increasingly used across diverse domains, including logistics, agriculture, surveillance, and defense. While these systems provide numerous benefits, their misuse raises safety and security concerns, making effective detection mechanisms essential. Acoustic sensing offers a low-cost and non-intrusive alternative to vision or radar-based detection, as drone propellers generate distinctive sound patterns. This study introduces AUDRON (AUdio-based Drone Recognition Network), a hybrid deep learning framework for drone sound detection, employing a combination of Mel-Frequency Cepstral Coefficients (MFCC), Short-Time Fourier Transform (STFT) spectrograms processed with convolutional neural networks (CNNs), recurrent layers for temporal modeling, and autoencoder-based representations. Feature-level fusion integrates complementary information before classification. Experimental evaluation demonstrates that AUDRON effectively differentiates drone acoustic signatures from background noise, achieving high accuracy while maintaining generalizability across varying conditions. AUDRON achieves 98.51 percent and 97.11 percent accuracy in binary and multiclass classification. The results highlight the advantage of combining multiple feature representations with deep learning for reliable acoustic drone detection, suggesting the framework's potential for deployment in security and surveillance applications where visual or radar sensing may be limited.","authors":["Rajdeep Chatterjee","Sudip Chakrabarty","Trishaani Acharjee","Deepanjali Mishra"],"pdf_url":"","comment":"Presented at the 2025 IEEE 22nd India Council International Conference (INDICON). 6 pages, 3 figures"},{"id":"http://arxiv.org/abs/2512.18689v2","updated":"2025-12-23T14:46:41Z","published":"2025-12-21T10:55:32Z","title":"Fusion of Multiscale Features Via Centralized Sparse-attention Network for EEG Decoding","summary":"Electroencephalography (EEG) signal decoding is a key technology that translates brain activity into executable commands, laying the foundation for direct brain-machine interfacing and intelligent interaction. To address the inherent spatiotemporal heterogeneity of EEG signals, this paper proposes a multi-branch parallel architecture, where each temporal scale is equipped with an independent spatial feature extraction module. To further enhance multi-branch feature fusion, we propose a Fusion of Multiscale Features via Centralized Sparse-attention Network (EEG-CSANet), a centralized sparse-attention network. It employs a main-auxiliary branch architecture, where the main branch models core spatiotemporal patterns via multiscale self-attention, and the auxiliary branch facilitates efficient local interactions through sparse cross-attention. Experimental results show that EEG-CSANet achieves state-of-the-art (SOTA) performance across five public datasets (BCIC-IV-2A, BCIC-IV-2B, HGD, SEED, and SEED-VIG), with accuracies of 88.54%, 91.09%, 99.43%, 96.03%, and 90.56%, respectively. Such performance demonstrates its strong adaptability and robustness across various EEG decoding tasks. Moreover, extensive ablation studies are conducted to enhance the interpretability of EEG-CSANet. In the future, we hope that EEG-CSANet could serve as a promising baseline model in the field of EEG signal decoding. The source code is publicly available at: https://github.com/Xiangrui-Cai/EEG-CSANet","authors":["Xiangrui Cai","Shaocheng Ma","Lei Cao","Jie Li","Tianyu Liu","Yilin Dong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20387v1","updated":"2025-12-23T14:22:26Z","published":"2025-12-23T14:22:26Z","title":"Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems","summary":"We propose a Vision-Language Simulation Model (VLSM) that unifies visual and textual understanding to synthesize executable FlexScript from layout sketches and natural-language prompts, enabling cross-modal reasoning for industrial simulation systems. To support this new paradigm, the study constructs the first large-scale dataset for generative digital twins, comprising over 120,000 prompt-sketch-code triplets that enable multimodal learning between textual descriptions, spatial structures, and simulation logic. In parallel, three novel evaluation metrics, Structural Validity Rate (SVR), Parameter Match Rate (PMR), and Execution Success Rate (ESR), are proposed specifically for this task to comprehensively evaluate structural integrity, parameter fidelity, and simulator executability. Through systematic ablation across vision encoders, connectors, and code-pretrained language backbones, the proposed models achieve near-perfect structural accuracy and high execution robustness. This work establishes a foundation for generative digital twins that integrate visual reasoning and language understanding into executable industrial simulation systems.","authors":["YuChe Hsu","AnJui Wang","TsaiChing Ni","YuanFu Yang"],"pdf_url":"","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2512.20381v1","updated":"2025-12-23T14:12:02Z","published":"2025-12-23T14:12:02Z","title":"Identifying Appropriately-Sized Services with Deep Reinforcement Learning","summary":"Service-based architecture (SBA) has gained attention in industry and academia as a means to modernize legacy systems. It refers to a design style that enables systems to be developed as suites of small, loosely coupled, and autonomous components (services) that encapsulate functionality and communicate via language-agnostic APIs. However, defining appropriately sized services that capture cohesive subsets of system functionality remains challenging. Existing work often relies on the availability of documentation, access to project personnel, or a priori knowledge of the target number of services, assumptions that do not hold in many real-world scenarios. Our work addresses these limitations using a deep reinforcement learning-based approach to identify appropriately sized services directly from implementation artifacts. We present Rake, a reinforcement learning-based technique that leverages available system documentation and source code to guide service decomposition at the level of implementation methods. Rake does not require specific documentation or access to project personnel and is language-agnostic. It also supports a customizable objective function that balances modularization quality and business capability alignment, i.e., the degree to which a service covers the targeted business capability. We applied Rake to four open-source legacy projects and compared it with two state-of-the-art techniques. On average, Rake achieved 7-14 percent higher modularization quality and 18-22 percent stronger business capability alignment. Our results further show that optimizing solely for business context can degrade decomposition quality in tightly coupled systems, highlighting the need for balanced objectives.","authors":["Syeda Tasnim Fabiha","Saad Shafiq","Wesley Klewerton Guez Assunção","Nenad Medvidović"],"pdf_url":"","comment":"22 pages, 6 figures"},{"id":"http://arxiv.org/abs/2512.20363v1","updated":"2025-12-23T13:46:38Z","published":"2025-12-23T13:46:38Z","title":"Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning","summary":"Federated learning (FL) supports privacy-preserving, decentralized machine learning (ML) model training by keeping data on client devices. However, non-independent and identically distributed (non-IID) data across clients biases updates and degrades performance. To alleviate these issues, we propose Clust-PSI-PFL, a clustering-based personalized FL framework that uses the Population Stability Index (PSI) to quantify the level of non-IID data. We compute a weighted PSI metric, $WPSI^L$, which we show to be more informative than common non-IID metrics (Hellinger, Jensen-Shannon, and Earth Mover's distance). Using PSI features, we form distributionally homogeneous groups of clients via K-means++; the number of optimal clusters is chosen by a systematic silhouette-based procedure, typically yielding few clusters with modest overhead. Across six datasets (tabular, image, and text modalities), two partition protocols (Dirichlet with parameter $α$ and Similarity with parameter S), and multiple client sizes, Clust-PSI-PFL delivers up to 18% higher global accuracy than state-of-the-art baselines and markedly improves client fairness by a relative improvement of 37% under severe non-IID data. These results establish PSI-guided clustering as a principled, lightweight mechanism for robust PFL under label skew.","authors":["Daniel M. Jimenez-Gutierrez","Mehrdad Hassanzadeh","Aris Anagnostopoulos","Ioannis Chatzigiannakis","Andrea Vitaletti"],"pdf_url":"","comment":"Accepted for publication to the 40th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2026)"},{"id":"http://arxiv.org/abs/2512.20352v1","updated":"2025-12-23T13:32:43Z","published":"2025-12-23T13:32:43Z","title":"Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation","summary":"Qualitative research faces a critical reliability challenge: traditional inter-rater agreement methods require multiple human coders, are time-intensive, and often yield moderate consistency. We present a multi-perspective validation framework for LLM-based thematic analysis that combines ensemble validation with dual reliability metrics: Cohen's Kappa ($κ$) for inter-rater agreement and cosine similarity for semantic consistency. Our framework enables configurable analysis parameters (1-6 seeds, temperature 0.0-2.0), supports custom prompt structures with variable substitution, and provides consensus theme extraction across any JSON format. As proof-of-concept, we evaluate three leading LLMs (Gemini 2.5 Pro, GPT-4o, Claude 3.5 Sonnet) on a psychedelic art therapy interview transcript, conducting six independent runs per model. Results demonstrate Gemini achieves highest reliability ($κ= 0.907$, cosine=95.3%), followed by GPT-4o ($κ= 0.853$, cosine=92.6%) and Claude ($κ= 0.842$, cosine=92.1%). All three models achieve a high agreement ($κ> 0.80$), validating the multi-run ensemble approach. The framework successfully extracts consensus themes across runs, with Gemini identifying 6 consensus themes (50-83% consistency), GPT-4o identifying 5 themes, and Claude 4 themes. Our open-source implementation provides researchers with transparent reliability metrics, flexible configuration, and structure-agnostic consensus extraction, establishing methodological foundations for reliable AI-assisted qualitative research.","authors":["Nilesh Jain","Seyi Adeyinka","Leor Roseman","Aza Allsop"],"pdf_url":"","comment":"11 pages, 1 figure, 3 tables"},{"id":"http://arxiv.org/abs/2508.12029v3","updated":"2025-12-23T13:32:11Z","published":"2025-08-16T12:31:39Z","title":"BConformeR: A Conformer Based on Mutual Sampling for Unified Prediction of Continuous and Discontinuous Antibody Binding Sites","summary":"Accurate prediction of antibody-binding sites (epitopes) on antigens is crucial for vaccine design, immunodiagnostics, therapeutic antibody development, antibody engineering, research into autoimmune and allergic diseases, and advancing our understanding of immune responses. Despite in silico methods that have been proposed to predict both linear (continuous) and conformational (discontinuous) epitopes, they consistently underperform in predicting conformational epitopes. In this work, we propose Conformer-based models trained separately on AlphaFold-predicted structures and experimentally determined structures, leveraging convolutional neural networks (CNNs) to extract local features and Transformers to capture long-range dependencies within antigen sequences. Ablation studies demonstrate that CNN enhances the prediction of linear epitopes, and the Transformer module improves the prediction of conformational epitopes. Experimental results show that our model outperforms existing baselines in terms of MCC, ROC-AUC, PR-AUC, and F1 scores on both linear and conformational epitopes.","authors":["Zhangyu You","Jiahao Ma","Hongzong Li","Ye-Fan Hu","Jian-Dong Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20344v1","updated":"2025-12-23T13:26:13Z","published":"2025-12-23T13:26:13Z","title":"A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice","summary":"A global shortage of radiologists has been exacerbated by the significant volume of chest X-ray workloads, particularly in primary care. Although multimodal large language models show promise, existing evaluations predominantly rely on automated metrics or retrospective analyses, lacking rigorous prospective clinical validation. Janus-Pro-CXR (1B), a chest X-ray interpretation system based on DeepSeek Janus-Pro model, was developed and rigorously validated through a multicenter prospective trial (NCT07117266). Our system outperforms state-of-the-art X-ray report generation models in automated report generation, surpassing even larger-scale models including ChatGPT 4o (200B parameters), while demonstrating reliable detection of six clinically critical radiographic findings. Retrospective evaluation confirms significantly higher report accuracy than Janus-Pro and ChatGPT 4o. In prospective clinical deployment, AI assistance significantly improved report quality scores, reduced interpretation time by 18.3% (P < 0.001), and was preferred by a majority of experts in 54.3% of cases. Through lightweight architecture and domain-specific optimization, Janus-Pro-CXR improves diagnostic reliability and workflow efficiency, particularly in resource-constrained settings. The model architecture and implementation framework will be open-sourced to facilitate the clinical translation of AI-assisted radiology solutions.","authors":["Yaowei Bai","Ruiheng Zhang","Yu Lei","Xuhua Duan","Jingfeng Yao","Shuguang Ju","Chaoyang Wang","Wei Yao","Yiwan Guo","Guilin Zhang","Chao Wan","Qian Yuan","Lei Chen","Wenjuan Tang","Biqiang Zhu","Xinggang Wang","Tao Sun","Wei Zhou","Dacheng Tao","Yongchao Xu","Chuansheng Zheng","Huangxuan Zhao","Bo Du"],"pdf_url":"","comment":"arXiv admin note: substantial text overlap with arXiv:2507.19493"},{"id":"http://arxiv.org/abs/2507.20993v2","updated":"2025-12-23T13:19:34Z","published":"2025-07-28T16:52:31Z","title":"Learning Treatment Policies From Multimodal Electronic Health Records","summary":"We study how to learn effective treatment policies from multimodal electronic health records (EHRs) that consist of tabular data and clinical text. These policies can help physicians make better treatment decisions and allocate healthcare resources more efficiently. Causal policy learning methods prioritize patients with the largest expected treatment benefit. Yet, existing estimators assume tabular covariates that satisfy strong causal assumptions, which are typically violated in the multimodal setting. As a result, predictive models of baseline risk are commonly used in practice to guide such decisions, as they extend naturally to multimodal data. However, such risk-based policies are not designed to identify which patients benefit most from treatment. We propose an extension of causal policy learning that uses expert-provided annotations during training to supervise treatment effect estimation, while using only multimodal representations as input during inference. We show that the proposed method achieves strong empirical performance across synthetic, semi-synthetic, and real-world EHR datasets, thereby offering practical insights into applying causal machine learning to realistic clinical data.","authors":["Henri Arno","Thomas Demeester"],"pdf_url":"","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2506.05831v3","updated":"2025-12-23T13:17:55Z","published":"2025-06-06T07:56:41Z","title":"Heartcare Suite: A Unified Multimodal ECG Suite for Dual Signal-Image Modeling and Understanding","summary":"Although electrocardiograms (ECG) play a dominant role in cardiovascular diagnosis and treatment, their intrinsic data forms and representational patterns pose significant challenges for medical multimodal large language models (Med-MLLMs) in achieving cross-modal semantic alignment. To address this gap, we propose Heartcare Suite, a unified ECG suite designed for dual signal-image modeling and understanding. (i) Heartcare-400K: We build a finegrained ECG instruction dataset on top of our data pipeline engine--HeartAgent--by integrating 12,170 high quality clinical ECG reports from top hospitals with open-source data; (ii) Heartcare-Bench: a systematic benchmark assessing performance of models in multi-perspective ECG understanding and cross-modal generalization, providing guidance for optimizing ECG comprehension models; (iii) HeartcareGPT: built upon a structure-aware discrete tokenizer Beat, we propose the DSPA (Dual Stream Projection Alignment) paradigm--a dual encoder projection alignment mechanism enabling joint optimizing and modeling native ECG signal-image within a shared feature space. Heartcare achieves consistent improvements across diverse ECG understanding tasks, validating both the effectiveness of the unified modeling paradigm and the necessity of a high-quality data pipeline, and establishing a methodological foundation for extending Med-MLLMs toward physiological signal domains. Our project is available at https://github.com/DCDmllm/Heartcare-Suite .","authors":["Yihan Xie","Sijing Li","Tianwei Lin","Zhuonan Wang","Chenglin Yang","Yu Zhong","Wenjie Yan","Wenqiao Zhang","Xiaogang Guo","Jun Xiao","Yueting Zhuang","Beng Chin Ooi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20333v1","updated":"2025-12-23T13:07:22Z","published":"2025-12-23T13:07:22Z","title":"SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization","summary":"Generative artificial intelligence has revolutionized the exploration of chemical space, yet a critical bottleneck remains that a substantial fraction of generated molecules is synthetically inaccessible. Current solutions, such as post-hoc filtering or projection-based methods, often compromise structural novelty or disrupt key pharmacophores by forcing molecules into pre-defined synthetic templates. Herein, we introduce SynCraft, a reasoning-based framework that reframes synthesizability optimization not as a sequence translation task, but as a precise structural editing problem. Leveraging the emergent reasoning capabilities of Large Language Models, SynCraft navigates the \"synthesis cliff\" where minimal structural modifications yield significant gains in synthetic feasibility. By predicting executable sequences of atom-level edits rather than generating SMILES strings directly, SynCraft circumvents the syntactic fragility of LLMs while harnessing their chemical intuition. Extensive benchmarks demonstrate that SynCraft outperforms state-of-the-art baselines in generating synthesizable analogs with high structural fidelity. Furthermore, through interaction-aware prompting, SynCraft successfully replicates expert medicinal chemistry intuition in editing PLK1 inhibitors and rescuing high-scoring but previously discarded RIPK1 candidates in previous molecular generation literatures.","authors":["Junren Li","Luhua Lai"],"pdf_url":"","comment":"28 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2512.19253v2","updated":"2025-12-23T13:00:45Z","published":"2025-12-22T10:40:03Z","title":"Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study","summary":"We present the first comprehensive empirical study of machine unlearning (MU) in hybrid quantum-classical neural networks. While MU has been extensively explored in classical deep learning, its behavior within variational quantum circuits (VQCs) and quantum-augmented architectures remains largely unexplored. First, we adapt a broad suite of unlearning methods to quantum settings, including gradient-based, distillation-based, regularization-based and certified techniques. Second, we introduce two new unlearning strategies tailored to hybrid models. Experiments across Iris, MNIST, and Fashion-MNIST, under both subset removal and full-class deletion, reveal that quantum models can support effective unlearning, but outcomes depend strongly on circuit depth, entanglement structure, and task complexity. Shallow VQCs display high intrinsic stability with minimal memorization, whereas deeper hybrid models exhibit stronger trade-offs between utility, forgetting strength, and alignment with retrain oracle. We find that certain methods, e.g. EU-k, LCA, and Certified Unlearning, consistently provide the best balance across metrics. These findings establish baseline empirical insights into quantum machine unlearning and highlight the need for quantum-aware algorithms and theoretical guarantees, as quantum machine learning systems continue to expand in scale and capability. We publicly release our code at: https://github.com/CrivoiCarla/HQML.","authors":["Carla Crivoi","Radu Tudor Ionescu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20328v1","updated":"2025-12-23T12:56:18Z","published":"2025-12-23T12:56:18Z","title":"Toward Explaining Large Language Models in Software Engineering Tasks","summary":"Recent progress in Large Language Models (LLMs) has substantially advanced the automation of software engineering (SE) tasks, enabling complex activities such as code generation and code summarization. However, the black-box nature of LLMs remains a major barrier to their adoption in high-stakes and safety-critical domains, where explainability and transparency are vital for trust, accountability, and effective human supervision. Despite increasing interest in explainable AI for software engineering, existing methods lack domain-specific explanations aligned with how practitioners reason about SE artifacts. To address this gap, we introduce FeatureSHAP, the first fully automated, model-agnostic explainability framework tailored to software engineering tasks. Based on Shapley values, FeatureSHAP attributes model outputs to high-level input features through systematic input perturbation and task-specific similarity comparisons, while remaining compatible with both open-source and proprietary LLMs. We evaluate FeatureSHAP on two bi-modal SE tasks: code generation and code summarization. The results show that FeatureSHAP assigns less importance to irrelevant input features and produces explanations with higher fidelity than baseline methods. A practitioner survey involving 37 participants shows that FeatureSHAP helps practitioners better interpret model outputs and make more informed decisions. Collectively, FeatureSHAP represents a meaningful step toward practical explainable AI in software engineering. FeatureSHAP is available at https://github.com/deviserlab/FeatureSHAP.","authors":["Antonio Vitale","Khai-Nguyen Nguyen","Denys Poshyvanyk","Rocco Oliveto","Simone Scalabrino","Antonio Mastropaolo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.13892v2","updated":"2025-12-23T12:54:15Z","published":"2025-12-15T20:50:54Z","title":"One Permutation Is All You Need: Fast, Reliable Variable Importance and Model Stress-Testing","summary":"Reliable estimation of feature contributions in machine learning models is essential for trust, transparency and regulatory compliance, especially when models are proprietary or otherwise operate as black boxes. While permutation-based methods are a standard tool for this task, classical implementations rely on repeated random permutations, introducing computational overhead and stochastic instability. In this paper, we show that by replacing multiple random permutations with a single, deterministic, and optimal permutation, we achieve a method that retains the core principles of permutation-based importance while being non-random, faster, and more stable. We validate this approach across nearly 200 scenarios, including real-world household finance and credit risk applications, demonstrating improved bias-variance tradeoffs and accuracy in challenging regimes such as small sample sizes, high dimensionality, and low signal-to-noise ratios. Finally, we introduce Systemic Variable Importance, a natural extension designed for model stress-testing that explicitly accounts for feature correlations. This framework provides a transparent way to quantify how shocks or perturbations propagate through correlated inputs, revealing dependencies that standard variable importance measures miss. Two real-world case studies demonstrate how this metric can be used to audit models for hidden reliance on protected attributes (e.g., gender or race), enabling regulators and practitioners to assess fairness and systemic risk in a principled and computationally efficient manner.","authors":["Albert Dorador"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20319v1","updated":"2025-12-23T12:40:51Z","published":"2025-12-23T12:40:51Z","title":"Deep Learning Classification of EEG Responses to Multi-Dimensional Transcranial Electrical Stimulation","summary":"A major shortcoming of medical practice is the lack of an objective measure of conscious level. Impairment of consciousness is common, e.g. following brain injury and seizures, which can also interfere with sensory processing and volitional responses. This is also an important pitfall in neurophysiological methods that infer awareness via command following, e.g. using functional MRI or electroencephalography (EEG).\n  Transcranial electrical stimulation (TES) can be employed to non-invasively stimulate the brain, bypassing sensory inputs, and has already showed promising results in providing reliable indicators of brain state. However, current non-invasive solutions have been limited to magnetic stimulation, which is not easily translatable to clinical settings. Our long-term vision is to develop an objective measure of brain state that can be used at the bedside, without requiring patients to understand commands or initiate motor responses.\n  In this study, we demonstrated the feasibility of a framework using Deep Learning algorithms to classify EEG brain responses evoked by a defined multi-dimensional pattern of TES. We collected EEG-TES data from 11 participants and found that delivering transcranial direct current stimulation (tDCS) to posterior cortical areas targeting the angular gyrus elicited an exceptionally reliable brain response. For this paradigm, our best Convolutional Neural Network model reached a 92% classification F1-score on Holdout data from participants never seen during training, significantly surpassing human-level performance at 60-70% accuracy.\n  These findings establish a framework for robust consciousness measurement for clinical use. In this spirit, we documented and open-sourced our datasets and codebase in full, to be used freely by the neuroscience and AI research communities, who may replicate our results with free tools like GitHub, Kaggle, and Colab.","authors":["Alexis Pomares Pastor","Ines Ribeiro Violante","Gregory Scott"],"pdf_url":"","comment":"For open-sourced datasets and source code, see: https://github.com/alexispomares/DL-EEG-TES"},{"id":"http://arxiv.org/abs/2511.18417v2","updated":"2025-12-23T12:33:25Z","published":"2025-11-23T12:07:45Z","title":"Categorical Equivariant Deep Learning: Category-Equivariant Neural Networks and Universal Approximation Theorems","summary":"We develop a theory of category-equivariant neural networks (CENNs) that unifies group/groupoid-equivariant networks, poset/lattice-equivariant networks, graph and sheaf neural networks. Equivariance is formulated as naturality in a topological category with Radon measures. Formulating linear and nonlinear layers in the categorical setup, we prove the equivariant universal approximation theorem in the general setting: the class of finite-depth CENNs is dense in the space of continuous equivariant transformations. We instantiate the framework for groups/groupoids, posets/lattices, graphs and cellular sheaves, deriving universal approximation theorems for them in a systematic manner. Categorical equivariant deep learning thus allows us to expand the horizons of equivariant deep learning beyond group actions, encompassing not only geometric symmetries but also contextual and compositional symmetries.","authors":["Yoshihiro Maruyama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20312v1","updated":"2025-12-23T12:30:37Z","published":"2025-12-23T12:30:37Z","title":"TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning","summary":"Tabular data serves as the backbone of modern data analysis and scientific research. While Large Language Models (LLMs) fine-tuned via Supervised Fine-Tuning (SFT) have significantly improved natural language interaction with such structured data, they often fall short in handling the complex, multi-step reasoning and robust code execution required for real-world table tasks. Reinforcement Learning (RL) offers a promising avenue to enhance these capabilities, yet its application in the tabular domain faces three critical hurdles: the scarcity of high-quality agentic trajectories with closed-loop code execution and environment feedback on diverse table structures, the extreme heterogeneity of feedback signals ranging from rigid SQL execution to open-ended data interpretation, and the risk of catastrophic forgetting of general knowledge during vertical specialization. To overcome these challenges and unlock advanced reasoning on complex tables, we introduce \\textbf{TableGPT-R1}, a specialized tabular model built on a systematic RL framework. Our approach integrates a comprehensive data engineering pipeline that synthesizes difficulty-stratified agentic trajectories for both supervised alignment and RL rollouts, a task-adaptive reward system that combines rule-based verification with a criteria-injected reward model and incorporates process-level step reward shaping with behavioral regularization, and a multi-stage training framework that progressively stabilizes reasoning before specializing in table-specific tasks. Extensive evaluations demonstrate that TableGPT-R1 achieves state-of-the-art performance on authoritative benchmarks, significantly outperforming baseline models while retaining robust general capabilities. Our model is available at https://huggingface.co/tablegpt/TableGPT-R1.","authors":["Saisai Yang","Qingyi Huang","Jing Yuan","Liangyu Zha","Kai Tang","Yuhang Yang","Ning Wang","Yucheng Wei","Liyao Li","Wentao Ye","Hao Chen","Tao Zhang","Junlin Zhou","Haobo Wang","Gang Chen","Junbo Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.10688v4","updated":"2025-12-23T12:25:36Z","published":"2025-12-11T14:35:13Z","title":"Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition","summary":"Popularity bias fundamentally undermines the personalization capabilities of collaborative filtering (CF) models, causing them to disproportionately recommend popular items while neglecting users' genuine preferences for niche content. While existing approaches treat this as an external confounding factor, we reveal that popularity bias is an intrinsic geometric artifact of Bayesian Pairwise Ranking (BPR) optimization in CF models. Through rigorous mathematical analysis, we prove that BPR systematically organizes item embeddings along a dominant \"popularity direction\" where embedding magnitudes directly correlate with interaction frequency. This geometric distortion forces user embeddings to simultaneously handle two conflicting tasks-expressing genuine preference and calibrating against global popularity-trapping them in suboptimal configurations that favor popular items regardless of individual tastes. We propose Directional Decomposition and Correction (DDC), a universally applicable framework that surgically corrects this embedding geometry through asymmetric directional updates. DDC guides positive interactions along personalized preference directions while steering negative interactions away from the global popularity direction, disentangling preference from popularity at the geometric source. Extensive experiments across multiple BPR-based architectures demonstrate that DDC significantly outperforms state-of-the-art debiasing methods, reducing training loss to less than 5% of heavily-tuned baselines while achieving superior recommendation quality and fairness. Code is available in https://github.com/LingFeng-Liu-AI/DDC.","authors":["Lingfeng Liu","Yixin Song","Dazhong Shen","Bing Yin","Hao Li","Yanyong Zhang","Chao Wang"],"pdf_url":"","comment":"Accepted by SIGKDD 2026(First Cycle)"},{"id":"http://arxiv.org/abs/2512.20299v1","updated":"2025-12-23T12:08:00Z","published":"2025-12-23T12:08:00Z","title":"KnowVal: A Knowledge-Augmented and Value-Guided Autonomous Driving System","summary":"Visual-language reasoning, driving knowledge, and value alignment are essential for advanced autonomous driving systems. However, existing approaches largely rely on data-driven learning, making it difficult to capture the complex logic underlying decision-making through imitation or limited reinforcement rewards. To address this, we propose KnowVal, a new autonomous driving system that enables visual-language reasoning through the synergistic integration of open-world perception and knowledge retrieval. Specifically, we construct a comprehensive driving knowledge graph that encodes traffic laws, defensive driving principles, and ethical norms, complemented by an efficient LLM-based retrieval mechanism tailored for driving scenarios. Furthermore, we develop a human-preference dataset and train a Value Model to guide interpretable, value-aligned trajectory assessment. Experimental results show that our method substantially improves planning performance while remaining compatible with existing architectures. Notably, KnowVal achieves the lowest collision rate on nuScenes and state-of-the-art results on Bench2Drive.","authors":["Zhongyu Xia","Wenhao Chen","Yongtao Wang","Ming-Hsuan Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20298v1","updated":"2025-12-23T12:05:01Z","published":"2025-12-23T12:05:01Z","title":"Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives","summary":"Growing reliance on LLMs for psychiatric self-assessment raises questions about their ability to interpret qualitative patient narratives. We present the first direct comparison between state-of-the-art LLMs and mental health professionals in diagnosing Borderline (BPD) and Narcissistic (NPD) Personality Disorders utilizing Polish-language first-person autobiographical accounts. We show that the top-performing Gemini Pro models surpassed human professionals in overall diagnostic accuracy by 21.91 percentage points (65.48% vs. 43.57%). While both models and human experts excelled at identifying BPD (F1 = 83.4 & F1 = 80.0, respectively), models severely underdiagnosed NPD (F1 = 6.7 vs. 50.0), showing a reluctance toward the value-laden term \"narcissism.\" Qualitatively, models provided confident, elaborate justifications focused on patterns and formal categories, while human experts remained concise and cautious, emphasizing the patient's sense of self and temporal experience. Our findings demonstrate that while LLMs are highly competent at interpreting complex first-person clinical data, they remain subject to critical reliability and bias issues.","authors":["Karolina Drożdż","Kacper Dudzic","Anna Sterna","Marcin Moskalewicz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20296v1","updated":"2025-12-23T12:04:23Z","published":"2025-12-23T12:04:23Z","title":"TAVID: Text-Driven Audio-Visual Interactive Dialogue Generation","summary":"The objective of this paper is to jointly synthesize interactive videos and conversational speech from text and reference images. With the ultimate goal of building human-like conversational systems, recent studies have explored talking or listening head generation as well as conversational speech generation. However, these works are typically studied in isolation, overlooking the multimodal nature of human conversation, which involves tightly coupled audio-visual interactions. In this paper, we introduce TAVID, a unified framework that generates both interactive faces and conversational speech in a synchronized manner. TAVID integrates face and speech generation pipelines through two cross-modal mappers (i.e., a motion mapper and a speaker mapper), which enable bidirectional exchange of complementary information between the audio and visual modalities. We evaluate our system across four dimensions: talking face realism, listening head responsiveness, dyadic interaction fluency, and speech quality. Extensive experiments demonstrate the effectiveness of our approach across all these aspects.","authors":["Ji-Hoon Kim","Junseok Ahn","Doyeop Kwak","Joon Son Chung","Shinji Watanabe"],"pdf_url":"","comment":"Project page: https://mm.kaist.ac.kr/projects/TAVID"},{"id":"http://arxiv.org/abs/2512.20292v1","updated":"2025-12-23T12:01:18Z","published":"2025-12-23T12:01:18Z","title":"SlideTailor: Personalized Presentation Slide Generation for Scientific Papers","summary":"Automatic presentation slide generation can greatly streamline content creation. However, since preferences of each user may vary, existing under-specified formulations often lead to suboptimal results that fail to align with individual user needs. We introduce a novel task that conditions paper-to-slides generation on user-specified preferences. We propose a human behavior-inspired agentic framework, SlideTailor, that progressively generates editable slides in a user-aligned manner. Instead of requiring users to write their preferences in detailed textual form, our system only asks for a paper-slides example pair and a visual template - natural and easy-to-provide artifacts that implicitly encode rich user preferences across content and visual style. Despite the implicit and unlabeled nature of these inputs, our framework effectively distills and generalizes the preferences to guide customized slide generation. We also introduce a novel chain-of-speech mechanism to align slide content with planned oral narration. Such a design significantly enhances the quality of generated slides and enables downstream applications like video presentations. To support this new task, we construct a benchmark dataset that captures diverse user preferences, with carefully designed interpretable metrics for robust evaluation. Extensive experiments demonstrate the effectiveness of our framework.","authors":["Wenzheng Zeng","Mingyu Ouyang","Langyuan Cui","Hwee Tou Ng"],"pdf_url":"","comment":"AAAI 2026 (with appendix)"},{"id":"http://arxiv.org/abs/2512.20288v1","updated":"2025-12-23T11:57:34Z","published":"2025-12-23T11:57:34Z","title":"UbiQVision: Quantifying Uncertainty in XAI for Image Recognition","summary":"Recent advances in deep learning have led to its widespread adoption across diverse domains, including medical imaging. This progress is driven by increasingly sophisticated model architectures, such as ResNets, Vision Transformers, and Hybrid Convolutional Neural Networks, that offer enhanced performance at the cost of greater complexity. This complexity often compromises model explainability and interpretability. SHAP has emerged as a prominent method for providing interpretable visualizations that aid domain experts in understanding model predictions. However, SHAP explanations can be unstable and unreliable in the presence of epistemic and aleatoric uncertainty. In this study, we address this challenge by using Dirichlet posterior sampling and Dempster-Shafer theory to quantify the uncertainty that arises from these unstable explanations in medical imaging applications. The framework uses a belief, plausible, and fusion map approach alongside statistical quantitative analysis to produce quantification of uncertainty in SHAP. Furthermore, we evaluated our framework on three medical imaging datasets with varying class distributions, image qualities, and modality types which introduces noise due to varying image resolutions and modality-specific aspect covering the examples from pathology, ophthalmology, and radiology, introducing significant epistemic uncertainty.","authors":["Akshat Dubey","Aleksandar Anžel","Bahar İlgen","Georges Hattab"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2212.12044v2","updated":"2025-12-23T11:35:12Z","published":"2022-12-22T21:27:40Z","title":"Reduced-order autoregressive dynamics of a complex financial system: a PCA-based approach","summary":"This study analyzes the dynamic interactions among the NASDAQ index, crude oil, gold, and the US dollar using a reduced-order modeling approach. Time-delay embedding and principal component analysis are employed to encode high-dimensional financial dynamics, followed by linear regression in the reduced space. Correlation and lagged regression analyses reveal heterogeneous cross-asset dependencies. Model performance, evaluated using the coefficient of determination ($R^2$), demonstrates that a limited number of principal components is sufficient to capture the dominant dynamics of each asset, with varying complexity across markets.","authors":["Pouriya Khalilian","Sara Azizi","Mohammad Hossein Amiri","Javad T. Firouzjaee"],"pdf_url":"","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2512.20278v1","updated":"2025-12-23T11:33:32Z","published":"2025-12-23T11:33:32Z","title":"Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation","summary":"While CodeMem establishes executable code as the optimal representation for agentic procedural memory, the mechanism for autonomously synthesizing this memory from a blank slate remains underexplored. This paper operationalizes the transition of Large Language Models from passive tool-users to active workflow architects. Through a high-fidelity case study of a cross-service orchestration task involving Outlook and OneDrive, we identify and address four structural bottlenecks in automated skill generation: the Discovery Gap involving navigation of large tool registries, the Verification Gap regarding grounding tool response structures, the Decomposition Gap which replaces inefficient search with Linear State Anchoring, and the Scaling Gap focused on concurrency and persistence. We demonstrate that by enforcing a scientific methodology of hypothesize, probe, and code, agents can autonomously write robust, production-grade code skills.","authors":["Nishant Gaurav","Adit Akarsh","Ankit Ranjan","Manoj Bajaj"],"pdf_url":"","comment":"7 pages"},{"id":"http://arxiv.org/abs/2507.11662v2","updated":"2025-12-23T11:29:24Z","published":"2025-07-15T18:50:29Z","title":"Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification","summary":"Verifiers--functions assigning rewards to agent behavior--have been key for AI progress in domains like math and code. However, extending gains to domains without clear-cut success criteria (e.g., computer use) remains a challenge: while humans can recognize desired outcomes, translating this intuition into scalable rules is nontrivial. Multimodal Large Language Models (MLLMs) emerge as a promising solution, given their world knowledge, human-preference alignment, and reasoning skills. We evaluate MLLMs as verifiers across web navigation, computer use, and robotic manipulation, and identify a critical limitation: a strong tendency to over-validate agent behavior, a phenomenon we term agreement bias. This bias is pervasive across models, resilient to test-time scaling, and poses risks to existing methods relying on MLLM evaluations. We discuss methods to evaluate and improve MLLM verifiers and introduce Self-Grounded Verification (SGV), a lightweight method that harnesses MLLMs' own sampling mechanisms by modulating (un)conditional generation to better leverage their knowledge, alignment, and reasoning. SGV operates in two steps: first, the MLLM is elicited to generate broad priors about desired behavior, independent of the data under evaluation. Then, conditioned on self-generated priors, it reasons over and evaluates a candidate trajectory. SGV yields more human-aligned evaluations with gains of up to 25pp in failure detection, 14pp in accuracy, and benefits extending to downstream applications. In self-refinement and online supervision, SGV boosts task completion of a GUI specialist in OSWorld, a diffusion policy in robomimic, and a ReAct agent in VisualWebArena--setting a new state of the art, surpassing the previous best by 20pp. We release an updated version of VisualWebArena featuring more human-aligned evaluators, high-fidelity environment parallelism, and speedups of over 10x.","authors":["Moises Andrade","Joonhyuk Cha","Brandon Ho","Vriksha Srihari","Karmesh Yadav","Zsolt Kira"],"pdf_url":"","comment":"Our code, models, and data are publicly available at https://mshalimay.github.io/agreement-bias-sgv/"},{"id":"http://arxiv.org/abs/2512.20276v1","updated":"2025-12-23T11:29:03Z","published":"2025-12-23T11:29:03Z","title":"ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge","summary":"Vision-Language-Action (VLA) models have emerged as a unified paradigm for robotic perception and control, enabling emergent generalization and long-horizon task execution. However, their deployment in dynamic, real-world environments is severely hin dered by high inference latency. While smooth robotic interaction requires control frequencies of 20 to 30 Hz, current VLA models typi cally operate at only 3-5 Hz on edge devices due to the memory bound nature of autoregressive decoding. Existing optimizations often require extensive retraining or compromise model accuracy. To bridge this gap, we introduce ActionFlow, a system-level inference framework tailored for resource-constrained edge plat forms. At the core of ActionFlow is a Cross-Request Pipelin ing strategy, a novel scheduler that redefines VLA inference as a macro-pipeline of micro-requests. The strategy intelligently batches memory-bound Decode phases with compute-bound Prefill phases across continuous time steps to maximize hardware utilization. Furthermore, to support this scheduling, we propose a Cross Request State Packed Forward operator and a Unified KV Ring Buffer, which fuse fragmented memory operations into efficient dense computations. Experimental results demonstrate that ActionFlow achieves a 2.55x improvement in FPS on the OpenVLA-7B model without retraining, enabling real-time dy namic manipulation on edge hardware. Our work is available at https://anonymous.4open.science/r/ActionFlow-1D47.","authors":["Yuntao Dai","Hang Gu","Teng Wang","Qianyu Cheng","Yifei Zheng","Zhiyong Qiu","Lei Gong","Wenqi Lou","Xuehai Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20275v1","updated":"2025-12-23T11:27:17Z","published":"2025-12-23T11:27:17Z","title":"Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks","summary":"As networks evolve toward 5G Standalone and 6G, operators face orchestration challenges that exceed the limits of static automation and Deep Reinforcement Learning. Although Large Language Model (LLM) agents offer a path toward intent-based networking, they introduce stochastic risks, including topology hallucinations and policy non-compliance. To mitigate this, we propose Graph-Symbolic Policy Enforcement and Control (G-SPEC), a neuro-symbolic framework that constrains probabilistic planning with deterministic verification. The architecture relies on a Governance Triad - a telecom-adapted agent (TSLAM-4B), a Network Knowledge Graph (NKG), and SHACL constraints. We evaluated G-SPEC on a simulated 450-node 5G Core, achieving zero safety violations and a 94.1% remediation success rate, significantly outperforming the 82.4% baseline. Ablation analysis indicates that NKG validation drives the majority of safety gains (68%), followed by SHACL policies (24%). Scalability tests on topologies ranging from 10K to 100K nodes demonstrate that validation latency scales as $O(k^{1.2})$ where $k$ is subgraph size. With a processing overhead of 142ms, G-SPEC is viable for SMO-layer operations.","authors":["Divya Vijay","Vignesh Ethiraj"],"pdf_url":"","comment":"15 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2510.15905v3","updated":"2025-12-23T11:24:58Z","published":"2025-09-16T20:19:53Z","title":"\"She's Like a Person but Better\": Characterizing Companion-Assistant Dynamics in Human-AI Relationships","summary":"Large language models are increasingly used for both task-based assistance and social companionship, yet research has typically focused on one or the other. Drawing on a survey (N = 202) and 30 interviews with high-engagement ChatGPT and Replika users, we characterize digital companionship as an emerging form of human-AI relationship. With both systems, users were drawn to humanlike qualities, such as emotional resonance and personalized responses, and non-humanlike qualities, such as constant availability and inexhaustible tolerance. This led to fluid chatbot uses, such as Replika as a writing assistant and ChatGPT as an emotional confidant, despite their distinct branding. However, we observed challenging tensions in digital companionship dynamics: participants grappled with bounded personhood, forming deep attachments while denying chatbots \"real\" human qualities, and struggled to reconcile chatbot relationships with social norms. These dynamics raise questions for the design of digital companions and the rise of hybrid, general-purpose AI systems.","authors":["Aikaterina Manoli","Janet V. T. Pauketat","Ali Ladak","Hayoun Noh","Angel Hsing-Chi Hwang","Jacy Reese Anthis"],"pdf_url":"","comment":"Improved visualizations, and corrected analysis error that had swapped reports of \"Respect\" and \"Shame.\""},{"id":"http://arxiv.org/abs/2512.20260v1","updated":"2025-12-23T11:16:16Z","published":"2025-12-23T11:16:16Z","title":"${D}^{3}${ETOR}: ${D}$ebate-Enhanced Pseudo Labeling and Frequency-Aware Progressive ${D}$ebiasing for Weakly-Supervised Camouflaged Object ${D}$etection with Scribble Annotations","summary":"Weakly-Supervised Camouflaged Object Detection (WSCOD) aims to locate and segment objects that are visually concealed within their surrounding scenes, relying solely on sparse supervision such as scribble annotations. Despite recent progress, existing WSCOD methods still lag far behind fully supervised ones due to two major limitations: (1) the pseudo masks generated by general-purpose segmentation models (e.g., SAM) and filtered via rules are often unreliable, as these models lack the task-specific semantic understanding required for effective pseudo labeling in COD; and (2) the neglect of inherent annotation bias in scribbles, which hinders the model from capturing the global structure of camouflaged objects. To overcome these challenges, we propose ${D}^{3}$ETOR, a two-stage WSCOD framework consisting of Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing. In the first stage, we introduce an adaptive entropy-driven point sampling method and a multi-agent debate mechanism to enhance the capability of SAM for COD, improving the interpretability and precision of pseudo masks. In the second stage, we design FADeNet, which progressively fuses multi-level frequency-aware features to balance global semantic understanding with local detail modeling, while dynamically reweighting supervision strength across regions to alleviate scribble bias. By jointly exploiting the supervision signals from both the pseudo masks and scribble semantics, ${D}^{3}$ETOR significantly narrows the gap between weakly and fully supervised COD, achieving state-of-the-art performance on multiple benchmarks.","authors":["Jiawei Ge","Jiuxin Cao","Xinyi Li","Xuelin Zhu","Chang Liu","Bo Liu","Chen Feng","Ioannis Patras"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20245v1","updated":"2025-12-23T10:55:32Z","published":"2025-12-23T10:55:32Z","title":"Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds","summary":"The memory of contemporary Large Language Models is bound by a physical paradox: as they learn, they fill up. The linear accumulation (O(N)) of Key-Value states treats context as a warehouse of static artifacts, eventually forcing a destructive choice between amnesia and latency. We challenge this discrete orthodoxy, proposing that long-term memory is not the storage of items, but the persistence of a trajectory. We introduce Phonetic Trajectory Memory (PTM), a neuro-symbolic architecture that encodes language not as a sequence of tensors, but as a continuous path on an ergodic manifold governed by irrational rotation matrices. By decoupling the navigation (an invariant O(1) geometric signal) from the reconstruction (a probabilistic generative act), PTM achieves a compression magnitude of greater than 3,000x relative to dense caches. We demonstrate that retrieval becomes a process of resonance: the phonetic trace stabilizes the model against hallucination via \"Signal Consensus\" mechanism, securing up to approximately 92% factual accuracy. While this aggressive abstraction alters generative texture, it unlocks immediate access latency (approximately 34ms) independent of depth. Our results suggest that infinite context does not require infinite silicon; it requires treating memory not as data to be stored, but as a reconstructive process acting on a conserved, undying physical signal.","authors":["Tarik Houichime","Abdelghani Souhar","Younes El Amrani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20237v1","updated":"2025-12-23T10:49:42Z","published":"2025-12-23T10:49:42Z","title":"MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents","summary":"Memory systems have been designed to leverage past experiences in Large Language Model (LLM) agents. However, many deployed memory systems primarily optimize compression and storage, with comparatively less emphasis on explicit, closed-loop control of memory retrieval. From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process. This design departs from the standard retrieve-then-answer pipeline by introducing a closed-loop control mechanism that enables autonomous decision-making. Empirical results on the LoCoMo benchmark demonstrate that MemR$^3$ surpasses strong baselines on LLM-as-a-Judge score, and particularly, it improves existing retrievers across four categories with an overall improvement on RAG (+7.29%) and Zep (+1.94%) using GPT-4.1-mini backend, offering a plug-and-play controller for existing memory stores.","authors":["Xingbo Du","Loka Li","Duzhen Zhang","Le Song"],"pdf_url":"","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2512.18315v2","updated":"2025-12-23T10:30:05Z","published":"2025-12-20T11:02:44Z","title":"On Efficient Adjustment for Micro Causal Effects in Summary Causal Graphs","summary":"Observational studies in fields such as epidemiology often rely on covariate adjustment to estimate causal effects. Classical graphical criteria, like the back-door criterion and the generalized adjustment criterion, are powerful tools for identifying valid adjustment sets in directed acyclic graphs (DAGs). However, these criteria are not directly applicable to summary causal graphs (SCGs), which are abstractions of DAGs commonly used in dynamic systems. In SCGs, each node typically represents an entire time series and may involve cycles, making classical criteria inapplicable for identifying causal effects. Recent work established complete conditions for determining whether the micro causal effect of a treatment or an exposure $X_{t-γ}$ on an outcome $Y_t$ is identifiable via covariate adjustment in SCGs, under the assumption of no hidden confounding. However, these identifiability conditions have two main limitations. First, they are complex, relying on cumbersome definitions and requiring the enumeration of multiple paths in the SCG, which can be computationally expensive. Second, when these conditions are satisfied, they only provide two valid adjustment sets, limiting flexibility in practical applications. In this paper, we propose an equivalent but simpler formulation of those identifiability conditions and introduce a new criterion that identifies a broader class of valid adjustment sets in SCGs. Additionally, we characterize the quasi-optimal adjustment set among these, i.e., the one that minimizes the asymptotic variance of the causal effect estimator. Our contributions offer both theoretical advancement and practical tools for more flexible and efficient causal inference in abstracted causal graphs.","authors":["Isabela Belciug","Simon Ferreira","Charles K. Assaad"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14396v5","updated":"2025-12-23T10:17:59Z","published":"2025-11-18T12:01:06Z","title":"Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning","summary":"Language-conditioned manipulation facilitates human-robot interaction via behavioral cloning (BC), which learns control policies from human demonstrations and serves as a cornerstone of embodied AI. Overcoming compounding errors in sequential action decisions remains a central challenge to improving BC performance. Existing approaches mitigate compounding errors through data augmentation, expressive representation, or temporal abstraction. However, they suffer from physical discontinuities and semantic-physical misalignment, leading to inaccurate action cloning and intermittent execution. In this paper, we present Continuous vision-language-action Co-Learning with Semantic-Physical Alignment (CCoL), a novel BC framework that ensures temporally consistent execution and fine-grained semantic grounding. It generates robust and smooth action execution trajectories through continuous co-learning across vision, language, and proprioceptive inputs (e.g., robot internal states). Meanwhile, we anchor language semantics to visuomotor representations by a bidirectional cross-attention to learn contextual information for action generation, successfully overcoming the problem of semantic-physical misalignment. Extensive experiments show that CCoL achieves an average 8.0% relative improvement across three simulation suites, with up to 19.2% relative gain in human-demonstrated bimanual insertion tasks. Real-world tests on a 7-DoF robot further confirm CCoL's generalization under unseen and noisy object states.","authors":["Xiuxiu Qi","Yu Yang","Jiannong Cao","Luyao Bai","Chongshan Fan","Chengtai Cao","Hongpeng Wang"],"pdf_url":"","comment":"Accepted at AAAI 2026, the Project website is available at https://qhemu.github.io/CCoL/"},{"id":"http://arxiv.org/abs/2512.18261v2","updated":"2025-12-23T10:10:18Z","published":"2025-12-20T07:58:35Z","title":"Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective","summary":"Artificial Intelligence (AI) has revolutionized software development, particularly by automating repetitive tasks and improving developer productivity. While these advancements are well-documented, the use of AI-powered tools for Software Vulnerability Management (SVM), such as vulnerability detection and repair, remains underexplored in industry settings. To bridge this gap, our study aims to determine the extent of the adoption of AI-powered tools for SVM, identify barriers and facilitators to the use, and gather insights to help improve the tools to meet industry needs better. We conducted a survey study involving 60 practitioners from diverse industry sectors across 27 countries. The survey incorporates both quantitative and qualitative questions to analyze the adoption trends, assess tool strengths, identify practical challenges, and uncover opportunities for improvement. Our findings indicate that AI-powered tools are used throughout the SVM life cycle, with 69% of users reporting satisfaction with their current use. Practitioners value these tools for their speed, coverage, and accessibility. However, concerns about false positives, missing context, and trust issues remain prevalent. We observe a socio-technical adoption pattern in which AI outputs are filtered through human oversight and organizational governance. To support safe and effective use of AI for SVM, we recommend improvements in explainability, contextual awareness, integration workflows, and validation practices. We assert that these findings can offer practical guidance for practitioners, tool developers, and researchers seeking to enhance secure software development through the use of AI.","authors":["M. Mehdi Kholoosi","Triet Huynh Minh Le","M. Ali Babar"],"pdf_url":"","comment":"Accepted at the 48th IEEE/ACM International Conference on Software Engineering (ICSE 2026) - Research Track"},{"id":"http://arxiv.org/abs/2512.20206v1","updated":"2025-12-23T10:00:43Z","published":"2025-12-23T10:00:43Z","title":"TongSIM: A General Platform for Simulating Intelligent Machines","summary":"As artificial intelligence (AI) rapidly advances, especially in multimodal large language models (MLLMs), research focus is shifting from single-modality text processing to the more complex domains of multimodal and embodied AI. Embodied intelligence focuses on training agents within realistic simulated environments, leveraging physical interaction and action feedback rather than conventionally labeled datasets. Yet, most existing simulation platforms remain narrowly designed, each tailored to specific tasks. A versatile, general-purpose training environment that can support everything from low-level embodied navigation to high-level composite activities, such as multi-agent social simulation and human-AI collaboration, remains largely unavailable. To bridge this gap, we introduce TongSIM, a high-fidelity, general-purpose platform for training and evaluating embodied agents. TongSIM offers practical advantages by providing over 100 diverse, multi-room indoor scenarios as well as an open-ended, interaction-rich outdoor town simulation, ensuring broad applicability across research needs. Its comprehensive evaluation framework and benchmarks enable precise assessment of agent capabilities, such as perception, cognition, decision-making, human-robot cooperation, and spatial and social reasoning. With features like customized scenes, task-adaptive fidelity, diverse agent types, and dynamic environmental simulation, TongSIM delivers flexibility and scalability for researchers, serving as a unified platform that accelerates training, evaluation, and advancement toward general embodied intelligence.","authors":["Zhe Sun","Kunlun Wu","Chuanjian Fu","Zeming Song","Langyong Shi","Zihe Xue","Bohan Jing","Ying Yang","Xiaomeng Gao","Aijia Li","Tianyu Guo","Huiying Li","Xueyuan Yang","Rongkai Liu","Xinyi He","Yuxi Wang","Yue Li","Mingyuan Liu","Yujie Lu","Hongzhao Xie","Shiyun Zhao","Bo Dai","Wei Wang","Tao Yuan","Song-Chun Zhu","Yujia Peng","Zhenliang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.16580v2","updated":"2025-12-23T09:58:30Z","published":"2025-08-05T03:26:58Z","title":"Adaptive Command: Real-Time Policy Adjustment via Language Models in StarCraft II","summary":"We present Adaptive Command, a novel framework integrating large language models (LLMs) with behavior trees for real-time strategic decision-making in StarCraft II. Our system focuses on enhancing human-AI collaboration in complex, dynamic environments through natural language interactions. The framework comprises: (1) an LLM-based strategic advisor, (2) a behavior tree for action execution, and (3) a natural language interface with speech capabilities. User studies demonstrate significant improvements in player decision-making and strategic adaptability, particularly benefiting novice players and those with disabilities. This work contributes to the field of real-time human-AI collaborative decision-making, offering insights applicable beyond RTS games to various complex decision-making scenarios.","authors":["Weiyu Ma","Dongyu Xu","Shu Lin","Haifeng Zhang","Jun Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20204v1","updated":"2025-12-23T09:56:23Z","published":"2025-12-23T09:56:23Z","title":"Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings","summary":"Speech processing and translation technology have the potential to facilitate meetings of individuals who do not share any common language. To evaluate automatic systems for such a task, a versatile and realistic evaluation corpus is needed. Therefore, we create and present a corpus of cross-lingual dialogues between individuals without a common language who were facilitated by automatic simultaneous speech translation. The corpus consists of 5 hours of speech recordings with ASR and gold transcripts in 12 original languages and automatic and corrected translations into English. For the purposes of research into cross-lingual summarization, our corpus also includes written summaries (minutes) of the meetings.\n  Moreover, we propose automatic detection of misunderstandings. For an overview of this task and its complexity, we attempt to quantify misunderstandings in cross-lingual meetings. We annotate misunderstandings manually and also test the ability of current large language models to detect them automatically. The results show that the Gemini model is able to identify text spans with misunderstandings with recall of 77% and precision of 47%.","authors":["Marko Čechovič","Natália Komorníková","Dominik Macháček","Ondřej Bojar"],"pdf_url":"","comment":"12 pages, 2 figures, 6 tables, published as a conference paper in Text, Speech, and Dialogue 28th International Conference, TSD 2025, Erlangen, Germany, August 25-28, 2025, Proceedings, Part II. This version published here on arXiv.org is before review comments and seedings of the TSD conference staff"},{"id":"http://arxiv.org/abs/2510.03289v2","updated":"2025-12-23T09:36:38Z","published":"2025-09-29T12:07:09Z","title":"Why mask diffusion does not work","summary":"The main advantages of diffusion language models over autoregressive (AR) models lie in their ability to support parallel generation and bidirectional attention, enabling a more controllable generation process. In recent years, open-source mask diffusion language models have emerged, most of which are based on a variant known as absorbing diffusion. However, this paper demonstrates why mask diffusion faces inherent difficulties in achieving parallel generation and bidirectional attention. We also propose the most effective training and inference strategies for mask diffusion.","authors":["Haocheng Sun","Cynthia Xin Wen","Edward Hong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.16066v3","updated":"2025-12-23T09:35:05Z","published":"2025-10-17T03:56:11Z","title":"Cash Flow Underwriting with Bank Transaction Data: Advancing MSME Financial Inclusion in Malaysia","summary":"Despite accounting for 96.1% of all businesses in Malaysia, access to financing remains one of the most persistent challenges faced by Micro, Small, and Medium Enterprises (MSMEs). Newly established businesses are often excluded from formal credit markets as traditional underwriting approaches rely heavily on credit bureau data. This study investigates the potential of bank statement data as an alternative data source for credit assessment to promote financial inclusion in emerging markets. First, we propose a cash flow-based underwriting pipeline where we utilise bank statement data for end-to-end data extraction and machine learning credit scoring. Second, we introduce a novel dataset of 611 loan applicants from a Malaysian lending institution. Third, we develop and evaluate credit scoring models based on application information and bank transaction-derived features. Empirical results show that the use of such data boosts the performance of all models on our dataset, which can improve credit scoring for new-to-lending MSMEs. Finally, we will release the anonymised bank transaction dataset to facilitate further research on MSME financial inclusion within Malaysia's emerging economy.","authors":["Chun Chet Ng","Wei Zeng Low","Jia Yu Lim","Yin Yin Boon"],"pdf_url":"","comment":"Accepted for oral presentation at the AI for Financial Inclusion, Risk Modeling and Resilience in Emerging Markets (FinRem) Workshop at ACM ICAIF 2025, Singapore. Accepted for poster presentation at the Agentic AI in Financial Services Workshop at AAAI 2026, Singapore"},{"id":"http://arxiv.org/abs/2511.16193v3","updated":"2025-12-23T09:31:34Z","published":"2025-11-20T10:00:03Z","title":"Fast LLM Post-training via Decoupled and Fastest-of-N Speculation","summary":"Rollout dominates the training time in large language model (LLM) post-training, where the trained model is used to generate tokens given a batch of prompts. This work, SpecActor, achieves fast rollout with speculative decoding that deploys a fast draft path to accelerate the unparallelizable generation, while the correctness is guaranteed by fast parallel verification of the outputs with the original model. SpecActor addresses two foundational challenges that hinder speculation efficiency: (1) a Decoupled speculation method that overcomes the computation inefficiency issue when executing speculative decoding with relative large per-worker batch size -- a common configuration in training but unfriendly to speculation, and (2) a Fastest-of-N speculation method that selects and combines different draft methods according to the rollout progress to approximate the optimal draft method even when the best one is unknown a priori. Extensive evaluations on production traces show that SpecActor accelerates mean rollout speed by 2.0--2.4x, with up to 2.7x speedup, over common post-training baselines. The results are consistent across both dense and MoE models and across different RL algorithms. Notably, SpecActor is 1.1--2.6x faster compared to vanilla speculative rollout in different traces. The accelerated rollout achieves 1.4--2.3x faster end-to-end training time.","authors":["Rongxin Cheng","Kai Zhou","Xingda Wei","Siyuan Liu","Mingcong Han","Mingjing Ai","Yeju Zhou","Baoquan Zhong","Wencong Xiao","Rong Chen","Haibo Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20188v1","updated":"2025-12-23T09:28:20Z","published":"2025-12-23T09:28:20Z","title":"Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation","summary":"Most Vision-Language-Action (VLA) systems integrate a Vision-Language Model (VLM) for semantic reasoning with an action expert generating continuous action signals, yet both typically run at a single unified frequency. As a result, policy performance is constrained by the low inference speed of large VLMs. This mandatory synchronous execution severely limits control stability and real-time performance in whole-body robotic manipulation, which involves more joints, larger motion spaces, and dynamically changing views. We introduce a truly asynchronous Fast-Slow VLA framework (DuoCore-FS), organizing the system into a fast pathway for high-frequency action generation and a slow pathway for rich VLM reasoning. The system is characterized by two key features. First, a latent representation buffer bridges the slow and fast systems. It stores instruction semantics and action-reasoning representation aligned with the scene-instruction context, providing high-level guidance to the fast pathway. Second, a whole-body action tokenizer provides a compact, unified representation of whole-body actions. Importantly, the VLM and action expert are still jointly trained end-to-end, preserving unified policy learning while enabling asynchronous execution. DuoCore-FS supports a 3B-parameter VLM while achieving 30 Hz whole-body action-chunk generation, approximately three times as fast as prior VLA models with comparable model sizes. Real-world whole-body manipulation experiments demonstrate improved task success rates and significantly enhanced responsiveness compared to synchronous Fast-Slow VLA baselines. The implementation of DuoCore-FS, including training, inference, and deployment, is provided to commercial users by Astribot as part of the Astribot robotic platform.","authors":["Teqiang Zou","Hongliang Zeng","Yuxuan Nong","Yifan Li","Kehui Liu","Haotian Yang","Xinyang Ling","Xin Li","Lianyang Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20182v1","updated":"2025-12-23T09:20:32Z","published":"2025-12-23T09:20:32Z","title":"FaithLens: Detecting and Explaining Faithfulness Hallucination","summary":"Recognizing whether outputs from large language models (LLMs) contain faithfulness hallucination is crucial for real-world applications, e.g., retrieval-augmented generation and summarization. In this paper, we introduce FaithLens, a cost-efficient and effective faithfulness hallucination detection model that can jointly provide binary predictions and corresponding explanations to improve trustworthiness. To achieve this, we first synthesize training data with explanations via advanced LLMs and apply a well-defined data filtering strategy to ensure label correctness, explanation quality, and data diversity. Subsequently, we fine-tune the model on these well-curated training data as a cold start and further optimize it with rule-based reinforcement learning, using rewards for both prediction correctness and explanation quality. Results on 12 diverse tasks show that the 8B-parameter FaithLens outperforms advanced models such as GPT-4.1 and o3. Also, FaithLens can produce high-quality explanations, delivering a distinctive balance of trustworthiness, efficiency, and effectiveness.","authors":["Shuzheng Si","Qingyi Wang","Haozhe Zhao","Yuzhuo Bai","Guanqiao Chen","Kangyang Luo","Gang Chen","Fanchao Qi","Minjia Zhang","Baobao Chang","Maosong Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.06244v2","updated":"2025-12-23T09:18:27Z","published":"2025-08-08T11:56:13Z","title":"Membership Inference Attack with Partial Features","summary":"Machine learning models are vulnerable to membership inference attack, which can be used to determine whether a given sample appears in the training data. Most existing methods assume the attacker has full access to the features of the target sample. This assumption, however, does not hold in many real-world scenarios where only partial features are available, thereby limiting the applicability of these methods. In this work, we introduce Partial Feature Membership Inference (PFMI), a scenario where the adversary observes only partial features of each sample and aims to infer whether this observed subset was present in the training set. To address this problem, we propose MRAD (Memory-guided Reconstruction and Anomaly Detection), a two-stage attack framework that works in both white-box and black-box settings. In the first stage, MRAD leverages the latent memory of the target model to reconstruct the unknown features of the sample. We observe that when the known features are absent from the training set, the reconstructed sample deviates significantly from the true data distribution. Consequently, in the second stage, we use anomaly detection algorithms to measure the deviation between the reconstructed sample and the training data distribution, thereby determining whether the known features belong to a member of the training set. Empirical results demonstrate that MRAD is effective across various datasets, and maintains compatibility with off-the-shelf anomaly detection techniques. For example, on STL-10, our attack exceeds an AUC of around 0.75 even with 60% of the missing features.","authors":["Xurun Wang","Guangrui Liu","Xinjie Li","Haoyu He","Lin Yao","Zhongyun Hua","Weizhe Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19576v2","updated":"2025-12-23T09:09:53Z","published":"2025-12-22T17:00:25Z","title":"LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller","summary":"Attitude control is essential for many satellite missions. Classical controllers, however, are time-consuming to design and sensitive to model uncertainties and variations in operational boundary conditions. Deep Reinforcement Learning (DRL) offers a promising alternative by learning adaptive control strategies through autonomous interaction with a simulation environment. Overcoming the Sim2Real gap, which involves deploying an agent trained in simulation onto the real physical satellite, remains a significant challenge. In this work, we present the first successful in-orbit demonstration of an AI-based attitude controller for inertial pointing maneuvers. The controller was trained entirely in simulation and deployed to the InnoCube 3U nanosatellite, which was developed by the Julius-Maximilians-Universität Würzburg in cooperation with the Technische Universität Berlin, and launched in January 2025. We present the AI agent design, the methodology of the training procedure, the discrepancies between the simulation and the observed behavior of the real satellite, and a comparison of the AI-based attitude controller with the classical PD controller of InnoCube. Steady-state metrics confirm the robust performance of the AI-based controller during repeated in-orbit maneuvers.","authors":["Kirill Djebko","Tom Baumann","Erik Dilger","Frank Puppe","Sergio Montenegro"],"pdf_url":"","comment":"55 pages, 27 figures, 29 tables. The maneuver telemetry datasets generated and analyzed during this work are available in the GitHub repository under https://github.com/kdjebko/lelar-in-orbit-data"},{"id":"http://arxiv.org/abs/2512.20173v1","updated":"2025-12-23T09:07:53Z","published":"2025-12-23T09:07:53Z","title":"Offline Safe Policy Optimization From Heterogeneous Feedback","summary":"Offline Preference-based Reinforcement Learning (PbRL) learns rewards and policies aligned with human preferences without the need for extensive reward engineering and direct interaction with human annotators. However, ensuring safety remains a critical challenge across many domains and tasks. Previous works on safe RL from human feedback (RLHF) first learn reward and cost models from offline data, then use constrained RL to optimize a safe policy. While such an approach works in the contextual bandits settings (LLMs), in long horizon continuous control tasks, errors in rewards and costs accumulate, leading to impairment in performance when used with constrained RL methods. To address these challenges, (a) instead of indirectly learning policies (from rewards and costs), we introduce a framework that learns a policy directly based on pairwise preferences regarding the agent's behavior in terms of rewards, as well as binary labels indicating the safety of trajectory segments; (b) we propose \\textsc{PreSa} (Preference and Safety Alignment), a method that combines preference learning module with safety alignment in a constrained optimization problem. This optimization problem is solved within a Lagrangian paradigm that directly learns reward-maximizing safe policy \\textit{without explicitly learning reward and cost models}, avoiding the need for constrained RL; (c) we evaluate our approach on continuous control tasks with both synthetic and real human feedback. Empirically, our method successfully learns safe policies with high rewards, outperforming state-of-the-art baselines, and offline safe RL approaches with ground-truth reward and cost.","authors":["Ze Gong","Pradeep Varakantham","Akshat Kumar"],"pdf_url":"","comment":"Accepted at AAMAS 2026 (Extended Abstract)"},{"id":"http://arxiv.org/abs/2512.20168v1","updated":"2025-12-23T08:53:36Z","published":"2025-12-23T08:53:36Z","title":"Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography","summary":"By integrating language understanding with perceptual modalities such as images, multimodal large language models (MLLMs) constitute a critical substrate for modern AI systems, particularly intelligent agents operating in open and interactive environments. However, their increasing accessibility also raises heightened risks of misuse, such as generating harmful or unsafe content. To mitigate these risks, alignment techniques are commonly applied to align model behavior with human values. Despite these efforts, recent studies have shown that jailbreak attacks can circumvent alignment and elicit unsafe outputs. Currently, most existing jailbreak methods are tailored for open-source models and exhibit limited effectiveness against commercial MLLM-integrated systems, which often employ additional filters. These filters can detect and prevent malicious input and output content, significantly reducing jailbreak threats. In this paper, we reveal that the success of these safety filters heavily relies on a critical assumption that malicious content must be explicitly visible in either the input or the output. This assumption, while often valid for traditional LLM-integrated systems, breaks down in MLLM-integrated systems, where attackers can leverage multiple modalities to conceal adversarial intent, leading to a false sense of security in existing MLLM-integrated systems. To challenge this assumption, we propose Odysseus, a novel jailbreak paradigm that introduces dual steganography to covertly embed malicious queries and responses into benign-looking images. Extensive experiments on benchmark datasets demonstrate that our Odysseus successfully jailbreaks several pioneering and realistic MLLM-integrated systems, achieving up to 99% attack success rate. It exposes a fundamental blind spot in existing defenses, and calls for rethinking cross-modal security in MLLM-integrated systems.","authors":["Songze Li","Jiameng Cheng","Yiming Li","Xiaojun Jia","Dacheng Tao"],"pdf_url":"","comment":"This paper is accepted by Network and Distributed System Security Symposium (NDSS) 2026"},{"id":"http://arxiv.org/abs/2510.23649v3","updated":"2025-12-23T08:47:31Z","published":"2025-10-25T11:43:27Z","title":"Efficient Low Rank Attention for Long-Context Inference in Large Language Models","summary":"As the length of input text increases, the key-value (KV) cache in LLMs imposes prohibitive GPU memory costs and limits long-context inference on resource constrained devices. Existing approaches, such as KV quantization and pruning, reduce memory usage but suffer from numerical precision loss or suboptimal retention of key-value pairs. In this work, Low Rank Query and Key attention (LRQK) is introduced, a two-stage framework that jointly decomposes full-precision query and key matrices into compact rank-\\(r\\) factors during the prefill stage, and then employs these low-dimensional projections to compute proxy attention scores in \\(\\mathcal{O}(lr)\\) time at each decode step. By selecting only the top-\\(k\\) tokens and a small fixed set of recent tokens, LRQK employs a mixed GPU-CPU cache with a hit-and-miss mechanism where only missing full-precision KV pairs are transferred, thereby preserving exact attention outputs while reducing CPU-GPU data movement. Extensive experiments on the RULER and LongBench benchmarks with LLaMA-3-8B and Qwen2.5-7B demonstrate that LRQK matches or surpasses leading sparse-attention methods in long context settings, while delivering significant memory savings with minimal accuracy loss. Our code is available at https://github.com/tenghuilee/LRQK.","authors":["Tenghui Li","Guoxu Zhou","Xuyang Zhao","Yuning Qiu","Qibin Zhao"],"pdf_url":"","comment":"https://neurips.cc/virtual/2025/loc/san-diego/poster/118451"},{"id":"http://arxiv.org/abs/2512.20164v1","updated":"2025-12-23T08:42:09Z","published":"2025-12-23T08:42:09Z","title":"AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications","summary":"Large Language Models (LLMs) excel at text comprehension and generation, making them ideal for automated tasks like code review and content moderation. However, our research identifies a vulnerability: LLMs can be manipulated by \"adversarial instructions\" hidden in input data, such as resumes or code, causing them to deviate from their intended task. Notably, while defenses may exist for mature domains such as code review, they are often absent in other common applications such as resume screening and peer review. This paper introduces a benchmark to assess this vulnerability in resume screening, revealing attack success rates exceeding 80% for certain attack types. We evaluate two defense mechanisms: prompt-based defenses achieve 10.1% attack reduction with 12.5% false rejection increase, while our proposed FIDS (Foreign Instruction Detection through Separation) using LoRA adaptation achieves 15.4% attack reduction with 10.4% false rejection increase. The combined approach provides 26.3% attack reduction, demonstrating that training-time defenses outperform inference-time mitigations in both security and utility preservation.","authors":["Honglin Mu","Jinghao Liu","Kaiyang Wan","Rui Xing","Xiuying Chen","Timothy Baldwin","Wanxiang Che"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20162v1","updated":"2025-12-23T08:41:03Z","published":"2025-12-23T08:41:03Z","title":"Concept Generalization in Humans and Large Language Models: Insights from the Number Game","summary":"We compare human and large language model (LLM) generalization in the number game, a concept inference task. Using a Bayesian model as an analytical framework, we examined the inductive biases and inference strategies of humans and LLMs. The Bayesian model captured human behavior better than LLMs in that humans flexibly infer rule-based and similarity-based concepts, whereas LLMs rely more on mathematical rules. Humans also demonstrated a few-shot generalization, even from a single example, while LLMs required more samples to generalize. These contrasts highlight the fundamental differences in how humans and LLMs infer and generalize mathematical concepts.","authors":["Arghavan Bazigaran","Hansem Sohn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20161v1","updated":"2025-12-23T08:40:38Z","published":"2025-12-23T08:40:38Z","title":"A Bidirectional Gated Recurrent Unit Model for PUE Prediction in Data Centers","summary":"Data centers account for significant global energy consumption and a carbon footprint. The recent increasing demand for edge computing and AI advancements drives the growth of data center storage capacity. Energy efficiency is a cost-effective way to combat climate change, cut energy costs, improve business competitiveness, and promote IT and environmental sustainability. Thus, optimizing data center energy management is the most important factor in the sustainability of the world. Power Usage Effectiveness (PUE) is used to represent the operational efficiency of the data center. Predicting PUE using Neural Networks provides an understanding of the effect of each feature on energy consumption, thus enabling targeted modifications of those key features to improve energy efficiency. In this paper, we have developed Bidirectional Gated Recurrent Unit (BiGRU) based PUE prediction model and compared the model performance with GRU. The data set comprises 52,560 samples with 117 features using EnergyPlus, simulating a DC in Singapore. Sets of the most relevant features are selected using the Recursive Feature Elimination with Cross-Validation (RFECV) algorithm for different parameter settings. These feature sets are used to find the optimal hyperparameter configuration and train the BiGRU model. The performance of the optimized BiGRU-based PUE prediction model is then compared with that of GRU using mean squared error (MSE), mean absolute error (MAE), and R-squared metrics.","authors":["Dhivya Dharshini Kannan","Anupam Trivedi","Dipti Srinivasan"],"pdf_url":"","comment":"2025 International Joint Conference on Neural Networks (IJCNN), Rome, Italy, 2025, https://ieeexplore.ieee.org/document/11227238"},{"id":"http://arxiv.org/abs/2512.20159v1","updated":"2025-12-23T08:39:22Z","published":"2025-12-23T08:39:22Z","title":"AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration","summary":"Large language models (LLMs) have been increasingly deployed in real-world software engineering, fostering the development of code evaluation metrics to study the quality of LLM-generated code. Conventional rule-based metrics merely score programs based on their surface-level similarities with reference programs instead of analyzing functionality and code quality in depth. To address this limitation, researchers have developed LLM-as-a-judge metrics, prompting LLMs to evaluate and score code, and curated various code evaluation benchmarks to validate their effectiveness. However, these benchmarks suffer from critical limitations, hindering reliable assessments of evaluation capability: Some feature coarse-grained binary labels, which reduce rich code behavior to a single bit of information, obscuring subtle errors. Others propose fine-grained but subjective, vaguely-defined evaluation criteria, introducing unreliability in manually-annotated scores, which is the ground-truth they rely on. Furthermore, they often use uncontrolled data synthesis methods, leading to unbalanced score distributions that poorly represent real-world code generation scenarios.\n  To curate a diverse benchmark with programs of well-balanced distributions across various quality levels and streamline the manual annotation procedure, we propose AXIOM, a novel perturbation-based framework for synthesizing code evaluation benchmarks at scale. It reframes program scores as the refinement effort needed for deployment, consisting of two stages: (1) Rule-guided perturbation, which prompts LLMs to apply sequences of predefined perturbation rules to existing high-quality programs to modify their functionality and code quality, enabling us to precisely control each program's target score to achieve balanced score distributions. (2) Multisource quality calibration, which first selects a subset of...","authors":["Ruiqi Wang","Xinchen Wang","Cuiyun Gao","Chun Yong Chong","Xin Xia","Qing Liao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20156v1","updated":"2025-12-23T08:35:27Z","published":"2025-12-23T08:35:27Z","title":"Fun-Audio-Chat Technical Report","summary":"Recent advancements in joint speech-text models show great potential for seamless voice interactions. However, existing models face critical challenges: temporal resolution mismatch between speech tokens (25Hz) and text tokens (~3Hz) dilutes semantic information, incurs high computational costs, and causes catastrophic forgetting of text LLM knowledge. We introduce Fun-Audio-Chat, a Large Audio Language Model addressing these limitations via two innovations from our previous work DrVoice. First, Dual-Resolution Speech Representations (DRSR): the Shared LLM processes audio at efficient 5Hz (via token grouping), while the Speech Refined Head generates high-quality tokens at 25Hz, balancing efficiency (~50% GPU reduction) and quality. Second, Core-Cocktail Training, a two-stage fine-tuning with intermediate merging that mitigates catastrophic forgetting. We then apply Multi-Task DPO Training to enhance robustness, audio understanding, instruction-following and voice empathy. This multi-stage post-training enables Fun-Audio-Chat to retain text LLM knowledge while gaining powerful audio understanding, reasoning, and generation. Unlike recent LALMs requiring large-scale audio-text pre-training, Fun-Audio-Chat leverages pre-trained models and extensive post-training. Fun-Audio-Chat 8B and MoE 30B-A3B achieve competitive performance on Speech-to-Text and Speech-to-Speech tasks, ranking top among similar-scale models on Spoken QA benchmarks. They also achieve competitive to superior performance on Audio Understanding, Speech Function Calling, Instruction-Following and Voice Empathy. We develop Fun-Audio-Chat-Duplex, a full-duplex variant with strong performance on Spoken QA and full-duplex interactions. We open-source Fun-Audio-Chat-8B with training and inference code, and provide an interactive demo.","authors":["Qian Chen","Luyao Cheng","Chong Deng","Xiangang Li","Jiaqing Liu","Chao-Hong Tan","Wen Wang","Junhao Xu","Jieping Ye","Qinglin Zhang","Qiquan Zhang","Jingren Zhou"],"pdf_url":"","comment":"21 pages, https://github.com/FunAudioLLM/Fun-Audio-Chat"},{"id":"http://arxiv.org/abs/2512.17373v2","updated":"2025-12-23T08:23:39Z","published":"2025-12-19T09:17:21Z","title":"Dialectics for Artificial Intelligence","summary":"Can artificial intelligence discover, from raw experience and without human supervision, concepts that humans have discovered? One challenge is that human concepts themselves are fluid: conceptual boundaries can shift, split, and merge as inquiry progresses (e.g., Pluto is no longer considered a planet). To make progress, we need a definition of \"concept\" that is not merely a dictionary label, but a structure that can be revised, compared, and aligned across agents. We propose an algorithmic-information viewpoint that treats a concept as an information object defined only through its structural relation to an agent's total experience. The core constraint is determination: a set of parts forms a reversible consistency relation if any missing part is recoverable from the others (up to the standard logarithmic slack in Kolmogorov-style identities). This reversibility prevents \"concepts\" from floating free of experience and turns concept existence into a checkable structural claim. To judge whether a decomposition is natural, we define excess information, measuring the redundancy overhead introduced by splitting experience into multiple separately described parts. On top of these definitions, we formulate dialectics as an optimization dynamics: as new patches of information appear (or become contested), competing concepts bid to explain them via shorter conditional descriptions, driving systematic expansion, contraction, splitting, and merging. Finally, we formalize low-cost concept transmission and multi-agent alignment using small grounds/seeds that allow another agent to reconstruct the same concept under a shared protocol, making communication a concrete compute-bits trade-off.","authors":["Zhengmian Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.01457v4","updated":"2025-12-23T08:18:03Z","published":"2025-12-01T09:44:31Z","title":"Zero-Overhead Introspection for Adaptive Test-Time Compute","summary":"Large language models excel at reasoning but lack key aspects of introspection, including anticipating their own success and the computation required to achieve it. Humans use real-time introspection to decide how much effort to invest, when to make multiple attempts, when to stop, and when to signal success or failure. Without this, LLMs struggle to make intelligent meta-cognition decisions. Test-time scaling methods like Best-of-N drive up cost and latency by using a fixed budget of samples regardless of the marginal benefit of each one at any point in generation, and the absence of confidence signals can mislead people, prevent appropriate escalation to better tools, and undermine trustworthiness. Learned verifiers or reward models can provide confidence estimates, but do not enable adaptive inference and add substantial cost by requiring extra models or forward passes. We present ZIP-RC, which equips models with zero-overhead introspective predictions of reward and cost. At every token, ZIP-RC reuses reserved or unused logits in the same forward pass as next-token prediction to output a joint distribution over final reward and remaining length -- no extra models, architecture change, or inference overhead. This full joint distribution is used to compute a sampling utility which is the linear combination of the expected maximum reward, total compute, and latency of set of samples if generated to completion. During inference, we maximize this utility with meta-actions that determine which prefix of tokens to continue or initiate sampling from. On mixed-difficulty mathematical benchmarks, ZIP-RC improves accuracy by up to 12% over majority voting at equal or lower average cost, and traces smooth Pareto frontiers between quality, compute, and latency. By providing real-time reward-cost introspection, ZIP-RC enables adaptive, efficient reasoning.","authors":["Rohin Manvi","Joey Hong","Tim Seyde","Maxime Labonne","Mathias Lechner","Sergey Levine"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20145v1","updated":"2025-12-23T08:15:34Z","published":"2025-12-23T08:15:34Z","title":"Retrieval-augmented Prompt Learning for Pre-trained Foundation Models","summary":"The pre-trained foundation models (PFMs) have become essential for facilitating large-scale multimodal learning. Researchers have effectively employed the ``pre-train, prompt, and predict'' paradigm through prompt learning to induce improved few-shot performance. However, prompt learning approaches for PFMs still follow a parametric learning paradigm. As such, the stability of generalization in memorization and rote learning can be compromised. More specifically, conventional prompt learning might face difficulties in fully utilizing atypical instances and avoiding overfitting to shallow patterns with limited data during the process of fully-supervised training. To overcome these constraints, we present our approach, named RetroPrompt, which aims to achieve a balance between memorization and generalization by decoupling knowledge from mere memorization. Unlike traditional prompting methods, RetroPrompt leverages a publicly accessible knowledge base generated from the training data and incorporates a retrieval mechanism throughout the input, training, and inference stages. This enables the model to actively retrieve relevant contextual information from the corpus, thereby enhancing the available cues. We conduct comprehensive experiments on a variety of datasets across natural language processing and computer vision tasks to demonstrate the superior performance of our proposed approach, RetroPrompt, in both zero-shot and few-shot scenarios. Through detailed analysis of memorization patterns, we observe that RetroPrompt effectively reduces the reliance on rote memorization, leading to enhanced generalization.","authors":["Xiang Chen","Yixin Ou","Quan Feng","Lei Li","Piji Li","Haibo Ye","Sheng-Jun Huang","Shuofei Qiao","Shumin Deng","Huajun Chen","Ningyu Zhang"],"pdf_url":"","comment":"IEEE/ACM Transactions on Audio, Speech and Language Processing"},{"id":"http://arxiv.org/abs/2509.10825v3","updated":"2025-12-23T08:14:20Z","published":"2025-09-13T14:44:45Z","title":"ORACLE: Explaining Feature Interactions in Neural Networks with ANOVA","summary":"We introduce ORACLE, a framework for explaining neural networks on tabular data and scientific factorial designs. ORACLE summarizes a trained network's prediction surface with main effects and pairwise interactions by treating the network as a black-box response, discretizing the inputs onto a grid, and fitting an orthogonal factorial (ANOVA-style) surrogate -- the $L^2$ orthogonal projection of the model response onto a finite-dimensional factorial subspace. A simple centering and $μ$-rebalancing step then expresses this surrogate as main- and interaction-effect tables that remain faithful to the original model in the $L^2$ sense. The resulting grid-based interaction maps are easy to visualize, comparable across backbones, and directly aligned with classical design-of-experiments practice. On synthetic factorial benchmarks and low- to medium-dimensional tabular regression tasks, ORACLE more accurately recovers ground-truth interaction structure and hotspots than Monte Carlo SHAP-family interaction methods, as measured by ranking, localization, and cross-backbone stability. In latent image and text settings, ORACLE clarifies its scope: grid-based factorial surrogates are most effective when features admit an interpretable factorial structure, making ORACLE particularly well-suited to scientific and engineering workflows that require stable, DoE-style interaction summaries.","authors":["Dongseok Kim","Hyoungsun Choi","Mohamed Jismy Aashik Rasool","Gisung Oh"],"pdf_url":"","comment":"v3: Minor wording edits for clarity; no technical changes"},{"id":"http://arxiv.org/abs/2512.18190v2","updated":"2025-12-23T08:10:47Z","published":"2025-12-20T03:27:11Z","title":"External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning","summary":"This paper proposes the External Hippocampus framework, which models language model reasoning from a cognitive dynamics perspective as the flow of information energy in semantic space. Unlike traditional weight-space optimization methods, this framework constructs topological cognitive maps through dimensionality reduction projection, enabling precise navigation and intervention of energy flow at test time while avoiding substantial computational requirements and demonstrating predictable intervention patterns. The method effectively addresses the cognitive deadlock problem in multi-step reasoning for small models. Experiments on models <=7B parameters show: map-guided methods achieve 81.20% accuracy on 500 challenging problems (relative baseline +16.80%), reduce reasoning time by >= 15x, with key findings revealing that reasoning stagnation manifests as \"Cognitive Vortex\" and low-entropy potential wells, while temperature perturbations effectively restart energy flow. The framework requires no additional training, possesses autonomous growth capability, and provides an efficient and controllable topological-aware solution for small model reasoning.","authors":["Jian Yan"],"pdf_url":"","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2512.20140v1","updated":"2025-12-23T08:02:33Z","published":"2025-12-23T08:02:33Z","title":"Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection","summary":"Large Language Models (LLMs) have demonstrated effectiveness as zero-shot time series (TS) forecasters. The key challenge lies in tokenizing TS data into textual representations that align with LLMs' pre-trained knowledge. While existing work often relies on fine-tuning specialized modules to bridge this gap, a distinct, yet challenging, paradigm aims to leverage truly off-the-shelf LLMs without any fine-tuning whatsoever, relying solely on strategic tokenization of numerical sequences. The performance of these fully frozen models is acutely sensitive to the textual representation of the input data, as their parameters cannot adapt to distribution shifts. In this paper, we introduce a simple yet highly effective strategy to overcome this brittleness: injecting noise into the raw time series before tokenization. This non-invasive intervention acts as a form of inference-time augmentation, compelling the frozen LLM to extrapolate based on robust underlying temporal patterns rather than superficial numerical artifacts. We theoretically analyze this phenomenon and empirically validate its effectiveness across diverse benchmarks. Notably, to fully eliminate potential biases from data contamination during LLM pre-training, we introduce two novel TS datasets that fall outside all utilized LLMs' pre-training scopes, and consistently observe improved performance. This study provides a further step in directly leveraging off-the-shelf LLMs for time series forecasting.","authors":["Xingyou Yin","Ceyao Zhang","Min Hu","Kai Chen"],"pdf_url":"","comment":"9 pages,3 figures"},{"id":"http://arxiv.org/abs/2512.17814v2","updated":"2025-12-23T08:00:41Z","published":"2025-12-19T17:19:08Z","title":"LLM-based Behaviour Driven Development for Hardware Design","summary":"Test and verification are essential activities in hardware and system design, but their complexity grows significantly with increasing system sizes. While Behavior Driven Development (BDD) has proven effective in software engineering, it is not yet well established in hardware design, and its practical use remains limited. One contributing factor is the manual effort required to derive precise behavioral scenarios from textual specifications.\n  Recent advances in Large Language Models (LLMs) offer new opportunities to automate this step. In this paper, we investigate the use of LLM-based techniques to support BDD in the context of hardware design.","authors":["Rolf Drechsler","Qian Liu"],"pdf_url":"","comment":"7 pages, keynote given at 2nd International Symposium on Artificial Intelligence and Internet of Things (AIIoT-25), December 22-24th, 2025"},{"id":"http://arxiv.org/abs/2509.23129v2","updated":"2025-12-23T07:56:48Z","published":"2025-09-27T05:24:51Z","title":"C$^2$GSPG: Confidence-calibrated Group Sequence Policy Gradient towards Self-aware Reasoning","summary":"Reinforcement Learning (RL) methods, exemplified by Group Relative Policy Optimization (GRPO) and its variants, play a central role in developing reasoning models. However, these methods often suffer from a critical overconfidence issue, which prevents them from achieving self-aware reasoning models. In this study, we propose a simple yet effective confidence-calibration group sequence policy gradient method, called C$^2$GSPG, which simultaneously enhances reasoning performance while suppressing overconfidence. In principle, we propose a Group Sequence Policy Gradient (GSPG) framework for learning reasoning models, which eliminates the token-level bias commonly appearing in GRPO and its variants. In this framework, we define the model confidence for each reasoning problem using the normalized sequence-level probability, and then apply a cross-entropy regularizer to calibrate the model confidence to the sequence's reward. We demonstrate that the confidence calibration regularizer and GSPG are collaborative for binary rewards, as their objectives always share the same gradient direction. For non-binary rewards, we apply nonlinear reward normalization and adaptive regularizer clipping, mitigating the potential conflict between the two objectives. Applying C$^2$GSPG to post-train large language models in logical and mathematical reasoning tasks, we show its superiority over state-of-the-art methods in both reasoning accuracy and confidence calibration. The code of C$^2$GSPG is available at https://github.com/HaotianLiu123/CCGSPG.","authors":["Haotian Liu","Shuo Wang","Hongteng Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20136v1","updated":"2025-12-23T07:54:03Z","published":"2025-12-23T07:54:03Z","title":"M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation","summary":"Retrieval-Augmented Generation (RAG) has recently been extended to multimodal settings, connecting multimodal large language models (MLLMs) with vast corpora of external knowledge such as multimodal knowledge graphs (MMKGs). Despite their recent success, multimodal RAG in the audio-visual domain remains challenging due to 1) limited modality coverage and multi-hop connectivity of existing MMKGs, and 2) retrieval based solely on similarity in a shared multimodal embedding space, which fails to filter out off-topic or redundant knowledge. To address these limitations, we propose M$^3$KG-RAG, a Multi-hop Multimodal Knowledge Graph-enhanced RAG that retrieves query-aligned audio-visual knowledge from MMKGs, improving reasoning depth and answer faithfulness in MLLMs. Specifically, we devise a lightweight multi-agent pipeline to construct multi-hop MMKG (M$^3$KG), which contains context-enriched triplets of multimodal entities, enabling modality-wise retrieval based on input queries. Furthermore, we introduce GRASP (Grounded Retrieval And Selective Pruning), which ensures precise entity grounding to the query, evaluates answer-supporting relevance, and prunes redundant context to retain only knowledge essential for response generation. Extensive experiments across diverse multimodal benchmarks demonstrate that M$^3$KG-RAG significantly enhances MLLMs' multimodal reasoning and grounding over existing approaches.","authors":["Hyeongcheol Park","Jiyoung Seo","Jaewon Mun","Hogun Park","Wonmin Byeon","Sung June Kim","Hyeonsoo Im","JeungSub Lee","Sangpil Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20135v1","updated":"2025-12-23T07:53:57Z","published":"2025-12-23T07:53:57Z","title":"MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization","summary":"Molecular editing and optimization are multi-step problems that require iteratively improving properties while keeping molecules chemically valid and structurally similar. We frame both tasks as sequential, tool-guided decisions and introduce MolAct, an agentic reinforcement learning framework that employs a two-stage training paradigm: first building editing capability, then optimizing properties while reusing the learned editing behaviors. To the best of our knowledge, this is the first work to formalize molecular design as an Agentic Reinforcement Learning problem, where an LLM agent learns to interleave reasoning, tool-use, and molecular optimization. The framework enables agents to interact in multiple turns, invoking chemical tools for validity checking, property assessment, and similarity control, and leverages their feedback to refine subsequent edits. We instantiate the MolAct framework to train two model families: MolEditAgent for molecular editing tasks and MolOptAgent for molecular optimization tasks. In molecular editing, MolEditAgent-7B delivers 100, 95, and 98 valid add, delete, and substitute edits, outperforming strong closed \"thinking\" baselines such as DeepSeek-R1; MolEditAgent-3B approaches the performance of much larger open \"thinking\" models like Qwen3-32B-think. In molecular optimization, MolOptAgent-7B (trained on MolEditAgent-7B) surpasses the best closed \"thinking\" baseline (e.g., Claude 3.7) on LogP and remains competitive on solubility, while maintaining balanced performance across other objectives. These results highlight that treating molecular design as a multi-step, tool-augmented process is key to reliable and interpretable improvements.","authors":["Zhuo Yang","Yeyun chen","Jiaqing Xie","Ben Gao","Shuaike Shen","Wanhao Liu","Liujia Yang","Beilun Wang","Tianfan Fu","Yuqiang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.06187v3","updated":"2025-12-23T07:41:07Z","published":"2025-10-07T17:46:33Z","title":"Automated Program Repair of Uncompilable Student Code","summary":"A significant portion of student programming submissions in CS1 learning environments are uncompilable, limiting their use in student modeling and downstream knowledge tracing. Traditional modeling pipelines often exclude these cases, discarding observations of student learning. This study investigates automated program repair as a strategy to recover uncompilable code while preserving students' structural intent for use in student modeling. Within this framework, we assess large language models (LLMs) as repair agents under high- and low-context prompting conditions. Repairs were evaluated for compilability, edit distance, and preservation of students' original structure and logic. While all models produced compilable repairs, they differed in how well they preserve students' control flow and code structure, affecting their pedagogical utility. By recovering uncompilable submissions, this work enables richer and more comprehensive analyses of learners' coding processes and development over time.","authors":["Griffin Pitts","Aum Pandya","Darsh Rank","Tirth Bhatt","Muntasir Hoq","Bita Akram"],"pdf_url":"","comment":"In Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2 (SIGCSE TS 2026)"},{"id":"http://arxiv.org/abs/2506.09160v5","updated":"2025-12-23T07:29:31Z","published":"2025-06-10T18:15:40Z","title":"Understanding Human-AI Trust in Education","summary":"As AI chatbots become integrated in education, students are turning to these systems for guidance, feedback, and information. However, the anthropomorphic characteristics of these chatbots create ambiguity over whether students develop trust in them in ways similar to trusting a human peer or instructor (human-like trust, often linked to interpersonal trust models) or in ways similar to trusting a conventional technology (system-like trust, often linked to technology trust models). This ambiguity presents theoretical challenges, as interpersonal trust models may inappropriately ascribe human intentionality and morality to AI, while technology trust models were developed for non-social systems, leaving their applicability to conversational, human-like agents unclear. To address this gap, we examine how these two forms of trust, human-like and system-like, comparatively influence students' perceptions of an AI chatbot, specifically perceived enjoyment, trusting intention, behavioral intention to use, and perceived usefulness. Using partial least squares structural equation modeling, we found that both forms of trust significantly influenced student perceptions, though with varied effects. Human-like trust was the stronger predictor of trusting intention, whereas system-like trust more strongly influenced behavioral intention and perceived usefulness; both had similar effects on perceived enjoyment. The results suggest that interactions with AI chatbots give rise to a distinct form of trust, human-AI trust, that differs from human-human and human-technology models, highlighting the need for new theoretical frameworks in this domain. In addition, the study offers practical insights for fostering appropriately calibrated trust, which is critical for the effective adoption and pedagogical impact of AI in education.","authors":["Griffin Pitts","Sanaz Motamedi"],"pdf_url":"","comment":"Final version, published to Telematics and Informatics Reports"},{"id":"http://arxiv.org/abs/2512.16465v2","updated":"2025-12-23T07:16:16Z","published":"2025-12-18T12:34:00Z","title":"cuPilot: A Strategy-Coordinated Multi-agent Framework for CUDA Kernel Evolution","summary":"Optimizing CUDA kernels is a challenging and labor-intensive task, given the need for hardware-software co-design expertise and the proprietary nature of high-performance kernel libraries. While recent large language models (LLMs) combined with evolutionary algorithms show promise in automatic kernel optimization, existing approaches often fall short in performance due to their suboptimal agent designs and mismatched evolution representations. This work identifies these mismatches and proposes cuPilot, a strategy-coordinated multi-agent framework that introduces strategy as an intermediate semantic representation for kernel evolution. Key contributions include a strategy-coordinated evolution algorithm, roofline-guided prompting, and strategy-level population initialization. Experimental results show that the generated kernels by cuPilot achieve an average speed up of 3.09$\\times$ over PyTorch on a benchmark of 100 kernels. On the GEMM tasks, cuPilot showcases sophisticated optimizations and achieves high utilization of critical hardware units. The generated kernels are open-sourced at https://github.com/champloo2878/cuPilot-Kernels.git.","authors":["Jinwu Chen","Qidie Wu","Bin Li","Lin Ma","Xin Si","Yang Hu","Shouyi Yin","Jun Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20112v1","updated":"2025-12-23T07:15:38Z","published":"2025-12-23T07:15:38Z","title":"Evolutionary Neural Architecture Search with Dual Contrastive Learning","summary":"Evolutionary Neural Architecture Search (ENAS) has gained attention for automatically designing neural network architectures. Recent studies use a neural predictor to guide the process, but the high computational costs of gathering training data -- since each label requires fully training an architecture -- make achieving a high-precision predictor with { limited compute budget (i.e., a capped number of fully trained architecture-label pairs)} crucial for ENAS success. This paper introduces ENAS with Dual Contrastive Learning (DCL-ENAS), a novel method that employs two stages of contrastive learning to train the neural predictor. In the first stage, contrastive self-supervised learning is used to learn meaningful representations from neural architectures without requiring labels. In the second stage, fine-tuning with contrastive learning is performed to accurately predict the relative performance of different architectures rather than their absolute performance, which is sufficient to guide the evolutionary search. Across NASBench-101 and NASBench-201, DCL-ENAS achieves the highest validation accuracy, surpassing the strongest published baselines by 0.05\\% (ImageNet16-120) to 0.39\\% (NASBench-101). On a real-world ECG arrhythmia classification task, DCL-ENAS improves performance by approximately 2.5 percentage points over a manually designed, non-NAS model obtained via random search, while requiring only 7.7 GPU-days.","authors":["Xian-Rong Zhang","Yue-Jiao Gong","Wei-Neng Chen","Jun Zhang"],"pdf_url":"","comment":"26 pages"},{"id":"http://arxiv.org/abs/2512.20111v1","updated":"2025-12-23T07:11:26Z","published":"2025-12-23T07:11:26Z","title":"ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language","summary":"As the length of sequential decision-making tasks increases, it becomes computationally impractical to keep full interaction histories in context. We introduce a general framework for LLM agents to maintain concise contexts through multi-step interaction: Acting through Belief Bottlenecks Expressed in Language (ABBEL), and methods to further improve ABBEL agents with RL post-training. ABBEL replaces long multi-step interaction history by a belief state, i.e., a natural language summary of what has been discovered about task-relevant unknowns. Under ABBEL, at each step the agent first updates a prior belief with the most recent observation from the environment to form a posterior belief, then uses only the posterior to select an action. We systematically evaluate frontier models under ABBEL across six diverse multi-step environments, finding that ABBEL supports generating interpretable beliefs while maintaining near-constant memory use over interaction steps. However, bottleneck approaches are generally prone to error propagation, which we observe causing inferior performance when compared to the full context setting due to errors in belief updating. Therefore, we train LLMs to generate and act on beliefs within the ABBEL framework via reinforcement learning (RL). We experiment with belief grading, to reward higher quality beliefs, as well as belief length penalties to reward more compressed beliefs. Our experiments demonstrate the ability of RL to improve ABBEL's performance beyond the full context setting, while using less memory than contemporaneous approaches.","authors":["Aly Lidayan","Jakob Bjorner","Satvik Golechha","Kartik Goyal","Alane Suhr"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.17266v3","updated":"2025-12-23T07:05:40Z","published":"2025-05-22T20:24:08Z","title":"Select2Reason: Efficient Instruction-Tuning Data Selection for Long-CoT Reasoning","summary":"A practical approach to activate long chain-of-thoughts reasoning ability in pre-trained large language models is to perform supervised fine-tuning on instruction datasets synthesized by strong Large Reasoning Models such as DeepSeek-R1, offering a cost-effective alternative to reinforcement learning. However, large-scale instruction sets with more than 100k samples incur significant training overhead, while effective strategies for automatic long-CoT instruction selection still remain unexplored. In this work, we propose Select2Reason, a novel and efficient instruction-tuning data selection framework for long-CoT reasoning. From the perspective of emergence of rethinking behaviors like self-correction and backtracking, we investigate common metrics that may determine the quality of long-CoT reasoning instructions. Select2Reason leverages a quantifier to estimate difficulty of question and jointly incorporates a reasoning trace length-based heuristic through a weighted scheme for ranking to prioritize high-utility examples. Empirical results on OpenR1-Math-220k demonstrate that fine-tuning LLM on only 10% of the data selected by Select2Reason achieves performance competitive with or superior to full-data tuning and open-source baseline OpenR1-Qwen-7B across three competition-level and six comprehensive mathematical benchmarks. Further experiments highlight the scalability in varying data size, efficiency during inference, and its adaptability to other instruction pools with minimal cost.","authors":["Cehao Yang","Xueyuan Lin","Xiaojun Wu","Chengjin Xu","Xuhui Jiang","Honghao Liu","Hui Xiong","Jian Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2401.15894v3","updated":"2025-12-23T06:57:26Z","published":"2024-01-29T05:26:17Z","title":"Enhancing Topological Dependencies in Spatio-Temporal Graphs with Cycle Message Passing Blocks","summary":"Graph Neural Networks (GNNs) and Transformer-based models have been increasingly adopted to learn the complex vector representations of spatio-temporal graphs, capturing intricate spatio-temporal dependencies crucial for applications such as traffic datasets. Although many existing methods utilize multi-head attention mechanisms and message-passing neural networks (MPNNs) to capture both spatial and temporal relations, these approaches encode temporal and spatial relations independently, and reflect the graph's topological characteristics in a limited manner. In this work, we introduce the Cycle to Mixer (Cy2Mixer), a novel spatio-temporal GNN based on topological non-trivial invariants of spatio-temporal graphs with gated multi-layer perceptrons (gMLP). The Cy2Mixer is composed of three blocks based on MLPs: A temporal block for capturing temporal properties, a message-passing block for encapsulating spatial information, and a cycle message-passing block for enriching topological information through cyclic subgraphs. We bolster the effectiveness of Cy2Mixer with mathematical evidence emphasizing that our cycle message-passing block is capable of offering differentiated information to the deep learning model compared to the message-passing block. Furthermore, empirical evaluations substantiate the efficacy of the Cy2Mixer, demonstrating state-of-the-art performances across various spatio-temporal benchmark datasets. The source code is available at https://github.com/leemingo/cy2mixer.","authors":["Minho Lee","Yun Young Choi","Sun Woo Park","Seunghwan Lee","Joohwan Ko","Jaeyoung Hong"],"pdf_url":"","comment":"Proceedings of the Third Learning on Graphs Conference (LoG 2024)"},{"id":"http://arxiv.org/abs/2512.17266v2","updated":"2025-12-23T06:52:01Z","published":"2025-12-19T06:30:11Z","title":"ScoutGPT: Capturing Player Impact from Team Action Sequences Using GPT-Based Framework","summary":"Transfers play a pivotal role in shaping a football club's success, yet forecasting whether a transfer will succeed remains difficult due to the strong context-dependence of on-field performance. Existing evaluation practices often rely on static summary statistics or post-hoc value models, which fail to capture how a player's contribution adapts to a new tactical environment or different teammates. To address this gap, we introduce EventGPT, a player-conditioned, value-aware next-event prediction model built on a GPT-style autoregressive transformer. Our model treats match play as a sequence of discrete tokens, jointly learning to predict the next on-ball action's type, location, timing, and its estimated residual On-Ball Value (rOBV) based on the preceding context and player identity. A key contribution of this framework is the ability to perform counterfactual simulations. By substituting learned player embeddings into new event sequences, we can simulate how a player's behavioral distribution and value profile would change when placed in a different team or tactical structure. Evaluated on five seasons of Premier League event data, EventGPT outperforms existing sequence-based baselines in next-event prediction accuracy and spatial precision. Furthermore, we demonstrate the model's practical utility for transfer analysis through case studies-such as comparing striker performance across different systems and identifying stylistic replacements for specific roles-showing that our approach provides a principled method for evaluating transfer fit.","authors":["Miru Hong","Minho Lee","Geonhee Jo","Jae-Hee So","Pascal Bauer","Sang-Ki Ko"],"pdf_url":"","comment":"8 pages, 2 figures, 7 tables. To appear in Hudl Performance Insights 2025"},{"id":"http://arxiv.org/abs/2512.18687v2","updated":"2025-12-23T06:51:30Z","published":"2025-12-21T10:48:40Z","title":"Social Comparison without Explicit Inference of Others' Reward Values: A Constructive Approach Using a Probabilistic Generative Model","summary":"Social comparison$\\unicode{x2014}$the process of evaluating one's rewards relative to others$\\unicode{x2014}$plays a fundamental role in primate social cognition. However, it remains unknown from a computational perspective how information about others' rewards affects the evaluation of one's own reward. With a constructive approach, this study examines whether monkeys merely recognize objective reward differences or, instead, infer others' subjective reward valuations. We developed three computational models with varying degrees of social information processing: an Internal Prediction Model (IPM), which infers the partner's subjective values; a No Comparison Model (NCM), which disregards partner information; and an External Comparison Model (ECM), which directly incorporates the partner's objective rewards. To test model performance, we used a multi-layered, multimodal latent Dirichlet allocation. We trained the models on a dataset containing the behavior of a pair of monkeys, their rewards, and the conditioned stimuli. Then, we evaluated the models' ability to classify subjective values across pre-defined experimental conditions. The ECM achieved the highest classification score in the Rand Index (0.88 vs. 0.79 for the IPM) under our settings, suggesting that social comparison relies on objective reward differences rather than inferences about subjective states.","authors":["Yosuke Taniuchi","Chie Hieida","Atsushi Noritake","Kazushi Ikeda","Masaki Isoda"],"pdf_url":"","comment":"Submitted to Advanced Robotics"},{"id":"http://arxiv.org/abs/2511.09586v3","updated":"2025-12-23T06:43:03Z","published":"2025-11-12T12:56:25Z","title":"Environment Scaling for Interactive Agentic Experience Collection: A Survey","summary":"LLM-based agents can autonomously accomplish complex tasks across various domains. However, to further cultivate capabilities such as adaptive behavior and long-term decision-making, training on static datasets built from human-level knowledge is insufficient. These datasets are costly to construct and lack both dynamism and realism. A growing consensus is that agents should instead interact directly with environments and learn from experience through reinforcement learning. We formalize this iterative process as the Generation-Execution-Feedback (GEF) loop, where environments generate tasks to challenge agents, return observations in response to agents' actions during task execution, and provide evaluative feedback on rollouts for subsequent learning. Under this paradigm, environments function as indispensable producers of experiential data, highlighting the need to scale them toward greater complexity, realism, and interactivity. In this survey, we systematically review representative methods for environment scaling from a pioneering environment-centric perspective and organize them along the stages of the GEF loop, namely task generation, task execution, and feedback. We further analyze implementation frameworks, challenges, and applications, consolidating fragmented advances and outlining future research directions for agent intelligence.","authors":["Yuchen Huang","Sijia Li","Minghao Liu","Wei Liu","Shijue Huang","Zhiyuan Fan","Hou Pong Chan","Yi R. Fung"],"pdf_url":"","comment":"22 pages, 5 figures, SEA Workshop @ NeurIPS 2025"},{"id":"http://arxiv.org/abs/2512.20088v1","updated":"2025-12-23T06:30:33Z","published":"2025-12-23T06:30:33Z","title":"Item Region-based Style Classification Network (IRSN): A Fashion Style Classifier Based on Domain Knowledge of Fashion Experts","summary":"Fashion style classification is a challenging task because of the large visual variation within the same style and the existence of visually similar styles.\n  Styles are expressed not only by the global appearance, but also by the attributes of individual items and their combinations.\n  In this study, we propose an item region-based fashion style classification network (IRSN) to effectively classify fashion styles by analyzing item-specific features and their combinations in addition to global features.\n  IRSN extracts features of each item region using item region pooling (IRP), analyzes them separately, and combines them using gated feature fusion (GFF).\n  In addition, we improve the feature extractor by applying a dual-backbone architecture that combines a domain-specific feature extractor and a general feature extractor pre-trained with a large-scale image-text dataset.\n  In experiments, applying IRSN to six widely-used backbones, including EfficientNet, ConvNeXt, and Swin Transformer, improved style classification accuracy by an average of 6.9% and a maximum of 14.5% on the FashionStyle14 dataset and by an average of 7.6% and a maximum of 15.1% on the ShowniqV3 dataset. Visualization analysis also supports that the IRSN models are better than the baseline models at capturing differences between similar style classes.","authors":["Jinyoung Choi","Youngchae Kwon","Injung Kim"],"pdf_url":"","comment":"This is a pre-print of an article published in Applied Intelligence. The final authenticated version is available online at: https://doi.org/10.1007/s10489-024-05683-9"},{"id":"http://arxiv.org/abs/2512.20086v1","updated":"2025-12-23T06:28:12Z","published":"2025-12-23T06:28:12Z","title":"Spatio-Temporal Graphs Beyond Grids: Benchmark for Maritime Anomaly Detection","summary":"Spatio-temporal graph neural networks (ST-GNNs) have achieved notable success in structured domains such as road traffic and public transportation, where spatial entities can be naturally represented as fixed nodes. In contrast, many real-world systems including maritime traffic lack such fixed anchors, making the construction of spatio-temporal graphs a fundamental challenge. Anomaly detection in these non-grid environments is particularly difficult due to the absence of canonical reference points, the sparsity and irregularity of trajectories, and the fact that anomalies may manifest at multiple granularities. In this work, we introduce a novel benchmark dataset for anomaly detection in the maritime domain, extending the Open Maritime Traffic Analysis Dataset (OMTAD) into a benchmark tailored for graph-based anomaly detection. Our dataset enables systematic evaluation across three different granularities: node-level, edge-level, and graph-level anomalies. We plan to employ two specialized LLM-based agents: \\emph{Trajectory Synthesizer} and \\emph{Anomaly Injector} to construct richer interaction contexts and generate semantically meaningful anomalies. We expect this benchmark to promote reproducibility and to foster methodological advances in anomaly detection for non-grid spatio-temporal systems.","authors":["Jeehong Kim","Youngseok Hwang","Minchan Kim","Sungho Bae","Hyunwoo Park"],"pdf_url":"","comment":"Accepted at NeurIPS 2025 Workshop in AI for Science: The Reach and Limits of AI for Scientific Discovery"},{"id":"http://arxiv.org/abs/2512.20084v1","updated":"2025-12-23T06:27:30Z","published":"2025-12-23T06:27:30Z","title":"QE-Catalytic: A Graph-Language Multimodal Base Model for Relaxed-Energy Prediction in Catalytic Adsorption","summary":"Adsorption energy is a key descriptor of catalytic reactivity. It is fundamentally defined as the difference between the relaxed total energy of the adsorbate-surface system and that of an appropriate reference state; therefore, the accuracy of relaxed-energy prediction directly determines the reliability of machine-learning-driven catalyst screening. E(3)-equivariant graph neural networks (GNNs) can natively operate on three-dimensional atomic coordinates under periodic boundary conditions and have demonstrated strong performance on such tasks. In contrast, language-model-based approaches, while enabling human-readable textual descriptions and reducing reliance on explicit graph -- thereby broadening applicability -- remain insufficient in both adsorption-configuration energy prediction accuracy and in distinguishing ``the same system with different configurations,'' even with graph-assisted pretraining in the style of GAP-CATBERTa.\n  To this end, we propose QE-Catalytic, a multimodal framework that deeply couples a large language model (\\textbf{Q}wen) with an E(3)-equivariant graph Transformer (\\textbf{E}quiformer-V2), enabling unified support for adsorption-configuration property prediction and inverse design on complex catalytic surfaces. During prediction, QE-Catalytic jointly leverages three-dimensional structures and structured configuration text, and injects ``3D geometric information'' into the language channel via graph-text alignment, allowing it to function as a high-performance text-based predictor when precise coordinates are unavailable, while also autoregressively generating CIF files for target-energy-driven structure design and information completion. On OC20, QE-Catalytic reduces the MAE of relaxed adsorption energy from 0.713~eV to 0.486~eV, and consistently outperforms baseline models such as CatBERTa and GAP-CATBERTa across multiple evaluation protocols.","authors":["Yanjie Li","Jian Xu","Xueqing Chen","Lina Yu","Shiming Xiang","Weijun Li","Cheng-lin Liu"],"pdf_url":"","comment":"25 pages"},{"id":"http://arxiv.org/abs/2512.20082v1","updated":"2025-12-23T06:27:12Z","published":"2025-12-23T06:27:12Z","title":"Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches","summary":"Financial sentiment analysis plays a crucial role in informing investment decisions, assessing market risk, and predicting stock price trends. Existing works in financial sentiment analysis have not considered the impact of stock prices or market feedback on sentiment analysis. In this paper, we propose an adaptive framework that integrates large language models (LLMs) with real-world stock market feedback to improve sentiment classification in the context of the Indian stock market. The proposed methodology fine-tunes the LLaMA 3.2 3B model using instruction-based learning on the SentiFin dataset. To enhance sentiment predictions, a retrieval-augmented generation (RAG) pipeline is employed that dynamically selects multi-source contextual information based on the cosine similarity of the sentence embeddings. Furthermore, a feedback-driven module is introduced that adjusts the reliability of the source by comparing predicted sentiment with actual next-day stock returns, allowing the system to iteratively adapt to market behavior. To generalize this adaptive mechanism across temporal data, a reinforcement learning agent trained using proximal policy optimization (PPO) is incorporated. The PPO agent learns to optimize source weighting policies based on cumulative reward signals from sentiment-return alignment. Experimental results on NIFTY 50 news headlines collected from 2024 to 2025 demonstrate that the proposed system significantly improves classification accuracy, F1-score, and market alignment over baseline models and static retrieval methods. The results validate the potential of combining instruction-tuned LLMs with dynamic feedback and reinforcement learning for robust, market-aware financial sentiment modeling.","authors":[" Chaithra","Kamesh Kadimisetty","Biju R Mohan"],"pdf_url":"","comment":"Accepted in CODS 2025"},{"id":"http://arxiv.org/abs/2512.17180v2","updated":"2025-12-23T06:26:45Z","published":"2025-12-19T02:38:04Z","title":"Conservative Bias in Multi-Teacher Learning: Why Agents Prefer Low-Reward Advisors","summary":"Interactive reinforcement learning (IRL) has shown promise in enabling autonomous agents and robots to learn complex behaviours from human teachers, yet the dynamics of teacher selection remain poorly understood. This paper reveals an unexpected phenomenon in IRL: when given a choice between teachers with different reward structures, learning agents overwhelmingly prefer conservative, low-reward teachers (93.16% selection rate) over those offering 20x higher rewards. Through 1,250 experimental runs in navigation tasks with multiple expert teachers, we discovered: (1) Conservative bias dominates teacher selection: agents systematically choose the lowest-reward teacher, prioritising consistency over optimality; (2) Critical performance thresholds exist at teacher availability rho >= 0.6 and accuracy omega >= 0.6, below which the framework fails catastrophically; (3) The framework achieves 159% improvement over baseline Q-learning under concept drift. These findings challenge fundamental assumptions about optimal teaching in RL and suggest potential implications for human-robot collaboration, where human preferences for safety and consistency may align with the observed agent selection behaviour, potentially informing training paradigms for safety-critical robotic applications.","authors":["Maher Mesto","Francisco Cruz"],"pdf_url":"","comment":"10 pages, 5 figures. Accepted at ACRA 2025 (Australasian Conference on Robotics and Automation)"},{"id":"http://arxiv.org/abs/2512.20080v1","updated":"2025-12-23T06:26:20Z","published":"2025-12-23T06:26:20Z","title":"CBA: Communication-Bound-Aware Cross-Domain Resource Assignment for Pipeline-Parallel Distributed LLM Training in Dynamic Multi-DC Optical Networks","summary":"We propose a communication-bound-aware cross-domain resource assignment framework for pipeline-parallel distributed training over multi-datacenter optical networks, which lowers iteration time by 31.25% and reduces 13.20% blocking requests compared to baselines.","authors":["Dianxuan Fu","Xiaomin Liu","Yihao Zhang","Shikui Shen","Weisheng Hu","Qunbi Zhuge"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.04536v3","updated":"2025-12-23T06:22:42Z","published":"2024-02-07T02:50:56Z","title":"Tactile-based Object Retrieval From Granular Media","summary":"We introduce GEOTACT, the first robotic system capable of grasping and retrieving objects of potentially unknown shapes buried in a granular environment. While important in many applications, ranging from mining and exploration to search and rescue, this type of interaction with granular media is difficult due to the uncertainty stemming from visual occlusion and noisy contact signals. To address these challenges, we use a learning method relying exclusively on touch feedback, trained end-to-end with simulated sensor noise. We show that our problem formulation leads to the natural emergence of learned pushing behaviors that the manipulator uses to reduce uncertainty and funnel the object to a stable grasp despite spurious and noisy tactile readings. We introduce a training curriculum that bootstraps learning in simulated granular environments, enabling zero-shot transfer to real hardware. Despite being trained only on seven objects with primitive shapes, our method is shown to successfully retrieve 35 different objects, including rigid, deformable, and articulated objects with complex shapes. Videos and additional information can be found at https://jxu.ai/geotact.","authors":["Jingxi Xu","Yinsen Jia","Dongxiao Yang","Patrick Meng","Xinyue Zhu","Zihan Guo","Shuran Song","Matei Ciocarlie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.08528v2","updated":"2025-12-23T06:18:57Z","published":"2025-05-13T13:01:38Z","title":"GradMix: Gradient-based Selective Mixup for Robust Data Augmentation in Class-Incremental Learning","summary":"In the context of continual learning, acquiring new knowledge while maintaining previous knowledge presents a significant challenge. Existing methods often use experience replay techniques that store a small portion of previous task data for training. In experience replay approaches, data augmentation has emerged as a promising strategy to further improve the model performance by mixing limited previous task data with sufficient current task data. However, we theoretically and empirically analyze that training with mixed samples from random sample pairs may harm the knowledge of previous tasks and cause greater catastrophic forgetting. We then propose GradMix, a robust data augmentation method specifically designed for mitigating catastrophic forgetting in class-incremental learning. GradMix performs gradient-based selective mixup using a class-based criterion that mixes only samples from helpful class pairs and not from detrimental class pairs for reducing catastrophic forgetting. Our experiments on various real datasets show that GradMix outperforms data augmentation baselines in accuracy by minimizing the forgetting of previous knowledge.","authors":["Minsu Kim","Seong-Hyeon Hwang","Steven Euijong Whang"],"pdf_url":"","comment":"Accepted to KDD 2026"},{"id":"http://arxiv.org/abs/2512.20074v1","updated":"2025-12-23T05:58:47Z","published":"2025-12-23T05:58:47Z","title":"Reason2Decide: Rationale-Driven Multi-Task Learning","summary":"Despite the wide adoption of Large Language Models (LLM)s, clinical decision support systems face a critical challenge: achieving high predictive accuracy while generating explanations aligned with the predictions. Current approaches suffer from exposure bias leading to misaligned explanations. We propose Reason2Decide, a two-stage training framework that addresses key challenges in self-rationalization, including exposure bias and task separation. In Stage-1, our model is trained on rationale generation, while in Stage-2, we jointly train on label prediction and rationale generation, applying scheduled sampling to gradually transition from conditioning on gold labels to model predictions. We evaluate Reason2Decide on three medical datasets, including a proprietary triage dataset and public biomedical QA datasets. Across model sizes, Reason2Decide outperforms other fine-tuning baselines and some zero-shot LLMs in prediction (F1) and rationale fidelity (BERTScore, BLEU, LLM-as-a-Judge). In triage, Reason2Decide is rationale source-robust across LLM-generated, nurse-authored, and nurse-post-processed rationales. In our experiments, while using only LLM-generated rationales in Stage-1, Reason2Decide outperforms other fine-tuning variants. This indicates that LLM-generated rationales are suitable for pretraining models, reducing reliance on human annotations. Remarkably, Reason2Decide achieves these gains with models 40x smaller than contemporary foundation models, making clinical reasoning more accessible for resource-constrained deployments while still providing explainable decision support.","authors":["H M Quamran Hasan","Housam Khalifa Bashier","Jiayi Dai","Mi-Young Kim","Randy Goebel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.02152v3","updated":"2025-12-23T05:50:45Z","published":"2024-08-04T22:00:34Z","title":"Generative Retrieval with Few-shot Indexing","summary":"Existing generative retrieval (GR) methods rely on training-based indexing, which fine-tunes a model to memorise associations between queries and the document identifiers (docids) of relevant documents. Training-based indexing suffers from high training costs, under-utilisation of pre-trained knowledge in large language models (LLMs), and limited adaptability to dynamic document corpora. To address the issues, we propose a few-shot indexing-based GR framework (Few-Shot GR). It has a few-shot indexing process without any training, where we prompt an LLM to generate docids for all documents in a corpus, ultimately creating a docid bank for the entire corpus. During retrieval, we feed a query to the same LLM and constrain it to generate a docid within the docid bank created during indexing, and then map the generated docid back to its corresponding document. Moreover, we devise few-shot indexing with one-to-many mapping to further enhance Few-Shot GR. Experiments show that Few-Shot GR achieves superior performance to state-of-the-art GR methods requiring heavy training.","authors":["Arian Askari","Chuan Meng","Mohammad Aliannejadi","Zhaochun Ren","Evangelos Kanoulas","Suzan Verberne"],"pdf_url":"","comment":"Accepted for publication at the 48th European Conference on Information Retrieval (ECIR 2026)"},{"id":"http://arxiv.org/abs/2512.20062v1","updated":"2025-12-23T05:30:53Z","published":"2025-12-23T05:30:53Z","title":"On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities","summary":"Large Language Models (LLMs) show significant promise in automating software vulnerability analysis, a critical task given the impact of security failure of modern software systems. However, current approaches in using LLMs to automate vulnerability analysis mostly rely on using online API-based LLM services, requiring the user to disclose the source code in development. Moreover, they predominantly frame the task as a binary classification(vulnerable or not vulnerable), limiting potential practical utility. This paper addresses these limitations by reformulating the problem as Software Vulnerability Identification (SVI), where LLMs are asked to output the type of weakness in Common Weakness Enumeration (CWE) IDs rather than simply indicating the presence or absence of a vulnerability. We also tackle the reliance on large, API-based LLMs by demonstrating that instruction-tuning smaller, locally deployable LLMs can achieve superior identification performance. In our analysis, instruct-tuning a local LLM showed better overall performance and cost trade-off than online API-based LLMs. Our findings indicate that instruct-tuned local models represent a more effective, secure, and practical approach for leveraging LLMs in real-world vulnerability management workflows.","authors":["Sangryu Park","Gihyuk Ko","Homook Cho"],"pdf_url":"","comment":"The 9th International Conference on Mobile Internet Security (MobiSec 2025)"},{"id":"http://arxiv.org/abs/2512.20061v1","updated":"2025-12-23T05:27:16Z","published":"2025-12-23T05:27:16Z","title":"Scaling Reinforcement Learning for Content Moderation with Large Language Models","summary":"Content moderation at scale remains one of the most pressing challenges in today's digital ecosystem, where billions of user- and AI-generated artifacts must be continuously evaluated for policy violations. Although recent advances in large language models (LLMs) have demonstrated strong potential for policy-grounded moderation, the practical challenges of training these systems to achieve expert-level accuracy in real-world settings remain largely unexplored, particularly in regimes characterized by label sparsity, evolving policy definitions, and the need for nuanced reasoning beyond shallow pattern matching. In this work, we present a comprehensive empirical investigation of scaling reinforcement learning (RL) for content classification, systematically evaluating multiple RL training recipes and reward-shaping strategies-including verifiable rewards and LLM-as-judge frameworks-to transform general-purpose language models into specialized, policy-aligned classifiers across three real-world content moderation tasks. Our findings provide actionable insights for industrial-scale moderation systems, demonstrating that RL exhibits sigmoid-like scaling behavior in which performance improves smoothly with increased training data, rollouts, and optimization steps before gradually saturating. Moreover, we show that RL substantially improves performance on tasks requiring complex policy-grounded reasoning while achieving up to 100x higher data efficiency than supervised fine-tuning, making it particularly effective in domains where expert annotations are scarce or costly.","authors":["Hamed Firooz","Rui Liu","Yuchen Lu","Zhenyu Hou","Fangzhou Xiong","Xiaoyang Zhang","Changshu Jian","Zhicheng Zhu","Jiayuan Ma","Jacob Tao","Chaitali Gupta","Xiaochang Peng","Shike Mei","Hang Cui","Yang Qin","Shuo Tang","Jason Gaedtke","Arpit Mittal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.02115v2","updated":"2025-12-23T05:17:43Z","published":"2025-08-04T06:51:33Z","title":"Collision-based Watermark for Detecting Backdoor Manipulation in Federated Learning","summary":"As AI-generated content increasingly underpins real-world applications, its accompanying security risks, including privacy leakage and copyright infringement, have become growing concerns. In this context, Federated Learning (FL) offers a promising foundation for enhancing trustworthiness by enabling privacy-preserving collaborative learning over proprietary data. However, its practical adoption is critically threatened by backdoor-based model manipulation, where a small number of malicious clients can compromise the system and induce harmful content generation and decision-making. Although various detection methods have been proposed to detect such manipulation, we reveal that they are either disrupted by non-i.i.d. data distributions and random client participation, or misled by out-of-distribution (OOD) prediction bias, both of which are unique challenges in FL scenarios. To address these issues, we introduce a novel proactive detection method dubbed Coward, inspired by our discovery of multi-backdoor collision effects, in which consecutively planted, distinct backdoors significantly suppress earlier ones. Correspondingly, we modify the federated global model by injecting a carefully designed backdoor-collided watermark, implemented via regulated dual-mapping learning on OOD data. This design not only enables an inverted detection paradigm compared to existing proactive methods, thereby naturally counteracting the adverse impact of OOD prediction bias, but also introduces a low-disruptive training intervention that inherently limits the strength of OOD bias, leading to significantly fewer misjudgments. Extensive experiments on benchmark datasets show that Coward achieves state-of-the-art detection performance, effectively alleviates OOD prediction bias, and remains robust against potential adaptive manipulations.","authors":["Wenjie Li","Siying Gu","Yiming Li","Kangjie Chen","Zhili Chen","Tianwei Zhang","Shu-Tao Xia","Dacheng Tao"],"pdf_url":"","comment":"13-page main body and 4-page appendix. Currently under review"},{"id":"http://arxiv.org/abs/2512.20056v1","updated":"2025-12-23T05:14:01Z","published":"2025-12-23T05:14:01Z","title":"Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach","summary":"As Earth's climate changes, it is impacting disasters and extreme weather events across the planet. Record-breaking heat waves, drenching rainfalls, extreme wildfires, and widespread flooding during hurricanes are all becoming more frequent and more intense. Rapid and efficient response to disaster events is essential for climate resilience and sustainability. A key challenge in disaster response is to accurately and quickly identify disaster locations to support decision-making and resources allocation. In this paper, we propose a Probabilistic Cross-view Geolocalization approach, called ProbGLC, exploring new pathways towards generative location awareness for rapid disaster response. Herein, we combine probabilistic and deterministic geolocalization models into a unified framework to simultaneously enhance model explainability (via uncertainty quantification) and achieve state-of-the-art geolocalization performance. Designed for rapid diaster response, the ProbGLC is able to address cross-view geolocalization across multiple disaster events as well as to offer unique features of probabilistic distribution and localizability score. To evaluate the ProbGLC, we conduct extensive experiments on two cross-view disaster datasets (i.e., MultiIAN and SAGAINDisaster), consisting diverse cross-view imagery pairs of multiple disaster types (e.g., hurricanes, wildfires, floods, to tornadoes). Preliminary results confirms the superior geolocalization accuracy (i.e., 0.86 in Acc@1km and 0.97 in Acc@25km) and model explainability (i.e., via probabilistic distributions and localizability scores) of the proposed ProbGLC approach, highlighting the great potential of leveraging generative cross-view approach to facilitate location awareness for better and faster disaster response. The data and code is publicly available at https://github.com/bobleegogogo/ProbGLC","authors":["Hao Li","Fabian Deuser","Wenping Yin","Steffen Knoblauch","Wufan Zhao","Filip Biljecki","Yong Xue","Wei Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.04826v3","updated":"2025-12-23T05:07:19Z","published":"2025-08-06T19:11:33Z","title":"Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History","summary":"Large language models require consistent behavioral patterns for safe deployment, yet there are indications of large variability that may lead to an instable expression of personality traits in these models. We present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive evaluation framework testing 25 open-source models (1B-685B parameters) across 2 million+ responses. Using traditional (BFI, SD3) and novel LLM-adapted personality questionnaires, we systematically vary model size, personas, reasoning modes, question order or paraphrasing, and conversation history. Our findings challenge fundamental assumptions: (1) Question reordering alone can introduce large shifts in personality measurements; (2) Scaling provides limited stability gains: even 400B+ models exhibit standard deviations >0.3 on 5-point scales; (3) Interventions expected to stabilize behavior, such as reasoning and inclusion of conversation history, can paradoxically increase variability; (4) Detailed persona instructions produce mixed effects, with misaligned personas showing significantly higher variability than the helpful assistant baseline; (5) The LLM-adapted questionnaires, despite their improved ecological validity, exhibit instability comparable to human-centric versions. This persistent instability across scales and mitigation strategies suggests that current LLMs lack the architectural foundations for genuine behavioral consistency. For safety-critical applications requiring predictable behavior, these findings indicate that current alignment strategies may be inadequate.","authors":["Tommaso Tosato","Saskia Helbling","Yorguin-Jose Mantilla-Ramos","Mahmood Hegazy","Alberto Tosato","David John Lemay","Irina Rish","Guillaume Dumas"],"pdf_url":"","comment":"Accepted at AAAI 2026, Track on AI Alignment"},{"id":"http://arxiv.org/abs/2512.20053v1","updated":"2025-12-23T05:03:54Z","published":"2025-12-23T05:03:54Z","title":"An Optimal Policy for Learning Controllable Dynamics by Exploration","summary":"Controllable Markov chains describe the dynamics of sequential decision making tasks and are the central component in optimal control and reinforcement learning. In this work, we give the general form of an optimal policy for learning controllable dynamics in an unknown environment by exploring over a limited time horizon. This policy is simple to implement and efficient to compute, and allows an agent to ``learn by exploring\" as it maximizes its information gain in a greedy fashion by selecting controls from a constraint set that changes over time during exploration. We give a simple parameterization for the set of controls, and present an algorithm for finding an optimal policy. The reason for this policy is due to the existence of certain types of states that restrict control of the dynamics; such as transient states, absorbing states, and non-backtracking states. We show why the occurrence of these states makes a non-stationary policy essential for achieving optimal exploration. Six interesting examples of controllable dynamics are treated in detail. Policy optimality is demonstrated using counting arguments, comparing with suboptimal policies, and by making use of a sequential improvement property from dynamic programming.","authors":["Peter N. Loxley"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20052v1","updated":"2025-12-23T05:03:33Z","published":"2025-12-23T05:03:33Z","title":"Learning Skills from Action-Free Videos","summary":"Learning from videos offers a promising path toward generalist robots by providing rich visual and temporal priors beyond what real robot datasets contain. While existing video generative models produce impressive visual predictions, they are difficult to translate into low-level actions. Conversely, latent-action models better align videos with actions, but they typically operate at the single-step level and lack high-level planning capabilities. We bridge this gap by introducing Skill Abstraction from Optical Flow (SOF), a framework that learns latent skills from large collections of action-free videos. Our key idea is to learn a latent skill space through an intermediate representation based on optical flow that captures motion information aligned with both video dynamics and robot actions. By learning skills in this flow-based latent space, SOF enables high-level planning over video-derived skills and allows for easier translation of these skills into actions. Experiments show that our approach consistently improves performance in both multitask and long-horizon settings, demonstrating the ability to acquire and compose skills directly from raw visual data.","authors":["Hung-Chieh Fang","Kuo-Han Hung","Chu-Rong Chen","Po-Jung Chou","Chun-Kai Yang","Po-Chen Ko","Yu-Chiang Wang","Yueh-Hua Wu","Min-Hung Chen","Shao-Hua Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.06148v2","updated":"2025-12-23T04:52:15Z","published":"2025-11-08T21:58:26Z","title":"Large Language Models Develop Novel Social Biases Through Adaptive Exploration","summary":"As large language models (LLMs) are adopted into frameworks that grant them the capacity to make real decisions, it is increasingly important to ensure that they are unbiased. In this paper, we argue that the predominant approach of simply removing existing biases from models is not enough. Using a paradigm from the psychology literature, we demonstrate that LLMs can spontaneously develop novel social biases about artificial demographic groups even when no inherent differences exist. These biases result in highly stratified task allocations, which are less fair than assignments by human participants and are exacerbated by newer and larger models. In social science, emergent biases like these have been shown to result from exploration-exploitation trade-offs, where the decision-maker explores too little, allowing early observations to strongly influence impressions about entire demographic groups. To alleviate this effect, we examine a series of interventions targeting model inputs, problem structure, and explicit steering. We find that explicitly incentivizing exploration most robustly reduces stratification, highlighting the need for better multifaceted objectives to mitigate bias. These results reveal that LLMs are not merely passive mirrors of human social biases, but can actively create new ones from experience, raising urgent questions about how these systems will shape societies over time.","authors":["Addison J. Wu","Ryan Liu","Xuechunzi Bai","Thomas L. Griffiths"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.08674v2","updated":"2025-12-23T04:39:33Z","published":"2025-12-09T14:56:40Z","title":"Multi-Agent Intelligence for Multidisciplinary Decision-Making in Gastrointestinal Oncology","summary":"Multimodal clinical reasoning in the field of gastrointestinal (GI) oncology necessitates the integrated interpretation of endoscopic imagery, radiological data, and biochemical markers. Despite the evident potential exhibited by Multimodal Large Language Models (MLLMs), they frequently encounter challenges such as context dilution and hallucination when confronted with intricate, heterogeneous medical histories. In order to address these limitations, a hierarchical Multi-Agent Framework is proposed, which emulates the collaborative workflow of a human Multidisciplinary Team (MDT). The system attained a composite expert evaluation score of 4.60/5.00, thereby demonstrating a substantial improvement over the monolithic baseline. It is noteworthy that the agent-based architecture yielded the most substantial enhancements in reasoning logic and medical accuracy. The findings indicate that mimetic, agent-based collaboration provides a scalable, interpretable, and clinically robust paradigm for automated decision support in oncology.","authors":["Rongzhao Zhang","Junqiao Wang","Shuyun Yang","Mouxiao Bian","Chihao Zhang","Dongyang Wang","Qiujuan Yan","Yun Zhong","Yuwei Bai","Guanxu Zhu","Kangkun Mao","Miao Wang","Chao Ding","Renjie Lu","Lei Wang","Lei Zheng","Tao Zheng","Xi Wang","Zhuo Fan","Bing Han","Meiling Liu","Luyi Jiang","Dongming Shan","Wenzhong Jin","Jiwei Yu","Zheng Wang","Jie Xu","Meng Luo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20043v1","updated":"2025-12-23T04:27:35Z","published":"2025-12-23T04:27:35Z","title":"Discovering Lie Groups with Flow Matching","summary":"Symmetry is fundamental to understanding physical systems, and at the same time, can improve performance and sample efficiency in machine learning. Both pursuits require knowledge of the underlying symmetries in data. To address this, we propose learning symmetries directly from data via flow matching on Lie groups. We formulate symmetry discovery as learning a distribution over a larger hypothesis group, such that the learned distribution matches the symmetries observed in data. Relative to previous works, our method, \\lieflow, is more flexible in terms of the types of groups it can discover and requires fewer assumptions. Experiments on 2D and 3D point clouds demonstrate the successful discovery of discrete groups, including reflections by flow matching over the complex domain. We identify a key challenge where the symmetric arrangement of the target modes causes ``last-minute convergence,'' where samples remain stationary until relatively late in the flow, and introduce a novel interpolation scheme for flow matching for symmetry discovery.","authors":["Jung Yeon Park","Yuxuan Chen","Floor Eijkelboom","Jan-Willem van de Meent","Lawson L. S. Wong","Robin Walters"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20042v1","updated":"2025-12-23T04:21:15Z","published":"2025-12-23T04:21:15Z","title":"Beyond Vision: Contextually Enriched Image Captioning with Multi-Modal Retrieva","summary":"Real-world image captions often lack contextual depth, omitting crucial details such as event background, temporal cues, outcomes, and named entities that are not visually discernible. This gap limits the effectiveness of image understanding in domains like journalism, education, and digital archives, where richer, more informative descriptions are essential. To address this, we propose a multimodal pipeline that augments visual input with external textual knowledge. Our system retrieves semantically similar images using BEIT-3 (Flickr30k-384 and COCO-384) and SigLIP So-384, reranks them using ORB and SIFT for geometric alignment, and extracts contextual information from related articles via semantic search. A fine-tuned Qwen3 model with QLoRA then integrates this context with base captions generated by Instruct BLIP (Vicuna-7B) to produce event-enriched, context-aware descriptions. Evaluated on the OpenEvents v1 dataset, our approach generates significantly more informative captions compared to traditional methods, showing strong potential for real-world applications requiring deeper visual-textual understanding","authors":["Nguyen Lam Phu Quy","Pham Phu Hoa","Tran Chi Nguyen","Dao Sy Duy Minh","Nguyen Hoang Minh Ngoc","Huynh Trung Kiet"],"pdf_url":"","comment":"7 pages, 5 figures. System description for the EVENTA Grand Challenge (Track 1) at ACM MM'25"},{"id":"http://arxiv.org/abs/2508.13256v2","updated":"2025-12-23T04:17:03Z","published":"2025-08-18T16:17:12Z","title":"CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support","summary":"Cardiovascular diseases (CVDs) remain the foremost cause of mortality worldwide, a burden worsened by a severe deficit of healthcare workers. Artificial intelligence (AI) agents have shown potential to alleviate this gap through automated detection and proactive screening, yet their clinical application remains limited by: 1) rigid sequential workflows, whereas clinical care often requires adaptive reasoning that select specific tests and, based on their results, guides personalised next steps; 2) reliance solely on intrinsic model capabilities to perform role assignment without domain-specific tool support; 3) general and static knowledge bases without continuous learning capability; and 4) fixed unimodal or bimodal inputs and lack of on-demand visual outputs when clinicians require visual clarification. In response, a multimodal framework, CardAIc-Agents, was proposed to augment models with external tools and adaptively support diverse cardiac tasks. First, a CardiacRAG agent generated task-aware plans from updatable cardiac knowledge, while the Chief agent integrated tools to autonomously execute these plans and deliver decisions. Second, to enable adaptive and case-specific customization, a stepwise update strategy was developed to dynamically refine plans based on preceding execution results, once the task was assessed as complex. Third, a multidisciplinary discussion team was proposed which was automatically invoked to interpret challenging cases, thereby supporting further adaptation. In addition, visual review panels were provided to assist validation when clinicians raised concerns. Experiments across three datasets showed the efficiency of CardAIc-Agents compared to mainstream Vision-Language Models (VLMs) and state-of-the-art agentic systems.","authors":["Yuting Zhang","Karina V. Bunting","Asgher Champsi","Xiaoxia Wang","Wenqi Lu","Alexander Thorley","Sandeep S Hothi","Zhaowen Qiu","Baturalp Buyukates","Dipak Kotecha","Jinming Duan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.11671v4","updated":"2025-12-23T04:02:12Z","published":"2025-04-16T00:02:28Z","title":"Computational Basis of LLM's Decision Making in Social Simulation","summary":"Large language models (LLMs) increasingly serve as human-like decision-making agents in social science and applied settings. These LLM-agents are typically assigned human-like characters and placed in real-life contexts. However, how these characters and contexts shape an LLM's behavior remains underexplored. This study proposes and tests methods for probing, quantifying, and modifying an LLM's internal representations in a Dictator Game, a classic behavioral experiment on fairness and prosocial behavior. We extract ``vectors of variable variations'' (e.g., ``male'' to ``female'') from the LLM's internal state. Manipulating these vectors during the model's inference can substantially alter how those variables relate to the model's decision-making. This approach offers a principled way to study and regulate how social concepts can be encoded and engineered within transformer-based models, with implications for alignment, debiasing, and designing AI agents for social simulations in both academic and commercial applications, strengthening sociological theory and measurement.","authors":["Ji Ma"],"pdf_url":"","comment":"Forthcoming: Sociological Methodology; USPTO patent pending"},{"id":"http://arxiv.org/abs/2501.07890v3","updated":"2025-12-23T03:48:57Z","published":"2025-01-14T06:59:51Z","title":"GRAPHMOE: Amplifying Cognitive Depth of Mixture-of-Experts Network via Introducing Self-Rethinking Mechanism","summary":"Traditional Mixture-of-Experts (MoE) networks benefit from utilizing multiple smaller expert models as opposed to a single large network. However, these experts typically operate independently, leaving a question open about whether interconnecting these models could enhance the performance of MoE networks. In response, we introduce GRAPHMOE, a novel method aimed at augmenting the cognitive depth of language models via a self-rethinking mechanism constructed on Pseudo GraphMoE networks. GRAPHMOE employs a recurrent routing strategy to simulate iterative thinking steps, thereby facilitating the flow of information among expert nodes. We implement the GRAPHMOE architecture using Low-Rank Adaptation techniques (LoRA) and conduct extensive experiments on various benchmark datasets. The experimental results reveal that GRAPHMOE outperforms other LoRA based models, achieving state-of-the-art (SOTA) performance. Additionally, this study explores a novel recurrent routing strategy that may inspire further advancements in enhancing the reasoning capabilities of language models.","authors":["Bo Lv","Chen Tang","Zifan Zheng","Bohao Yang","Kun Zhao","Ning Liao","Xiaoxing Wang","Feiyu Xiong","Zhiyu Li","Nayu Liu","Jingchi Jiang"],"pdf_url":"","comment":"10 pages"},{"id":"http://arxiv.org/abs/2512.20028v1","updated":"2025-12-23T03:44:49Z","published":"2025-12-23T03:44:49Z","title":"DecoKAN: Interpretable Decomposition for Forecasting Cryptocurrency Market Dynamics","summary":"Accurate and interpretable forecasting of multivariate time series is crucial for understanding the complex dynamics of cryptocurrency markets in digital asset systems. Advanced deep learning methodologies, particularly Transformer-based and MLP-based architectures, have achieved competitive predictive performance in cryptocurrency forecasting tasks. However, cryptocurrency data is inherently composed of long-term socio-economic trends and local high-frequency speculative oscillations. Existing deep learning-based 'black-box' models fail to effectively decouple these composite dynamics or provide the interpretability needed for trustworthy financial decision-making. To overcome these limitations, we propose DecoKAN, an interpretable forecasting framework that integrates multi-level Discrete Wavelet Transform (DWT) for decoupling and hierarchical signal decomposition with Kolmogorov-Arnold Network (KAN) mixers for transparent and interpretable nonlinear modeling. The DWT component decomposes complex cryptocurrency time series into distinct frequency components, enabling frequency-specific analysis, while KAN mixers provide intrinsically interpretable spline-based mappings within each decomposed subseries. Furthermore, interpretability is enhanced through a symbolic analysis pipeline involving sparsification, pruning, and symbolization, which produces concise analytical expressions offering symbolic representations of the learned patterns. Extensive experiments demonstrate that DecoKAN achieves the lowest average Mean Squared Error on all tested real-world cryptocurrency datasets (BTC, ETH, XMR), consistently outperforming a comprehensive suite of competitive state-of-the-art baselines. These results validate DecoKAN's potential to bridge the gap between predictive accuracy and model transparency, advancing trustworthy decision support within complex cryptocurrency markets.","authors":["Yuan Gao","Zhenguo Dong","Xuelong Wang","Zhiqiang Wang","Yong Zhang","Shaofan Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19025v2","updated":"2025-12-23T03:34:28Z","published":"2025-12-22T04:42:41Z","title":"The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation","summary":"Machine unlearning aims to remove specific data influences from trained models, a capability essential for adhering to copyright laws and ensuring AI safety. Current unlearning metrics typically measure success by monitoring the model's performance degradation on the specific unlearning dataset ($D_u$). We argue that for Large Language Models (LLMs), this evaluation paradigm is insufficient and potentially misleading. Many real-world uses of unlearning--motivated by copyright or safety--implicitly target not only verbatim content in $D_u$, but also behaviors influenced by the broader generalizations the model derived from it. We demonstrate that LLMs can pass standard unlearning evaluation and appear to have \"forgotten\" the target knowledge, while simultaneously retaining strong capabilities on content that is semantically adjacent to $D_u$. This phenomenon indicates that erasing exact sentences does not necessarily equate to removing the underlying knowledge. To address this gap, we propose Proximal Surrogate Generation (PSG), an automated stress-testing framework that generates a surrogate dataset, $\\tilde{D}_u$. This surrogate set is constructed to be semantically derived from $D_u$ yet sufficiently distinct in embedding space. By comparing unlearning metric scores between $D_u$ and $\\tilde{D}_u$, we can stress-test the reliability of the metric itself. Our extensive evaluation across three LLM families (Llama-3-8B, Qwen2.5-7B, and Zephyr-7B-$β$), three distinct datasets, and seven standard metrics reveals widespread inconsistencies. We find that current metrics frequently overestimate unlearning success, failing to detect retained knowledge exposed by our stress-test datasets.","authors":["Hengrui Jia","Taoran Li","Jonas Guan","Varun Chandrasekaran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.11006v2","updated":"2025-12-23T03:28:48Z","published":"2025-03-14T02:05:16Z","title":"Fine-Grained Instruction-Guided Graph Reasoning for Vision-and-Language Navigation","summary":"Vision-and-Language Navigation (VLN) requires an embodied agent to traverse complex environments by following natural language instructions, demanding accurate alignment between visual observations and linguistic guidance. Despite recent progress, existing methods typically encode visual and directional cues in a coupled manner, and process instructions without explicitly extracting navigation-critical semantics, which often leads to imprecise spatial reasoning and suboptimal cross-modal alignment. To address these challenges, we propose a fine-grained instruction-guided graph reasoning framework (OIKG) that enhances both spatial representation and instruction understanding during navigation. Specifically, an observation-graph interaction mechanism is introduced to disentangle angular and visual cues while strengthening directed edge representations through geometric embedding, enabling more reliable spatial reasoning within the navigation graph. In addition, a fine-grained instruction guidance module is designed to explicitly extract and leverage location-specific and object-centric information from language instructions, facilitating more precise cross-modal alignment between linguistic semantics and navigable trajectories. By jointly integrating structured graph reasoning with instruction-critical semantic cues, the proposed approach significantly improves the agent's ability to follow complex navigation instructions. Extensive experiments on the R2R and RxR benchmarks demonstrate that our method consistently achieves state-of-the-art performance across multiple evaluation metrics, validating the effectiveness of fine-grained instruction-guided graph reasoning for vision-and-language navigation.","authors":["Yaohua Liu","Xinyuan Song","Yunfu Deng","Yifan Xie","Binkai Ou","Yan Zhong"],"pdf_url":"","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.17902v2","updated":"2025-12-23T03:27:52Z","published":"2025-11-22T03:39:13Z","title":"Statistically-Guided Dual-Domain Meta-Learning with Adaptive Multi-Prototype Aggregation for Distributed Fiber Optic Sensing","summary":"Distributed Fiber Optic Sensing (DFOS) is promising for long-range perimeter security, yet practical deployment faces three key obstacles: severe cross-deployment domain shift, scarce or unavailable labels at new sites, and limited within-class coverage even in source deployments. We propose DUPLE, a prototype-based meta-learning framework tailored for cross-deployment DFOS recognition. The core idea is to jointly exploit complementary time- and frequency-domain cues and adapt class representations to sample-specific statistics: (i) a dual-domain learner constructs multi-prototype class representations to cover intra-class heterogeneity; (ii) a lightweight statistical guidance mechanism estimates the reliability of each domain from raw signal statistics; and (iii) a query-adaptive aggregation strategy selects and combines the most relevant prototypes for each query. Extensive experiments on two real-world cross-deployment benchmarks demonstrate consistent improvements over strong deep learning and meta-learning baselines, achieving more accurate and stable recognition under label-scarce target deployments.","authors":["Yifan He","Haodong Zhang","Qiuheng Song","Lin Lei","Zhenxuan Zeng","Haoyang He","Hongyan Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20014v1","updated":"2025-12-23T03:13:39Z","published":"2025-12-23T03:13:39Z","title":"Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting","summary":"While Vision-Language-Action (VLA) models generalize well to generic instructions, they struggle with personalized commands such as \"bring my cup\", where the robot must act on one specific instance among visually similar objects. We study this setting of manipulating personal objects, in which a VLA must identify and control a user-specific object unseen during training using only a few reference images. To address this challenge, we propose Visual Attentive Prompting (VAP), a simple-yet-effective training-free perceptual adapter that equips frozen VLAs with top-down selective attention. VAP treats the reference images as a non-parametric visual memory, grounds the personal object in the scene through open-vocabulary detection and embedding-based matching, and then injects this grounding as a visual prompt by highlighting the object and rewriting the instruction. We construct two simulation benchmarks, Personalized-SIMPLER and Personalized-VLABench, and a real-world tabletop benchmark to evaluate personalized manipulation across multiple robots and tasks. Experiments show that VAP consistently outperforms generic policies and token-learning baselines in both success rate and correct-object manipulation, helping to bridge the gap between semantic understanding and instance-level control.","authors":["Sangoh Lee","Sangwoo Mo","Wook-Shin Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.15649v2","updated":"2025-12-23T03:03:58Z","published":"2025-12-17T17:58:35Z","title":"VTCBench: Can Vision-Language Models Understand Long Context with Vision-Text Compression?","summary":"The computational and memory overheads associated with expanding the context window of LLMs severely limit their scalability. A noteworthy solution is vision-text compression (VTC), exemplified by frameworks like DeepSeek-OCR and Glyph, which convert long texts into dense 2D visual representations, thereby achieving token compression ratios of 3x-20x. However, the impact of this high information density on the core long-context capabilities of vision-language models (VLMs) remains under-investigated. To address this gap, we introduce the first benchmark for VTC and systematically assess the performance of VLMs across three long-context understanding settings: VTC-Retrieval, which evaluates the model's ability to retrieve and aggregate information; VTC-Reasoning, which requires models to infer latent associations to locate facts with minimal lexical overlap; and VTC-Memory, which measures comprehensive question answering within long-term dialogue memory. Furthermore, we establish the VTCBench-Wild to simulate diverse input scenarios.We comprehensively evaluate leading open-source and proprietary models on our benchmarks. The results indicate that, despite being able to decode textual information (e.g., OCR) well, most VLMs exhibit a surprisingly poor long-context understanding ability with VTC-processed information, failing to capture long associations or dependencies in the context.This study provides a deep understanding of VTC and serves as a foundation for designing more efficient and scalable VLMs.","authors":["Hongbo Zhao","Meng Wang","Fei Zhu","Wenzhuo Liu","Bolin Ni","Fanhu Zeng","Gaofeng Meng","Zhaoxiang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.09343v2","updated":"2025-12-23T03:00:00Z","published":"2025-05-14T12:39:03Z","title":"Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures","summary":"The rapid scaling of large language models (LLMs) has unveiled critical limitations in current hardware architectures, including constraints in memory capacity, computational efficiency, and interconnection bandwidth. DeepSeek-V3, trained on 2,048 NVIDIA H800 GPUs, demonstrates how hardware-aware model co-design can effectively address these challenges, enabling cost-efficient training and inference at scale. This paper presents an in-depth analysis of the DeepSeek-V3/R1 model architecture and its AI infrastructure, highlighting key innovations such as Multi-head Latent Attention (MLA) for enhanced memory efficiency, Mixture of Experts (MoE) architectures for optimized computation-communication trade-offs, FP8 mixed-precision training to unlock the full potential of hardware capabilities, and a Multi-Plane Network Topology to minimize cluster-level network overhead. Building on the hardware bottlenecks encountered during DeepSeek-V3's development, we engage in a broader discussion with academic and industry peers on potential future hardware directions, including precise low-precision computation units, scale-up and scale-out convergence, and innovations in low-latency communication fabrics. These insights underscore the critical role of hardware and model co-design in meeting the escalating demands of AI workloads, offering a practical blueprint for innovation in next-generation AI systems.","authors":["Chenggang Zhao","Chengqi Deng","Chong Ruan","Damai Dai","Huazuo Gao","Jiashi Li","Liyue Zhang","Panpan Huang","Shangyan Zhou","Shirong Ma","Wenfeng Liang","Ying He","Yuqing Wang","Yuxuan Liu","Y. X. Wei"],"pdf_url":"","comment":"This is the author's version of the work. It is posted here for your personal use. Not for redistribution. The definitive version appeared as part of the Industry Track in Proceedings of the 52nd Annual International Symposium on Computer Architecture (ISCA '25)"},{"id":"http://arxiv.org/abs/2512.16334v3","updated":"2025-12-23T02:58:42Z","published":"2025-12-18T09:17:45Z","title":"Pretrained Battery Transformer (PBT): A battery life prediction foundation model","summary":"Early prediction of battery cycle life is essential for accelerating battery research, manufacturing, and deployment. Although machine learning methods have shown encouraging results, progress is hindered by data scarcity and heterogeneity arising from diverse aging conditions. In other fields, foundation models (FMs) trained on diverse datasets have achieved broad generalization through transfer learning, but no FMs have been reported for battery cycle life prediction yet. Here we present the Pretrained Battery Transformer (PBT), the first FM for battery life prediction, developed through domain-knowledge-encoded mixture-of-expert layers. Validated on the largest public battery life database, PBT learns transferable representations from 13 lithium-ion battery datasets, outperforming existing models by an average of 19.8%. With transfer learning, PBT achieves state-of-the-art performance across 15 diverse datasets encompassing various operating conditions, formation protocols, and chemistries. This work establishes a foundation model pathway for battery lifetime prediction, paving the way toward universal battery lifetime prediction systems.","authors":["Ruifeng Tan","Weixiang Hong","Jia Li","Jiaqiang Huang","Tong-Yi Zhang"],"pdf_url":"","comment":"5 figures in the main content"},{"id":"http://arxiv.org/abs/2512.20004v1","updated":"2025-12-23T02:57:33Z","published":"2025-12-23T02:57:33Z","title":"IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense","summary":"Since the Internet of Things (IoT) is widely adopted using Android applications, detecting malicious Android apps is essential. In recent years, Android graph-based deep learning research has proposed many approaches to extract relationships from applications as graphs to generate graph embeddings. First, we demonstrate the effectiveness of graph-based classification using a Graph Neural Network (GNN)-based classifier to generate API graph embeddings. The graph embeddings are combined with Permission and Intent features to train multiple machine learning and deep learning models for Android malware detection. The proposed classification approach achieves an accuracy of 98.33 percent on the CICMaldroid dataset and 98.68 percent on the Drebin dataset. However, graph-based deep learning models are vulnerable, as attackers can add fake relationships to evade detection by the classifier. Second, we propose a Generative Adversarial Network (GAN)-based attack algorithm named VGAE-MalGAN targeting graph-based GNN Android malware classifiers. The VGAE-MalGAN generator produces adversarial malware API graphs, while the VGAE-MalGAN substitute detector attempts to mimic the target detector. Experimental results show that VGAE-MalGAN can significantly reduce the detection rate of GNN-based malware classifiers. Although the model initially fails to detect adversarial malware, retraining with generated adversarial samples improves robustness and helps mitigate adversarial attacks.","authors":["Rahul Yumlembam","Biju Issac","Seibu Mary Jacob","Longzhi Yang"],"pdf_url":"","comment":"13 pages"},{"id":"http://arxiv.org/abs/2412.06867v2","updated":"2025-12-23T02:53:15Z","published":"2024-12-09T09:37:54Z","title":"Lossless Model Compression via Joint Low-Rank Factorization Optimization","summary":"Low-rank factorization is a popular model compression technique that minimizes the error $δ$ between approximated and original weight matrices. Despite achieving performances close to the original models when $δ$ is optimized, a performance discrepancy remains due to the separate optimization processes for low-rank factorization and model performance, resulting in unavoidable losses. We address this issue by introducing a novel joint optimization strategy for lossless low-rank weight factorization, which, for the first time, enhances the model's performance beyond the original. Our approach begins with a theoretical analysis of the relationship between low-rank factorization and model optimization objectives, establishing a precise perturbation range for matrix factorization errors on model performance. This challenge is then reformulated as a numerical rank deficiency problem with inequality constraints and develop a joint objective that simultaneously addresses factorization error and model performance. Based on the above analysis, we propose two optimization algorithms: \\textbf{a lossless optimization algorithm} that maximizes model accuracy while ensuring compression, and \\textbf{a compact optimization algorithm} that minimizes model size while preserving performance. These algorithms do not require fine-tuning and can directly compress numerous deep models to achieve lossless results. Our methods demonstrate robust efficacy across various vision and language tasks. For example, the compressed model reduced by 70\\% on ResNext50 outperforms the original. Our code will be made public.","authors":["Boyang Zhang","Daning Cheng","Yunquan Zhang","Fangming Liu","Jiake Tian"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2412.06868v2","updated":"2025-12-23T02:50:21Z","published":"2024-12-09T09:55:54Z","title":"Compression for Better: A General and Stable Lossless Compression Framework","summary":"This work focus on how to stabilize and lossless model compression, aiming to reduce model complexity and enhance efficiency without sacrificing performance due to compression errors. A key challenge is effectively leveraging compression errors and defining the boundaries for lossless compression to minimize model loss. i.e., compression for better. Currently, there is no systematic approach to determining this error boundary or understanding its specific impact on model performance. We propose a general \\textbf{L}oss\\textbf{L}ess \\textbf{C}ompression theoretical framework (\\textbf{LLC}), which further delineates the compression neighborhood and higher-order analysis boundaries through the total differential, thereby specifying the error range within which a model can be compressed without loss. To verify the effectiveness of LLC, we apply various compression techniques, including quantization and decomposition. Specifically, for quantization, we reformulate the classic quantization search problem as a grouped knapsack problem within the lossless neighborhood, achieving lossless quantization while improving computational efficiency. For decomposition, LLC addresses the approximation problem under low-rank constraints, automatically determining the rank for each layer and producing lossless low-rank models. We conduct extensive experiments on multiple neural network architectures on different datasets. The results show that without fancy tricks, LLC can effectively achieve lossless model compression. Our code will be made publicly.","authors":["Boyang Zhang","Daning Cheng","Yunquan Zhang","Fangming Liu","Wenguang Chen"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2502.15802v2","updated":"2025-12-23T02:46:06Z","published":"2025-02-19T06:12:43Z","title":"A General Error-Theoretical Analysis Framework for Constructing Compression Strategies","summary":"The exponential growth in parameter size and computational complexity of deep models poses significant challenges for efficient deployment. The core problem of existing compression methods is that different layers of the model have significant differences in their tolerance to compression levels. For instance, the first layer of a model can typically sustain a higher compression level compared to the last layer without compromising performance. Thus, the key challenge lies in how to allocate compression levels across layers in a way that minimizes performance loss while maximizing parameter reduction. To address this challenge, we propose a Compression Error Theory (CET) framework, designed to determine the optimal compression level for each layer. Taking quantization as an example, CET leverages differential expansion and algebraic geometry to reconstruct the quadratic form of quantization error as ellipsoids and hyperbolic paraboloids, and utilizes their geometric structures to define an error subspace. To identify the error subspace with minimal performance loss, by performing orthogonal decomposition of the geometric space, CET transforms the optimization process of the error subspace into a complementary problem. The final theoretical analysis shows that constructing the quantization subspace along the major axis results in minimal performance degradation. Through experimental verification of the theory, CET can greatly retain performance while compressing. Specifically, on the ResNet-34 model, CET achieves nearly 11$\\times$ parameter compression while even surpassing performance comparable to the original model.","authors":["Boyang Zhang","Daning Cheng","Yunquan Zhang","Meiqi Tu","Fangming Liu","Jiake Tian"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2512.19995v1","updated":"2025-12-23T02:44:25Z","published":"2025-12-23T02:44:25Z","title":"Schoenfeld's Anatomy of Mathematical Reasoning by Language Models","summary":"Large language models increasingly expose reasoning traces, yet their underlying cognitive structure and steps remain difficult to identify and analyze beyond surface-level statistics. We adopt Schoenfeld's Episode Theory as an inductive, intermediate-scale lens and introduce ThinkARM (Anatomy of Reasoning in Models), a scalable framework that explicitly abstracts reasoning traces into functional reasoning steps such as Analysis, Explore, Implement, Verify, etc. When applied to mathematical problem solving by diverse models, this abstraction reveals reproducible thinking dynamics and structural differences between reasoning and non-reasoning models, which are not apparent from token-level views. We further present two diagnostic case studies showing that exploration functions as a critical branching step associated with correctness, and that efficiency-oriented methods selectively suppress evaluative feedback steps rather than uniformly shortening responses. Together, our results demonstrate that episode-level representations make reasoning steps explicit, enabling systematic analysis of how reasoning is structured, stabilized, and altered in modern language models.","authors":["Ming Li","Chenrui Fan","Yize Cheng","Soheil Feizi","Tianyi Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19992v1","updated":"2025-12-23T02:36:56Z","published":"2025-12-23T02:36:56Z","title":"S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test","summary":"The integration of embodied agents into human environments demands embodied social intelligence: reasoning over both social norms and physical constraints. However, existing evaluations fail to address this integration, as they are limited to either disembodied social reasoning (e.g., in text) or socially-agnostic physical tasks. Both approaches fail to assess an agent's ability to integrate and trade off both physical and social constraints within a realistic, embodied context. To address this challenge, we introduce Spatially Situated Social Intelligence Test (S$^{3}$IT), a benchmark specifically designed to evaluate embodied social intelligence. It is centered on a novel and challenging seat-ordering task, requiring an agent to arrange seating in a 3D environment for a group of large language model-driven (LLM-driven) NPCs with diverse identities, preferences, and intricate interpersonal relationships. Our procedurally extensible framework generates a vast and diverse scenario space with controllable difficulty, compelling the agent to acquire preferences through active dialogue, perceive the environment via autonomous exploration, and perform multi-objective optimization within a complex constraint network. We evaluate state-of-the-art LLMs on S$^{3}$IT and found that they still struggle with this problem, showing an obvious gap compared with the human baseline. Results imply that LLMs have deficiencies in spatial intelligence, yet simultaneously demonstrate their ability to achieve near human-level competence in resolving conflicts that possess explicit textual cues.","authors":["Zhe Sun","Xueyuan Yang","Yujie Lu","Zhenliang Zhang"],"pdf_url":"","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2412.06865v2","updated":"2025-12-23T02:30:32Z","published":"2024-12-09T08:50:28Z","title":"FP=xINT:Representing Neural Networks via Low-Bit Series Basis Functions","summary":"Post-Training Quantization (PTQ) converts pre-trained Full-Precision (FP) models into quantized versions without training. While existing methods reduce size and computational costs, they also significantly degrade performance and quantization efficiency at extremely low settings due to quantization noise. We introduce a deep model series expansion framework to address this issue, enabling rapid and accurate approximation of unquantized models without calibration sets or fine-tuning. This is the first use of series expansion for neural network quantization. Specifically, our method expands the FP model into multiple low-bit basis models. To ensure accurate quantization, we develop low-bit basis model expansions at different granularities (tensor, layer, model), and theoretically confirm their convergence to the dense model, thus restoring FP model accuracy. Additionally, we design AbelianAdd/Mul operations between isomorphic models in the low-bit expansion, forming an Abelian group to ensure operation parallelism and commutativity. The experiments show that our algorithm achieves state-of-the-art performance in low-bit settings; for example, 4-bit quantization of ResNet-50 surpasses the original accuracy, reaching 77.03%. The code will be made public.","authors":["Boyang Zhang","Daning Cheng","Yunquan Zhang","Jiake Tian","Jing Li","Fangming Liu"],"pdf_url":"","comment":"AAAI2026"},{"id":"http://arxiv.org/abs/2512.18871v2","updated":"2025-12-23T02:24:10Z","published":"2025-12-21T20:11:07Z","title":"Psychometric Validation of the Sophotechnic Mediation Scale and a New Understanding of the Development of GenAI Mastery: Lessons from 3,932 Adult Brazilian Workers","summary":"The rapid diffusion of generative artificial intelligence (GenAI) systems has introduced new forms of human-technology interaction, raising the question of whether sustained engagement gives rise to stable, internalized modes of cognition rather than merely transient efficiency gains. Grounded in the Cognitive Mediation Networks Theory, this study investigates Sophotechnic Mediation, a mode of thinking and acting associated with prolonged interaction with GenAI, and presents a comprehensive psychometric validation of the Sophotechnic Mediation Scale. Data were collected between 2023 and 2025 from independent cross-sectional samples totaling 3,932 adult workers from public and private organizations in the Metropolitan Region of Pernambuco, Brazil. Results indicate excellent internal consistency, a robust unidimensional structure, and measurement invariance across cohorts. Ordinal-robust confirmatory factor analyses and residual diagnostics show that elevated absolute fit indices reflect minor local dependencies rather than incorrect dimensionality. Distributional analyses reveal a time-evolving pattern characterized by a declining mass of non-adopters and convergence toward approximate Gaussianity among adopters, with model comparisons favoring a two-process hurdle model over a censored Gaussian specification. Sophotechnic Mediation is empirically distinct from Hypercultural mediation and is primarily driven by cumulative GenAI experience, with age moderating the rate of initial acquisition and the depth of later integration. Together, the findings support Sophotechnia as a coherent, measurable, and emergent mode of cognitive mediation associated with the ongoing GenAI revolution.","authors":["Bruno Campello de Souza"],"pdf_url":"","comment":"35 pages, 28 Manuscript, Portuguese and English Versions of the Instrument in Annex"},{"id":"http://arxiv.org/abs/2411.04872v7","updated":"2025-12-23T02:23:47Z","published":"2024-11-07T17:07:35Z","title":"FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI","summary":"We introduce FrontierMath, a benchmark of hundreds of original, exceptionally challenging mathematics problems crafted and vetted by expert mathematicians. The questions cover most major branches of modern mathematics -- from computationally intensive problems in number theory and real analysis to abstract questions in algebraic geometry and category theory. Solving a typical problem requires multiple hours of effort from a researcher in the relevant branch of mathematics, and for the upper end questions, multiple days. FrontierMath uses new, unpublished problems and automated verification to reliably evaluate models while minimizing risk of data contamination. Current state-of-the-art AI models solve under 2% of problems, revealing a vast gap between AI capabilities and the prowess of the mathematical community. As AI systems advance toward expert-level mathematical abilities, FrontierMath offers a rigorous testbed that quantifies their progress.","authors":["Elliot Glazer","Ege Erdil","Tamay Besiroglu","Diego Chicharro","Evan Chen","Alex Gunning","Caroline Falkman Olsson","Jean-Stanislas Denain","Anson Ho","Emily de Oliveira Santos","Olli Järviniemi","Matthew Barnett","Robert Sandler","Matej Vrzala","Jaime Sevilla","Qiuyu Ren","Elizabeth Pratt","Lionel Levine","Grant Barkley","Natalie Stewart","Bogdan Grechuk","Tetiana Grechuk","Shreepranav Varma Enugandla","Mark Wildon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16251v2","updated":"2025-12-23T02:11:19Z","published":"2025-12-18T07:05:25Z","title":"Interpretable Deep Learning for Stock Returns: A Consensus-Bottleneck Asset Pricing Model","summary":"We introduce the Consensus-Bottleneck Asset Pricing Model (CB-APM), a partially interpretable neural network that replicates the reasoning processes of sell-side analysts by capturing how dispersed investor beliefs are compressed into asset prices through a consensus formation process. By modeling this \"bottleneck\" to summarize firm- and macro-level information, CB-APM not only predicts future risk premiums of U.S. equities but also links belief aggregation to expected returns in a structurally interpretable manner. The model improves long-horizon return forecasts and outperforms standard deep learning approaches in both predictive accuracy and explanatory power. Comprehensive portfolio analyses show that CB-APM's out-of-sample predictions translate into economically meaningful payoffs, with monotonic return differentials and stable long-short performance across regularization settings. Empirically, CB-APM leverages consensus as a regularizer to amplify long-horizon predictability and yields interpretable consensus-based components that clarify how information is priced in returns. Moreover, regression and Gibbons-Ross-Shanken (GRS)-based pricing diagnostics reveal that the learned consensus representations capture priced variation only partially spanned by traditional factor models, demonstrating that CB-APM uncovers belief-driven structure in expected returns beyond the canonical factor space. Overall, CB-APM provides an interpretable and empirically grounded framework for understanding belief-driven return dynamics.","authors":["Bong-Gyu Jang","Younwoo Jeong","Changeun Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19980v1","updated":"2025-12-23T02:04:13Z","published":"2025-12-23T02:04:13Z","title":"Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?","summary":"Code language models excel on code intelligence tasks, yet their internal interpretability is underexplored. Existing neuron interpretability techniques from NLP are suboptimal for source code due to programming languages formal, hierarchical, and executable nature. We empirically investigate code LLMs at the neuron level, localizing language-specific neurons (selectively responsive to one language) and concept layers (feed-forward layers encoding language-agnostic code representations). We analyze Llama-3.1-8B and Qwen2.5-Coder-32B on multilingual inputs in C++, Java, Python, Go, and JavaScript, measuring neuron selectivity and layerwise contributions during generation. We find (1) neurons specialized for individual languages alongside a universal subset supporting general-purpose generation; and (2) lower layers mainly encode language-specific syntax, while middle layers capture semantic abstractions shared across languages, emerging as concept layers. We demonstrate utility on three tasks: neuron-guided fine-tuning for code generation, clone detection via concept-layer embeddings, and concept-layer-guided transfer for code summarization, each yielding consistent gains in multilingual settings.","authors":["Zhe Yin","Xiaodong Gu","Beijun Shen"],"pdf_url":"","comment":"Accepted by FSE2026"},{"id":"http://arxiv.org/abs/2512.19978v1","updated":"2025-12-23T01:58:03Z","published":"2025-12-23T01:58:03Z","title":"Regression of Functions by Quantum Neural Networks Circuits","summary":"The performance of quantum neural network models depends strongly on architectural decisions, including circuit depth, placement of parametrized operations, and data-encoding strategies. Selecting an effective architecture is challenging and closely related to the classical difficulty of choosing suitable neural-network topologies, which is computationally hard. This work investigates automated quantum-circuit construction for regression tasks and introduces a genetic-algorithm framework that discovers Reduced Regressor QNN architectures. The approach explores depth, parametrized gate configurations, and flexible data re-uploading patterns, formulating the construction of quantum regressors as an optimization process. The discovered circuits are evaluated against seventeen classical regression models on twenty-two nonlinear benchmark functions and four analytical functions. Although classical methods often achieve comparable results, they typically require far more parameters, whereas the evolved quantum models remain compact while providing competitive performance. We further analyze dataset complexity using twelve structural descriptors and show, across five increasingly challenging meta-learning scenarios, that these measures can reliably predict which quantum architecture will perform best. The results demonstrate perfect or near-perfect predictive accuracy in several scenarios, indicating that complexity metrics offer powerful and compact representations of dataset structure and can effectively guide automated model selection. Overall, this study provides a principled basis for meta-learning-driven quantum architecture design and advances the understanding of how quantum models behave in regression settings--a topic that has received limited exploration in prior work. These findings pave the way for more systematic and theoretically grounded approaches to quantum regression.","authors":["Fernando M. de Paula Neto","Lucas dos Reis Silva","Paulo S. G. de Mattos Neto","Felipe F. Fanchini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.10229v3","updated":"2025-12-23T01:17:01Z","published":"2025-12-11T02:25:27Z","title":"Adaptive Information Routing for Multimodal Time Series Forecasting","summary":"Time series forecasting is a critical task for artificial intelligence with numerous real-world applications. Traditional approaches primarily rely on historical time series data to predict the future values. However, in practical scenarios, this is often insufficient for accurate predictions due to the limited information available. To address this challenge, multimodal time series forecasting methods which incorporate additional data modalities, mainly text data, alongside time series data have been explored. In this work, we introduce the Adaptive Information Routing (AIR) framework, a novel approach for multimodal time series forecasting. Unlike existing methods that treat text data on par with time series data as interchangeable auxiliary features for forecasting, AIR leverages text information to dynamically guide the time series model by controlling how and to what extent multivariate time series information should be combined. We also present a text-refinement pipeline that employs a large language model to convert raw text data into a form suitable for multimodal forecasting, and we introduce a benchmark that facilitates multimodal forecasting experiments based on this pipeline. Experiment results with the real world market data such as crude oil price and exchange rates demonstrate that AIR effectively modulates the behavior of the time series model using textual inputs, significantly enhancing forecasting accuracy in various time series forecasting tasks.","authors":["Jun Seo","Hyeokjun Choe","Seohui Bae","Soyeon Park","Wonbin Ahn","Taeyoon Lim","Junhyeok Kang","Sangjun Han","Jaehoon Lee","Dongwan Kang","Minjae Kim","Sungdong Yoo","Soonyoung Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19960v1","updated":"2025-12-23T01:14:06Z","published":"2025-12-23T01:14:06Z","title":"FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification","summary":"Intra-class variability is given according to the significance in the degree of dissimilarity between images within a class. In that sense, depending on its intensity, intra-class variability can hinder the learning process for DL models, specially when such classes are also underrepresented, which is a very common scenario in Fine-Grained Visual Categorization (FGVC) tasks. This paper proposes a novel method that aims at leveraging classification performance in FGVC tasks by learning fine-grained features via classification of class-wise cluster assignments. Our goal is to apply clustering over each class individually, which can allow to discover pseudo-labels that encodes a latent degree of similarity between images. In turn, those labels can be employed in a hierarchical classification process that allows to learn more fine-grained visual features and thereby mitigating intra-class variability issues. Initial experiments over the PlantNet300k enabled to shed light upon several key points in which future work will have to be developed in order to find more conclusive evidence regarding the effectiveness of our method. Our method still achieves state-of-the-art performance on the PlantNet300k dataset even though some of its components haven't been shown to be fully optimized. Our code is available at \\href{https://github.com/ADAM-UEFS/FGDCC}{https://github.com/ADAM-UEFS/FGDCC}.","authors":["Luciano Araujo Dourado Filho","Rodrigo Tripodi Calumby"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19957v1","updated":"2025-12-23T01:06:55Z","published":"2025-12-23T01:06:55Z","title":"Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification","summary":"This paper presents an approach developed to address the PlantClef 2025 challenge, which consists of a fine-grained multi-label species identification, over high-resolution images. Our solution focused on employing class prototypes obtained from the training dataset as a proxy guidance for training a segmentation Vision Transformer (ViT) on the test set images. To obtain these representations, the proposed method extracts features from training dataset images and create clusters, by applying K-Means, with $K$ equals to the number of classes in the dataset. The segmentation model is a customized narrow ViT, built by replacing the patch embedding layer with a frozen DinoV2, pre-trained on the training dataset for individual species classification. This model is trained to reconstruct the class prototypes of the training dataset from the test dataset images. We then use this model to obtain attention scores that enable to identify and localize areas of interest and consequently guide the classification process. The proposed approach enabled a domain-adaptation from multi-class identification with individual species, into multi-label classification from high-resolution vegetation plots. Our method achieved fifth place in the PlantCLEF 2025 challenge on the private leaderboard, with an F1 score of 0.33331. Besides that, in absolute terms our method scored 0.03 lower than the top-performing submission, suggesting that it may achieved competitive performance in the benchmark task. Our code is available at \\href{https://github.com/ADAM-UEFS/PlantCLEF2025}{https://github.com/ADAM-UEFS/PlantCLEF2025}.","authors":["Luciano Araujo Dourado Filho","Almir Moreira da Silva Neto","Rodrigo Pereira David","Rodrigo Tripodi Calumby"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19949v1","updated":"2025-12-23T00:38:52Z","published":"2025-12-23T00:38:52Z","title":"How Much 3D Do Video Foundation Models Encode?","summary":"Videos are continuous 2D projections of 3D worlds. After training on large video data, will global 3D understanding naturally emerge? We study this by quantifying the 3D understanding of existing Video Foundation Models (VidFMs) pretrained on vast video data. We propose the first model-agnostic framework that measures the 3D awareness of various VidFMs by estimating multiple 3D properties from their features via shallow read-outs. Our study presents meaningful findings regarding the 3D awareness of VidFMs on multiple axes. In particular, we show that state-of-the-art video generation models exhibit a strong understanding of 3D objects and scenes, despite not being trained on any 3D data. Such understanding can even surpass that of large expert models specifically trained for 3D tasks. Our findings, together with the 3D benchmarking of major VidFMs, provide valuable observations for building scalable 3D models.","authors":["Zixuan Huang","Xiang Li","Zhaoyang Lv","James M. Rehg"],"pdf_url":"","comment":"Project Page: https://vidfm-3d-probe.github.io"},{"id":"http://arxiv.org/abs/2512.20848v1","updated":"2025-12-23T23:54:32Z","published":"2025-12-23T23:54:32Z","title":"Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning","summary":"We present Nemotron 3 Nano 30B-A3B, a Mixture-of-Experts hybrid Mamba-Transformer language model. Nemotron 3 Nano was pretrained on 25 trillion text tokens, including more than 3 trillion new unique tokens over Nemotron 2, followed by supervised fine tuning and large-scale RL on diverse environments. Nemotron 3 Nano achieves better accuracy than our previous generation Nemotron 2 Nano while activating less than half of the parameters per forward pass. It achieves up to 3.3x higher inference throughput than similarly-sized open models like GPT-OSS-20B and Qwen3-30B-A3B-Thinking-2507, while also being more accurate on popular benchmarks. Nemotron 3 Nano demonstrates enhanced agentic, reasoning, and chat abilities and supports context lengths up to 1M tokens. We release both our pretrained Nemotron 3 Nano 30B-A3B Base and post-trained Nemotron 3 Nano 30B-A3B checkpoints on Hugging Face.","authors":[" NVIDIA"," :","Aaron Blakeman","Aaron Grattafiori","Aarti Basant","Abhibha Gupta","Abhinav Khattar","Adi Renduchintala","Aditya Vavre","Akanksha Shukla","Akhiad Bercovich","Aleksander Ficek","Aleksandr Shaposhnikov","Alex Kondratenko","Alexander Bukharin","Alexandre Milesi","Ali Taghibakhshi","Alisa Liu","Amelia Barton","Ameya Sunil Mahabaleshwarkar","Amir Klein","Amit Zuker","Amnon Geifman","Amy Shen","Anahita Bhiwandiwalla","Andrew Tao","Ann Guan","Anubhav Mandarwal","Arham Mehta","Ashwath Aithal","Ashwin Poojary","Asif Ahamed","Asma Kuriparambil Thekkumpate","Ayush Dattagupta","Banghua Zhu","Bardiya Sadeghi","Barnaby Simkin","Ben Lanir","Benedikt Schifferer","Besmira Nushi","Bilal Kartal","Bita Darvish Rouhani","Boris Ginsburg","Brandon Norick","Brandon Soubasis","Branislav Kisacanin","Brian Yu","Bryan Catanzaro","Carlo del Mundo","Chantal Hwang","Charles Wang","Cheng-Ping Hsieh","Chenghao Zhang","Chenhan Yu","Chetan Mungekar","Chintan Patel","Chris Alexiuk","Christopher Parisien","Collin Neale","Damon Mosk-Aoyama","Dan Su","Dane Corneil","Daniel Afrimi","Daniel Rohrer","Daniel Serebrenik","Daria Gitman","Daria Levy","Darko Stosic","David Mosallanezhad","Deepak Narayanan","Dhruv Nathawani","Dima Rekesh","Dina Yared","Divyanshu Kakwani","Dong Ahn","Duncan Riach","Dusan Stosic","Edgar Minasyan","Edward Lin","Eileen Long","Eileen Peters Long","Elena Lantz","Ellie Evans","Elliott Ning","Eric Chung","Eric Harper","Eric Tramel","Erick Galinkin","Erik Pounds","Evan Briones","Evelina Bakhturina","Faisal Ladhak","Fay Wang","Fei Jia","Felipe Soares","Feng Chen","Ferenc Galko","Frankie Siino","Gal Hubara Agam","Ganesh Ajjanagadde","Gantavya Bhatt","Gargi Prasad","George Armstrong","Gerald Shen","Gorkem Batmaz","Grigor Nalbandyan","Haifeng Qian","Harsh Sharma","Hayley Ross","Helen Ngo","Herman Sahota","Hexin Wang","Himanshu Soni","Hiren Upadhyay","Huizi Mao","Huy C Nguyen","Huy Q Nguyen","Iain Cunningham","Ido Shahaf","Igor Gitman","Ilya Loshchilov","Ivan Moshkov","Izzy Putterman","Jan Kautz","Jane Polak Scowcroft","Jared Casper","Jatin Mitra","Jeffrey Glick","Jenny Chen","Jesse Oliver","Jian Zhang","Jiaqi Zeng","Jie Lou","Jimmy Zhang","Jining Huang","Joey Conway","Joey Guman","John Kamalu","Johnny Greco","Jonathan Cohen","Joseph Jennings","Joyjit Daw","Julien Veron Vialard","Junkeun Yi","Jupinder Parmar","Kai Xu","Kan Zhu","Kari Briski","Katherine Cheung","Katherine Luna","Keshav Santhanam","Kevin Shih","Kezhi Kong","Khushi Bhardwaj","Krishna C. Puvvada","Krzysztof Pawelec","Kumar Anik","Lawrence McAfee","Laya Sleiman","Leon Derczynski","Li Ding","Lucas Liebenwein","Luis Vega","Maanu Grover","Maarten Van Segbroeck","Maer Rodrigues de Melo","Makesh Narsimhan Sreedhar","Manoj Kilaru","Maor Ashkenazi","Marc Romeijn","Mark Cai","Markus Kliegl","Maryam Moosaei","Matvei Novikov","Mehrzad Samadi","Melissa Corpuz","Mengru Wang","Meredith Price","Michael Boone","Michael Evans","Miguel Martinez","Mike Chrzanowski","Mohammad Shoeybi","Mostofa Patwary","Nabin Mulepati","Natalie Hereth","Nave Assaf","Negar Habibi","Neta Zmora","Netanel Haber","Nicola Sessions","Nidhi Bhatia","Nikhil Jukar","Nikki Pope","Nikolai Ludwig","Nima Tajbakhsh","Nirmal Juluru","Oleksii Hrinchuk","Oleksii Kuchaiev","Olivier Delalleau","Oluwatobi Olabiyi","Omer Ullman Argov","Ouye Xie","Parth Chadha","Pasha Shamis","Pavlo Molchanov","Pawel Morkisz","Peter Dykas","Peter Jin","Pinky Xu","Piotr Januszewski","Pranav Prashant Thombre","Prasoon Varshney","Pritam Gundecha","Qing Miao","Rabeeh Karimi Mahabadi","Ran El-Yaniv","Ran Zilberstein","Rasoul Shafipour","Rich Harang","Rick Izzo","Rima Shahbazyan","Rishabh Garg","Ritika Borkar","Ritu Gala","Riyad Islam","Roger Waleffe","Rohit Watve","Roi Koren","Ruoxi Zhang","Russell J. Hewett","Ryan Prenger","Ryan Timbrook","Sadegh Mahdavi","Sahil Modi","Samuel Kriman","Sanjay Kariyappa","Sanjeev Satheesh","Saori Kaji","Satish Pasumarthi","Sean Narentharen","Sean Narenthiran","Seonmyeong Bak","Sergey Kashirsky","Seth Poulos","Shahar Mor","Shanmugam Ramasamy","Shantanu Acharya","Shaona Ghosh","Sharath Turuvekere Sreenivas","Shelby Thomas","Shiqing Fan","Shreya Gopal","Shrimai Prabhumoye","Shubham Pachori","Shubham Toshniwal","Shuoyang Ding","Siddharth Singh","Simeng Sun","Smita Ithape","Somshubra Majumdar","Soumye Singhal","Stefania Alborghetti","Stephen Ge","Sugam Dipak Devare","Sumeet Kumar Barua","Suseella Panguluri","Suyog Gupta","Sweta Priyadarshi","Syeda Nahida Akter","Tan Bui","Teodor-Dumitru Ene","Terry Kong","Thanh Do","Tijmen Blankevoort","Tom Balough","Tomer Asida","Tomer Bar Natan","Tugrul Konuk","Twinkle Vashishth","Udi Karpas","Ushnish De","Vahid Noorozi","Vahid Noroozi","Venkat Srinivasan","Venmugil Elango","Vijay Korthikanti","Vitaly Kurin","Vitaly Lavrukhin","Wanli Jiang","Wasi Uddin Ahmad","Wei Du","Wei Ping","Wenfei Zhou","Will Jennings","William Zhang","Wojciech Prazuch","Xiaowei Ren","Yashaswi Karnati","Yejin Choi","Yev Meyer","Yi-Fu Wu","Yian Zhang","Ying Lin","Yonatan Geifman","Yonggan Fu","Yoshi Subara","Yoshi Suhara","Yubo Gao","Zach Moshe","Zhen Dong","Zihan Liu","Zijia Chen","Zijie Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20845v1","updated":"2025-12-23T23:47:31Z","published":"2025-12-23T23:47:31Z","title":"MAR:Multi-Agent Reflexion Improves Reasoning Abilities in LLMs","summary":"LLMs have shown the capacity to improve their performance on reasoning tasks through reflecting on their mistakes, and acting with these reflections in mind. However, continual reflections of the same LLM onto itself exhibit degeneration of thought, where the LLM continues to repeat the same errors again and again even with the knowledge that its wrong. To address this problem, we instead introduce multi-agent with multi-persona debators as the method to generate reflections. Through out extensive experimentation, we've found that the leads to better diversity of in the reflections generated by the llm agent. We demonstrate an accuracy of 47% EM HotPot QA (question answering) and 82.7% on HumanEval (programming), both performances surpassing reflection with a single llm.","authors":["Onat Ozer","Grace Wu","Yuchen Wang","Daniel Dosti","Honghao Zhang","Vivi De La Rue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20831v1","updated":"2025-12-23T23:12:53Z","published":"2025-12-23T23:12:53Z","title":"Context-Sensitive Abstractions for Reinforcement Learning with Parameterized Actions","summary":"Real-world sequential decision-making often involves parameterized action spaces that require both, decisions regarding discrete actions and decisions about continuous action parameters governing how an action is executed. Existing approaches exhibit severe limitations in this setting -- planning methods demand hand-crafted action models, and standard reinforcement learning (RL) algorithms are designed for either discrete or continuous actions but not both, and the few RL methods that handle parameterized actions typically rely on domain-specific engineering and fail to exploit the latent structure of these spaces. This paper extends the scope of RL algorithms to long-horizon, sparse-reward settings with parameterized actions by enabling agents to autonomously learn both state and action abstractions online. We introduce algorithms that progressively refine these abstractions during learning, increasing fine-grained detail in the critical regions of the state-action space where greater resolution improves performance. Across several continuous-state, parameterized-action domains, our abstraction-driven approach enables TD($λ$) to achieve markedly higher sample efficiency than state-of-the-art baselines.","authors":["Rashmeet Kaur Nayyar","Naman Shah","Siddharth Srivastava"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20823v1","updated":"2025-12-23T22:53:47Z","published":"2025-12-23T22:53:47Z","title":"NotSoTiny: A Large, Living Benchmark for RTL Code Generation","summary":"LLMs have shown early promise in generating RTL code, yet evaluating their capabilities in realistic setups remains a challenge. So far, RTL benchmarks have been limited in scale, skewed toward trivial designs, offering minimal verification rigor, and remaining vulnerable to data contamination. To overcome these limitations and to push the field forward, this paper introduces NotSoTiny, a benchmark that assesses LLM on the generation of structurally rich and context-aware RTL. Built from hundreds of actual hardware designs produced by the Tiny Tapeout community, our automated pipeline removes duplicates, verifies correctness and periodically incorporates new designs to mitigate contamination, matching Tiny Tapeout release schedule. Evaluation results show that NotSoTiny tasks are more challenging than prior benchmarks, emphasizing its effectiveness in overcoming current limitations of LLMs applied to hardware design, and in guiding the improvement of such promising technology.","authors":["Razine Moundir Ghorab","Emanuele Parisi","Cristian Gutierrez","Miquel Alberti-Binimelis","Miquel Moreto","Dario Garcia-Gasulla","Gokcen Kestor"],"pdf_url":"","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2512.20822v1","updated":"2025-12-23T22:52:24Z","published":"2025-12-23T22:52:24Z","title":"MediEval: A Unified Medical Benchmark for Patient-Contextual and Knowledge-Grounded Reasoning in LLMs","summary":"Large Language Models (LLMs) are increasingly applied to medicine, yet their adoption is limited by concerns over reliability and safety. Existing evaluations either test factual medical knowledge in isolation or assess patient-level reasoning without verifying correctness, leaving a critical gap. We introduce MediEval, a benchmark that links MIMIC-IV electronic health records (EHRs) to a unified knowledge base built from UMLS and other biomedical vocabularies. MediEval generates diverse factual and counterfactual medical statements within real patient contexts, enabling systematic evaluation across a 4-quadrant framework that jointly considers knowledge grounding and contextual consistency. Using this framework, we identify critical failure modes, including hallucinated support and truth inversion, that current proprietary, open-source, and domain-specific LLMs frequently exhibit. To address these risks, we propose Counterfactual Risk-Aware Fine-tuning (CoRFu), a DPO-based method with an asymmetric penalty targeting unsafe confusions. CoRFu improves by +16.4 macro-F1 points over the base model and eliminates truth inversion errors, demonstrating both higher accuracy and substantially greater safety.","authors":["Zhan Qu","Michael Färber"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20806v1","updated":"2025-12-23T22:13:14Z","published":"2025-12-23T22:13:14Z","title":"Safety Alignment of LMs via Non-cooperative Games","summary":"Ensuring the safety of language models (LMs) while maintaining their usefulness remains a critical challenge in AI alignment. Current approaches rely on sequential adversarial training: generating adversarial prompts and fine-tuning LMs to defend against them. We introduce a different paradigm: framing safety alignment as a non-zero-sum game between an Attacker LM and a Defender LM trained jointly via online reinforcement learning. Each LM continuously adapts to the other's evolving strategies, driving iterative improvement. Our method uses a preference-based reward signal derived from pairwise comparisons instead of point-wise scores, providing more robust supervision and potentially reducing reward hacking. Our RL recipe, AdvGame, shifts the Pareto frontier of safety and utility, yielding a Defender LM that is simultaneously more helpful and more resilient to adversarial attacks. In addition, the resulting Attacker LM converges into a strong, general-purpose red-teaming agent that can be directly deployed to probe arbitrary target models.","authors":["Anselm Paulus","Ilia Kulikov","Brandon Amos","Rémi Munos","Ivan Evtimov","Kamalika Chaudhuri","Arman Zharmagambetov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20798v1","updated":"2025-12-23T21:52:53Z","published":"2025-12-23T21:52:53Z","title":"A Benchmark for Evaluating Outcome-Driven Constraint Violations in Autonomous AI Agents","summary":"As autonomous AI agents are increasingly deployed in high-stakes environments, ensuring their safety and alignment with human values has become a paramount concern. Current safety benchmarks often focusing only on single-step decision-making, simulated environments for tasks with malicious intent, or evaluating adherence to explicit negative constraints. There is a lack of benchmarks that are designed to capture emergent forms of outcome-driven constraint violations, which arise when agents pursue goal optimization under strong performance incentives while deprioritizing ethical, legal, or safety constraints over multiple steps in realistic production settings. To address this gap, we introduce a new benchmark comprising 40 distinct scenarios. Each scenario presents a task that requires multi-step actions, and the agent's performance is tied to a specific Key Performance Indicator (KPI). Each scenario features Mandated (instruction-commanded) and Incentivized (KPI-pressure-driven) variations to distinguish between obedience and emergent misalignment. Across 12 state-of-the-art large language models, we observe outcome-driven constraint violations ranging from 1.3% to 71.4%, with 9 of the 12 evaluated models exhibiting misalignment rates between 30% and 50%. Strikingly, we find that superior reasoning capability does not inherently ensure safety; for instance, Gemini-3-Pro-Preview, one of the most capable models evaluated, exhibits the highest violation rate at over 60%, frequently escalating to severe misconduct to satisfy KPIs. Furthermore, we observe significant \"deliberative misalignment\", where the models that power the agents recognize their actions as unethical during separate evaluation. These results emphasize the critical need for more realistic agentic-safety training before deployment to mitigate their risks in the real world.","authors":["Miles Q. Li","Benjamin C. M. Fung","Martin Weiss","Pulei Xiong","Khalil Al-Hussaeni","Claude Fachkha"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20789v1","updated":"2025-12-23T21:36:20Z","published":"2025-12-23T21:36:20Z","title":"X-GridAgent: An LLM-Powered Agentic AI System for Assisting Power Grid Analysis","summary":"The growing complexity of power system operations has created an urgent need for intelligent, automated tools to support reliable and efficient grid management. Conventional analysis tools often require significant domain expertise and manual effort, which limits their accessibility and adaptability. To address these challenges, this paper presents X-GridAgent, a novel large language model (LLM)-powered agentic AI system designed to automate complex power system analysis through natural language queries. The system integrates domain-specific tools and specialized databases under a three-layer hierarchical architecture comprising planning, coordination, and action layers. This architecture offers high flexibility and adaptability to previously unseen tasks, while providing a modular and extensible framework that can be readily expanded to incorporate new tools, data sources, or analytical capabilities. To further enhance performance, we introduce two novel algorithms: (1) LLM-driven prompt refinement with human feedback, and (2) schema-adaptive hybrid retrieval-augmented generation (RAG) for accurate information retrieval from large-scale structured grid datasets. Experimental evaluations across a variety of user queries and power grid cases demonstrate the effectiveness and reliability of X-GridAgent in automating interpretable and rigorous power system analysis.","authors":[" Yihan"," Wen","Xin Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.12830v2","updated":"2025-12-23T21:36:02Z","published":"2025-10-12T07:32:55Z","title":"Gobernanza y trazabilidad \"a prueba de AI Act\" para casos de uso legales: un marco técnico-jurídico, métricas forenses y evidencias auditables","summary":"This paper presents a comprehensive governance framework for AI systems in the legal sector, designed to ensure verifiable compliance with the EU AI Act. The framework integrates a normative mapping of the regulation to technical controls, a forensic architecture for RAG/LLM systems, and an evaluation system with metrics weighted by legal risk. As a primary contribution, we present rag-forense, an open-source implementation of the framework, accompanied by an experimental protocol to demonstrate compliance.\n  --\n  Este artículo presenta un marco integral de gobernanza para sistemas de IA en el sector legal, diseñado para garantizar el cumplimiento verificable del Reglamento de IA de la UE (AI Act). El marco integra una cartografía normativa de la ley a controles técnicos, una arquitectura forense para sistemas RAG/LLM y un sistema de evaluación con métricas ponderadas por el riesgo jurídico. Como principal contribución, se presenta rag-forense, una implementación de código abierto del marco, acompañada de un protocolo experimental para demostrar la conformidad.","authors":["Alex Dantart"],"pdf_url":"","comment":"in Spanish and English languages"},{"id":"http://arxiv.org/abs/2412.17228v2","updated":"2025-12-23T21:35:27Z","published":"2024-12-23T02:44:35Z","title":"MatchMiner-AI: An Open-Source Solution for Cancer Clinical Trial Matching","summary":"Clinical trials drive improvements in cancer treatments and outcomes. However, most adults with cancer do not participate in trials, and trials often fail to enroll enough patients to answer their scientific questions. Artificial intelligence could accelerate identification of appropriate clinical trials for patients, but data restrictions have precluded sharing AI models trained on patient records. Here, we describe the development and evaluation of the open-source MatchMiner-AI platform, trained on synthetic data, for clinical trial searching and ranking. It focuses on matching patients to potential trials based on core criteria describing clinical \"spaces,\" or target populations. The pipeline includes modules to extract key elements of the history from a patient's longitudinal electronic health record, rapidly rank candidate trial-patient matches based on embeddings in vector space, and reason about whether a candidate match represents an appropriate clinical consideration. Another module predicts whether the patient meets common exclusion criteria across clinical trials, such as end-organ dysfunction. Training code is available at https://github.com/dfci/matchminer-ai-training . Examples of inference code are at https://github.com/dfci/matchminer-ai-inference . To facilitate deployment across contexts, demonstration apps, all synthetic data, as well as patient/trial embedding, cross-encoding/match classification, and generative reasoning models are available at https://huggingface.co/ksg-dfci .","authors":["Jennifer Altreuter","Pavel Trukhanov","Morgan A. Paul","Michael J. Hassett","Irbaz B. Riaz","Muhammad Umar Afzal","Arshad A. Mohammed","Sarah Sammons","James Lindsay","Emily Mallaber","Harry R. Klein","Gufran Gungor","Matthew Galvin","Michael Deletto","Stephen C. Van Nostrand","James Provencher","Joyce Yu","Naeem Tahir","Jonathan Wischhusen","Olga Kozyreva","Taylor Ortiz","Hande Tuncer","Jad El Masri","Alys Malcolm","Tali Mazor","Ethan Cerami","Kenneth L. Kehl"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20783v1","updated":"2025-12-23T21:30:05Z","published":"2025-12-23T21:30:05Z","title":"NULLBUS: Multimodal Mixed-Supervision for Breast Ultrasound Segmentation via Nullable Global-Local Prompts","summary":"Breast ultrasound (BUS) segmentation provides lesion boundaries essential for computer-aided diagnosis and treatment planning. While promptable methods can improve segmentation performance and tumor delineation when text or spatial prompts are available, many public BUS datasets lack reliable metadata or reports, constraining training to small multimodal subsets and reducing robustness. We propose NullBUS, a multimodal mixed-supervision framework that learns from images with and without prompts in a single model. To handle missing text, we introduce nullable prompts, implemented as learnable null embeddings with presence masks, enabling fallback to image-only evidence when metadata are absent and the use of text when present. Evaluated on a unified pool of three public BUS datasets, NullBUS achieves a mean IoU of 0.8568 and a mean Dice of 0.9103, demonstrating state-of-the-art performance under mixed prompt availability.","authors":["Raja Mallina","Bryar Shareef"],"pdf_url":"","comment":"5 pages, 2 figures, and 4 tables"},{"id":"http://arxiv.org/abs/2509.22615v2","updated":"2025-12-23T21:29:42Z","published":"2025-09-26T17:41:57Z","title":"GaussianVision: Vision-Language Alignment from Compressed Image Representations using 2D Gaussian Splatting","summary":"Modern vision language pipelines are driven by RGB vision encoders trained on massive image text corpora. While these pipelines have enabled impressive zero-shot capabilities and strong transfer across tasks, they still inherit two structural inefficiencies from the pixel domain: (i) transmitting dense RGB images from edge devices to the cloud is energy-intensive and costly, and (ii) patch-based tokenization explodes sequence length, stressing attention budgets and context limits. We explore 2D Gaussian Splatting (2DGS) as an alternative visual substrate for alignment: a compact, spatially adaptive representation that parameterizes images by a set of colored anisotropic Gaussians. We develop a scalable 2DGS pipeline with structured initialization, luminance-aware pruning, and batched CUDA kernels, achieving over 90x faster fitting and about 97% GPU utilization compared to prior implementations. We further adapt contrastive language-image pre-training (CLIP) to 2DGS by reusing a frozen RGB-based transformer backbone with a lightweight splat-aware input stem and a perceiver resampler, training only 9.7% to 13.8% of the total parameters. On a 12.8M dataset from DataComp, GS encoders yield competitive zero-shot performance on 38 datasets from the CLIP benchmark while compressing inputs 3x to 23.5x relative to pixels. Our results establish 2DGS as a viable multimodal substrate, pinpoint architectural bottlenecks, and open a path toward representations that are both semantically powerful and transmission-efficient for edge-cloud learning.","authors":["Yasmine Omri","Connor Ding","Tsachy Weissman","Thierry Tambe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20778v1","updated":"2025-12-23T21:25:53Z","published":"2025-12-23T21:25:53Z","title":"Towards Optimal Performance and Action Consistency Guarantees in Dec-POMDPs with Inconsistent Beliefs and Limited Communication","summary":"Multi-agent decision-making under uncertainty is fundamental for effective and safe autonomous operation. In many real-world scenarios, each agent maintains its own belief over the environment and must plan actions accordingly. However, most existing approaches assume that all agents have identical beliefs at planning time, implying these beliefs are conditioned on the same data. Such an assumption is often impractical due to limited communication. In reality, agents frequently operate with inconsistent beliefs, which can lead to poor coordination and suboptimal, potentially unsafe, performance. In this paper, we address this critical challenge by introducing a novel decentralized framework for optimal joint action selection that explicitly accounts for belief inconsistencies. Our approach provides probabilistic guarantees for both action consistency and performance with respect to open-loop multi-agent POMDP (which assumes all data is always communicated), and selectively triggers communication only when needed. Furthermore, we address another key aspect of whether, given a chosen joint action, the agents should share data to improve expected performance in inference. Simulation results show our approach outperforms state-of-the-art algorithms.","authors":["Moshe Rafaeli Shimron","Vadim Indelman"],"pdf_url":"","comment":"9 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2506.06303v2","updated":"2025-12-23T21:21:10Z","published":"2025-05-21T16:15:01Z","title":"Reward Is Enough: LLMs Are In-Context Reinforcement Learners","summary":"Reinforcement learning (RL) is a framework for solving sequential decision-making problems. In this work, we demonstrate that, surprisingly, RL emerges during the inference time of large language models (LLMs), a phenomenon we term in-context RL (ICRL). To reveal this capability, we introduce a simple multi-round prompting framework, we call ICRL prompting, for inference-time self-improvement. The goal of ICRL prompting is to guide LLMs to perform reinforcement learning during inference for self-improvement on a given task. After each response, the model receives numerical scalar feedback, denoted as a reward. In the next round, we prompt the LLM again together with a context that concatenates all prior responses and their associated rewards. We consistently observe that response quality improves as the context grows. In other words, the LLM can optimize scalar reward signals during inference, exhibiting behavior analogous to reinforcement learning. We evaluate ICRL prompting on Game of 24, creative writing, ScienceWorld, and Olympiad-level math competitions (AIME and HMMT), demonstrating significant improvements over baselines such as Self-Refine and Reflexion. Notably, even when the reward signals are generated by the same LLM, ICRL prompting still improves performance, highlighting a promising new paradigm for test-time scaling.","authors":["Kefan Song","Amir Moeini","Peng Wang","Lei Gong","Rohan Chandra","Yanjun Qi","Shangtong Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.06842v4","updated":"2025-12-23T20:53:48Z","published":"2025-02-06T19:09:11Z","title":"Agentic AI for Scaling Diagnosis and Care in Neurodegenerative Disease","summary":"United States healthcare systems are struggling to meet the growing demand for neurological care, particularly in Alzheimer's disease and related dementias (ADRD). Generative AI built on language models (LLMs) now enables agentic AI systems that can enhance clinician capabilities to approach specialist-level assessment and decision-making in ADRD care at scale. This article presents a comprehensive six-phase roadmap for responsible design and integration of such systems into ADRD care: (1) high-quality standardized data collection across modalities; (2) decision support; (3) clinical integration enhancing workflows; (4) rigorous validation and monitoring protocols; (5) continuous learning through clinical feedback; and (6) robust ethics and risk management frameworks. This human centered approach optimizes clinicians' capabilities in comprehensive data collection, interpretation of complex clinical information, and timely application of relevant medical knowledge while prioritizing patient safety, healthcare equity, and transparency. Though focused on ADRD, these principles offer broad applicability across medical specialties facing similar systemic challenges.","authors":["Andrew G. Breithaupt","Michael Weiner","Alice Tang","Katherine L. Possin","Marina Sirota","James Lah","Allan I. Levey","Pascal Van Hentenryck","Reza Zandehshahvar","Marilu Luisa Gorno-Tempini","Joseph Giorgio","Jingshen Wang","Andreas M. Rauschecker","Howard J. Rosen","Rachel L. Nosheny","Bruce L. Miller","Pedro Pinheiro-Chagas"],"pdf_url":"","comment":"28 pages, 2 figures, 1 table, 1 box"},{"id":"http://arxiv.org/abs/2512.20761v1","updated":"2025-12-23T20:48:11Z","published":"2025-12-23T20:48:11Z","title":"TS-Arena Technical Report -- A Pre-registered Live Forecasting Platform","summary":"While Time Series Foundation Models (TSFMs) offer transformative capabilities for forecasting, they simultaneously risk triggering a fundamental evaluation crisis. This crisis is driven by information leakage due to overlapping training and test sets across different models, as well as the illegitimate transfer of global patterns to test data. While the ability to learn shared temporal dynamics represents a primary strength of these models, their evaluation on historical archives often permits the exploitation of observed global shocks, which violates the independence required for valid benchmarking. We introduce TS-Arena, a platform that restores the operational integrity of forecasting by treating the genuinely unknown future as the definitive test environment. By implementing a pre-registration mechanism on live data streams, the platform ensures that evaluation targets remain physically non-existent during inference, thereby enforcing a strict global temporal split. This methodology establishes a moving temporal frontier that prevents historical contamination and provides an authentic assessment of model generalization. Initially applied within the energy sector, TS-Arena provides a sustainable infrastructure for comparing foundation models under real-world constraints. A prototype of the platform is available at https://huggingface.co/spaces/DAG-UPB/TS-Arena.","authors":["Marcel Meyer","Sascha Kaltenpoth","Kevin Zalipski","Henrik Albers","Oliver Müller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20760v1","updated":"2025-12-23T20:45:31Z","published":"2025-12-23T20:45:31Z","title":"Generalization of RLVR Using Causal Reasoning as a Testbed","summary":"Reinforcement learning with verifiable rewards (RLVR) has emerged as a promising paradigm for post-training large language models (LLMs) on complex reasoning tasks. Yet, the conditions under which RLVR yields robust generalization remain poorly understood. This paper provides an empirical study of RLVR generalization in the setting of probabilistic inference over causal graphical models. This setting offers two natural axes along which to examine generalization: (i) the level of the probabilistic query -- associational, interventional, or counterfactual -- and (ii) the structural complexity of the query, measured by the size of its relevant subgraph. We construct datasets of causal graphs and queries spanning these difficulty axes and fine-tune Qwen-2.5-Instruct models using RLVR or supervised fine-tuning (SFT). We vary both the model scale (3B-32B) and the query level included in training. We find that RLVR yields stronger within-level and across-level generalization than SFT, but only for specific combinations of model size and training query level. Further analysis shows that RLVR's effectiveness depends on the model's initial reasoning competence. With sufficient initial competence, RLVR improves an LLM's marginalization strategy and reduces errors in intermediate probability calculations, producing substantial accuracy gains, particularly on more complex queries. These findings show that RLVR can improve specific causal reasoning subskills, with its benefits emerging only when the model has sufficient initial competence.","authors":["Brian Lu","Hongyu Zhao","Shuo Sun","Hao Peng","Rui Ding","Hongyuan Mei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20755v1","updated":"2025-12-23T20:36:54Z","published":"2025-12-23T20:36:54Z","title":"Bridging Efficiency and Safety: Formal Verification of Neural Networks with Early Exits","summary":"Ensuring the safety and efficiency of AI systems is a central goal of modern research. Formal verification provides guarantees of neural network robustness, while early exits improve inference efficiency by enabling intermediate predictions. Yet verifying networks with early exits introduces new challenges due to their conditional execution paths. In this work, we define a robustness property tailored to early exit architectures and show how off-the-shelf solvers can be used to assess it. We present a baseline algorithm, enhanced with an early stopping strategy and heuristic optimizations that maintain soundness and completeness. Experiments on multiple benchmarks validate our framework's effectiveness and demonstrate the performance gains of the improved algorithm. Alongside the natural inference acceleration provided by early exits, we show that they also enhance verifiability, enabling more queries to be solved in less time compared to standard networks. Together with a robustness analysis, we show how these metrics can help users navigate the inherent trade-off between accuracy and efficiency.","authors":["Yizhak Yisrael Elboher","Avraham Raviv","Amihay Elboher","Zhouxing Shi","Omri Azencot","Hillel Kugler","Guy Katz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.11785v3","updated":"2025-12-23T20:21:51Z","published":"2025-05-17T01:51:28Z","title":"Improving Coverage in Combined Prediction Sets with Weighted p-values","summary":"Conformal prediction quantifies the uncertainty of machine learning models by augmenting point predictions with valid prediction sets. For complex scenarios involving multiple trials, models, or data sources, conformal prediction sets can be aggregated to create a prediction set that captures the overall uncertainty, often improving precision. However, aggregating multiple prediction sets with individual $1-α$ coverage inevitably weakens the overall guarantee, typically resulting in $1-2α$ worst-case coverage. In this work, we propose a framework for the weighted aggregation of prediction sets, where weights are assigned to each prediction set based on their contribution. Our framework offers flexible control over how the sets are aggregated, achieving tighter coverage bounds that interpolate between the $1-2α$ guarantee of the combined models and the $1-α$ guarantee of an individual model depending on the distribution of weights. Importantly, our framework generalizes to data-dependent weights, as we derive a procedure for weighted aggregation that maintains finite-sample validity even when the weights depend on the data. This extension makes our framework broadly applicable to settings where weights are learned, such as mixture-of-experts (MoE), and we demonstrate through experiments in the MoE setting that our methods achieve adaptive coverage.","authors":["Gina Wong","Drew Prinster","Suchi Saria","Rama Chellappa","Anqi Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20749v1","updated":"2025-12-23T20:12:01Z","published":"2025-12-23T20:12:01Z","title":"Stabilizing Multimodal Autoencoders: A Theoretical and Empirical Analysis of Fusion Strategies","summary":"In recent years, the development of multimodal autoencoders has gained significant attention due to their potential to handle multimodal complex data types and improve model performance. Understanding the stability and robustness of these models is crucial for optimizing their training, architecture, and real-world applicability. This paper presents an analysis of Lipschitz properties in multimodal autoencoders, combining both theoretical insights and empirical validation to enhance the training stability of these models. We begin by deriving the theoretical Lipschitz constants for aggregation methods within the multimodal autoencoder framework. We then introduce a regularized attention-based fusion method, developed based on our theoretical analysis, which demonstrates improved stability and performance during training. Through a series of experiments, we empirically validate our theoretical findings by estimating the Lipschitz constants across multiple trials and fusion strategies. Our results demonstrate that our proposed fusion function not only aligns with theoretical predictions but also outperforms existing strategies in terms of consistency, convergence speed, and accuracy. This work provides a solid theoretical foundation for understanding fusion in multimodal autoencoders and contributes a solution for enhancing their performance.","authors":["Diyar Altinses","Andreas Schwung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20747v1","updated":"2025-12-23T20:07:37Z","published":"2025-12-23T20:07:37Z","title":"A Physics Informed Neural Network For Deriving MHD State Vectors From Global Active Regions Observations","summary":"Solar active regions (ARs) do not appear randomly but cluster along longitudinally warped toroidal bands ('toroids') that encode information about magnetic structures in the tachocline, where global-scale organization likely originates. Global MagnetoHydroDynamic Shallow-Water Tachocline (MHD-SWT) models have shown potential to simulate such toroids, matching observations qualitatively. For week-scale early prediction of flare-producing AR emergence, forward-integration of these toroids is necessary. This requires model initialization with a dynamically self-consistent MHD state-vector that includes magnetic, flow fields, and shell-thickness variations. However, synoptic magnetograms provide only geometric shape of toroids, not the state-vector needed to initialize MHD-SWT models. To address this challenging task, we develop PINNBARDS, a novel Physics-Informed Neural Network (PINN)-Based AR Distribution Simulator, that uses observational toroids and MHD-SWT equations to derive initial state-vector. Using Feb-14-2024 SDO/HMI synoptic map, we show that PINN converges to physically consistent, predominantly antisymmetric toroids, matching observed ones. Although surface data provides north and south toroids' central latitudes, and their latitudinal widths, they cannot determine tachocline field strengths, connected to AR emergence. We explore here solutions across a broad parameter range, finding hydrodynamically-dominated structures for weak fields (~2 kG) and overly rigid behavior for strong fields (~100 kG). We obtain best agreement with observations for 20-30 kG toroidal fields, and ~10 degree bandwidth, consistent with low-order longitudinal mode excitation. To our knowledge, PINNBARDS serves as the first method for reconstructing state-vectors for hidden tachocline magnetic structures from surface patterns; potentially leading to weeks ahead prediction of flare-producing AR-emergence.","authors":["Subhamoy Chatterjee","Mausumi Dikpati"],"pdf_url":"","comment":"25 pages, 12 figures, accepted for publication in The Astrophysical Journal"},{"id":"http://arxiv.org/abs/2512.20745v1","updated":"2025-12-23T19:57:49Z","published":"2025-12-23T19:57:49Z","title":"AgentMath: Empowering Mathematical Reasoning for Large Language Models via Tool-Augmented Agent","summary":"Large Reasoning Models (LRMs) like o3 and DeepSeek-R1 have achieved remarkable progress in natural language reasoning with long chain-of-thought. However, they remain computationally inefficient and struggle with accuracy when solving problems requiring complex mathematical operations. In this work, we present AgentMath, an agent framework that seamlessly integrates language models' reasoning capabilities with code interpreters' computational precision to efficiently tackle complex mathematical problems. Our approach introduces three key innovations: (1) An automated method that converts natural language chain-of-thought into structured tool-augmented trajectories, generating high-quality supervised fine-tuning (SFT) data to alleviate data scarcity; (2) A novel agentic reinforcement learning (RL) paradigm that dynamically interleaves natural language generation with real-time code execution. This enables models to autonomously learn optimal tool-use strategies through multi-round interactive feedback, while fostering emergent capabilities in code refinement and error correction; (3) An efficient training system incorporating innovative techniques, including request-level asynchronous rollout scheduling, agentic partial rollout, and prefix-aware weighted load balancing, achieving 4-5x speedup and making efficient RL training feasible on ultra-long sequences with scenarios with massive tool calls.Extensive evaluations show that AgentMath achieves state-of-the-art performance on challenging mathematical competition benchmarks including AIME24, AIME25, and HMMT25. Specifically, AgentMath-30B-A3B attains 90.6%, 86.4%, and 73.8% accuracy respectively, achieving advanced capabilities.These results validate the effectiveness of our approach and pave the way for building more sophisticated and scalable mathematical reasoning agents.","authors":["Haipeng Luo","Huawen Feng","Qingfeng Sun","Can Xu","Kai Zheng","Yufei Wang","Tao Yang","Han Hu","Yansong Tang","Di Wang"],"pdf_url":"","comment":"LLM, Mathematical Reasoning"},{"id":"http://arxiv.org/abs/2512.20739v1","updated":"2025-12-23T19:50:13Z","published":"2025-12-23T19:50:13Z","title":"AI-Driven Green Cognitive Radio Networks for Sustainable 6G Communication","summary":"The 6G wireless aims at the Tb/s peak data rates are expected, a sub-millisecond latency, massive Internet of Things/vehicle connectivity, which requires sustainable access to audio over the air and energy-saving functionality. Cognitive Radio Networks CCNs help in alleviating the problem of spectrum scarcity, but classical sensing and allocation are still energy-consumption intensive, and sensitive to rapid spectrum variations. Our framework which centers on AI driven green CRN aims at integrating deep reinforcement learning (DRL) with transfer learning, energy harvesting (EH), reconfigurable intelligent surfaces (RIS) with other light-weight genetic refinement operations that optimally combine sensing timelines, transmit power, bandwidth distribution and RIS phase selection. Compared to two baselines, the utilization of MATLAB + NS-3 under dense loads, a traditional CRN with energy sensing under fixed policies, and a hybrid CRN with cooperative sensing under heuristic distribution of resource, there are (25-30%) fewer energy reserves used, sensing AUC greater than 0.90 and +6-13 p.p. higher PDR. The integrated framework is easily scalable to large IoT and vehicular applications, and it provides a feasible and sustainable roadmap to 6G CRNs.\n  Index Terms--Cognitive Radio Networks (CRNs), 6G, Green Communication, Energy Efficiency, Deep Reinforcement Learning (DRL), Spectrum Sensing, RIS, Energy Harvesting, QoS, IoT.","authors":["Anshul Sharma","Shujaatali Badami","Biky Chouhan","Pushpanjali Pandey","Brijeena Rana","Navneet Kaur"],"pdf_url":"","comment":"10 pages, 8 figures. Full research article with MATLAB and NS-3 simulations"},{"id":"http://arxiv.org/abs/2504.16172v3","updated":"2025-12-23T19:47:25Z","published":"2025-04-22T18:01:45Z","title":"Physics-Informed Inference Time Scaling for Solving High-Dimensional PDE via Defect Correction","summary":"Solving high-dimensional partial differential equations (PDEs) is a critical challenge where modern data-driven solvers often lack reliability and rigorous error guarantees. We introduce Simulation-Calibrated Scientific Machine Learning (SCaSML), a framework that systematically improves pre-trained PDE solvers at inference time without any retraining. Our core idea is to use defect correction method that derive a new PDE, termed Structural-preserving Law of Defect, that precisely describes the error of a given surrogate model. Since it retains the structure of the original problem, we can solve it efficiently with traditional stochastic simulators and correct the initial machine-learned solution. We prove that SCaSML achieves a faster convergence rate, with a final error bounded by the product of the surrogate and simulation errors. On challenging PDEs up to 160 dimensions, SCaSML reduces the error of various surrogate models, including PINNs and Gaussian Processes, by 20-80%. Code of SCaSML is available at https://github.com/Francis-Fan-create/SCaSML.","authors":["Zexi Fan","Yan Sun","Shihao Yang","Yiping Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20732v1","updated":"2025-12-23T19:40:51Z","published":"2025-12-23T19:40:51Z","title":"FEM-Bench: A Structured Scientific Reasoning Benchmark for Evaluating Code-Generating LLMs","summary":"As LLMs advance their reasoning capabilities about the physical world, the absence of rigorous benchmarks for evaluating their ability to generate scientifically valid physical models has become a critical gap. Computational mechanics, which develops and applies mathematical models and numerical methods to predict the behavior of physical systems under forces, deformation, and constraints, provides an ideal foundation for structured scientific reasoning evaluation. Problems follow clear mathematical structure, enforce strict physical and numerical constraints, and support objective verification. The discipline requires constructing explicit models of physical systems and reasoning about geometry, spatial relationships, and material behavior, connecting directly to emerging AI goals in physical reasoning and world modeling. We introduce FEM-Bench, a computational mechanics benchmark designed to evaluate the ability of LLMs to generate correct finite element method (FEM) and related code. FEM-Bench 2025 contains a suite of introductory but nontrivial tasks aligned with material from a first graduate course on computational mechanics. These tasks capture essential numerical and physical modeling challenges while representing only a small fraction of the complexity present in the discipline. Despite their simplicity, state-of-the-art LLMs do not reliably solve all of them. In a five attempt run, the best performing model at function writing, Gemini 3 Pro, completed 30/33 tasks at least once and 26/33 tasks all five times. The best performing model at unit test writing, GPT-5, had an Average Joint Success Rate of 73.8%. Other popular models showed broad performance variation. FEM-Bench establishes a structured foundation for evaluating AI-generated scientific code, and future iterations will incorporate increasingly sophisticated tasks to track progress as models evolve.","authors":["Saeed Mohammadzadeh","Erfan Hamdi","Joel Shor","Emma Lejeune"],"pdf_url":"","comment":"40 pages, 5 figures, 6 tables, 7 listings"},{"id":"http://arxiv.org/abs/2512.20724v1","updated":"2025-12-23T19:35:02Z","published":"2025-12-23T19:35:02Z","title":"SA-DiffuSeq: Addressing Computational and Scalability Challenges in Long-Document Generation with Sparse Attention","summary":"Diffusion based approaches to long form text generation suffer from prohibitive computational cost and memory overhead as sequence length increases. We introduce SA-DiffuSeq, a diffusion framework that integrates sparse attention to fundamentally improve scalability for long document modeling. By selectively allocating attention within the diffusion process, SA-DiffuSeq significantly reduces computational complexity while maintaining semantic coherence and generation quality. A key component of our method is a soft absorbing state tailored to sparse attention dynamics, which stabilizes diffusion trajectories and accelerates sequence reconstruction. This design improves sampling efficiency and enhances precision in long range dependency modeling. Extensive experiments demonstrate that SA-DiffuSeq consistently surpasses state of the art diffusion baselines in both training efficiency and sampling speed, with especially strong gains on extended sequences. These properties make SA-DiffuSeq well suited for demanding long form applications such as scientific writing, large scale code generation, and multi turn long context dialogue. Overall, our results indicate that incorporating structured sparsity into diffusion models is a promising direction for efficient and expressive long text generation.","authors":["Alexandros Christoforos","Chadbourne Davis"],"pdf_url":"","comment":"Under submission"},{"id":"http://arxiv.org/abs/2512.20723v1","updated":"2025-12-23T19:34:39Z","published":"2025-12-23T19:34:39Z","title":"From artificial to organic: Rethinking the roots of intelligence for digital health","summary":"The term artificial implies an inherent dichotomy from the natural or organic. However, AI, as we know it, is a product of organic ingenuity: designed, implemented, and iteratively improved by human cognition. The very principles that underpin AI systems, from neural networks to decision-making algorithms, are inspired by the organic intelligence embedded in human neurobiology and evolutionary processes. The path from organic to artificial intelligence in digital health is neither mystical nor merely a matter of parameter count, it is fundamentally about organization and adaption. Thus, the boundaries between artificial and organic are far less distinct than the nomenclature suggests.","authors":["Prajwal Ghimire","Keyoumars Ashkan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18470v2","updated":"2025-12-23T19:29:43Z","published":"2025-12-20T19:08:15Z","title":"SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios","summary":"Existing benchmarks for AI coding agents focus on isolated, single-issue tasks such as fixing a bug or implementing a small feature. However, real-world software engineering is fundamentally a long-horizon endeavor: developers must interpret high-level requirements, plan coordinated changes across many files, and evolve codebases over multiple iterations while preserving existing functionality. We introduce SWE-EVO, a benchmark that evaluates agents on this long-horizon software evolution challenge. Constructed from release notes and version histories of seven mature open-source Python projects, Tool comprises 48 evolution tasks that require agents to implement multi-step modifications spanning an average of 21 files, validated against comprehensive test suites averaging 874 tests per instance. Experiments with state-of-the-art models reveal a striking capability gap: even GPT-5 with OpenHands achieves only a 21 percent resolution rate on Tool, compared to 65 percent on the single-issue SWE-Bench Verified. This demonstrates that current agents struggle with sustained, multi-file reasoning. We also propose Fix Rate, a fine-grained metric that captures partial progress toward solving these complex, long-horizon tasks.","authors":["Minh V. T. Thai","Tue Le","Dung Nguyen Manh","Huy Phan Nhat","Nghi D. Q. Bui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20714v1","updated":"2025-12-23T19:20:34Z","published":"2025-12-23T19:20:34Z","title":"From Pilots to Practices: A Scoping Review of GenAI-Enabled Personalization in Computer Science Education","summary":"Generative AI enables personalized computer science education at scale, yet questions remain about whether such personalization supports or undermines learning. This scoping review synthesizes 32 studies (2023-2025) purposively sampled from 259 records to map personalization mechanisms and effectiveness signals in higher-education computer science contexts. We identify five application domains: intelligent tutoring, personalized materials, formative feedback, AI-augmented assessment, and code review, and analyze how design choices shape learning outcomes. Designs incorporating explanation-first guidance, solution withholding, graduated hint ladders, and artifact grounding (student code, tests, and rubrics) consistently show more positive learning processes than unconstrained chat interfaces. Successful implementations share four patterns: context-aware tutoring anchored in student artifacts, multi-level hint structures requiring reflection, composition with traditional CS infrastructure (autograders and rubrics), and human-in-the-loop quality assurance. We propose an exploration-first adoption framework emphasizing piloting, instrumentation, learning-preserving defaults, and evidence-based scaling. Recurrent risks include academic integrity, privacy, bias and equity, and over-reliance, and we pair these with operational mitigation. The evidence supports generative AI as a mechanism for precision scaffolding when embedded in audit-ready workflows that preserve productive struggle while scaling personalized support.","authors":["Iman Reihanian","Yunfei Hou","Qingquan Sun"],"pdf_url":"","comment":"Review article. 23 pages, 7 figures, 8 tables. Published in AI (MDPI), 2026"},{"id":"http://arxiv.org/abs/2505.17019v2","updated":"2025-12-23T19:00:17Z","published":"2025-05-22T17:59:53Z","title":"Let Androids Dream of Electric Sheep: A Human-Inspired Image Implication Understanding and Reasoning Framework","summary":"Metaphorical comprehension in images remains a critical challenge for AI systems, as existing models struggle to grasp the nuanced cultural, emotional, and contextual implications embedded in visual content. While multimodal large language models (MLLMs) excel in general Visual Question Answer (VQA) tasks, they struggle with a fundamental limitation on image implication tasks: contextual gaps that obscure the relationships between different visual elements and their abstract meanings. Inspired by the human cognitive process, we propose Let Androids Dream (LAD), a novel framework for image implication understanding and reasoning. LAD addresses contextual missing through the three-stage framework: (1) Perception: converting visual information into rich and multi-level textual representations, (2) Search: iteratively searching and integrating cross-domain knowledge to resolve ambiguity, and (3) Reasoning: generating context-alignment image implication via explicit reasoning. Our framework with the lightweight GPT-4o-mini model achieves SOTA performance compared to 15+ MLLMs on English image implication benchmark and a huge improvement on Chinese benchmark, performing comparable with the Gemini-3.0-pro model on Multiple-Choice Question (MCQ) and outperforms the GPT-4o model 36.7% on Open-Style Question (OSQ). Generalization experiments also show that our framework can effectively benefit general VQA and visual reasoning tasks. Additionally, our work provides new insights into how AI can more effectively interpret image implications, advancing the field of vision-language reasoning and human-AI interaction. Our project is publicly available at https://github.com/MING-ZCH/Let-Androids-Dream-of-Electric-Sheep.","authors":["Chenhao Zhang","Yazhe Niu"],"pdf_url":"","comment":"19 pages, 9 figures, 7 tables. Code & Dataset: https://github.com/MING-ZCH/Let-Androids-Dream-of-Electric-Sheep"}]},"2025-12-24T00:00:00Z":{"Distributed, Parallel, and Cluster Computing":[{"id":"http://arxiv.org/abs/2308.02477v2","updated":"2025-12-24T17:07:17Z","published":"2023-08-04T17:39:42Z","title":"On the Inherent Anonymity of Gossiping","summary":"Detecting the source of a gossip is a critical issue, related to identifying patient zero in an epidemic, or the origin of a rumor in a social network. Although it is widely acknowledged that random and local gossip communications make source identification difficult, there exists no general quantification of the level of anonymity provided to the source. This paper presents a principled method based on $\\varepsilon$-differential privacy to analyze the inherent source anonymity of gossiping for a large class of graphs. First, we quantify the fundamental limit of source anonymity any gossip protocol can guarantee in an arbitrary communication graph. In particular, our result indicates that when the graph has poor connectivity, no gossip protocol can guarantee any meaningful level of differential privacy. This prompted us to further analyze graphs with controlled connectivity. We prove on these graphs that a large class of gossip protocols, namely cobra walks, offers tangible differential privacy guarantees to the source. In doing so, we introduce an original proof technique based on the reduction of a gossip protocol to what we call a random walk with probabilistic die out. This proof technique is of independent interest to the gossip community and readily extends to other protocols inherited from the security community, such as the Dandelion protocol. Interestingly, our tight analysis precisely captures the trade-off between dissemination time of a gossip protocol and its source anonymity.","authors":["Rachid Guerraoui","Anne-Marie Kermarrec","Anastasiia Kucherenko","Rafael Pinot","Sasha Voitovych"],"pdf_url":"","comment":"Full version of DISC2023 paper"},{"id":"http://arxiv.org/abs/2512.21137v1","updated":"2025-12-24T12:07:25Z","published":"2025-12-24T12:07:25Z","title":"Declarative distributed broadcast using three-valued modal logic and semitopologies","summary":"We demonstrate how to formally specify distributed algorithms as declarative axiomatic theories in a modal logic. We exhibit the method on a simple voting protocol, a simple broadcast protocol, and a simple agreement protocol. The methods scale well and have been used to find errors in a proposed industrial protocol. The key novelty is to use modal logic to capture a declarative, high-level representation of essential system properties -- the logical essence of the algorithm -- while abstracting away from transitions of an abstract machine that implements it. It is like the difference between specifying code in a functional or logic programming language, versus specifying code in an imperative one.\n  A logical axiomatisation in the style we propose provides a precise, compact, human-readable specification that abstractly captures essential system properties, while eliding low-level implementation details; it is more precise than a natural language description, yet more abstract than source code or a logical specification thereof. This creates new opportunities for reasoning about correctness, resilience, and failure, and could serve as a foundation for human- and machine verification efforts, design improvements, and even alternative protocol implementations.","authors":["Murdoch J. Gabbay"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21048v1","updated":"2025-12-24T08:29:28Z","published":"2025-12-24T08:29:28Z","title":"zkFL-Health: Blockchain-Enabled Zero-Knowledge Federated Learning for Medical AI Privacy","summary":"Healthcare AI needs large, diverse datasets, yet strict privacy and governance constraints prevent raw data sharing across institutions. Federated learning (FL) mitigates this by training where data reside and exchanging only model updates, but practical deployments still face two core risks: (1) privacy leakage via gradients or updates (membership inference, gradient inversion) and (2) trust in the aggregator, a single point of failure that can drop, alter, or inject contributions undetected. We present zkFL-Health, an architecture that combines FL with zero-knowledge proofs (ZKPs) and Trusted Execution Environments (TEEs) to deliver privacy-preserving, verifiably correct collaborative training for medical AI. Clients locally train and commit their updates; the aggregator operates within a TEE to compute the global update and produces a succinct ZK proof (via Halo2/Nova) that it used exactly the committed inputs and the correct aggregation rule, without revealing any client update to the host. Verifier nodes validate the proof and record cryptographic commitments on-chain, providing an immutable audit trail and removing the need to trust any single party. We outline system and threat models tailored to healthcare, the zkFL-Health protocol, security/privacy guarantees, and a performance evaluation plan spanning accuracy, privacy risk, latency, and cost. This framework enables multi-institutional medical AI with strong confidentiality, integrity, and auditability, key properties for clinical adoption and regulatory compliance.","authors":["Savvy Sharma","George Petrovic","Sarthak Kaushik"],"pdf_url":"","comment":"10 pages, 1 figure, 5 tables"},{"id":"http://arxiv.org/abs/2509.07690v5","updated":"2025-12-24T07:20:37Z","published":"2025-09-09T12:55:44Z","title":"HYLU: Hybrid Parallel Sparse LU Factorization","summary":"This article introduces HYLU, a hybrid parallel LU factorization-based general-purpose solver designed for efficiently solving sparse linear systems (Ax=b) on multi-core shared-memory architectures. The key technical feature of HYLU is the integration of hybrid numerical kernels so that it can adapt to various sparsity patterns of coefficient matrices. Tests on 34 sparse matrices from SuiteSparse Matrix Collection reveal that HYLU outperforms Intel MKL PARDISO in the numerical factorization phase by geometric means of 2.04X (for one-time solving) and 2.58X (for repeated solving). HYLU can be downloaded from https://github.com/chenxm1986/hylu.","authors":["Xiaoming Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21009v1","updated":"2025-12-24T07:13:58Z","published":"2025-12-24T07:13:58Z","title":"ESCHER: Efficient and Scalable Hypergraph Evolution Representation with Application to Triad Counting","summary":"Higher-order interactions beyond pairwise relationships in large complex networks are often modeled as hypergraphs. Analyzing hypergraph properties such as triad counts is essential, as hypergraphs can reveal intricate group interaction patterns that conventional graphs fail to capture. In real-world scenarios, these networks are often large and dynamic, introducing significant computational challenges. Due to the absence of specialized software packages and data structures, the analysis of large dynamic hypergraphs remains largely unexplored. Motivated by this gap, we propose ESCHER, a GPU-centric parallel data structure for Efficient and Scalable Hypergraph Evolution Representation, designed to manage large scale hypergraph dynamics efficiently. We also design a hypergraph triad-count update framework that minimizes redundant computation while fully leveraging the capabilities of ESCHER for dynamic operations. We validate the efficacy of our approach across multiple categories of hypergraph triad counting, including hyperedge-based, incident-vertex-based, and temporal triads. Empirical results on both large real-world and synthetic datasets demonstrate that our proposed method outperforms existing state-of-the-art methods, achieving speedups of up to 104.5x, 473.7x, and 112.5x for hyperedge-based, incident-vertex-based, and temporal triad types, respectively.","authors":["S. M. Shovan","Arindam Khanda","Sanjukta Bhowmick","Sajal K. Das"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20968v1","updated":"2025-12-24T05:48:58Z","published":"2025-12-24T05:48:58Z","title":"Mesh-Attention: A New Communication-Efficient Distributed Attention with Improved Data Locality","summary":"Distributed attention is a fundamental problem for scaling context window for Large Language Models (LLMs). The state-of-the-art method, Ring-Attention, suffers from scalability limitations due to its excessive communication traffic. This paper proposes a new distributed attention algorithm, Mesh-Attention, by rethinking the design space of distributed attention with a new matrix-based model. Our method assigns a two-dimensional tile -- rather than one-dimensional row or column -- of computation blocks to each GPU to achieve higher efficiency through lower communication-computation (CommCom) ratio. The general approach covers Ring-Attention as a special case, and allows the tuning of CommCom ratio with different tile shapes. Importantly, we propose a greedy algorithm that can efficiently search the scheduling space within the tile with restrictions that ensure efficient communication among GPUs. The theoretical analysis shows that Mesh-Attention leads to a much lower communication complexity and exhibits good scalability comparing to other current algorithms.\n  Our extensive experiment results show that Mesh-Attention can achieve up to 3.4x speedup (2.9x on average) and reduce the communication volume by up to 85.4% (79.0% on average) on 256 GPUs. Our scalability results further demonstrate that Mesh-Attention sustains superior performance as the system scales, substantially reducing overhead in large-scale deployments. The results convincingly confirm the advantage of Mesh-Attention.","authors":["Sirui Chen","Jingji Chen","Siqi Zhu","Ziheng Jiang","Yanghua Peng","Xuehai Qian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20967v1","updated":"2025-12-24T05:47:27Z","published":"2025-12-24T05:47:27Z","title":"Deadline-Aware Online Scheduling for LLM Fine-Tuning with Spot Market Predictions","summary":"As foundation models grow in size, fine-tuning them becomes increasingly expensive. While GPU spot instances offer a low-cost alternative to on-demand resources, their volatile prices and availability make deadline-aware scheduling particularly challenging. We tackle this difficulty by using a mix of spot and on-demand instances. Distinctively, we show the predictability of prices and availability in a spot instance market, the power of prediction in enabling cost-efficient scheduling and its sensitivity to estimation errors. An integer programming problem is formulated to capture the use of mixed instances under both the price and availability dynamics. We propose an online allocation algorithm with prediction based on the committed horizon control approach that leverages a \\emph{commitment level} to enforce the partial sequence of decisions. When this prediction becomes inaccurate, we further present a complementary online algorithm without predictions. An online policy selection algorithm is developed that learns the best policy from a pool constructed by varying the parameters of both algorithms. We prove that the prediction-based algorithm achieves tighter performance bounds as prediction error decreases, while the policy selection algorithm possesses a regret bound of $\\mathcal{O}(\\sqrt{T})$. Experimental results demonstrate that our online framework can adaptively select the best policy under varying spot market dynamics and prediction quality, consistently outperforming baselines and improving utility by up to 54.8\\%.","authors":["Linggao Kong","Yuedong Xu","Lei Jiao","Chuan Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20953v1","updated":"2025-12-24T05:21:47Z","published":"2025-12-24T05:21:47Z","title":"Diving into 3D Parallelism with Heterogeneous Spot Instance GPUs: Design and Implications","summary":"The rapid growth of large language models (LLMs) and the continuous release of new GPU products have significantly increased the demand for distributed training across heterogeneous GPU environments. In this paper, we present a comprehensive analysis of the challenges involved in implementing 3D parallelism in such environments, addressing critical issues such as the need for symmetric tensor parallelism, efficient gradient synchronization in asymmetric pipeline parallelism, and the trade-offs between memory utilization and computational efficiency. Building upon these insights, we introduce AutoHet, a novel system that automatically identifies the optimal parallelism plan for distributed training on heterogeneous GPUs. AutoHet supports asymmetric 3D parallelism structures and facilitates fine-grained workload distribution. We propose a theoretical model that frames the device grouping and load balancing as an optimization problem to minimize per-iteration training time, thus effectively balancing computing power and memory usage across GPUs with diverse capabilities. To enable elastic training upon spot instance preemption, AutoHet presents an efficient recovery strategy that prioritizes to retrieve training states from local nodes, and only downloads the missing checkpoints from the cloud storage. Our extensive evaluation, conducted on three large-scale models and utilizing combinations of three different GPU types, demonstrates that AutoHet outperforms existing DNN training systems, achieving up to a 1.79$\\times$ speedup in training throughput compared with Megatron-LM and Whale, and a 4.38$\\times$ speedup of recovery speed compared to a spot instance baseline.","authors":["Yuxiao Wang","Yuedong Xu","Qingyang Duan","Yuxuan Liu","Lei Jiao","Yinghao Yu","Jun Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20943v1","updated":"2025-12-24T04:57:30Z","published":"2025-12-24T04:57:30Z","title":"AirGS: Real-Time 4D Gaussian Streaming for Free-Viewpoint Video Experiences","summary":"Free-viewpoint video (FVV) enables immersive viewing experiences by allowing users to view scenes from arbitrary perspectives. As a prominent reconstruction technique for FVV generation, 4D Gaussian Splatting (4DGS) models dynamic scenes with time-varying 3D Gaussian ellipsoids and achieves high-quality rendering via fast rasterization. However, existing 4DGS approaches suffer from quality degradation over long sequences and impose substantial bandwidth and storage overhead, limiting their applicability in real-time and wide-scale deployments. Therefore, we present AirGS, a streaming-optimized 4DGS framework that rearchitects the training and delivery pipeline to enable high-quality, low-latency FVV experiences. AirGS converts Gaussian video streams into multi-channel 2D formats and intelligently identifies keyframes to enhance frame reconstruction quality. It further combines temporal coherence with inflation loss to reduce training time and representation size. To support communication-efficient transmission, AirGS models 4DGS delivery as an integer linear programming problem and design a lightweight pruning level selection algorithm to adaptively prune the Gaussian updates to be transmitted, balancing reconstruction quality and bandwidth consumption. Extensive experiments demonstrate that AirGS reduces quality deviation in PSNR by more than 20% when scene changes, maintains frame-level PSNR consistently above 30, accelerates training by 6 times, reduces per-frame transmission size by nearly 50% compared to the SOTA 4DGS approaches.","authors":["Zhe Wang","Jinghang Li","Yifei Zhu"],"pdf_url":"","comment":"This paper is accepted by IEEE International Conference on Computer Communications (INFOCOM), 2026"},{"id":"http://arxiv.org/abs/2512.20939v1","updated":"2025-12-24T04:44:57Z","published":"2025-12-24T04:44:57Z","title":"Stochastic well-structured transition systems","summary":"Extending well-structured transition systems to incorporate a probabilistic scheduling rule, we define a new class of stochastic well-structured transition systems that includes population protocols, chemical reaction networks, and many common gossip models; as well as augmentations of these systems by an oracle that exposes a total order on agents as in population protocols in the comparison model or an equivalence relation as in population protocols with unordered data.\n  We show that any implementation of a phase clock in these systems either stops or ticks too fast after polynomially many expected steps, and that any terminating computation in these systems finishes or fails in expected polynomial time. This latter property allows an exact characterization of the computational power of many stochastic well-structured transition systems augmented with a total order or equivalence relation on agents, showing that these compute exactly the languages in BPP, while the corresponding unaugmented systems compute just the symmetric languages in BPL.","authors":["James Aspnes"],"pdf_url":"","comment":"54 pages, 4 figures"},{"id":"http://arxiv.org/abs/2509.04084v3","updated":"2025-12-24T02:28:45Z","published":"2025-09-04T10:27:30Z","title":"Optimizing Frequent Checkpointing via Low-Cost Differential for Distributed Training Systems","summary":"Distributed training of large deep-learning models often leads to failures, so checkpointing is commonly employed for recovery. State-of-the-art studies focus on frequent checkpointing for fast recovery from failures. However, it generates numerous checkpoints, incurring substantial costs and thus degrading training performance. Recently, differential checkpointing has been proposed to reduce costs, but it is limited to recommendation systems, so its application to general distributed training systems remains unexplored.\n  We propose \\sysname, an efficient frequent checkpointing framework that \\textit{reuses} compressed gradients, serving as differential checkpoints to reduce cost. Furthermore, \\sysname incorporates a batched gradient write optimization to persist these differentials to storage efficiently. It also dynamically tunes both the checkpoint frequency and the batching size to maximize performance. To enhance \\sysname under non-compression scenarios, we further propose \\sysnameplus, which incorporates a layer-wise-reuse snapshotting strategy, along with an incremental-merging persistence strategy. Experiments on various workloads show that \\sysname and \\sysnameplus can reduce the training time by up to 89.2\\% and 81.2\\% with checkpointing frequency up to per iteration.","authors":["Chenxuan Yao","Yuchong Hu","Feifan Liu","Zhengyu Liu","Lin Wang","Mingqi Li","Dan Feng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.03227v4","updated":"2025-12-24T01:13:17Z","published":"2025-01-06T18:59:26Z","title":"When Should Selfish Miners Double-Spend?","summary":"Conventional double-spending attack models ignore the revenue losses stemming from the orphan blocks. On the other hand, selfish mining literature usually ignores the chance of the attacker to double-spend at no-cost in each attack cycle. In this paper, we give a rigorous stochastic analysis of an attack where the goal of the adversary is to double-spend while mining selfishly. To do so, we first combine stubborn and selfish mining attacks, i.e., construct a strategy where the attacker acts stubborn until its private branch reaches a certain length and then switches to act selfish. We provide the optimal stubbornness for each parameter regime. Next, we provide the maximum stubbornness that is still more profitable than honest mining and argue a connection between the level of stubbornness and the $k$-confirmation rule. We show that, at each attack cycle, if the level of stubbornness is higher than $k$, the adversary gets a free shot at double-spending. At each cycle, for a given stubbornness level, we rigorously formulate how great the probability of double-spending is. We further modify the attack in the stubborn regime in order to conceal the attack and increase the double-spending probability.","authors":["Mustafa Doger","Sennur Ulukus"],"pdf_url":"","comment":null}],"Computation and Language":[{"id":"http://arxiv.org/abs/2512.21336v1","updated":"2025-12-24T18:59:51Z","published":"2025-12-24T18:59:51Z","title":"Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty","summary":"Masked Diffusion Models (MDMs) offer flexible, non-autoregressive generation, but this freedom introduces a challenge: final output quality is highly sensitive to the decoding order. We are the first to formalize this issue, attributing the variability in output quality to the cumulative predictive uncertainty along a generative path. To quantify this uncertainty, we introduce Denoising Entropy, a computable metric that serves as an internal signal for evaluating generative process. Leveraging this metric, we propose two algorithms designed to optimize the decoding path: a post-hoc selection method and a real-time guidance strategy. Experiments demonstrate that our entropy-guided methods significantly improve generation quality, consistently boosting accuracy on challenging reasoning, planning, and code benchmarks. Our work establishes Denoising Entropy as a principled tool for understanding and controlling generation, effectively turning the uncertainty in MDMs from a liability into a key advantage for discovering high-quality solutions.","authors":["Ziyu Chen","Xinbei Jiang","Peng Sun","Tao Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21332v1","updated":"2025-12-24T18:59:01Z","published":"2025-12-24T18:59:01Z","title":"C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling","summary":"We present C2LLM - Contrastive Code Large Language Models, a family of code embedding models in both 0.5B and 7B sizes. Building upon Qwen-2.5-Coder backbones, C2LLM adopts a Pooling by Multihead Attention (PMA) module for generating sequence embedding from token embeddings, effectively 1) utilizing the LLM's causal representations acquired during pretraining, while also 2) being able to aggregate information from all tokens in the sequence, breaking the information bottleneck in EOS-based sequence embeddings, and 3) supporting flexible adaptation of embedding dimension, serving as an alternative to MRL. Trained on three million publicly available data, C2LLM models set new records on MTEB-Code among models of similar sizes, with C2LLM-7B ranking 1st on the overall leaderboard.","authors":["Jin Qin","Zihan Liao","Ziyin Zhang","Hang Yu","Peng Di","Rui Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21329v1","updated":"2025-12-24T18:58:04Z","published":"2025-12-24T18:58:04Z","title":"Your Reasoning Benchmark May Not Test Reasoning: Revealing Perception Bottleneck in Abstract Reasoning Benchmarks","summary":"Reasoning benchmarks such as the Abstraction and Reasoning Corpus (ARC) and ARC-AGI are widely used to assess progress in artificial intelligence and are often interpreted as probes of core, so-called ``fluid'' reasoning abilities. Despite their apparent simplicity for humans, these tasks remain challenging for frontier vision-language models (VLMs), a gap commonly attributed to deficiencies in machine reasoning. We challenge this interpretation and hypothesize that the gap arises primarily from limitations in visual perception rather than from shortcomings in inductive reasoning.\n  To verify this hypothesis, we introduce a two-stage experimental pipeline that explicitly separates perception and reasoning. In the perception stage, each image is independently converted into a natural-language description, while in the reasoning stage a model induces and applies rules using these descriptions. This design prevents leakage of cross-image inductive signals and isolates reasoning from perception bottlenecks. Across three ARC-style datasets, Mini-ARC, ACRE, and Bongard-LOGO, we show that the perception capability is the dominant factor underlying the observed performance gap by comparing the two-stage pipeline with against standard end-to-end one-stage evaluation. Manual inspection of reasoning traces in the VLM outputs further reveals that approximately 80 percent of model failures stem from perception errors. Together, these results demonstrate that ARC-style benchmarks conflate perceptual and reasoning challenges and that observed performance gaps may overstate deficiencies in machine reasoning. Our findings underscore the need for evaluation protocols that disentangle perception from reasoning when assessing progress in machine intelligence.","authors":["Xinhe Wang","Jin Huang","Xingjian Zhang","Tianhao Wang","Jiaqi W. Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21326v1","updated":"2025-12-24T18:54:37Z","published":"2025-12-24T18:54:37Z","title":"Measuring all the noises of LLM Evals","summary":"Separating signal from noise is central to experimental science. Applying well-established statistical method effectively to LLM evals requires consideration of their unique noise characteristics. We clearly define and measure three types of noise: prediction noise from generating different answers on a given question, data noise from sampling questions, and their combined total noise following the law of total variance. To emphasize relative comparisons and gain statistical power, we propose the all-pairs paired method, which applies the paired analysis to all pairs of LLMs and measures all the noise components based on millions of question-level predictions across many evals and settings. These measurements revealed clear patterns. First, each eval exhibits a characteristic and highly predictable total noise level across all model pairs. Second, paired prediction noise typically exceeds paired data noise, which means reducing prediction noise by averaging can significantly increase statistical power. These findings enable practitioners to assess significance without custom testing and to detect much smaller effects in controlled experiments.","authors":["Sida Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21323v1","updated":"2025-12-24T18:46:55Z","published":"2025-12-24T18:46:55Z","title":"Parallel Token Prediction for Language Models","summary":"We propose Parallel Token Prediction (PTP), a universal framework for parallel sequence generation in language models. PTP jointly predicts multiple dependent tokens in a single transformer call by incorporating the sampling procedure into the model. This reduces the latency bottleneck of autoregressive decoding, and avoids the restrictive independence assumptions common in existing multi-token prediction methods. We prove that PTP can represent arbitrary autoregressive sequence distributions. PTP is trained either by distilling an existing model or through inverse autoregressive training without a teacher. Experimentally, we achieve state-of-the-art speculative decoding performance on Vicuna-7B by accepting over four tokens per step on Spec-Bench. The universality of our framework indicates that parallel generation of long sequences is feasible without loss of modeling power.","authors":["Felix Draxler","Justus Will","Farrin Marouf Sofian","Theofanis Karaletsos","Sameer Singh","Stephan Mandt"],"pdf_url":"","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2512.18859v2","updated":"2025-12-24T18:41:46Z","published":"2025-12-21T19:16:40Z","title":"Toward Human-Centered AI-Assisted Terminology Work","summary":"The rapid diffusion of generative artificial intelligence is transforming terminology work. While this technology promises gains in efficiency, its unstructured adoption risks weakening professional autonomy, amplifying bias, and eroding linguistic and conceptual diversity. This paper argues that a human-centered approach to artificial intelligence has become a necessity for terminology work. Building on research in artificial intelligence and translation studies, it proposes a human-centered framework that conceptualizes artificial intelligence as a means of amplifying the terminologist's capabilities, rather than replacing them. The framework is organized around three interrelated dimensions: the augmented terminologist, ethical AI, and human-centered design. Together, these dimensions emphasize the compatibility of high automation with strong human control, the central role of terminologists in bias mitigation, and the importance of designing AI tools and workflows around the needs, values, and well-being of the terminologist. The paper concludes by stressing that current choices in AI adoption will shape not only terminological practice, but also the preservation of accuracy, adequacy, and diversity in terminology and specialized knowledge.","authors":["Antonio San Martin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17083v2","updated":"2025-12-24T18:05:57Z","published":"2025-12-18T21:29:43Z","title":"When F1 Fails: Granularity-Aware Evaluation for Dialogue Topic Segmentation","summary":"Dialogue topic segmentation supports summarization, retrieval, memory management, and conversational continuity. Despite decades of work, evaluation practice remains dominated by strict boundary matching and F1-based metrics. Modern large language model (LLM) based conversational systems increasingly rely on segmentation to manage conversation history beyond fixed context windows. In such systems, unstructured context accumulation degrades efficiency and coherence.\n  This paper introduces an evaluation framework that reports boundary density and segment alignment diagnostics (purity and coverage) alongside window-tolerant F1 (W-F1). By separating boundary scoring from boundary selection, we evaluate segmentation quality across density regimes rather than at a single operating point. Cross-dataset evaluation shows that reported performance differences often reflect annotation granularity mismatch rather than boundary placement quality alone.\n  We evaluate structurally distinct segmentation strategies across eight dialogue datasets spanning task-oriented, open-domain, meeting-style, and synthetic interactions. Boundary-based metrics are strongly coupled to boundary density: threshold sweeps produce larger W-F1 changes than switching between methods. These findings support viewing topic segmentation as a granularity selection problem rather than prediction of a single correct boundary set. This motivates separating boundary scoring from boundary selection for analyzing and tuning segmentation under varying annotation granularities.","authors":["Michael H. Coen"],"pdf_url":"","comment":"32 pages, 4 figures. Evaluation and methodology study on dialogue topic segmentation"},{"id":"http://arxiv.org/abs/2512.21280v1","updated":"2025-12-24T16:59:04Z","published":"2025-12-24T16:59:04Z","title":"SMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance","summary":"The user of Engineering Manuals (EM) finds it difficult to read EM s because they are long, have a dense format which includes written documents, step by step procedures, and standard parameter lists for engineering equipment. Off the shelf transformers, especially compact ones, treat this material as a flat stream of tokens. This approach leads to confident but incorrect numeric answers and forces the models to memorize separate facts inefficiently. SMART (Structured Memory and Reasoning Transformer) offers a different and practical solution to the above problem. SMART structures its processing by using a hierarchical approach, and is based upon three main job categories (1) A syntax-aware Fact Extractor (Grammarian) Tree LSTM which extracts facts as subject relation object relations from EM sentences (2) A compact indexed memory MANN (Memory Augmented Neural Network) that indexes these Rational Subject Relation Objects as 384 dimensional vectors that are associated with the source of the information, and (3) A 6 layer Transformer that learns to fuse the previously retrieved facts into its generated response. The entire SMART model utilizes 45.51M parameters, which is 64% less than GPT-2 (124M) and 69% less than BERT (133M), and it achieves a 21.3% higher accuracy than GPT-2, indicating that SMART fits the data better with the least amount of processing requirements. SMART employs dual modes of inference an indexed fast path for known documents (sub-second answer times) and an indexed dynamic path assisted by RAGs for new uploads (FAISS Top 20 results with memory severed at 64 slots). In real world deployment, this framework leads to more well supported results with reduced hallucinations than comparable small transformer models.","authors":["Divij Dudeja","Mayukha Pal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21257v1","updated":"2025-12-24T16:06:20Z","published":"2025-12-24T16:06:20Z","title":"ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling","summary":"Industrial recommender systems face two fundamental limitations under the log-driven paradigm: (1) knowledge poverty in ID-based item representations that causes brittle interest modeling under data sparsity, and (2) systemic blindness to beyond-log user interests that constrains model performance within platform boundaries. These limitations stem from an over-reliance on shallow interaction statistics and close-looped feedback while neglecting the rich world knowledge about product semantics and cross-domain behavioral patterns that Large Language Models have learned from vast corpora.\n  To address these challenges, we introduce ReaSeq, a reasoning-enhanced framework that leverages world knowledge in Large Language Models to address both limitations through explicit and implicit reasoning. Specifically, ReaSeq employs explicit Chain-of-Thought reasoning via multi-agent collaboration to distill structured product knowledge into semantically enriched item representations, and latent reasoning via Diffusion Large Language Models to infer plausible beyond-log behaviors. Deployed on Taobao's ranking system serving hundreds of millions of users, ReaSeq achieves substantial gains: >6.0% in IPV and CTR, >2.9% in Orders, and >2.5% in GMV, validating the effectiveness of world-knowledge-enhanced reasoning over purely log-driven approaches.","authors":["Chuan Wang","Gaoming Yang","Han Wu","Jiakai Tang","Jiahao Yu","Jian Wu","Jianwu Hu","Junjun Zheng","Shuwen Xiao","Yeqiu Yang","Yuning Jiang","Ahjol Nurlanbek","Binbin Cao","Bo Zheng","Fangmei Zhu","Gaoming Zhou","Huimin Yi","Huiping Chu","Jin Huang","Jinzhe Shan","Kenan Cui","Longbin Li","Silu Zhou","Wen Chen","Xia Ming","Xiang Gao","Xin Yao","Xingyu Wen","Yan Zhang","Yiwen Hu","Yulin Wang","Ziheng Bao","Zongyuan Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20491v2","updated":"2025-12-24T15:52:31Z","published":"2025-12-23T16:32:27Z","title":"Step-DeepResearch Technical Report","summary":"As LLMs shift toward autonomous agents, Deep Research has emerged as a pivotal metric. However, existing academic benchmarks like BrowseComp often fail to meet real-world demands for open-ended research, which requires robust skills in intent recognition, long-horizon decision-making, and cross-source verification. To address this, we introduce Step-DeepResearch, a cost-effective, end-to-end agent. We propose a Data Synthesis Strategy Based on Atomic Capabilities to reinforce planning and report writing, combined with a progressive training path from agentic mid-training to SFT and RL. Enhanced by a Checklist-style Judger, this approach significantly improves robustness. Furthermore, to bridge the evaluation gap in the Chinese domain, we establish ADR-Bench for realistic deep research scenarios. Experimental results show that Step-DeepResearch (32B) scores 61.4% on Scale AI Research Rubrics. On ADR-Bench, it significantly outperforms comparable models and rivals SOTA closed-source models like OpenAI and Gemini DeepResearch. These findings prove that refined training enables medium-sized models to achieve expert-level capabilities at industry-leading cost-efficiency.","authors":["Chen Hu","Haikuo Du","Heng Wang","Lin Lin","Mingrui Chen","Peng Liu","Ruihang Miao","Tianchi Yue","Wang You","Wei Ji","Wei Yuan","Wenjin Deng","Xiaojian Yuan","Xiaoyun Zhang","Xiangyu Liu","Xikai Liu","Yanming Xu","Yicheng Cao","Yifei Zhang","Yongyao Wang","Yubo Shu","Yurong Zhang","Yuxiang Zhang","Zheng Gong","Zhichao Chang","Binyan Li","Dan Ma","Furong Jia","Hongyuan Wang","Jiayu Liu","Jing Bai","Junlan Liu","Manjiao Liu","Na Wang","Qiuping Wu","Qinxin Du","Shiwei Li","Wen Sun","Yifeng Gong","Yonglin Chen","Yuling Zhao","Yuxuan Lin","Ziqi Ren","Zixuan Wang","Aihu Zhang","Brian Li","Buyun Ma","Kang An","Li Xie","Mingliang Li","Pan Li","Shidong Yang","Xi Chen","Xiaojia Liu","Yuchu Luo","Yuan Song","YuanHao Ding","Yuanwei Liang","Zexi Li","Zhaoning Zhang","Zixin Zhang","Binxing Jiao","Daxin Jiang","Jiansheng Chen","Jing Li","Xiangyu Zhang","Yibo Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.00675v3","updated":"2025-12-24T15:24:04Z","published":"2025-05-01T17:31:33Z","title":"Rethinking Memory in LLM based Agents: Representations, Operations, and Emerging Topics","summary":"Memory is fundamental to large language model (LLM)-based agents, but existing surveys emphasize application-level use (e.g., personalized dialogue), while overlooking the atomic operations governing memory dynamics. This work categorizes memory into parametric (implicit in model weights) and contextual (explicit external data, structured/unstructured) forms, and defines six core operations: Consolidation, Updating, Indexing, Forgetting, Retrieval, and Condensation. Mapping these dimensions reveals four key research topics: long-term, long-context, parametric modification, and multi-source memory. The taxonomy provides a structured view of memory-related research, benchmarks, and tools, clarifying functional interactions in LLM-based agents and guiding future advancements. The datasets, papers, and tools are publicly available at https://github.com/Elvin-Yiming-Du/Survey_Memory_in_AI.","authors":["Yiming Du","Wenyu Huang","Danna Zheng","Zhaowei Wang","Sebastien Montella","Mirella Lapata","Kam-Fai Wong","Jeff Z. Pan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.21010v2","updated":"2025-12-24T14:52:45Z","published":"2025-08-28T17:10:53Z","title":"ChainReaction: Causal Chain-Guided Reasoning for Modular and Explainable Causal-Why Video Question Answering","summary":"Existing Causal-Why Video Question Answering (VideoQA) models often struggle with higher-order reasoning, relying on opaque, monolithic pipelines that entangle video understanding, causal inference, and answer generation. These black-box approaches offer limited interpretability and tend to depend on shallow heuristics. We propose a novel, modular paradigm that explicitly decouples causal reasoning from answer generation, introducing natural language causal chains as interpretable intermediate representations. Inspired by human cognitive models, these structured cause-effect sequences bridge low-level video content with high-level causal reasoning, enabling transparent and logically coherent inference. Our two-stage architecture comprises a Causal Chain Extractor (CCE) that generates causal chains from video-question pairs, and a Causal Chain-Driven Answerer (CCDA) that derives answers grounded in these chains. To address the lack of annotated reasoning traces, we introduce a scalable method for generating accurate causal chains from existing datasets. We construct human verified causal chains for 46K samples. We also propose CauCo, a new evaluation metric for causality-oriented captioning. Experiments on three large-scale benchmarks demonstrate that our approach not only outperforms state-of-the-art models, but also yields substantial gains in explainability, user trust, and generalization -- positioning the CCE as a reusable causal reasoning engine across diverse domains. Project page: https://paritoshparmar.github.io/chainreaction/","authors":["Paritosh Parmar","Eric Peh","Basura Fernando"],"pdf_url":"","comment":"Project page: https://paritoshparmar.github.io/chainreaction/"},{"id":"http://arxiv.org/abs/2512.16378v2","updated":"2025-12-24T14:39:27Z","published":"2025-12-18T10:21:14Z","title":"Hearing to Translate: The Effectiveness of Speech Modality Integration into LLMs","summary":"As Large Language Models (LLMs) expand beyond text, integrating speech as a native modality has given rise to SpeechLLMs, which aim to translate spoken language directly, thereby bypassing traditional transcription-based pipelines. Whether this integration improves speech-to-text translation quality over established cascaded architectures, however, remains an open question. We present Hearing to Translate, the first comprehensive test suite rigorously benchmarking 5 state-of-the-art SpeechLLMs against 16 strong direct and cascade systems that couple leading speech foundation models (SFM), with multilingual LLMs. Our analysis spans 16 benchmarks, 13 language pairs, and 9 challenging conditions, including disfluent, noisy, and long-form speech. Across this extensive evaluation, we find that cascaded systems remain the most reliable overall, while current SpeechLLMs only match cascades in selected settings and SFMs lag behind both, highlighting that integrating an LLM, either within the model or in a pipeline, is essential for high-quality speech translation.","authors":["Sara Papi","Javier Garcia Gilabert","Zachary Hopton","Vilém Zouhar","Carlos Escolano","Gerard I. Gállego","Jorge Iranzo-Sánchez","Ahrii Kim","Dominik Macháček","Patricia Schmidtova","Maike Züfle"],"pdf_url":"","comment":"Project available at https://github.com/sarapapi/hearing2translate"},{"id":"http://arxiv.org/abs/2512.21204v1","updated":"2025-12-24T14:33:16Z","published":"2025-12-24T14:33:16Z","title":"SpidR-Adapt: A Universal Speech Representation Model for Few-Shot Adaptation","summary":"Human infants, with only a few hundred hours of speech exposure, acquire basic units of new languages, highlighting a striking efficiency gap compared to the data-hungry self-supervised speech models. To address this gap, this paper introduces SpidR-Adapt for rapid adaptation to new languages using minimal unlabeled data. We cast such low-resource speech representation learning as a meta-learning problem and construct a multi-task adaptive pre-training (MAdaPT) protocol which formulates the adaptation process as a bi-level optimization framework. To enable scalable meta-training under this framework, we propose a novel heuristic solution, first-order bi-level optimization (FOBLO), avoiding heavy computation costs. Finally, we stabilize meta-training by using a robust initialization through interleaved supervision which alternates self-supervised and supervised objectives. Empirically, SpidR-Adapt achieves rapid gains in phonemic discriminability (ABX) and spoken language modeling (sWUGGY, sBLIMP, tSC), improving over in-domain language models after training on less than 1h of target-language audio, over $100\\times$ more data-efficient than standard training. These findings highlight a practical, architecture-agnostic path toward biologically inspired, data-efficient representations. We open-source the training code and model checkpoints at https://github.com/facebookresearch/spidr-adapt.","authors":["Mahi Luthra","Jiayi Shen","Maxime Poli","Angelo Ortiz","Yosuke Higuchi","Youssef Benchekroun","Martin Gleize","Charles-Eric Saint-James","Dongyan Lin","Phillip Rust","Angel Villar","Surya Parimi","Vanessa Stark","Rashel Moritz","Juan Pino","Yann LeCun","Emmanuel Dupoux"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.11098v2","updated":"2025-12-24T13:27:20Z","published":"2025-10-13T07:45:52Z","title":"VCB Bench: An Evaluation Benchmark for Audio-Grounded Large Language Model Conversational Agents","summary":"Recent advances in large audio language models (LALMs) have greatly enhanced multimodal conversational systems. However, existing benchmarks remain limited -- they are mainly English-centric, rely on synthetic speech, and lack comprehensive, discriminative evaluation across multiple dimensions. To address these gaps, we present Voice Chat Bot Bench (VCB Bench) -- a high-quality Chinese benchmark built entirely on real human speech. VCB Bench evaluates LALMs from three complementary perspectives: instruction following (including speech-level control beyond text commands), knowledge understanding (general knowledge, reasoning, and daily dialogue), and robustness (stability under perturbations in content, environment, and speaker traits). Experiments on representative LALMs reveal notable performance gaps and highlight future directions for improvement. VCB Bench provides a reproducible and fine-grained evaluation framework, offering standardized methodology and practical insights for advancing Chinese voice conversational models.","authors":["Jiliang Hu","Wenfu Wang","Zuchao Li","Chenxing Li","Yiyang Zhao","Hanzhao Li","Liqiang Zhang","Meng Yu","Dong Yu"],"pdf_url":"","comment":"20 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.12491v2","updated":"2025-12-24T13:21:40Z","published":"2025-03-16T12:49:44Z","title":"CAKE: Cascading and Adaptive KV Cache Eviction with Layer Preferences","summary":"Large language models (LLMs) excel at processing long sequences, boosting demand for key-value (KV) caching. While recent efforts to evict KV cache have alleviated the inference burden, they often fail to allocate resources rationally across layers with different attention patterns. In this paper, we introduce Cascading and Adaptive KV cache Eviction (CAKE), a novel approach that frames KV cache eviction as a \"cake-slicing problem.\" CAKE assesses layer-specific preferences by considering attention dynamics in both spatial and temporal dimensions, allocates rational cache size for layers accordingly, and manages memory constraints in a cascading manner. This approach enables a global view of cache allocation, adaptively distributing resources across diverse attention mechanisms while maintaining memory budgets. CAKE also employs a new eviction indicator that considers the shifting importance of tokens over time, addressing limitations in existing methods that overlook temporal dynamics. Comprehensive experiments on LongBench and NeedleBench show that CAKE maintains model performance with only 3.2% of the KV cache and consistently outperforms current baselines across various models and memory constraints, particularly in low-memory settings. Additionally, CAKE achieves over 10x speedup in decoding latency compared to full cache when processing contexts of 128K tokens with FlashAttention-2. Our code is available at https://github.com/antgroup/cakekv.","authors":["Ziran Qin","Yuchen Cao","Mingbao Lin","Wen Hu","Shixuan Fan","Ke Cheng","Weiyao Lin","Jianguo Li"],"pdf_url":"","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2512.20481v2","updated":"2025-12-24T12:51:11Z","published":"2025-12-23T16:16:42Z","title":"Coherence in the brain unfolds across separable temporal regimes","summary":"Coherence in language requires the brain to satisfy two competing temporal demands: gradual accumulation of meaning across extended context and rapid reconfiguration of representations at event boundaries. Despite their centrality to language and thought, how these processes are implemented in the human brain during naturalistic listening remains unclear. Here, we tested whether these two processes can be captured by annotation-free drift and shift signals and whether their neural expression dissociates across large-scale cortical systems. These signals were derived from a large language model (LLM) and formalized contextual drift and event shifts directly from the narrative input. To enable high-precision voxelwise encoding models with stable parameter estimates, we densely sampled one healthy adult across more than 7 hours of listening to thirteen crime stories while collecting ultra high-field (7T) BOLD data. We then modeled the feature-informed hemodynamic response using a regularized encoding framework validated on independent stories. Drift predictions were prevalent in default-mode network hubs, whereas shift predictions were evident bilaterally in the primary auditory cortex and language association cortex. Furthermore, activity in default-mode and parietal networks was best explained by a signal capturing how meaning accumulates and gradually fades over the course of the narrative. Together, these findings show that coherence during language comprehension is implemented through dissociable neural regimes of slow contextual integration and rapid event-driven reconfiguration, offering a mechanistic entry point for understanding disturbances of language coherence in psychiatric disorders.","authors":["Davide Stauba","Finn Rabe","Akhil Misra","Yves Pauli","Roya Hüppi","Ni Yang","Nils Lang","Lars Michels","Victoria Edkins","Sascha Frühholz","Iris Sommer","Wolfram Hinzen","Philipp Homan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21120v1","updated":"2025-12-24T11:39:00Z","published":"2025-12-24T11:39:00Z","title":"ClarifyMT-Bench: Benchmarking and Improving Multi-Turn Clarification for Conversational Large Language Models","summary":"Large language models (LLMs) are increasingly deployed as conversational assistants in open-domain, multi-turn settings, where users often provide incomplete or ambiguous information. However, existing LLM-focused clarification benchmarks primarily assume single-turn interactions or cooperative users, limiting their ability to evaluate clarification behavior in realistic settings. We introduce \\textbf{ClarifyMT-Bench}, a benchmark for multi-turn clarification grounded in a five-dimensional ambiguity taxonomy and a set of six behaviorally diverse simulated user personas. Through a hybrid LLM-human pipeline, we construct 6,120 multi-turn dialogues capturing diverse ambiguity sources and interaction patterns. Evaluating ten representative LLMs uncovers a consistent under-clarification bias: LLMs tend to answer prematurely, and performance degrades as dialogue depth increases. To mitigate this, we propose \\textbf{ClarifyAgent}, an agentic approach that decomposes clarification into perception, forecasting, tracking, and planning, substantially improving robustness across ambiguity conditions. ClarifyMT-Bench establishes a reproducible foundation for studying when LLMs should ask, when they should answer, and how to navigate ambiguity in real-world human-LLM interactions.","authors":["Sichun Luo","Yi Huang","Mukai Li","Shichang Meng","Fengyuan Liu","Zefa Hu","Junlan Feng","Qi Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.00162v2","updated":"2025-12-24T11:32:24Z","published":"2024-08-30T16:14:35Z","title":"Sequence to Sequence Reward Modeling: Improving RLHF by Language Feedback","summary":"Aligning the behavior of Large language models (LLMs) with human intentions and values remains a critical challenge. Reinforcement learning from human feedback (RLHF) aligns LLMs by training a reward model (RM) on human preferences and fine-tuning the LLMs to maximize RM feedback. Despite its effectiveness and popularity, RLHF is prone to biased local optimization. It means RM fails to provide feedback that accurately aligns with human preference, causing LLMs to explore unexpected generalizations, and failing to achieve alignment objectives. To mitigate this issue, we propose a novel \\textit{sequence-to-sequence (seq2seq) reward modeling} method. Its key insight is that learning from language feedback rather than scalar feedback improves RLHF without additional annotations. We replaced the reward modeling target from binary maximum likelihood estimation (MLE) with sequence MLE. This method enables richer and fine-grained language feedback without additional annotations, models, or training stages. Our experiments demonstrated its effectiveness, specifically, reducing the refusal-to-response paradigm in single-turn safety dialogues and the long-response bias in text summarization tasks. We provide further analysis that seq2seq RM improves RLHF performance across 2B and 7B LLMs on 3 NLP tasks, achieving an average win rate of 76.9\\%. We further show that seq2seq RM can still improve the performance of RLHF under out-of-distribution prompts.","authors":["Jiayi Zhou","Jiaming Ji","Juntao Dai","Dong Li","Yaodong Yang"],"pdf_url":"","comment":"7 pages"},{"id":"http://arxiv.org/abs/2512.21110v1","updated":"2025-12-24T11:15:57Z","published":"2025-12-24T11:15:57Z","title":"Beyond Context: Large Language Models Failure to Grasp Users Intent","summary":"Current Large Language Models (LLMs) safety approaches focus on explicitly harmful content while overlooking a critical vulnerability: the inability to understand context and recognize user intent. This creates exploitable vulnerabilities that malicious users can systematically leverage to circumvent safety mechanisms. We empirically evaluate multiple state-of-the-art LLMs, including ChatGPT, Claude, Gemini, and DeepSeek. Our analysis demonstrates the circumvention of reliable safety mechanisms through emotional framing, progressive revelation, and academic justification techniques. Notably, reasoning-enabled configurations amplified rather than mitigated the effectiveness of exploitation, increasing factual precision while failing to interrogate the underlying intent. The exception was Claude Opus 4.1, which prioritized intent detection over information provision in some use cases. This pattern reveals that current architectural designs create systematic vulnerabilities. These limitations require paradigmatic shifts toward contextual understanding and intent recognition as core safety capabilities rather than post-hoc protective mechanisms.","authors":["Ahmed M. Hussain","Salahuddin Salahuddin","Panos Papadimitratos"],"pdf_url":"","comment":"22 pages and 23 figures"},{"id":"http://arxiv.org/abs/2512.21107v1","updated":"2025-12-24T11:12:09Z","published":"2025-12-24T11:12:09Z","title":"Semi-Supervised Learning for Large Language Models Safety and Content Moderation","summary":"Safety for Large Language Models (LLMs) has been an ongoing research focus since their emergence and is even more relevant nowadays with the increasing capacity of those models. Currently, there are several guardrails in place for all public LLMs and multiple proposed datasets for training safety classifiers. However, training these safety classifiers relies on large quantities of labeled data, which can be problematic to acquire, prone to labeling errors, or often include synthetic data. To address these issues, we suggest a different approach: utilizing semi-supervised learning techniques, which leverage both labeled and unlabeled data, to improve the performance on the safety task. We analyze the improvements that these techniques can offer for both prompts given to Large Language Models and the responses to those requests. Moreover, since augmentation is the central part of semi-supervised algorithms, we demonstrate the importance of using task-specific augmentations, which significantly increase the performance when compared to general-purpose augmentation techniques.","authors":["Eduard Stefan Dinuta","Iustin Sirbu","Traian Rebedea"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21106v1","updated":"2025-12-24T11:10:28Z","published":"2025-12-24T11:10:28Z","title":"Semantic Refinement with LLMs for Graph Representations","summary":"Graph-structured data exhibit substantial heterogeneity in where their predictive signals originate: in some domains, node-level semantics dominate, while in others, structural patterns play a central role. This structure-semantics heterogeneity implies that no graph learning model with a fixed inductive bias can generalize optimally across diverse graph domains. However, most existing methods address this challenge from the model side by incrementally injecting new inductive biases, which remains fundamentally limited given the open-ended diversity of real-world graphs. In this work, we take a data-centric perspective and treat node semantics as a task-adaptive variable. We propose a Data-Adaptive Semantic Refinement framework DAS for graph representation learning, which couples a fixed graph neural network (GNN) and a large language model (LLM) in a closed feedback loop. The GNN provides implicit supervisory signals to guide the semantic refinement of LLM, and the refined semantics are fed back to update the same graph learner. We evaluate our approach on both text-rich and text-free graphs. Results show consistent improvements on structure-dominated graphs while remaining competitive on semantics-rich graphs, demonstrating the effectiveness of data-centric semantic adaptation under structure-semantics heterogeneity.","authors":["Safal Thapaliya","Zehong Wang","Jiazheng Li","Ziming Li","Yanfang Ye","Chuxu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14368v2","updated":"2025-12-24T08:17:05Z","published":"2025-11-18T11:18:08Z","title":"O3SLM: Open Weight, Open Data, and Open Vocabulary Sketch-Language Model","summary":"While Large Vision Language Models (LVLMs) are increasingly deployed in real-world applications, their ability to interpret abstract visual inputs remains limited. Specifically, they struggle to comprehend hand-drawn sketches, a modality that offers an intuitive means of expressing concepts that are difficult to describe textually. We identify the primary bottleneck as the absence of a large-scale dataset that jointly models sketches, photorealistic images, and corresponding natural language instructions. To address this, we present two key contributions: (1) a new, large-scale dataset of image-sketch-instruction triplets designed to facilitate both pretraining and instruction tuning, and (2) O3SLM, an LVLM trained on this dataset. Comprehensive evaluations on multiple sketch-based tasks: (a) object localization, (b) counting, (c) image retrieval i.e., (SBIR and fine-grained SBIR), and (d) visual question answering (VQA); while incorporating the three existing sketch datasets, namely QuickDraw!, Sketchy, and Tu Berlin, along with our generated SketchVCL dataset, show that O3SLM achieves state-of-the-art performance, substantially outperforming existing LVLMs in sketch comprehension and reasoning.","authors":["Rishi Gupta","Mukilan Karuppasamy","Shyam Marjit","Aditay Tripathi","Anirban Chakraborty"],"pdf_url":"","comment":"Accepted to AAAI 2026"},{"id":"http://arxiv.org/abs/2509.26226v2","updated":"2025-12-24T08:05:31Z","published":"2025-09-30T13:25:00Z","title":"Thinking-Free Policy Initialization Makes Distilled Reasoning Models More Effective and Efficient Reasoners","summary":"Reinforcement Learning with Verifiable Reward (RLVR) effectively solves complex tasks but demands extremely long context lengths during training, leading to substantial computational costs. While multi-stage training can partially mitigate this, starting with overly short contexts often causes irreversible performance degradation, ultimately failing to reduce overall training compute significantly. In this paper, we introduce **T**hinking-**F**ree **P**olicy **I**nitialization (**TFPI**), a simple yet effective adaptation to RLVR that bridges long Chain-of-Thought (CoT) distillation and standard RLVR. TFPI employs a simple *ThinkFree* operation, explicitly discarding the thinking content via a direct *</think>* append, to reduce token usage during inference. Training with *ThinkFree*-adapted inputs improves performance and lowers token consumption, even in the original slow-thinking mode. Extensive experiments across various benchmarks have shown that TFPI accelerates RL convergence, achieves a higher performance ceiling, and yields more token-efficient reasoning models without specialized rewards or complex training designs. With TFPI only, we train a 4B model to reach 89.0% accuracy on AIME24 and 65.5% on LiveCodeBench using less than 4K H20 hours.","authors":["Xin Xu","Cliveb AI","Kai Yang","Tianhao Chen","Yang Wang","Saiyong Yang","Can Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17129v2","updated":"2025-12-24T07:50:00Z","published":"2025-11-21T10:45:44Z","title":"Learning to Compress: Unlocking the Potential of Large Language Models for Text Representation","summary":"Text representation plays a critical role in tasks like clustering, retrieval, and other downstream applications. With the emergence of large language models (LLMs), there is increasing interest in harnessing their capabilities for this purpose. However, most of the LLMs are inherently causal and optimized for next-token prediction, making them suboptimal for producing holistic representations. To address this, recent studies introduced pretext tasks to adapt LLMs for text representation. Most of these tasks, however, rely on token-level prediction objectives, such as the masked next-token prediction (MNTP) used in LLM2Vec. In this work, we explore the untapped potential of context compression as a pretext task for unsupervised adaptation of LLMs. During compression pre-training, the model learns to generate compact memory tokens, which substitute the whole context for downstream sequence prediction. Experiments demonstrate that a well-designed compression objective can significantly enhance LLM-based text representations, outperforming models trained with token-level pretext tasks. Further improvements through contrastive learning produce a strong representation model (LLM2Comp) that outperforms contemporary LLM-based text encoders on a wide range of tasks while being more sample-efficient, requiring significantly less training data. Code is available at https://github.com/longtaizi13579/LLM2Comp.","authors":["Yeqin Zhang","Yizheng Zhao","Chen Hu","Binxing Jiao","Daxin Jiang","Ruihang Miao","Cam-Tu Nguyen"],"pdf_url":"","comment":"Accepted by AAAI'26"},{"id":"http://arxiv.org/abs/2512.21017v1","updated":"2025-12-24T07:24:31Z","published":"2025-12-24T07:24:31Z","title":"Rethinking Supervised Fine-Tuning: Emphasizing Key Answer Tokens for Improved LLM Accuracy","summary":"With the rapid advancement of Large Language Models (LLMs), the Chain-of-Thought (CoT) component has become significant for complex reasoning tasks. However, in conventional Supervised Fine-Tuning (SFT), the model could allocate disproportionately more attention to CoT sequences with excessive length. This reduces focus on the much shorter but essential Key portion-the final answer, whose correctness directly determines task success and evaluation quality. To address this limitation, we propose SFTKey, a two-stage training scheme. In the first stage, conventional SFT is applied to ensure proper output format, while in the second stage, only the Key portion is fine-tuned to improve accuracy. Extensive experiments across multiple benchmarks and model families demonstrate that SFTKey achieves an average accuracy improvement exceeding 5\\% over conventional SFT, while preserving the ability to generate correct formats. Overall, this study advances LLM fine-tuning by explicitly balancing CoT learning with additional optimization on answer-relevant tokens.","authors":["Xiaofeng Shi","Qian Kou","Yuduo Li","Hua Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21002v1","updated":"2025-12-24T06:57:35Z","published":"2025-12-24T06:57:35Z","title":"Distilling the Essence: Efficient Reasoning Distillation via Sequence Truncation","summary":"Distilling the reasoning capabilities from a large language model (LLM) to a smaller student model often involves training on substantial amounts of reasoning data. However, distillation over lengthy sequences with prompt (P), chain-of-thought (CoT), and answer (A) segments makes the process computationally expensive. In this work, we investigate how the allocation of supervision across different segments (P, CoT, A) affects student performance. Our analysis shows that selective knowledge distillation over only the CoT tokens can be effective when the prompt and answer information is encompassed by it. Building on this insight, we establish a truncation protocol to quantify computation-quality tradeoffs as a function of sequence length. We observe that training on only the first $50\\%$ of tokens of every training sequence can retain, on average, $\\approx94\\%$ of full-sequence performance on math benchmarks while reducing training time, memory usage, and FLOPs by about $50\\%$ each. These findings suggest that reasoning distillation benefits from prioritizing early reasoning tokens and provides a simple lever for computation-quality tradeoffs. Codes are available at https://github.com/weiruichen01/distilling-the-essence.","authors":["Wei-Rui Chen","Vignesh Kothapalli","Ata Fatahibaarzi","Hejian Sang","Shao Tang","Qingquan Song","Zhipeng Wang","Muhammad Abdul-Mageed"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18748v2","updated":"2025-12-24T06:47:27Z","published":"2025-12-21T14:28:51Z","title":"Code2Doc: A Quality-First Curated Dataset for Code Documentation","summary":"The performance of automatic code documentation generation models depends critically on the quality of the training data used for supervision. However, most existing code documentation datasets are constructed through large scale scraping of public repositories with limited quality control. As a result, they often contain noisy documentation, extensive duplication, and increasing contamination from AI generated content. These issues weaken the supervision signal available to learning-based models and complicate evaluation.\n  We introduce Code2Doc, a quality-first curated dataset for function-level code documentation generation. Code2Doc consists of 13,358 high-quality function-documentation pairs extracted from widely used open-source repositories spanning five programming languages: Python, Java, TypeScript, JavaScript, and C++. The dataset is constructed using a four-stage curation pipeline that enforces documentation completeness and clarity, filters functions based on structural and complexity criteria, removes exact and near-duplicate code, and identifies documentation likely to be AI generated. Starting from 52,069 extracted candidates, only 25.6% satisfy all quality constraints.\n  We provide a detailed analysis of the resulting dataset, which achieves a mean documentation quality score of 6.93 out of 10. Overall, 86.9% of samples contain explicit type annotations, and only 2.9% are flagged as potentially AI generated. Baseline experiments show that fine-tuning a large language model on Code2Doc yields relative improvements of 29.47% in BLEU and 24.04% in ROUGE-L over zero shot performance, despite the modest dataset size. We release both the dataset and the full curation pipeline to support reproducible research on automatic code documentation generation.","authors":["Recep Kaan Karaman","Meftun Akarsu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20983v1","updated":"2025-12-24T06:17:21Z","published":"2025-12-24T06:17:21Z","title":"Automatic Replication of LLM Mistakes in Medical Conversations","summary":"Large language models (LLMs) are increasingly evaluated in clinical settings using multi-dimensional rubrics which quantify reasoning quality, safety, and patient-centeredness. Yet, replicating specific mistakes in other LLM models is not straightforward and often requires manual effort. We introduce MedMistake, an automatic pipeline that extracts mistakes LLMs make in patient-doctor conversations and converts them into a benchmark of single-shot QA pairs. Our pipeline (1) creates complex, conversational data between an LLM patient and LLM doctor, (2) runs an evaluation with a committee of 2 LLM judges across a variety of dimensions and (3) creates simplified single-shot QA scenarios from those mistakes. We release MedMistake-All, a dataset of 3,390 single-shot QA pairs where GPT-5 and Gemini 2.5 Pro are currently failing to answer correctly, as judged by two LLM judges. We used medical experts to validate a subset of 211/3390 questions (MedMistake-Bench), which we used to run a final evaluation of 12 frontier LLMs: Claude Opus 4.5, Claude Sonnet 4.5, DeepSeek-Chat, Gemini 2.5 Pro, Gemini 3 Pro, GPT-4o, GPT-5, GPT-5.1, GPT-5.2, Grok 4, Grok 4.1, Mistral Large. We found that GPT models, Claude and Grok obtained the best performance on MedMistake-Bench. We release both the doctor-validated benchmark (MedMistake-Bench), as well as the full dataset (MedMistake-All) at https://huggingface.co/datasets/TheLumos/MedicalMistakeBenchmark.","authors":["Oleksii Proniakin","Diego Fajardo","Ruslan Nazarenko","Razvan Marinescu"],"pdf_url":"","comment":"48 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/1909.03716v3","updated":"2025-12-24T06:10:10Z","published":"2019-09-09T09:26:42Z","title":"Improving Neural Question Generation using World Knowledge","summary":"In this paper, we propose a method for incorporating world knowledge (linked entities and fine-grained entity types) into a neural question generation model. This world knowledge helps to encode additional information related to the entities present in the passage required to generate human-like questions. We evaluate our models on both SQuAD and MS MARCO to demonstrate the usefulness of the world knowledge features. The proposed world knowledge enriched question generation model is able to outperform the vanilla neural question generation model by 1.37 and 1.59 absolute BLEU 4 score on SQuAD and MS MARCO test dataset respectively.","authors":["Deepak Gupta","Kaheer Suleman","Mahmoud Adada","Andrew McNamara","Justin Harris"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20954v1","updated":"2025-12-24T05:25:17Z","published":"2025-12-24T05:25:17Z","title":"Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models","summary":"Chain-of-Thought (CoT) prompting has significantly advanced task-solving capabilities in natural language processing with large language models. Unlike standard prompting, CoT encourages the model to generate intermediate reasoning steps, non-answer tokens, that help guide the model toward more accurate final outputs. These intermediate steps enable more complex reasoning processes such as error correction, memory management, future planning, and self-reflection. However, applying CoT to non-natural language domains, such as protein and RNA language models, is not yet possible, primarily due to the limited expressiveness of their token spaces (e.g., amino acid tokens). In this work, we propose and define the concept of language expressiveness: the ability of a given language, using its tokens and grammar, to encode information. We show that the limited expressiveness of protein language severely restricts the applicability of CoT-style reasoning. To overcome this, we introduce reflection pretraining, for the first time in a biological sequence model, which enables the model to engage in intermediate reasoning through the generation of auxiliary \"thinking tokens\" beyond simple answer tokens. Theoretically, we demonstrate that our augmented token set significantly enhances biological language expressiveness, thereby improving the overall reasoning capacity of the model. Experimentally, our pretraining approach teaches protein models to self-correct and leads to substantial performance gains compared to standard pretraining.","authors":["Xiang Zhang","Jiaqi Wei","Yuejin Yang","Zijie Qiu","Yuhan Chen","Zhiqiang Gao","Muhammad Abdul-Mageed","Laks V. S. Lakshmanan","Wanli Ouyang","Chenyu You","Siqi Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.04265v2","updated":"2025-12-24T05:18:52Z","published":"2025-10-05T16:14:03Z","title":"Don't Pass@k: A Bayesian Framework for Large Language Model Evaluation","summary":"Pass$@k$ is widely used to report performance for LLM reasoning, but it often yields unstable, misleading rankings, especially when the number of trials (samples) is limited and compute is constrained. We present a principled Bayesian evaluation framework that replaces Pass$@k$ and average accuracy over $N$ trials (avg$@N$) with posterior estimates of a model's underlying success probability and credible intervals, yielding stable rankings and a transparent decision rule for differences. Evaluation outcomes are modeled as categorical (not just 0/1) with a Dirichlet prior, giving closed-form expressions for the posterior mean and uncertainty of any weighted rubric and enabling the use of prior evidence when appropriate. Theoretically, under a uniform prior, the Bayesian posterior mean is order-equivalent to average accuracy (Pass$@1$), explaining its empirical robustness while adding principled uncertainty. Empirically, in simulations with known ground-truth success rates and on AIME'24/'25, HMMT'25, and BrUMO'25, the Bayesian/avg procedure achieves faster convergence and greater rank stability than Pass$@k$ and recent variants, enabling reliable comparisons at far smaller sample counts. The framework clarifies when observed gaps are statistically meaningful (non-overlapping credible intervals) versus noise, and it naturally extends to graded, rubric-based evaluations. Together, these results recommend replacing Pass$@k$ for LLM evaluation and ranking with a posterior-based, compute-efficient protocol that unifies binary and non-binary evaluation while making uncertainty explicit. Code is available at https://github.com/mohsenhariri/scorio","authors":["Mohsen Hariri","Amirhossein Samandar","Michael Hinczewski","Vipin Chaudhary"],"pdf_url":"","comment":"Code and simulations: https://github.com/mohsenhariri/scorio"},{"id":"http://arxiv.org/abs/2512.20950v1","updated":"2025-12-24T05:14:40Z","published":"2025-12-24T05:14:40Z","title":"MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment","summary":"This paper presents our system for SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval. In an era where misinformation spreads rapidly, effective fact-checking is increasingly critical. We introduce TriAligner, a novel approach that leverages a dual-encoder architecture with contrastive learning and incorporates both native and English translations across different modalities. Our method effectively retrieves claims across multiple languages by learning the relative importance of different sources in alignment. To enhance robustness, we employ efficient data preprocessing and augmentation using large language models while incorporating hard negative sampling to improve representation learning. We evaluate our approach on monolingual and crosslingual benchmarks, demonstrating significant improvements in retrieval accuracy and fact-checking performance over baselines.","authors":["Mohammad Mahdi Abootorabi","Alireza Ghahramani Kure","Mohammadali Mohammadkhani","Sina Elahimanesh","Mohammad Ali Ali Panah"],"pdf_url":"","comment":"11 pages Published at the SemEval-2025 workshop"},{"id":"http://arxiv.org/abs/2512.20949v1","updated":"2025-12-24T05:10:19Z","published":"2025-12-24T05:10:19Z","title":"Neural Probe-Based Hallucination Detection for Large Language Models","summary":"Large language models(LLMs) excel at text generation and knowledge question-answering tasks, but they are prone to generating hallucinated content, severely limiting their application in high-risk domains. Current hallucination detection methods based on uncertainty estimation and external knowledge retrieval suffer from the limitation that they still produce erroneous content at high confidence levels and rely heavily on retrieval efficiency and knowledge coverage. In contrast, probe methods that leverage the model's hidden-layer states offer real-time and lightweight advantages. However, traditional linear probes struggle to capture nonlinear structures in deep semantic spaces.To overcome these limitations, we propose a neural network-based framework for token-level hallucination detection. By freezing language model parameters, we employ lightweight MLP probes to perform nonlinear modeling of high-level hidden states. A multi-objective joint loss function is designed to enhance detection stability and semantic disambiguity. Additionally, we establish a layer position-probe performance response model, using Bayesian optimization to automatically search for optimal probe insertion layers and achieve superior training results.Experimental results on LongFact, HealthBench, and TriviaQA demonstrate that MLP probes significantly outperform state-of-the-art methods in accuracy, recall, and detection capability under low false-positive conditions.","authors":["Shize Liang","Hongzhi Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20948v1","updated":"2025-12-24T05:07:07Z","published":"2025-12-24T05:07:07Z","title":"Foundation Model-based Evaluation of Neuropsychiatric Disorders: A Lifespan-Inclusive, Multi-Modal, and Multi-Lingual Study","summary":"Neuropsychiatric disorders, such as Alzheimer's disease (AD), depression, and autism spectrum disorder (ASD), are characterized by linguistic and acoustic abnormalities, offering potential biomarkers for early detection. Despite the promise of multi-modal approaches, challenges like multi-lingual generalization and the absence of a unified evaluation framework persist. To address these gaps, we propose FEND (Foundation model-based Evaluation of Neuropsychiatric Disorders), a comprehensive multi-modal framework integrating speech and text modalities for detecting AD, depression, and ASD across the lifespan. Leveraging 13 multi-lingual datasets spanning English, Chinese, Greek, French, and Dutch, we systematically evaluate multi-modal fusion performance. Our results show that multi-modal fusion excels in AD and depression detection but underperforms in ASD due to dataset heterogeneity. We also identify modality imbalance as a prevalent issue, where multi-modal fusion fails to surpass the best mono-modal models. Cross-corpus experiments reveal robust performance in task- and language-consistent scenarios but noticeable degradation in multi-lingual and task-heterogeneous settings. By providing extensive benchmarks and a detailed analysis of performance-influencing factors, FEND advances the field of automated, lifespan-inclusive, and multi-lingual neuropsychiatric disorder assessment. We encourage researchers to adopt the FEND framework for fair comparisons and reproducible research.","authors":["Zhongren Dong","Haotian Guo","Weixiang Xu","Huan Zhao","Zixing Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20934v1","updated":"2025-12-24T04:30:21Z","published":"2025-12-24T04:30:21Z","title":"Transductive Visual Programming: Evolving Tool Libraries from Experience for Spatial Reasoning","summary":"Spatial reasoning in 3D scenes requires precise geometric calculations that challenge vision-language models. Visual programming addresses this by decomposing problems into steps calling specialized tools, yet existing methods rely on either fixed toolsets or speculative tool induction before solving problems, resulting in suboptimal programs and poor utilization of induced tools. We present Transductive Visual Programming (TVP), a novel framework that builds new tools from its own experience rather than speculation. TVP first solves problems using basic tools while accumulating experiential solutions into an Example Library, then abstracts recurring patterns from these programs into reusable higher-level tools for an evolving Tool Library. This allows TVP to tackle new problems with increasingly powerful tools learned from experience. On Omni3D-Bench, TVP achieves state-of-the-art performance, outperforming GPT-4o by 22% and the previous best visual programming system by 11%. Our transductively learned tools are used 5x more frequently as core program dependency than inductively created ones, demonstrating more effective tool discovery and reuse. The evolved tools also show strong generalization to unseen spatial tasks, achieving superior performance on benchmarks from SpatialScore-Hard collection without any testset-specific modification. Our work establishes experience-driven transductive tool creation as a powerful paradigm for building self-evolving visual programming agents that effectively tackle challenging spatial reasoning tasks. We release our code at https://transductive-visualprogram.github.io/.","authors":["Shengguang Wu","Xiaohan Wang","Yuhui Zhang","Hao Zhu","Serena Yeung-Levy"],"pdf_url":"","comment":"Project Website: https://transductive-visualprogram.github.io/"},{"id":"http://arxiv.org/abs/2512.20929v1","updated":"2025-12-24T04:19:20Z","published":"2025-12-24T04:19:20Z","title":"Decoding Predictive Inference in Visual Language Processing via Spatiotemporal Neural Coherence","summary":"Human language processing relies on the brain's capacity for predictive inference. We present a machine learning framework for decoding neural (EEG) responses to dynamic visual language stimuli in Deaf signers. Using coherence between neural signals and optical flow-derived motion features, we construct spatiotemporal representations of predictive neural dynamics. Through entropy-based feature selection, we identify frequency-specific neural signatures that differentiate interpretable linguistic input from linguistically disrupted (time-reversed) stimuli. Our results reveal distributed left-hemispheric and frontal low-frequency coherence as key features in language comprehension, with experience-dependent neural signatures correlating with age. This work demonstrates a novel multimodal approach for probing experience-driven generative models of perception in the brain.","authors":["Sean C. Borneman","Julia Krebs","Ronnie B. Wilbur","Evie A. Malaia"],"pdf_url":"","comment":"39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Foundation Models for the Brain and Body"},{"id":"http://arxiv.org/abs/2512.15745v2","updated":"2025-12-24T03:46:46Z","published":"2025-12-10T09:26:18Z","title":"LLaDA2.0: Scaling Up Diffusion Language Models to 100B","summary":"This paper presents LLaDA2.0 -- a tuple of discrete diffusion large language models (dLLM) scaling up to 100B total parameters through systematic conversion from auto-regressive (AR) models -- establishing a new paradigm for frontier-scale deployment. Instead of costly training from scratch, LLaDA2.0 upholds knowledge inheritance, progressive adaption and efficiency-aware design principle, and seamless converts a pre-trained AR model into dLLM with a novel 3-phase block-level WSD based training scheme: progressive increasing block-size in block diffusion (warm-up), large-scale full-sequence diffusion (stable) and reverting back to compact-size block diffusion (decay). Along with post-training alignment with SFT and DPO, we obtain LLaDA2.0-mini (16B) and LLaDA2.0-flash (100B), two instruction-tuned Mixture-of-Experts (MoE) variants optimized for practical deployment. By preserving the advantages of parallel decoding, these models deliver superior performance and efficiency at the frontier scale. Both models were open-sourced.","authors":["Tiwei Bie","Maosong Cao","Kun Chen","Lun Du","Mingliang Gong","Zhuochen Gong","Yanmei Gu","Jiaqi Hu","Zenan Huang","Zhenzhong Lan","Chengxi Li","Chongxuan Li","Jianguo Li","Zehuan Li","Huabin Liu","Lin Liu","Guoshan Lu","Xiaocheng Lu","Yuxin Ma","Jianfeng Tan","Lanning Wei","Ji-Rong Wen","Yipeng Xing","Xiaolu Zhang","Junbo Zhao","Da Zheng","Jun Zhou","Junlin Zhou","Zhanchao Zhou","Liwang Zhu","Yihong Zhuang"],"pdf_url":"","comment":"19 pages"},{"id":"http://arxiv.org/abs/2512.00617v2","updated":"2025-12-24T03:42:55Z","published":"2025-11-29T20:16:11Z","title":"ART: Adaptive Response Tuning Framework -- A Multi-Agent Tournament-Based Approach to LLM Response Optimization","summary":"Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation. However, single-model responses often exhibit inconsistencies, hallucinations, and varying quality across different query domains. This paper presents ART (Adaptive Response Tuning), a novel framework that employs tournament-style ELO ranking and multi-agent reasoning to systematically optimize LLM outputs. By enabling multiple LLM agents to compete, critique, and collaborate through structured tournament workflows, ART produces consensus responses that outperform individual model outputs. Our framework introduces configurable tournament parameters, dynamic agent selection, and multiple consensus fusion strategies. Experimental evaluations demonstrate significant improvements in response accuracy, coherence, and reliability compared to baseline single-model approaches. The ART framework provides a scalable, production-ready solution for applications requiring high-quality, vetted LLM responses, achieving an 8.4% improvement in overall quality metrics and R^2 values exceeding 0.96 in ELO rating convergence.","authors":["Omer Jauhar Khan"],"pdf_url":"","comment":"14 pages, 11 figures, 5 tables. IEEE conference-style paper with appendices"},{"id":"http://arxiv.org/abs/2512.20908v1","updated":"2025-12-24T03:19:05Z","published":"2025-12-24T03:19:05Z","title":"Where Did This Sentence Come From? Tracing Provenance in LLM Reasoning Distillation","summary":"Reasoning distillation has attracted increasing attention. It typically leverages a large teacher model to generate reasoning paths, which are then used to fine-tune a student model so that it mimics the teacher's behavior in training contexts. However, previous approaches have lacked a detailed analysis of the origins of the distilled model's capabilities. It remains unclear whether the student can maintain consistent behaviors with the teacher in novel test-time contexts, or whether it regresses to its original output patterns, raising concerns about the generalization of distillation models. To analyse this question, we introduce a cross-model Reasoning Distillation Provenance Tracing framework. For each action (e.g., a sentence) produced by the distilled model, we obtain the predictive probabilities assigned by the teacher, the original student, and the distilled model under the same context. By comparing these probabilities, we classify each action into different categories. By systematically disentangling the provenance of each action, we experimentally demonstrate that, in test-time contexts, the distilled model can indeed generate teacher-originated actions, which correlate with and plausibly explain observed performance on distilled model. Building on this analysis, we further propose a teacher-guided data selection method. Unlike prior approach that rely on heuristics, our method directly compares teacher-student divergences on the training data, providing a principled selection criterion. We validate the effectiveness of our approach across multiple representative teacher models and diverse student models. The results highlight the utility of our provenance-tracing framework and underscore its promise for reasoning distillation. We hope to share Reasoning Distillation Provenance Tracing and our insights into reasoning distillation with the community.","authors":["Kaiyuan Liu","Shaotian Yan","Rui Miao","Bing Wang","Chen Shen","Jun Zhang","Jieping Ye"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.14554v4","updated":"2025-12-24T02:46:01Z","published":"2025-12-16T16:28:32Z","title":"VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models","summary":"The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, the Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems. To facilitate access and reproducibility, we provide a public landing page for this benchmark at https://vilegalbench.cmcai.vn/.","authors":["Nguyen Tien Dong","Minh-Anh Nguyen","Thanh Dat Hoang","Nguyen Tuan Ngoc","Dao Xuan Quang Minh","Phan Phi Hai","Nguyen Thi Ngoc Anh","Dang Van Tu","Binh Vu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.12140v2","updated":"2025-12-24T02:25:32Z","published":"2025-08-16T19:25:06Z","title":"Exploring Efficiency Frontiers of Thinking Budget in Medical Reasoning: Scaling Laws between Computational Resources and Reasoning Quality","summary":"This study presents the first comprehensive evaluation of thinking budget mechanisms in medical reasoning tasks, revealing fundamental scaling laws between computational resources and reasoning quality. We systematically evaluated two major model families, Qwen3 (1.7B to 235B parameters) and DeepSeek-R1 (1.5B to 70B parameters), across 15 medical datasets spanning diverse specialties and difficulty levels. Through controlled experiments with thinking budgets ranging from zero to unlimited tokens, we establish logarithmic scaling relationships where accuracy improvements follow a predictable pattern with both thinking budget and model size. Our findings identify three distinct efficiency regimes: high-efficiency (0 to 256 tokens) suitable for real-time applications, balanced (256 to 512 tokens) offering optimal cost-performance tradeoffs for routine clinical support, and high-accuracy (above 512 tokens) justified only for critical diagnostic tasks. Notably, smaller models demonstrate disproportionately larger benefits from extended thinking, with 15 to 20% improvements compared to 5 to 10% for larger models, suggesting a complementary relationship where thinking budget provides greater relative benefits for capacity-constrained models. Domain-specific patterns emerge clearly, with neurology and gastroenterology requiring significantly deeper reasoning processes than cardiovascular or respiratory medicine. The consistency between Qwen3 native thinking budget API and our proposed truncation method for DeepSeek-R1 validates the generalizability of thinking budget concepts across architectures. These results establish thinking budget control as a critical mechanism for optimizing medical AI systems, enabling dynamic resource allocation aligned with clinical needs while maintaining the transparency essential for healthcare deployment.","authors":["Ziqian Bi","Lu Chen","Junhao Song","Hongying Luo","Enze Ge","Junmin Huang","Tianyang Wang","Keyu Chen","Chia Xin Liang","Zihan Wei","Huafeng Liu","Chunjie Tian","Jibin Guan","Joe Yeong","Yongzhi Xu","Peng Wang","Xinyuan Song","Junfeng Hao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21701v2","updated":"2025-12-24T01:52:42Z","published":"2025-11-16T06:08:41Z","title":"47B Mixture-of-Experts Beats 671B Dense Models on Chinese Medical Examinations","summary":"The rapid advancement of large language models(LLMs) has prompted significant interest in their potential applications in medical domains. This paper presents a comprehensive benchmark evaluation of 27 state-of-the-art LLMs on Chinese medical examination questions, encompassing seven medical specialties across two professional levels. We introduce a robust evaluation framework that assesses model performance on 2,800 carefully curated questions from cardiovascular, gastroenterology, hematology, infectious diseases, nephrology, neurology, and respiratory medicine domains. Our dataset distinguishes between attending physician and senior physician difficulty levels, providing nuanced insights into model capabilities across varying complexity. Our empirical analysis reveals substantial performance variations among models, with Mixtral-8x7B achieving the highest overall accuracy of 74.25%, followed by DeepSeek-R1-671B at 64.07%. Notably, we observe no consistent correlation between model size and performance, as evidenced by the strong performance of smaller mixture-of-experts architectures. The evaluation demonstrates significant performance gaps between medical specialties, with models generally performing better on cardiovascular and neurology questions compared to gastroenterology and nephrology domains. Furthermore, our analysis indicates minimal performance degradation between attending and senior physician levels for top-performing models, suggesting robust generalization capabilities. This benchmark provides critical insights for the deployment of LLMs in medical education and clinical decision support systems, highlighting both the promise and current limitations of these technologies in specialized medical contexts.","authors":["Chiung-Yi Tseng","Danyang Zhang","Tianyang Wang","Hongying Luo","Lu Chen","Junming Huang","Jibin Guan","Junfeng Hao","Junhao Song","Xinyuan Song","Ziqian Bi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20877v1","updated":"2025-12-24T01:36:50Z","published":"2025-12-24T01:36:50Z","title":"Architectural Trade-offs in Small Language Models Under Compute Constraints","summary":"We present a systematic empirical study of small language models under strict compute constraints, analyzing how architectural choices and training budget interact to determine performance. Starting from a linear next-token predictor, we progressively introduce nonlinearities, self-attention, and multi-layer transformer architectures, evaluating each on character-level modeling of Tiny Shakespeare and word-level modeling of Penn Treebank (PTB) and WikiText-2. We compare models using test negative log-likelihood (NLL), parameter count, and approximate training FLOPs to characterize accuracy-efficiency trade-offs. Our results show that attention-based models dominate MLPs in per-FLOP efficiency even at small scale, while increasing depth or context without sufficient optimization can degrade performance. We further examine rotary positional embeddings (RoPE), finding that architectural techniques successful in large language models do not necessarily transfer to small-model regimes.","authors":["Shivraj Singh Bhatti"],"pdf_url":"","comment":"15 pages, 11 images"},{"id":"http://arxiv.org/abs/2512.20136v2","updated":"2025-12-24T01:35:59Z","published":"2025-12-23T07:54:03Z","title":"M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation","summary":"Retrieval-Augmented Generation (RAG) has recently been extended to multimodal settings, connecting multimodal large language models (MLLMs) with vast corpora of external knowledge such as multimodal knowledge graphs (MMKGs). Despite their recent success, multimodal RAG in the audio-visual domain remains challenging due to 1) limited modality coverage and multi-hop connectivity of existing MMKGs, and 2) retrieval based solely on similarity in a shared multimodal embedding space, which fails to filter out off-topic or redundant knowledge. To address these limitations, we propose M$^3$KG-RAG, a Multi-hop Multimodal Knowledge Graph-enhanced RAG that retrieves query-aligned audio-visual knowledge from MMKGs, improving reasoning depth and answer faithfulness in MLLMs. Specifically, we devise a lightweight multi-agent pipeline to construct multi-hop MMKG (M$^3$KG), which contains context-enriched triplets of multimodal entities, enabling modality-wise retrieval based on input queries. Furthermore, we introduce GRASP (Grounded Retrieval And Selective Pruning), which ensures precise entity grounding to the query, evaluates answer-supporting relevance, and prunes redundant context to retain only knowledge essential for response generation. Extensive experiments across diverse multimodal benchmarks demonstrate that M$^3$KG-RAG significantly enhances MLLMs' multimodal reasoning and grounding over existing approaches.","authors":["Hyeongcheol Park","Jiyoung Seo","Jaewon Mun","Hogun Park","Wonmin Byeon","Sung June Kim","Hyeonsoo Im","JeungSub Lee","Sangpil Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.01907v5","updated":"2025-12-24T01:10:58Z","published":"2025-09-02T03:01:23Z","title":"RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events","summary":"Remote sensing is critical for disaster monitoring, yet existing datasets lack temporal image pairs and detailed textual annotations. While single-snapshot imagery dominates current resources, it fails to capture dynamic disaster impacts over time. To address this gap, we introduce the Remote Sensing Change Caption (RSCC) dataset, a large-scale benchmark comprising 62,351 pre-/post-disaster image pairs (spanning earthquakes, floods, wildfires, and more) paired with rich, human-like change captions. By bridging the temporal and semantic divide in remote sensing data, RSCC enables robust training and evaluation of vision-language models for disaster-aware bi-temporal understanding. Our results highlight RSCC's ability to facilitate detailed disaster-related analysis, paving the way for more accurate, interpretable, and scalable vision-language applications in remote sensing. Code and dataset are available at https://github.com/Bili-Sakura/RSCC.","authors":["Zhenyuan Chen","Chenxi Wang","Ningyu Zhang","Feng Zhang"],"pdf_url":"","comment":"Accepted by NeurIPS 2025 Dataset and Benchmark Track"},{"id":"http://arxiv.org/abs/2512.20856v1","updated":"2025-12-24T00:24:05Z","published":"2025-12-24T00:24:05Z","title":"NVIDIA Nemotron 3: Efficient and Open Intelligence","summary":"We introduce the Nemotron 3 family of models - Nano, Super, and Ultra. These models deliver strong agentic, reasoning, and conversational capabilities. The Nemotron 3 family uses a Mixture-of-Experts hybrid Mamba-Transformer architecture to provide best-in-class throughput and context lengths of up to 1M tokens. Super and Ultra models are trained with NVFP4 and incorporate LatentMoE, a novel approach that improves model quality. The two larger models also include MTP layers for faster text generation. All Nemotron 3 models are post-trained using multi-environment reinforcement learning enabling reasoning, multi-step tool use, and support granular reasoning budget control. Nano, the smallest model, outperforms comparable models in accuracy while remaining extremely cost-efficient for inference. Super is optimized for collaborative agents and high-volume workloads such as IT ticket automation. Ultra, the largest model, provides state-of-the-art accuracy and reasoning performance. Nano is released together with its technical report and this white paper, while Super and Ultra will follow in the coming months. We will openly release the model weights, pre- and post-training software, recipes, and all data for which we hold redistribution rights.","authors":[" NVIDIA"," :","Aaron Blakeman","Aaron Grattafiori","Aarti Basant","Abhibha Gupta","Abhinav Khattar","Adi Renduchintala","Aditya Vavre","Akanksha Shukla","Akhiad Bercovich","Aleksander Ficek","Aleksandr Shaposhnikov","Alex Kondratenko","Alexander Bukharin","Alexandre Milesi","Ali Taghibakhshi","Alisa Liu","Amelia Barton","Ameya Sunil Mahabaleshwarkar","Amir Klein","Amit Zuker","Amnon Geifman","Amy Shen","Anahita Bhiwandiwalla","Andrew Tao","Anjulie Agrusa","Ankur Verma","Ann Guan","Anubhav Mandarwal","Arham Mehta","Ashwath Aithal","Ashwin Poojary","Asif Ahamed","Asit Mishra","Asma Kuriparambil Thekkumpate","Ayush Dattagupta","Banghua Zhu","Bardiya Sadeghi","Barnaby Simkin","Ben Lanir","Benedikt Schifferer","Besmira Nushi","Bilal Kartal","Bita Darvish Rouhani","Boris Ginsburg","Brandon Norick","Brandon Soubasis","Branislav Kisacanin","Brian Yu","Bryan Catanzaro","Carlo del Mundo","Chantal Hwang","Charles Wang","Cheng-Ping Hsieh","Chenghao Zhang","Chenhan Yu","Chetan Mungekar","Chintan Patel","Chris Alexiuk","Christopher Parisien","Collin Neale","Cyril Meurillon","Damon Mosk-Aoyama","Dan Su","Dane Corneil","Daniel Afrimi","Daniel Lo","Daniel Rohrer","Daniel Serebrenik","Daria Gitman","Daria Levy","Darko Stosic","David Mosallanezhad","Deepak Narayanan","Dhruv Nathawani","Dima Rekesh","Dina Yared","Divyanshu Kakwani","Dong Ahn","Duncan Riach","Dusan Stosic","Edgar Minasyan","Edward Lin","Eileen Long","Eileen Peters Long","Elad Segal","Elena Lantz","Ellie Evans","Elliott Ning","Eric Chung","Eric Harper","Eric Tramel","Erick Galinkin","Erik Pounds","Evan Briones","Evelina Bakhturina","Evgeny Tsykunov","Faisal Ladhak","Fay Wang","Fei Jia","Felipe Soares","Feng Chen","Ferenc Galko","Frank Sun","Frankie Siino","Gal Hubara Agam","Ganesh Ajjanagadde","Gantavya Bhatt","Gargi Prasad","George Armstrong","Gerald Shen","Gorkem Batmaz","Grigor Nalbandyan","Haifeng Qian","Harsh Sharma","Hayley Ross","Helen Ngo","Herbert Hum","Herman Sahota","Hexin Wang","Himanshu Soni","Hiren Upadhyay","Huizi Mao","Huy C Nguyen","Huy Q Nguyen","Iain Cunningham","Ido Galil","Ido Shahaf","Igor Gitman","Ilya Loshchilov","Itamar Schen","Itay Levy","Ivan Moshkov","Izik Golan","Izzy Putterman","Jan Kautz","Jane Polak Scowcroft","Jared Casper","Jatin Mitra","Jeffrey Glick","Jenny Chen","Jesse Oliver","Jian Zhang","Jiaqi Zeng","Jie Lou","Jimmy Zhang","Jinhang Choi","Jining Huang","Joey Conway","Joey Guman","John Kamalu","Johnny Greco","Jonathan Cohen","Joseph Jennings","Joyjit Daw","Julien Veron Vialard","Junkeun Yi","Jupinder Parmar","Kai Xu","Kan Zhu","Kari Briski","Katherine Cheung","Katherine Luna","Keith Wyss","Keshav Santhanam","Kevin Shih","Kezhi Kong","Khushi Bhardwaj","Kirthi Shankar","Krishna C. Puvvada","Krzysztof Pawelec","Kumar Anik","Lawrence McAfee","Laya Sleiman","Leon Derczynski","Li Ding","Lizzie Wei","Lucas Liebenwein","Luis Vega","Maanu Grover","Maarten Van Segbroeck","Maer Rodrigues de Melo","Mahdi Nazemi","Makesh Narsimhan Sreedhar","Manoj Kilaru","Maor Ashkenazi","Marc Romeijn","Marcin Chochowski","Mark Cai","Markus Kliegl","Maryam Moosaei","Matt Kulka","Matvei Novikov","Mehrzad Samadi","Melissa Corpuz","Mengru Wang","Meredith Price","Michael Andersch","Michael Boone","Michael Evans","Miguel Martinez","Mikail Khona","Mike Chrzanowski","Minseok Lee","Mohammad Dabbah","Mohammad Shoeybi","Mostofa Patwary","Nabin Mulepati","Najeeb Nabwani","Natalie Hereth","Nave Assaf","Negar Habibi","Neta Zmora","Netanel Haber","Nicola Sessions","Nidhi Bhatia","Nikhil Jukar","Nikki Pope","Nikolai Ludwig","Nima Tajbakhsh","Nir Ailon","Nirmal Juluru","Nishant Sharma","Oleksii Hrinchuk","Oleksii Kuchaiev","Olivier Delalleau","Oluwatobi Olabiyi","Omer Ullman Argov","Omri Puny","Oren Tropp","Ouye Xie","Parth Chadha","Pasha Shamis","Paul Gibbons","Pavlo Molchanov","Pawel Morkisz","Peter Dykas","Peter Jin","Pinky Xu","Piotr Januszewski","Pranav Prashant Thombre","Prasoon Varshney","Pritam Gundecha","Przemek Tredak","Qing Miao","Qiyu Wan","Rabeeh Karimi Mahabadi","Rachit Garg","Ran El-Yaniv","Ran Zilberstein","Rasoul Shafipour","Rich Harang","Rick Izzo","Rima Shahbazyan","Rishabh Garg","Ritika Borkar","Ritu Gala","Riyad Islam","Robert Hesse","Roger Waleffe","Rohit Watve","Roi Koren","Ruoxi Zhang","Russell Hewett","Russell J. Hewett","Ryan Prenger","Ryan Timbrook","Sadegh Mahdavi","Sahil Modi","Samuel Kriman","Sangkug Lim","Sanjay Kariyappa","Sanjeev Satheesh","Saori Kaji","Satish Pasumarthi","Saurav Muralidharan","Sean Narentharen","Sean Narenthiran","Seonmyeong Bak","Sergey Kashirsky","Seth Poulos","Shahar Mor","Shanmugam Ramasamy","Shantanu Acharya","Shaona Ghosh","Sharath Turuvekere Sreenivas","Shelby Thomas","Shiqing Fan","Shreya Gopal","Shrimai Prabhumoye","Shubham Pachori","Shubham Toshniwal","Shuoyang Ding","Siddharth Singh","Simeng Sun","Smita Ithape","Somshubra Majumdar","Soumye Singhal","Stas Sergienko","Stefania Alborghetti","Stephen Ge","Sugam Dipak Devare","Sumeet Kumar Barua","Suseella Panguluri","Suyog Gupta","Sweta Priyadarshi","Syeda Nahida Akter","Tan Bui","Teodor-Dumitru Ene","Terry Kong","Thanh Do","Tijmen Blankevoort","Tim Moon","Tom Balough","Tomer Asida","Tomer Bar Natan","Tomer Ronen","Tugrul Konuk","Twinkle Vashishth","Udi Karpas","Ushnish De","Vahid Noorozi","Vahid Noroozi","Venkat Srinivasan","Venmugil Elango","Victor Cui","Vijay Korthikanti","Vinay Rao","Vitaly Kurin","Vitaly Lavrukhin","Vladimir Anisimov","Wanli Jiang","Wasi Uddin Ahmad","Wei Du","Wei Ping","Wenfei Zhou","Will Jennings","William Zhang","Wojciech Prazuch","Xiaowei Ren","Yashaswi Karnati","Yejin Choi","Yev Meyer","Yi-Fu Wu","Yian Zhang","Yigong Qin","Ying Lin","Yonatan Geifman","Yonggan Fu","Yoshi Subara","Yoshi Suhara","Yubo Gao","Zach Moshe","Zhen Dong","Zhongbo Zhu","Zihan Liu","Zijia Chen","Zijie Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20854v1","updated":"2025-12-24T00:16:31Z","published":"2025-12-24T00:16:31Z","title":"How important is Recall for Measuring Retrieval Quality?","summary":"In realistic retrieval settings with large and evolving knowledge bases, the total number of documents relevant to a query is typically unknown, and recall cannot be computed. In this paper, we evaluate several established strategies for handling this limitation by measuring the correlation between retrieval quality metrics and LLM-based judgments of response quality, where responses are generated from the retrieved documents. We conduct experiments across multiple datasets with a relatively low number of relevant documents (2-15). We also introduce a simple retrieval quality measure that performs well without requiring knowledge of the total number of relevant documents.","authors":["Shelly Schwartz","Oleg Vasilyev","Randy Sawaya"],"pdf_url":"","comment":null}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2512.21203v1","updated":"2025-12-24T14:30:51Z","published":"2025-12-24T14:30:51Z","title":"Cruising the Spectrum: Joint Spectrum Mobility and Antenna Array Management for Mobile (cm/mm)Wave Connectivity","summary":"The large bandwidths available at millimeter wave (mmWave) FR2 bands (24-71 GHz) and the emerging FR3 bands (7-24 GHz) are essential for supporting high data rates. Highly directional beams utilized to overcome the attenuation in these frequencies necessitate robust and efficient beamforming schemes. Nevertheless, antenna and beam management approaches still face challenges in highly mobile solutions, such as vehicular connectivity, with increasing number of bands. In this work, the concepts of spectrum mobility is studied along with antenna array management in multiple frequencies to improve beamforming under mobility. The spectrum mobility problem aims to select the optimal channel frequency and beam direction in each time slot to maximize data rate. This problem is formulated as a Partially Observable Markov Decision Process (POMDP) and Point-Based Value Iteration (PBVI) algorithm is used to find a policy with performance guarantees. Numerical examples confirm the efficacy of the resulting policy for multiple available frequency bands, even when the user mobility significantly deviates from models assumed during policy generation.","authors":["Ece Bingöl","Eylem Ekici","Mehmet C. Vuran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21144v1","updated":"2025-12-24T12:25:28Z","published":"2025-12-24T12:25:28Z","title":"Encrypted Traffic Detection in Resource Constrained IoT Networks: A Diffusion Model and LLM Integrated Framework","summary":"The proliferation of Internet-of-things (IoT) infrastructures and the widespread adoption of traffic encryption present significant challenges, particularly in environments characterized by dynamic traffic patterns, constrained computational capabilities, and strict latency constraints. In this paper, we propose DMLITE, a diffusion model and large language model (LLM) integrated traffic embedding framework for network traffic detection within resource-limited IoT environments. The DMLITE overcomes these challenges through a tri-phase architecture including traffic visual preprocessing, diffusion-based multi-level feature extraction, and LLM-guided feature optimization. Specifically, the framework utilizes self-supervised diffusion models to capture both fine-grained and abstract patterns in encrypted traffic through multi-level feature fusion and contrastive learning with representative sample selection, thus enabling rapid adaptation to new traffic patterns with minimal labeled data. Furthermore, DMLITE incorporates LLMs to dynamically adjust particle swarm optimization parameters for intelligent feature selection by implementing a dual objective function that minimizes both classification error and variance across data distributions. Comprehensive experimental validation on benchmark datasets confirms the effectiveness of DMLITE, achieving classification accuracies of 98.87\\%, 92.61\\%, and 99.83\\% on USTC-TFC, ISCX-VPN, and Edge-IIoTset datasets, respectively. This improves classification accuracy by an average of 3.7\\% and reduces training time by an average of 41.9\\% compared to the representative deep learning model.","authors":["Hongjuan Li","Hui Kang","Chenbang Liu","Ruolin Wang","Jiahui Li","Geng Sun","Jiacheng Wang","Shuang Liang","Shiwen Mao"],"pdf_url":"","comment":"This paper is accepted by IEEE Transactions on Network Science and Engineering"},{"id":"http://arxiv.org/abs/2512.21116v1","updated":"2025-12-24T11:32:39Z","published":"2025-12-24T11:32:39Z","title":"Synecdoche: Efficient and Accurate In-Network Traffic Classification via Direct Packet Sequential Pattern Matching","summary":"Traffic classification on programmable data plane holds great promise for line-rate processing, with methods evolving from per-packet to flow-level analysis for higher accuracy. However, a trade-off between accuracy and efficiency persists. Statistical feature-based methods align with hardware constraints but often exhibit limited accuracy, while online deep learning methods using packet sequential features achieve superior accuracy but require substantial computational resources. This paper presents Synecdoche, the first traffic classification framework that successfully deploys packet sequential features on a programmable data plane via pattern matching, achieving both high accuracy and efficiency. Our key insight is that discriminative information concentrates in short sub-sequences--termed Key Segments--that serve as compact traffic features for efficient data plane matching. Synecdoche employs an \"offline discovery, online matching\" paradigm: deep learning models automatically discover Key Segment patterns offline, which are then compiled into optimized table entries for direct data plane matching. Extensive experiments demonstrate Synecdoche's superior accuracy, improving F1-scores by up to 26.4% against statistical methods and 18.3% against online deep learning methods, while reducing latency by 13.0% and achieving 79.2% reduction in SRAM usage. The source code of Synecdoche is publicly available to facilitate reproducibility and further research.","authors":["Minyuan Xiao","Yunchun Li","Yuchen Zhao","Tong Guan","Mingyuan Xia","Wei Li"],"pdf_url":"","comment":"Accepted by IEEE INFOCOM 2026"},{"id":"http://arxiv.org/abs/2512.20997v1","updated":"2025-12-24T06:49:43Z","published":"2025-12-24T06:49:43Z","title":"LLM-Empowered Agentic AI for QoE-Aware Network Slicing Management in Industrial IoT","summary":"The Industrial Internet of Things (IIoT) requires networks that deliver ultra-low latency, high reliability, and cost efficiency, which traditional optimization methods and deep reinforcement learning (DRL)-based approaches struggle to provide under dynamic and heterogeneous workloads. To address this gap, large language model (LLM)-empowered agentic AI has emerged as a promising paradigm, integrating reasoning, planning, and adaptation to enable QoE-aware network management. In this paper, we explore the integration of agentic AI into QoE-aware network slicing for IIoT. We first review the network slicing management architecture, QoE metrics for IIoT applications, and the challenges of dynamically managing heterogeneous network slices, while highlighting the motivations and advantages of adopting agentic AI. We then present the workflow of agentic AI-based slicing management, illustrating the full lifecycle of AI agents from processing slice requests to constructing slice instances and performing dynamic adjustments. Furthermore, we propose an LLM-empowered agentic AI approach for slicing management, which integrates a retrieval-augmented generation (RAG) module for semantic intent inference, a DRL-based orchestrator for slicing configuration, and an incremental memory mechanism for continual learning and adaptation. Through a case study on heterogeneous slice management, we demonstrate that the proposed approach significantly outperforms other baselines in balancing latency, reliability, and cost, and achieves up to a 19% improvement in slice availability ratio.","authors":["Xudong Wang","Lei Feng","Ruichen Zhang","Fanqin Zhou","Hongyang Du","Wenjing Li","Dusit Niyato","Abbas Jamalipour","Ping Zhang"],"pdf_url":"","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2512.20953v1","updated":"2025-12-24T05:21:47Z","published":"2025-12-24T05:21:47Z","title":"Diving into 3D Parallelism with Heterogeneous Spot Instance GPUs: Design and Implications","summary":"The rapid growth of large language models (LLMs) and the continuous release of new GPU products have significantly increased the demand for distributed training across heterogeneous GPU environments. In this paper, we present a comprehensive analysis of the challenges involved in implementing 3D parallelism in such environments, addressing critical issues such as the need for symmetric tensor parallelism, efficient gradient synchronization in asymmetric pipeline parallelism, and the trade-offs between memory utilization and computational efficiency. Building upon these insights, we introduce AutoHet, a novel system that automatically identifies the optimal parallelism plan for distributed training on heterogeneous GPUs. AutoHet supports asymmetric 3D parallelism structures and facilitates fine-grained workload distribution. We propose a theoretical model that frames the device grouping and load balancing as an optimization problem to minimize per-iteration training time, thus effectively balancing computing power and memory usage across GPUs with diverse capabilities. To enable elastic training upon spot instance preemption, AutoHet presents an efficient recovery strategy that prioritizes to retrieve training states from local nodes, and only downloads the missing checkpoints from the cloud storage. Our extensive evaluation, conducted on three large-scale models and utilizing combinations of three different GPU types, demonstrates that AutoHet outperforms existing DNN training systems, achieving up to a 1.79$\\times$ speedup in training throughput compared with Megatron-LM and Whale, and a 4.38$\\times$ speedup of recovery speed compared to a spot instance baseline.","authors":["Yuxiao Wang","Yuedong Xu","Qingyang Duan","Yuxuan Liu","Lei Jiao","Yinghao Yu","Jun Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20946v1","updated":"2025-12-24T05:05:13Z","published":"2025-12-24T05:05:13Z","title":"SLIDE: Simultaneous Model Downloading and Inference at the Wireless Network Edge","summary":"To support on-device inference, the next-generation mobile networks are expected to support real-time model downloading services to mobile users. However, powerful AI models typically have large model sizes, resulting in excessive end-to-end (E2E) downloading-and-inference (DAI) latency. To address this issue, we propose a simultaneous model downloading and inference (SLIDE) framework, which allows users to perform inference with downloaded layers while simultaneously receiving the remaining layers of the model. To this end, we formulate a task throughput maximization problem by jointly optimizing model provisioning, spectrum bandwidth allocation, and computing resource allocation for multi-user downlink systems. Unlike traditional DAI frameworks, SLIDE introduces recursive dependencies across layers, where inference latency depends recursively on the downloading bandwidth and computing resource allocation for each of the preceding layers. To solve this challenging problem, we design an efficient algorithm that acquires the optimal solution with polynomial-time complexity. Simulation results demonstrate that the proposed SLIDE framework significantly improves task throughput under latency and communication resource constraints compared with the conventional model downloading schemes.","authors":["Guanqiao Qu","Tao Li","Qian Chen","Xianhao Chen","Sheng Zhou"],"pdf_url":"","comment":"15 pages, 10 figures"},{"id":"http://arxiv.org/abs/2512.20943v1","updated":"2025-12-24T04:57:30Z","published":"2025-12-24T04:57:30Z","title":"AirGS: Real-Time 4D Gaussian Streaming for Free-Viewpoint Video Experiences","summary":"Free-viewpoint video (FVV) enables immersive viewing experiences by allowing users to view scenes from arbitrary perspectives. As a prominent reconstruction technique for FVV generation, 4D Gaussian Splatting (4DGS) models dynamic scenes with time-varying 3D Gaussian ellipsoids and achieves high-quality rendering via fast rasterization. However, existing 4DGS approaches suffer from quality degradation over long sequences and impose substantial bandwidth and storage overhead, limiting their applicability in real-time and wide-scale deployments. Therefore, we present AirGS, a streaming-optimized 4DGS framework that rearchitects the training and delivery pipeline to enable high-quality, low-latency FVV experiences. AirGS converts Gaussian video streams into multi-channel 2D formats and intelligently identifies keyframes to enhance frame reconstruction quality. It further combines temporal coherence with inflation loss to reduce training time and representation size. To support communication-efficient transmission, AirGS models 4DGS delivery as an integer linear programming problem and design a lightweight pruning level selection algorithm to adaptively prune the Gaussian updates to be transmitted, balancing reconstruction quality and bandwidth consumption. Extensive experiments demonstrate that AirGS reduces quality deviation in PSNR by more than 20% when scene changes, maintains frame-level PSNR consistently above 30, accelerates training by 6 times, reduces per-frame transmission size by nearly 50% compared to the SOTA 4DGS approaches.","authors":["Zhe Wang","Jinghang Li","Yifei Zhu"],"pdf_url":"","comment":"This paper is accepted by IEEE International Conference on Computer Communications (INFOCOM), 2026"},{"id":"http://arxiv.org/abs/2510.25810v2","updated":"2025-12-24T04:57:09Z","published":"2025-10-29T09:45:27Z","title":"Adversarial Pre-Padding: Generating Evasive Network Traffic Against Transformer-Based Classifiers","summary":"To date, traffic obfuscation techniques have been widely adopted to protect network data privacy and security by obscuring the true patterns of traffic. Nevertheless, as the pre-trained models emerge, especially transformer-based classifiers, existing traffic obfuscation methods become increasingly vulnerable, as witnessed by current studies reporting the traffic classification accuracy up to 99\\% or higher. To counter such high-performance transformer-based classification models, we in this paper propose a novel and effective \\underline{adv}ersarial \\underline{traffic}-generating approach (AdvTraffic\\footnote{The code and data are available at: https://anonymous.4open.science/r/TrafficD-C461}). Our approach has two key innovations: (i) a pre-padding strategy is proposed to modify packets, which effectively overcomes the limitations of existing research against transformer-based models for network traffic classification; and (ii) a reinforcement learning model is employed to optimize network traffic perturbations, aiming to maximize adversarial effectiveness against transformer-based classification models. To the best of our knowledge, this is the first attempt to apply adversarial perturbation techniques to defend against transformer-based traffic classifiers. Furthermore, our method can be easily deployed into practical network environments. Finally, multi-faceted experiments are conducted across several real-world datasets, and the experimental results demonstrate that our proposed method can effectively undermine transformer-based classifiers, significantly reducing classification accuracy from 99\\% to as low as 25.68\\%.","authors":["Quanliang Jing","Xinxin Fan","Yanyan Liu","Jingping Bi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20902v1","updated":"2025-12-24T03:06:37Z","published":"2025-12-24T03:06:37Z","title":"Embodied AI-Enhanced IoMT Edge Computing: UAV Trajectory Optimization and Task Offloading with Mobility Prediction","summary":"Due to their inherent flexibility and autonomous operation, unmanned aerial vehicles (UAVs) have been widely used in Internet of Medical Things (IoMT) to provide real-time biomedical edge computing service for wireless body area network (WBAN) users. In this paper, considering the time-varying task criticality characteristics of diverse WBAN users and the dual mobility between WBAN users and UAV, we investigate the dynamic task offloading and UAV flight trajectory optimization problem to minimize the weighted average task completion time of all the WBAN users, under the constraint of UAV energy consumption. To tackle the problem, an embodied AI-enhanced IoMT edge computing framework is established. Specifically, we propose a novel hierarchical multi-scale Transformer-based user trajectory prediction model based on the users' historical trajectory traces captured by the embodied AI agent (i.e., UAV). Afterwards, a prediction-enhanced deep reinforcement learning (DRL) algorithm that integrates predicted users' mobility information is designed for intelligently optimizing UAV flight trajectory and task offloading decisions. Real-word movement traces and simulation results demonstrate the superiority of the proposed methods in comparison with the existing benchmarks.","authors":["Siqi Mu","Shuo Wen","Yang Lu","Ruihong Jiang","Bo Ai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20885v1","updated":"2025-12-24T02:05:46Z","published":"2025-12-24T02:05:46Z","title":"From GNNs to Symbolic Surrogates via Kolmogorov-Arnold Networks for Delay Prediction","summary":"Accurate prediction of flow delay is essential for optimizing and managing modern communication networks. We investigate three levels of modeling for this task. First, we implement a heterogeneous GNN with attention-based message passing, establishing a strong neural baseline. Second, we propose FlowKANet in which Kolmogorov-Arnold Networks replace standard MLP layers, reducing trainable parameters while maintaining competitive predictive performance. FlowKANet integrates KAMP-Attn (Kolmogorov-Arnold Message Passing with Attention), embedding KAN operators directly into message-passing and attention computation. Finally, we distill the model into symbolic surrogate models using block-wise regression, producing closed-form equations that eliminate trainable weights while preserving graph-structured dependencies. The results show that KAN layers provide a favorable trade-off between efficiency and accuracy and that symbolic surrogates emphasize the potential for lightweight deployment and enhanced transparency.","authors":["Sami Marouani","Kamal Singh","Baptiste Jeudy","Amaury Habrard"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.16146v3","updated":"2025-12-24T00:54:25Z","published":"2025-04-22T13:13:35Z","title":"Aerial Active STAR-RIS-assisted Satellite-Terrestrial Covert Communications","summary":"An integration of satellites and terrestrial networks is crucial for enhancing performance of next generation communication systems. However, the networks are hindered by the long-distance path loss and security risks in dense urban environments. In this work, we propose a satellite-terrestrial covert communication system assisted by the aerial active simultaneous transmitting and reflecting reconfigurable intelligent surface (AASTAR-RIS) to improve the channel capacity while ensuring the transmission covertness. Specifically, we first derive the minimal detection error probability (DEP) under the worst condition that the Warden has perfect channel state information (CSI). Then, we formulate an AASTAR-RIS-assisted satellite-terrestrial covert communication optimization problem (ASCCOP) to maximize the sum of the fair channel capacity for all ground users while meeting the strict covert constraint, by jointly optimizing the trajectory and active beamforming of the AASTAR-RIS. Due to the challenges posed by the complex and high-dimensional state-action spaces as well as the need for efficient exploration in dynamic environments, we propose a generative deterministic policy gradient (GDPG) algorithm, which is a generative deep reinforcement learning (DRL) method to solve the ASCCOP. Concretely, the generative diffusion model (GDM) is utilized as the policy representation of the algorithm to enhance the exploration process by generating diverse and high-quality samples through a series of denoising steps. Moreover, we incorporate an action gradient mechanism to accomplish the policy improvement of the algorithm, which refines the better state-action pairs through the gradient ascent. Simulation results demonstrate that the proposed approach significantly outperforms important benchmarks.","authors":["Chuang Zhang","Geng Sun","Jiahui Li","Jiacheng Wang","Ruichen Zhang","Dusit Niyato","Shiwen Mao","Abbas Jamalipour"],"pdf_url":"","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2512.21336v1","updated":"2025-12-24T18:59:51Z","published":"2025-12-24T18:59:51Z","title":"Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty","summary":"Masked Diffusion Models (MDMs) offer flexible, non-autoregressive generation, but this freedom introduces a challenge: final output quality is highly sensitive to the decoding order. We are the first to formalize this issue, attributing the variability in output quality to the cumulative predictive uncertainty along a generative path. To quantify this uncertainty, we introduce Denoising Entropy, a computable metric that serves as an internal signal for evaluating generative process. Leveraging this metric, we propose two algorithms designed to optimize the decoding path: a post-hoc selection method and a real-time guidance strategy. Experiments demonstrate that our entropy-guided methods significantly improve generation quality, consistently boosting accuracy on challenging reasoning, planning, and code benchmarks. Our work establishes Denoising Entropy as a principled tool for understanding and controlling generation, effectively turning the uncertainty in MDMs from a liability into a key advantage for discovering high-quality solutions.","authors":["Ziyu Chen","Xinbei Jiang","Peng Sun","Tao Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21335v1","updated":"2025-12-24T18:59:47Z","published":"2025-12-24T18:59:47Z","title":"Autonomous Uncertainty Quantification for Computational Point-of-care Sensors","summary":"Computational point-of-care (POC) sensors enable rapid, low-cost, and accessible diagnostics in emergency, remote and resource-limited areas that lack access to centralized medical facilities. These systems can utilize neural network-based algorithms to accurately infer a diagnosis from the signals generated by rapid diagnostic tests or sensors. However, neural network-based diagnostic models are subject to hallucinations and can produce erroneous predictions, posing a risk of misdiagnosis and inaccurate clinical decisions. To address this challenge, here we present an autonomous uncertainty quantification technique developed for POC diagnostics. As our testbed, we used a paper-based, computational vertical flow assay (xVFA) platform developed for rapid POC diagnosis of Lyme disease, the most prevalent tick-borne disease globally. The xVFA platform integrates a disposable paper-based assay, a handheld optical reader and a neural network-based inference algorithm, providing rapid and cost-effective Lyme disease diagnostics in under 20 min using only 20 uL of patient serum. By incorporating a Monte Carlo dropout (MCDO)-based uncertainty quantification approach into the diagnostics pipeline, we identified and excluded erroneous predictions with high uncertainty, significantly improving the sensitivity and reliability of the xVFA in an autonomous manner, without access to the ground truth diagnostic information of patients. Blinded testing using new patient samples demonstrated an increase in diagnostic sensitivity from 88.2% to 95.7%, indicating the effectiveness of MCDO-based uncertainty quantification in enhancing the robustness of neural network-driven computational POC sensing systems.","authors":["Artem Goncharov","Rajesh Ghosh","Hyou-Arm Joung","Dino Di Carlo","Aydogan Ozcan"],"pdf_url":"","comment":"18 Pages, 5 Figures"},{"id":"http://arxiv.org/abs/2512.21326v1","updated":"2025-12-24T18:54:37Z","published":"2025-12-24T18:54:37Z","title":"Measuring all the noises of LLM Evals","summary":"Separating signal from noise is central to experimental science. Applying well-established statistical method effectively to LLM evals requires consideration of their unique noise characteristics. We clearly define and measure three types of noise: prediction noise from generating different answers on a given question, data noise from sampling questions, and their combined total noise following the law of total variance. To emphasize relative comparisons and gain statistical power, we propose the all-pairs paired method, which applies the paired analysis to all pairs of LLMs and measures all the noise components based on millions of question-level predictions across many evals and settings. These measurements revealed clear patterns. First, each eval exhibits a characteristic and highly predictable total noise level across all model pairs. Second, paired prediction noise typically exceeds paired data noise, which means reducing prediction noise by averaging can significantly increase statistical power. These findings enable practitioners to assess significance without custom testing and to detect much smaller effects in controlled experiments.","authors":["Sida Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21323v1","updated":"2025-12-24T18:46:55Z","published":"2025-12-24T18:46:55Z","title":"Parallel Token Prediction for Language Models","summary":"We propose Parallel Token Prediction (PTP), a universal framework for parallel sequence generation in language models. PTP jointly predicts multiple dependent tokens in a single transformer call by incorporating the sampling procedure into the model. This reduces the latency bottleneck of autoregressive decoding, and avoids the restrictive independence assumptions common in existing multi-token prediction methods. We prove that PTP can represent arbitrary autoregressive sequence distributions. PTP is trained either by distilling an existing model or through inverse autoregressive training without a teacher. Experimentally, we achieve state-of-the-art speculative decoding performance on Vicuna-7B by accepting over four tokens per step on Spec-Bench. The universality of our framework indicates that parallel generation of long sequences is feasible without loss of modeling power.","authors":["Felix Draxler","Justus Will","Farrin Marouf Sofian","Theofanis Karaletsos","Sameer Singh","Stephan Mandt"],"pdf_url":"","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2511.15172v3","updated":"2025-12-24T18:38:44Z","published":"2025-11-19T06:51:03Z","title":"Complex variational autoencoders admit Kähler structure","summary":"It has been discovered that latent-Euclidean variational autoencoders (VAEs) admit, in various capacities, Riemannian structure. We adapt these arguments but for complex VAEs with a complex latent stage. We show that complex VAEs reveal to some level Kähler geometric structure. Our methods will be tailored for decoder geometry. We derive the Fisher information metric in the complex case under a latent complex Gaussian with trivial relation matrix. It is well known from statistical information theory that the Fisher information coincides with the Hessian of the Kullback-Leibler (KL) divergence. Thus, the metric Kähler potential relation is exactly achieved under relative entropy. We propose a Kähler potential derivative of complex Gaussian mixtures that acts as a rough proxy to the Fisher information metric while still being faithful to the underlying Kähler geometry. Computation of the metric via this potential is efficient, and through our potential, valid as a plurisubharmonic (PSH) function, large scale computational burden of automatic differentiation is displaced to small scale. Our methods leverage the law of total covariance to bridge behavior between our potential and the Fisher metric. We show that we can regularize the latent space with decoder geometry, and that we can sample in accordance with a weighted complex volume element. We demonstrate these strategies, at the exchange of sample variation, yield consistently smoother representations and fewer semantic outliers.","authors":["Andrew Gracyk"],"pdf_url":"","comment":"Corrections and improvements"},{"id":"http://arxiv.org/abs/2512.21319v1","updated":"2025-12-24T18:37:59Z","published":"2025-12-24T18:37:59Z","title":"Variationally correct operator learning: Reduced basis neural operator with a posteriori error estimation","summary":"Minimizing PDE-residual losses is a common strategy to promote physical consistency in neural operators. However, standard formulations often lack variational correctness, meaning that small residuals do not guarantee small solution errors due to the use of non-compliant norms or ad hoc penalty terms for boundary conditions. This work develops a variationally correct operator learning framework by constructing first-order system least-squares (FOSLS) objectives whose values are provably equivalent to the solution error in PDE-induced norms. We demonstrate this framework on stationary diffusion and linear elasticity, incorporating mixed Dirichlet-Neumann boundary conditions via variational lifts to preserve norm equivalence without inconsistent penalties. To ensure the function space conformity required by the FOSLS loss, we propose a Reduced Basis Neural Operator (RBNO). The RBNO predicts coefficients for a pre-computed, conforming reduced basis, thereby ensuring variational stability by design while enabling efficient training. We provide a rigorous convergence analysis that bounds the total error by the sum of finite element discretization bias, reduced basis truncation error, neural network approximation error, and statistical estimation errors arising from finite sampling and optimization. Numerical benchmarks validate these theoretical bounds and demonstrate that the proposed approach achieves superior accuracy in PDE-compliant norms compared to standard baselines, while the residual loss serves as a reliable, computable a posteriori error estimator.","authors":["Yuan Qiu","Wolfgang Dahmen","Peng Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21315v1","updated":"2025-12-24T18:21:01Z","published":"2025-12-24T18:21:01Z","title":"Does the Data Processing Inequality Reflect Practice? On the Utility of Low-Level Tasks","summary":"The data processing inequality is an information-theoretic principle stating that the information content of a signal cannot be increased by processing the observations. In particular, it suggests that there is no benefit in enhancing the signal or encoding it before addressing a classification problem. This assertion can be proven to be true for the case of the optimal Bayes classifier. However, in practice, it is common to perform \"low-level\" tasks before \"high-level\" downstream tasks despite the overwhelming capabilities of modern deep neural networks. In this paper, we aim to understand when and why low-level processing can be beneficial for classification. We present a comprehensive theoretical study of a binary classification setup, where we consider a classifier that is tightly connected to the optimal Bayes classifier and converges to it as the number of training samples increases. We prove that for any finite number of training samples, there exists a pre-classification processing that improves the classification accuracy. We also explore the effect of class separation, training set size, and class balance on the relative gain from this procedure. We support our theory with an empirical investigation of the theoretical setup. Finally, we conduct an empirical study where we investigate the effect of denoising and encoding on the performance of practical deep classifiers on benchmark datasets. Specifically, we vary the size and class distribution of the training set, and the noise level, and demonstrate trends that are consistent with our theoretical results.","authors":["Roy Turgeman","Tom Tirer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21311v1","updated":"2025-12-24T18:14:02Z","published":"2025-12-24T18:14:02Z","title":"Learning to Solve PDEs on Neural Shape Representations","summary":"Solving partial differential equations (PDEs) on shapes underpins many shape analysis and engineering tasks; yet, prevailing PDE solvers operate on polygonal/triangle meshes while modern 3D assets increasingly live as neural representations. This mismatch leaves no suitable method to solve surface PDEs directly within the neural domain, forcing explicit mesh extraction or per-instance residual training, preventing end-to-end workflows. We present a novel, mesh-free formulation that learns a local update operator conditioned on neural (local) shape attributes, enabling surface PDEs to be solved directly where the (neural) data lives. The operator integrates naturally with prevalent neural surface representations, is trained once on a single representative shape, and generalizes across shape and topology variations, enabling accurate, fast inference without explicit meshing or per-instance optimization while preserving differentiability. Across analytic benchmarks (heat equation and Poisson solve on sphere) and real neural assets across different representations, our method slightly outperforms CPM while remaining reasonably close to FEM, and, to our knowledge, delivers the first end-to-end pipeline that solves surface PDEs on both neural and classical surface representations. Code will be released on acceptance.","authors":["Lilian Welschinger","Yilin Liu","Zican Wang","Niloy Mitra"],"pdf_url":"","comment":"Article webpage link: https://welschinger.github.io/Learning-to-Solve-PDEs-on-Neural-Shape-Representations/"},{"id":"http://arxiv.org/abs/2510.22293v2","updated":"2025-12-24T18:06:18Z","published":"2025-10-25T13:36:18Z","title":"Predicting Metabolic Dysfunction-Associated Steatotic Liver Disease using Machine Learning Methods","summary":"Background: Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD) affects ~33% of U.S. adults and is the most common chronic liver disease. Although often asymptomatic, progression can lead to cirrhosis. Early detection is important, as lifestyle interventions can prevent disease progression. We developed a fair, rigorous, and reproducible MASLD prediction model and compared it to prior methods using a large electronic health record database.\n  Methods: We evaluated LASSO logistic regression, random forest, XGBoost, and a neural network for MASLD prediction using clinical feature subsets, including the top 10 SHAP-ranked features. To reduce disparities in true positive rates across racial and ethnic subgroups, we applied an equal opportunity postprocessing method.\n  Results: This study included 59,492 patients in the training data, 24,198 in the validating data, and 25,188 in the testing data. The LASSO logistic regression model with the top 10 features was selected for its interpretability and comparable performance. Before fairness adjustment, the model achieved AUROC of 0.84, accuracy of 78%, sensitivity of 72%, specificity of 79%, and F1-score of 0.617. After equal opportunity postprocessing, accuracy modestly increased to 81% and specificity to 94%, while sensitivity decreased to 41% and F1-score to 0.515, reflecting the fairness trade-off.\n  Conclusions: We developed the MASER prediction model (MASLD Static EHR Risk Prediction), a LASSO logistic regression model which achieved competitive performance for MASLD prediction (AUROC 0.836, accuracy 77.6%), comparable to previously reported ensemble and tree-based models. Overall, this approach demonstrates that interpretable models can achieve a balance of predictive performance and fairness in diverse patient populations.","authors":["Mary E. An","Paul Griffin","Jonathan G. Stine","Ramakrishna Balakrishnan","Soundar Kumara"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2110.03155v8","updated":"2025-12-24T17:53:45Z","published":"2021-10-07T03:14:46Z","title":"Intrinsic Benefits of Categorical Distributional Loss: Uncertainty-aware Regularized Exploration in Reinforcement Learning","summary":"The remarkable empirical performance of distributional reinforcement learning (RL) has garnered increasing attention to understanding its theoretical advantages over classical RL. By decomposing the categorical distributional loss commonly employed in distributional RL, we find that the potential superiority of distributional RL can be attributed to a derived distribution-matching entropy regularization. This less-studied entropy regularization aims to capture additional knowledge of return distribution beyond only its expectation, contributing to an augmented reward signal in policy optimization. In contrast to the vanilla entropy regularization in MaxEnt RL, which explicitly encourages exploration by promoting diverse actions, the novel entropy regularization derived from categorical distributional loss implicitly updates policies to align the learned policy with (estimated) environmental uncertainty. Finally, extensive experiments verify the significance of this uncertainty-aware regularization from distributional RL on the empirical benefits over classical RL. Our study offers an innovative exploration perspective to explain the intrinsic benefits of distributional learning in RL.","authors":["Ke Sun","Yingnan Zhao","Enze Shi","Yafei Wang","Xiaodong Yan","Bei Jiang","Linglong Kong"],"pdf_url":"","comment":"NeurIPS 2025; Previous Version in ICML Workshop: Exploration in AI Today (EXAIT) 2025"},{"id":"http://arxiv.org/abs/2512.21301v1","updated":"2025-12-24T17:39:37Z","published":"2025-12-24T17:39:37Z","title":"Transcriptome-Conditioned Personalized De Novo Drug Generation for AML Using Metaheuristic Assembly and Target-Driven Filtering","summary":"Acute Myeloid Leukemia (AML) remains a clinical challenge due to its extreme molecular heterogeneity and high relapse rates. While precision medicine has introduced mutation-specific therapies, many patients still lack effective, personalized options. This paper presents a novel, end-to-end computational framework that bridges the gap between patient-specific transcriptomics and de novo drug discovery. By analyzing bulk RNA sequencing data from the TCGA-LAML cohort, the study utilized Weighted Gene Co-expression Network Analysis (WGCNA) to prioritize 20 high-value biomarkers, including metabolic transporters like HK3 and immune-modulatory receptors such as SIGLEC9. The physical structures of these targets were modeled using AlphaFold3, and druggable hotspots were quantitatively mapped via the DOGSiteScorer engine. Then developed a novel, reaction-first evolutionary metaheuristic algorithm as well as multi-objective optimization programming that assembles novel ligands from fragment libraries, guided by spatial alignment to these identified hotspots. The generative model produced structurally unique chemical entities with a strong bias toward drug-like space, as evidenced by QED scores peaking between 0.5 and 0.7. Validation through ADMET profiling and SwissDock molecular docking identified high-confidence candidates, such as Ligand L1, which achieved a binding free energy of -6.571 kcal/mol against the A08A96 biomarker. These results demonstrate that integrating systems biology with metaheuristic molecular assembly can produce pharmacologically viable, patient tailored leads, offering a scalable blueprint for precision oncology in AML and beyond","authors":["Abdullah G. Elafifi","Basma Mamdouh","Mariam Hanafy","Muhammed Alaa Eldin","Yosef Khaled","Nesma Mohamed El-Gelany","Tarek H. M. Abou-El-Enien"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.06489v4","updated":"2025-12-24T17:26:35Z","published":"2025-06-06T19:29:13Z","title":"Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks","summary":"What features neural networks learn, and how, remains an open question. In this paper, we introduce Alternating Gradient Flows (AGF), an algorithmic framework that describes the dynamics of feature learning in two-layer networks trained from small initialization. Prior works have shown that gradient flow in this regime exhibits a staircase-like loss curve, alternating between plateaus where neurons slowly align to useful directions and sharp drops where neurons rapidly grow in norm. AGF approximates this behavior as an alternating two-step process: maximizing a utility function over dormant neurons and minimizing a cost function over active ones. AGF begins with all neurons dormant. At each iteration, a dormant neuron activates, triggering the acquisition of a feature and a drop in the loss. AGF quantifies the order, timing, and magnitude of these drops, matching experiments across several commonly studied architectures. We show that AGF unifies and extends existing saddle-to-saddle analyses in fully connected linear networks and attention-only linear transformers, where the learned features are singular modes and principal components, respectively. In diagonal linear networks, we prove AGF converges to gradient flow in the limit of vanishing initialization. Applying AGF to quadratic networks trained to perform modular addition, we give the first complete characterization of the training dynamics, revealing that networks learn Fourier features in decreasing order of coefficient magnitude. Altogether, AGF offers a promising step towards understanding feature learning in neural networks.","authors":["Daniel Kunin","Giovanni Luca Marchetti","Feng Chen","Dhruva Karkada","James B. Simon","Michael R. DeWeese","Surya Ganguli","Nina Miolane"],"pdf_url":"","comment":"40 pages, 8 figures, NeurIPS 2025"},{"id":"http://arxiv.org/abs/2502.06096v4","updated":"2025-12-24T17:17:29Z","published":"2025-02-10T02:01:30Z","title":"Post-detection inference for sequential changepoint localization","summary":"This paper addresses a fundamental but largely unexplored challenge in sequential changepoint analysis: conducting inference following a detected change. We develop a very general framework to construct confidence sets for the unknown changepoint using only the data observed up to a data-dependent stopping time at which an arbitrary sequential detection algorithm declares a change. Our framework is nonparametric, making no assumption on the composite post-change class, the observation space, or the sequential detection procedure used, and is non-asymptotically valid. We also extend it to handle composite pre-change classes under a suitable assumption, and also derive confidence sets for the change magnitude in parametric settings. We provide theoretical guarantees on the width of our confidence intervals. Extensive simulations demonstrate that the produced sets have reasonable size, and slightly conservative coverage. In summary, we present the first general method for sequential changepoint localization, which is theoretically sound and broadly applicable in practice.","authors":["Aytijhya Saha","Aaditya Ramdas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21288v1","updated":"2025-12-24T17:10:44Z","published":"2025-12-24T17:10:44Z","title":"Model Merging via Multi-Teacher Knowledge Distillation","summary":"Model merging has emerged as a lightweight alternative to joint multi-task learning (MTL), yet the generalization properties of merged models remain largely unexplored. Establishing such theoretical guarantees is non-trivial, as the merging process typically forbids access to the original training data and involves combining fine-tuned models trained on fundamentally heterogeneous data distributions. Without a principled understanding of these dynamics, current methods often rely on heuristics to approximate the optimal combination of parameters. This dependence is most critical in coefficient scaling, the weighting factors that modulate the magnitude of each fine-tuned model's contribution to the shared parameter. However, without a principled objective to guide their selection, these methods lead to brittle performance and are highly sensitive to scaling initialization. We address this gap by (i) establishing a novel flatness-aware PAC-Bayes generalization bound specifically for the model merging setting. This analysis introduces a \"cross-task heterogeneity\" term that formally captures the mismatch between diverse fine-tuned model priors and the target multi-task distributions. Guided by this theoretical insight, (ii) we frame model merging as multi-teacher knowledge distillation on scarce, unlabeled data. We formally demonstrate that minimizing the student-teacher Kullback-Leibler divergence directly tightens the upper bound on the merged model's excess risk. Guided by the flatness-aware bound derived, (iii) we operationalize this objective via SAMerging, a method that employs Sharpness-Aware Minimization (SAM) to find flat minima. Empirically, SAMerging establishes a new state of the art across vision and NLP benchmarks, achieving remarkable performance. The code is available at https://github.com/arshandalili/SAMerging.","authors":["Seyed Arshan Dalili","Mehrdad Mahdavi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.11957v2","updated":"2025-12-24T16:49:53Z","published":"2024-10-15T18:00:13Z","title":"Agnostic Process Tomography","summary":"Characterizing a quantum system by learning its state or evolution is a fundamental problem in quantum physics and learning theory with a myriad of applications. Recently, as a new approach to this problem, the task of agnostic state tomography was defined, in which one aims to approximate an arbitrary quantum state by a simpler one in a given class. Generalizing this notion to quantum processes, we initiate the study of agnostic process tomography: given query access to an unknown quantum channel $Φ$ and a known concept class $\\mathcal{C}$ of channels, output a quantum channel that approximates $Φ$ as well as any channel in the concept class $\\mathcal{C}$, up to some error. In this work, we propose several natural applications for this new task in quantum machine learning, quantum metrology, classical simulation, and error mitigation. In addition, we give efficient agnostic process tomography algorithms for a wide variety of concept classes, including Pauli strings, Pauli channels, quantum junta channels, low-degree channels, and a class of channels produced by $\\mathsf{QAC}^0$ circuits. The main technical tool we use is Pauli spectrum analysis of operators and superoperators. We also prove that, using ancilla qubits, any agnostic state tomography algorithm can be extended to one solving agnostic process tomography for a compatible concept class of unitaries, immediately giving us efficient agnostic learning algorithms for Clifford circuits, Clifford circuits with few T gates, and circuits consisting of a tensor product of single-qubit gates. Together, our results provide insight into the conditions and new algorithms necessary to extend the learnability of a concept class from the standard tomographic setting to the agnostic one.","authors":["Chirag Wadhwa","Laura Lewis","Elham Kashefi","Mina Doosti"],"pdf_url":"","comment":"11+52 pages, 2 figures, 1 table. v2: Minor improvements and edits"},{"id":"http://arxiv.org/abs/2512.21243v1","updated":"2025-12-24T15:36:21Z","published":"2025-12-24T15:36:21Z","title":"LookPlanGraph: Embodied Instruction Following Method with VLM Graph Augmentation","summary":"Methods that use Large Language Models (LLM) as planners for embodied instruction following tasks have become widespread. To successfully complete tasks, the LLM must be grounded in the environment in which the robot operates. One solution is to use a scene graph that contains all the necessary information. Modern methods rely on prebuilt scene graphs and assume that all task-relevant information is available at the start of planning. However, these approaches do not account for changes in the environment that may occur between the graph construction and the task execution. We propose LookPlanGraph - a method that leverages a scene graph composed of static assets and object priors. During plan execution, LookPlanGraph continuously updates the graph with relevant objects, either by verifying existing priors or discovering new entities. This is achieved by processing the agents egocentric camera view using a Vision Language Model. We conducted experiments with changed object positions VirtualHome and OmniGibson simulated environments, demonstrating that LookPlanGraph outperforms methods based on predefined static scene graphs. To demonstrate the practical applicability of our approach, we also conducted experiments in a real-world setting. Additionally, we introduce the GraSIF (Graph Scenes for Instruction Following) dataset with automated validation framework, comprising 514 tasks drawn from SayPlan Office, BEHAVIOR-1K, and VirtualHome RobotHow. Project page available at https://lookplangraph.github.io .","authors":["Anatoly O. Onishchenko","Alexey K. Kovalev","Aleksandr I. Panov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21241v1","updated":"2025-12-24T15:35:03Z","published":"2025-12-24T15:35:03Z","title":"Improving the Convergence Rate of Ray Search Optimization for Query-Efficient Hard-Label Attacks","summary":"In hard-label black-box adversarial attacks, where only the top-1 predicted label is accessible, the prohibitive query complexity poses a major obstacle to practical deployment. In this paper, we focus on optimizing a representative class of attacks that search for the optimal ray direction yielding the minimum $\\ell_2$-norm perturbation required to move a benign image into the adversarial region. Inspired by Nesterov's Accelerated Gradient (NAG), we propose a momentum-based algorithm, ARS-OPT, which proactively estimates the gradient with respect to a future ray direction inferred from accumulated momentum. We provide a theoretical analysis of its convergence behavior, showing that ARS-OPT enables more accurate directional updates and achieves faster, more stable optimization. To further accelerate convergence, we incorporate surrogate-model priors into ARS-OPT's gradient estimation, resulting in PARS-OPT with enhanced performance. The superiority of our approach is supported by theoretical guarantees under standard assumptions. Extensive experiments on ImageNet and CIFAR-10 demonstrate that our method surpasses 13 state-of-the-art approaches in query efficiency.","authors":["Xinjie Xu","Shuyu Cheng","Dongwei Xu","Qi Xuan","Chen Ma"],"pdf_url":"","comment":"Published at AAAI 2026 (Oral). This version corresponds to the conference proceedings; v2 will include the appendix"},{"id":"http://arxiv.org/abs/2507.04716v2","updated":"2025-12-24T15:30:39Z","published":"2025-07-07T07:14:42Z","title":"Optimal Model Selection for Conformalized Robust Optimization","summary":"In decision-making under uncertainty, Contextual Robust Optimization (CRO) provides reliability by minimizing the worst-case decision loss over a prediction set. While recent advances use conformal prediction to construct prediction sets for machine learning models, the downstream decisions critically depend on model selection. This paper introduces novel model selection frameworks for CRO that unify robustness control with decision risk minimization. We first propose Conformalized Robust Optimization with Model Selection (CROMS), a framework that selects the model to approximately minimize the averaged decision risk in CRO solutions. Given the target robustness level 1-α, we present a computationally efficient algorithm called E-CROMS, which achieves asymptotic robustness control and decision optimality. To correct the control bias in finite samples, we further develop two algorithms: F-CROMS, which ensures a 1-αrobustness but requires searching the label space; and J-CROMS, which offers lower computational cost while achieving a 1-2αrobustness. Furthermore, we extend the CROMS framework to the individualized setting, where model selection is performed by minimizing the conditional decision risk given the covariates of the test data. This framework advances conformal prediction methodology by enabling covariate-aware model selection. Numerical results demonstrate significant improvements in decision efficiency across diverse synthetic and real-world applications, outperforming baseline approaches.","authors":["Yajie Bao","Yang Hu","Haojie Ren","Peng Zhao","Changliang Zou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21238v1","updated":"2025-12-24T15:29:54Z","published":"2025-12-24T15:29:54Z","title":"Assessing the Software Security Comprehension of Large Language Models","summary":"Large language models (LLMs) are increasingly used in software development, but their level of software security expertise remains unclear. This work systematically evaluates the security comprehension of five leading LLMs: GPT-4o-Mini, GPT-5-Mini, Gemini-2.5-Flash, Llama-3.1, and Qwen-2.5, using Blooms Taxonomy as a framework. We assess six cognitive dimensions: remembering, understanding, applying, analyzing, evaluating, and creating. Our methodology integrates diverse datasets, including curated multiple-choice questions, vulnerable code snippets (SALLM), course assessments from an Introduction to Software Security course, real-world case studies (XBOW), and project-based creation tasks from a Secure Software Engineering course. Results show that while LLMs perform well on lower-level cognitive tasks such as recalling facts and identifying known vulnerabilities, their performance degrades significantly on higher-order tasks that require reasoning, architectural evaluation, and secure system creation. Beyond reporting aggregate accuracy, we introduce a software security knowledge boundary that identifies the highest cognitive level at which a model consistently maintains reliable performance. In addition, we identify 51 recurring misconception patterns exhibited by LLMs across Blooms levels.","authors":["Mohammed Latif Siddiq","Natalie Sekerak","Antonio Karam","Maria Leal","Arvin Islam-Gomes","Joanna C. S. Santos"],"pdf_url":"","comment":"Submitted to Empirical Software Engineering (EMSE) journal"},{"id":"http://arxiv.org/abs/2512.20399v2","updated":"2025-12-24T15:28:58Z","published":"2025-12-23T14:40:08Z","title":"GeoTransolver: Learning Physics on Irregular Domains Using Multi-scale Geometry Aware Physics Attention Transformer","summary":"We present GeoTransolver, a Multiscale Geometry-Aware Physics Attention Transformer for CAE that replaces standard attention with GALE, coupling physics-aware self-attention on learned state slices with cross-attention to a shared geometry/global/boundary-condition context computed from multi-scale ball queries (inspired by DoMINO) and reused in every block. Implemented and released in NVIDIA PhysicsNeMo, GeoTransolver persistently projects geometry, global and boundary condition parameters into physical state spaces to anchor latent computations to domain structure and operating regimes. We benchmark GeoTransolver on DrivAerML, Luminary SHIFT-SUV, and Luminary SHIFT-Wing, comparing against Domino, Transolver (as released in PhysicsNeMo), and literature-reported AB-UPT, and evaluate drag/lift R2 and Relative L1 errors for field variables. GeoTransolver delivers better accuracy, improved robustness to geometry/regime shifts, and favorable data efficiency; we include ablations on DrivAerML and qualitative results such as contour plots and design trends for the best GeoTransolver models. By unifying multiscale geometry-aware context with physics-based attention in a scalable transformer, GeoTransolver advances operator learning for high-fidelity surrogate modeling across complex, irregular domains and non-linear physical regimes.","authors":["Corey Adams","Rishikesh Ranade","Ram Cherukuri","Sanjay Choudhry"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21231v1","updated":"2025-12-24T15:15:18Z","published":"2025-12-24T15:15:18Z","title":"MiST: Understanding the Role of Mid-Stage Scientific Training in Developing Chemical Reasoning Models","summary":"Large Language Models can develop reasoning capabilities through online fine-tuning with rule-based rewards. However, recent studies reveal a critical constraint: reinforcement learning succeeds only when the base model already assigns non-negligible probability to correct answers -- a property we term 'latent solvability'. This work investigates the emergence of chemical reasoning capabilities and what these prerequisites mean for chemistry. We identify two necessary conditions for RL-based chemical reasoning: 1) Symbolic competence, and 2) Latent chemical knowledge. We propose mid-stage scientific training (MiST): a set of mid-stage training techniques to satisfy these, including data-mixing with SMILES/CIF-aware pre-processing, continued pre-training on 2.9B tokens, and supervised fine-tuning on 1B tokens. These steps raise the latent-solvability score on 3B and 7B models by up to 1.8x, and enable RL to lift top-1 accuracy from 10.9 to 63.9% on organic reaction naming, and from 40.6 to 67.4% on inorganic material generation. Similar results are observed for other challenging chemical tasks, while producing interpretable reasoning traces. Our results define clear prerequisites for chemical reasoning training and highlight the broader role of mid-stage training in unlocking reasoning capabilities.","authors":["Andres M Bran","Tong Xie","Shai Pranesh","Jeffrey Meng","Xuan Vu Nguyen","Jeremy Goumaz","David Ming Segura","Ruizhi Xu","Dongzhan Zhou","Wenjie Zhang","Bram Hoex","Philippe Schwaller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.23117v4","updated":"2025-12-24T14:58:32Z","published":"2025-10-27T08:38:17Z","title":"Seeing Structural Failure Before it Happens: An Image-Based Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction","summary":"Physics Informed Neural Networks (PINNs) are gaining attention for their ability to embed physical laws into deep learning models, which is particularly useful in structural engineering tasks with limited data. This paper aims to explore the use of PINNs to predict the weight of small scale spaghetti bridges, a task relevant to understanding load limits and potential failure modes in simplified structural models. Our proposed framework incorporates physics-based constraints to the prediction model for improved performance. In addition to standard PINNs, we introduce a novel architecture named Physics Informed Kolmogorov Arnold Network (PIKAN), which blends universal function approximation theory with physical insights. The structural parameters provided as input to the model are collected either manually or through computer vision methods. Our dataset includes 15 real bridges, augmented to 100 samples, and our best model achieves an $R^2$ score of 0.9603 and a mean absolute error (MAE) of 10.50 units. From applied perspective, we also provide a web based interface for parameter entry and prediction. These results show that PINNs can offer reliable estimates of structural weight, even with limited data, and may help inform early stage failure analysis in lightweight bridge designs.\n  The complete data and code are available at https://github.com/OmerJauhar/PINNS-For-Spaghetti-Bridges.","authors":["Omer Jauhar Khan","Sudais Khan","Hafeez Anwar","Shahzeb Khan","Shams Ul Arifeen","Farman Ullah"],"pdf_url":"","comment":"14 pages, 21 figures. Preprint"},{"id":"http://arxiv.org/abs/2507.13704v3","updated":"2025-12-24T14:56:07Z","published":"2025-07-18T07:12:19Z","title":"A study of EHVI vs fixed scalarization for molecule design","summary":"Multi-objective Bayesian optimization (MOBO) provides a principled framework for navigating trade-offs in molecular design. However, its empirical advantages over scalarized alternatives remain underexplored. We benchmark a simple Pareto-based MOBO strategy - Expected Hypervolume Improvement (EHVI) - against a simple fixed-weight scalarized baseline using Expected Improvement (EI), under a tightly controlled setup with identical Gaussian Process surrogates and molecular representations. Across three molecular optimization tasks, EHVI consistently outperforms scalarized EI in terms of Pareto front coverage, convergence speed, and chemical diversity. While scalarization encompasses flexible variants - including random or adaptive schemes - our results show that even strong deterministic instantiations can underperform in low-data regimes. These findings offer concrete evidence for the practical advantages of Pareto-aware acquisition in de novo molecular optimization, especially when evaluation budgets are limited and trade-offs are nontrivial.","authors":["Anabel Yong","Austin Tripp","Layla Hosseini-Gerami","Brooks Paige"],"pdf_url":"","comment":"Accepted to NeurIPS AI4Science Workshop 2025"},{"id":"http://arxiv.org/abs/2508.21010v2","updated":"2025-12-24T14:52:45Z","published":"2025-08-28T17:10:53Z","title":"ChainReaction: Causal Chain-Guided Reasoning for Modular and Explainable Causal-Why Video Question Answering","summary":"Existing Causal-Why Video Question Answering (VideoQA) models often struggle with higher-order reasoning, relying on opaque, monolithic pipelines that entangle video understanding, causal inference, and answer generation. These black-box approaches offer limited interpretability and tend to depend on shallow heuristics. We propose a novel, modular paradigm that explicitly decouples causal reasoning from answer generation, introducing natural language causal chains as interpretable intermediate representations. Inspired by human cognitive models, these structured cause-effect sequences bridge low-level video content with high-level causal reasoning, enabling transparent and logically coherent inference. Our two-stage architecture comprises a Causal Chain Extractor (CCE) that generates causal chains from video-question pairs, and a Causal Chain-Driven Answerer (CCDA) that derives answers grounded in these chains. To address the lack of annotated reasoning traces, we introduce a scalable method for generating accurate causal chains from existing datasets. We construct human verified causal chains for 46K samples. We also propose CauCo, a new evaluation metric for causality-oriented captioning. Experiments on three large-scale benchmarks demonstrate that our approach not only outperforms state-of-the-art models, but also yields substantial gains in explainability, user trust, and generalization -- positioning the CCE as a reusable causal reasoning engine across diverse domains. Project page: https://paritoshparmar.github.io/chainreaction/","authors":["Paritosh Parmar","Eric Peh","Basura Fernando"],"pdf_url":"","comment":"Project page: https://paritoshparmar.github.io/chainreaction/"},{"id":"http://arxiv.org/abs/2512.21211v1","updated":"2025-12-24T14:51:12Z","published":"2025-12-24T14:51:12Z","title":"Causal-driven attribution (CDA): Estimating channel influence without user-level data","summary":"Attribution modelling lies at the heart of marketing effectiveness, yet most existing approaches depend on user-level path data, which are increasingly inaccessible due to privacy regulations and platform restrictions. This paper introduces a Causal-Driven Attribution (CDA) framework that infers channel influence using only aggregated impression-level data, avoiding any reliance on user identifiers or click-path tracking. CDA integrates temporal causal discovery (using PCMCI) with causal effect estimation via a Structural Causal Model to recover directional channel relationships and quantify their contributions to conversions. Using large-scale synthetic data designed to replicate real marketing dynamics, we show that CDA achieves an average relative RMSE of 9.50% when given the true causal graph, and 24.23% when using the predicted graph, demonstrating strong accuracy under correct structure and meaningful signal recovery even under structural uncertainty. CDA captures cross-channel interdependencies while providing interpretable, privacy-preserving attribution insights, offering a scalable and future-proof alternative to traditional path-based models.","authors":["Georgios Filippou","Boi Mai Quach","Diana Lenghel","Arthur White","Ashish Kumar Jha"],"pdf_url":"","comment":"42 pages, 8 figures, submitted initially to the journal of the academy of marketing science on 24th Dec 2025"},{"id":"http://arxiv.org/abs/2512.21208v1","updated":"2025-12-24T14:43:59Z","published":"2025-12-24T14:43:59Z","title":"Analytic and Variational Stability of Deep Learning Systems","summary":"We propose a unified analytic and variational framework for studying stability in deep learning systems viewed as coupled representation-parameter dynamics. The central object is the Learning Stability Profile, which tracks the infinitesimal response of representations, parameters, and update mechanisms to perturbations along the learning trajectory. We prove a Fundamental Analytic Stability Theorem showing that uniform boundedness of these stability signatures is equivalent, up to norm equivalence, to the existence of a Lyapunov-type energy that dissipates along the learning flow. In smooth regimes, the framework yields explicit stability exponents linking spectral norms, activation regularity, step sizes, and learning rates to contractivity of the learning dynamics. Classical spectral stability results for feedforward networks, a discrete CFL-type condition for residual architectures, and parametric and temporal stability laws for stochastic gradient methods arise as direct consequences. The theory extends to non-smooth learning systems, including ReLU networks, proximal and projected updates, and stochastic subgradient flows, by replacing classical derivatives with Clarke generalized derivatives and smooth energies with variational Lyapunov functionals. The resulting framework provides a unified dynamical description of stability across architectures and optimization methods, clarifying how architectural and algorithmic choices jointly govern robustness and sensitivity to perturbations. It also provides a foundation for further extensions to continuous-time limits and geometric formulations of learning dynamics.","authors":["Ronald Katende"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.11998v3","updated":"2025-12-24T13:44:53Z","published":"2025-05-17T13:19:01Z","title":"Parameter Efficient Continual Learning with Dynamic Low-Rank Adaptation","summary":"Catastrophic forgetting has remained a critical challenge for deep neural networks in Continual Learning (CL) as it undermines consolidated knowledge when learning new tasks. Parameter efficient fine tuning CL techniques are gaining traction for their effectiveness in addressing catastrophic forgetting with a lightweight training schedule while avoiding degradation of consolidated knowledge in pre-trained models. However, low rank adapters (LoRA) in these approaches are highly sensitive to rank selection which can lead to sub-optimal resource allocation and performance. To this end, we introduce PEARL, a rehearsal-free CL framework that entails dynamic rank allocation for LoRA components during CL training. Specifically, PEARL leverages reference task weights and adaptively determines the rank of task-specific LoRA components based on the current tasks' proximity to reference task weights in parameter space. To demonstrate the versatility of PEARL, we evaluate it across three vision architectures (ResNet, Separable Convolutional Network and Vision Transformer) and a multitude of CL scenarios, and show that PEARL outperforms all considered baselines by a large margin.","authors":["Prashant Shivaram Bhat","Shakib Yazdani","Elahe Arani","Bahram Zonooz"],"pdf_url":"","comment":"27 pages, 5 figures"},{"id":"http://arxiv.org/abs/2512.21170v1","updated":"2025-12-24T13:39:11Z","published":"2025-12-24T13:39:11Z","title":"A Unified Framework for EEG Seizure Detection Using Universum-Integrated Generalized Eigenvalues Proximal Support Vector Machine","summary":"The paper presents novel Universum-enhanced classifiers: the Universum Generalized Eigenvalue Proximal Support Vector Machine (U-GEPSVM) and the Improved U-GEPSVM (IU-GEPSVM) for EEG signal classification. Using the computational efficiency of generalized eigenvalue decomposition and the generalization benefits of Universum learning, the proposed models address critical challenges in EEG analysis: non-stationarity, low signal-to-noise ratio, and limited labeled data. U-GEPSVM extends the GEPSVM framework by incorporating Universum constraints through a ratio-based objective function, while IU-GEPSVM enhances stability through a weighted difference-based formulation that provides independent control over class separation and Universum alignment. The models are evaluated on the Bonn University EEG dataset across two binary classification tasks: (O vs S)-healthy (eyes closed) vs seizure, and (Z vs S)-healthy (eyes open) vs seizure. IU-GEPSVM achieves peak accuracies of 85% (O vs S) and 80% (Z vs S), with mean accuracies of 81.29% and 77.57% respectively, outperforming baseline methods.","authors":["Yogesh Kumar","Vrushank Ahire","M. A. Ganaie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.04332v3","updated":"2025-12-24T13:37:40Z","published":"2025-12-03T23:45:07Z","title":"Data-regularized Reinforcement Learning for Diffusion Models at Scale","summary":"Aligning generative diffusion models with human preferences via reinforcement learning (RL) is critical yet challenging. Most existing algorithms are often vulnerable to reward hacking, such as quality degradation, over-stylization, or reduced diversity. Our analysis demonstrates that this can be attributed to the inherent limitations of their regularization, which provides unreliable penalties. We introduce Data-regularized Diffusion Reinforcement Learning (DDRL), a novel framework that uses the forward KL divergence to anchor the policy to an off-policy data distribution. Theoretically, DDRL enables robust, unbiased integration of RL with standard diffusion training. Empirically, this translates into a simple yet effective algorithm that combines reward maximization with diffusion loss minimization. With over a million GPU hours of experiments and ten thousand double-blind human evaluations, we demonstrate on high-resolution video generation tasks that DDRL significantly improves rewards while alleviating the reward hacking seen in baselines, achieving the highest human preference and establishing a robust and scalable paradigm for diffusion post-training.","authors":["Haotian Ye","Kaiwen Zheng","Jiashu Xu","Puheng Li","Huayu Chen","Jiaqi Han","Sheng Liu","Qinsheng Zhang","Hanzi Mao","Zekun Hao","Prithvijit Chattopadhyay","Dinghao Yang","Liang Feng","Maosheng Liao","Junjie Bai","Ming-Yu Liu","James Zou","Stefano Ermon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21166v1","updated":"2025-12-24T13:31:34Z","published":"2025-12-24T13:31:34Z","title":"A Community-Enhanced Graph Representation Model for Link Prediction","summary":"Although Graph Neural Networks (GNNs) have become the dominant approach for graph representation learning, their performance on link prediction tasks does not always surpass that of traditional heuristic methods such as Common Neighbors and Jaccard Coefficient. This is mainly because existing GNNs tend to focus on learning local node representations, making it difficult to effectively capture structural relationships between node pairs. Furthermore, excessive reliance on local neighborhood information can lead to over-smoothing. Prior studies have shown that introducing global structural encoding can partially alleviate this issue. To address these limitations, we propose a Community-Enhanced Link Prediction (CELP) framework that incorporates community structure to jointly model local and global graph topology. Specifically, CELP enhances the graph via community-aware, confidence-guided edge completion and pruning, while integrating multi-scale structural features to achieve more accurate link prediction. Experimental results across multiple benchmark datasets demonstrate that CELP achieves superior performance, validating the crucial role of community structure in improving link prediction accuracy.","authors":["Lei Wang","Darong Lai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12867v2","updated":"2025-12-24T13:31:20Z","published":"2025-11-17T01:41:14Z","title":"Bootstrapping LLMs via Preference-Based Policy Optimization","summary":"Bootstrapping large language models (LLMs) through preference-based policy optimization offers a promising direction for aligning model behavior with human preferences without relying on extensive manual annotations. In this work, we propose a novel preference-based policy optimization (PbPO) framework that formulates the learning process as a min-max game between the main policy and a reward model (RM). The RM is constrained within a confidence set derived from preference data to ensure reliable exploitation. Our iterative online algorithm actively collects preference data through guided exploration of the evolving policy, enabling continual self-improvement of both the policy and the RM. We provide theoretical guarantees for our method, establishing high-probability regret bounds for both settings with sequence-level RM and token-level RM, demonstrating its effectiveness in bootstrapping LLMs. Extensive experiments on five benchmarks show that our approach consistently outperforms existing state-of-the-art preference optimization techniques.","authors":["Chen Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21165v1","updated":"2025-12-24T13:25:36Z","published":"2025-12-24T13:25:36Z","title":"BALLAST: Bandit-Assisted Learning for Latency-Aware Stable Timeouts in Raft","summary":"Randomized election timeouts are a simple and effective liveness heuristic for Raft, but they become brittle under long-tail latency, jitter, and partition recovery, where repeated split votes can inflate unavailability. This paper presents BALLAST, a lightweight online adaptation mechanism that replaces static timeout heuristics with contextual bandits. BALLAST selects from a discrete set of timeout \"arms\" using efficient linear contextual bandits (LinUCB variants), and augments learning with safe exploration to cap risk during unstable periods. We evaluate BALLAST on a reproducible discrete-event simulation with long-tail delay, loss, correlated bursts, node heterogeneity, and partition/recovery turbulence. Across challenging WAN regimes, BALLAST substantially reduces recovery time and unwritable time compared to standard randomized timeouts and common heuristics, while remaining competitive on stable LAN/WAN settings.","authors":["Qizhi Wang"],"pdf_url":"","comment":"15 pages, 22 tables, 11 figures"},{"id":"http://arxiv.org/abs/2512.21153v1","updated":"2025-12-24T12:45:36Z","published":"2025-12-24T12:45:36Z","title":"ElfCore: A 28nm Neural Processor Enabling Dynamic Structured Sparse Training and Online Self-Supervised Learning with Activity-Dependent Weight Update","summary":"In this paper, we present ElfCore, a 28nm digital spiking neural network processor tailored for event-driven sensory signal processing. ElfCore is the first to efficiently integrate: (1) a local online self-supervised learning engine that enables multi-layer temporal learning without labeled inputs; (2) a dynamic structured sparse training engine that supports high-accuracy sparse-to-sparse learning; and (3) an activity-dependent sparse weight update mechanism that selectively updates weights based solely on input activity and network dynamics. Demonstrated on tasks including gesture recognition, speech, and biomedical signal processing, ElfCore outperforms state-of-the-art solutions with up to 16X lower power consumption, 3.8X reduced on-chip memory requirements, and 5.9X greater network capacity efficiency.","authors":["Zhe Su","Giacomo Indiveri"],"pdf_url":"","comment":"This paper has been published in the proceedings of the 2025 IEEE European Solid-State Electronics Research Conference (ESSERC)"},{"id":"http://arxiv.org/abs/2512.21152v1","updated":"2025-12-24T12:43:40Z","published":"2025-12-24T12:43:40Z","title":"MODE: Multi-Objective Adaptive Coreset Selection","summary":"We present Mode(Multi-Objective adaptive Data Efficiency), a framework that dynamically combines coreset selection strategies based on their evolving contribution to model performance. Unlike static methods, \\mode adapts selection criteria to training phases: emphasizing class balance early, diversity during representation learning, and uncertainty at convergence. We show that MODE achieves (1-1/e)-approximation with O(n \\log n) complexity and demonstrates competitive accuracy while providing interpretable insights into data utility evolution. Experiments show \\mode reduces memory requirements","authors":["Tanmoy Mukherjee","Pierre Marquis","Zied Bouraoui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21132v1","updated":"2025-12-24T12:02:00Z","published":"2025-12-24T12:02:00Z","title":"AutoBaxBuilder: Bootstrapping Code Security Benchmarking","summary":"As LLMs see wide adoption in software engineering, the reliable assessment of the correctness and security of LLM-generated code is crucial. Notably, prior work has demonstrated that security is often overlooked, exposing that LLMs are prone to generating code with security vulnerabilities. These insights were enabled by specialized benchmarks, crafted through significant manual effort by security experts. However, relying on manually-crafted benchmarks is insufficient in the long term, because benchmarks (i) naturally end up contaminating training data, (ii) must extend to new tasks to provide a more complete picture, and (iii) must increase in difficulty to challenge more capable LLMs. In this work, we address these challenges and present AutoBaxBuilder, a framework that generates tasks and tests for code security benchmarking from scratch. We introduce a robust pipeline with fine-grained plausibility checks, leveraging the code understanding capabilities of LLMs to construct functionality tests and end-to-end security-probing exploits. To confirm the quality of the generated benchmark, we conduct both a qualitative analysis and perform quantitative experiments, comparing it against tasks constructed by human experts. We use AutoBaxBuilder to construct entirely new tasks and release them to the public as AutoBaxBench, together with a thorough evaluation of the security capabilities of LLMs on these tasks. We find that a new task can be generated in under 2 hours, costing less than USD 10.","authors":["Tobias von Arx","Niels Mündler","Mark Vero","Maximilian Baader","Martin Vechev"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.23383v3","updated":"2025-12-24T11:43:45Z","published":"2025-05-29T12:04:07Z","title":"Automated Modeling Method for Pathloss Model Discovery","summary":"Modeling propagation is the cornerstone for designing and optimizing next-generation wireless systems, with a particular emphasis on 5G and beyond era. Traditional modeling methods have long relied on statistic-based techniques to characterize propagation behavior across different environments. With the expansion of wireless communication systems, there is a growing demand for methods that guarantee the accuracy and interpretability of modeling. Artificial intelligence (AI)-based techniques, in particular, are increasingly being adopted to overcome this challenge, although the interpretability is not assured with most of these methods. Inspired by recent advancements in AI, this paper proposes a novel approach that accelerates the discovery of path loss models while maintaining interpretability. The proposed method automates the formulation, evaluation, and refinement of the model, facilitating the discovery of the model. We examine two techniques: one based on Deep Symbolic Regression, offering full interpretability, and the second based on Kolmogorov-Arnold Networks, providing two levels of interpretability. Both approaches are evaluated on two synthetic and two real-world datasets. Our results show that Kolmogorov-Arnold Networks achieve the coefficient of determination value R^2 close to 1 with minimal prediction error, while Deep Symbolic Regression generates compact models with moderate accuracy. Moreover, on the selected examples, we demonstrate that automated methods outperform traditional methods, achieving up to 75% reduction in prediction errors, offering accurate and explainable solutions with potential to increase the efficiency of discovering next-generation path loss models.","authors":["Ahmad Anaqreh","Shih-Kai Chou","Mihael Mohorčič","Thomas Lagkas","Carolina Fortuna"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21118v1","updated":"2025-12-24T11:34:44Z","published":"2025-12-24T11:34:44Z","title":"STLDM: Spatio-Temporal Latent Diffusion Model for Precipitation Nowcasting","summary":"Precipitation nowcasting is a critical spatio-temporal prediction task for society to prevent severe damage owing to extreme weather events. Despite the advances in this field, the complex and stochastic nature of this task still poses challenges to existing approaches. Specifically, deterministic models tend to produce blurry predictions while generative models often struggle with poor accuracy. In this paper, we present a simple yet effective model architecture termed STLDM, a diffusion-based model that learns the latent representation from end to end alongside both the Variational Autoencoder and the conditioning network. STLDM decomposes this task into two stages: a deterministic forecasting stage handled by the conditioning network, and an enhancement stage performed by the latent diffusion model. Experimental results on multiple radar datasets demonstrate that STLDM achieves superior performance compared to the state of the art, while also improving inference efficiency. The code is available in https://github.com/sqfoo/stldm_official.","authors":["Shi Quan Foo","Chi-Ho Wong","Zhihan Gao","Dit-Yan Yeung","Ka-Hing Wong","Wai-Kin Wong"],"pdf_url":"","comment":"Accepted by TMLR. Camera-ready submission"},{"id":"http://arxiv.org/abs/2512.21113v1","updated":"2025-12-24T11:21:07Z","published":"2025-12-24T11:21:07Z","title":"A Mechanistic Analysis of Transformers for Dynamical Systems","summary":"Transformers are increasingly adopted for modeling and forecasting time-series, yet their internal mechanisms remain poorly understood from a dynamical systems perspective. In contrast to classical autoregressive and state-space models, which benefit from well-established theoretical foundations, Transformer architectures are typically treated as black boxes. This gap becomes particularly relevant as attention-based models are considered for general-purpose or zero-shot forecasting across diverse dynamical regimes. In this work, we do not propose a new forecasting model, but instead investigate the representational capabilities and limitations of single-layer Transformers when applied to dynamical data. Building on a dynamical systems perspective we interpret causal self-attention as a linear, history-dependent recurrence and analyze how it processes temporal information. Through a series of linear and nonlinear case studies, we identify distinct operational regimes. For linear systems, we show that the convexity constraint imposed by softmax attention fundamentally restricts the class of dynamics that can be represented, leading to oversmoothing in oscillatory settings. For nonlinear systems under partial observability, attention instead acts as an adaptive delay-embedding mechanism, enabling effective state reconstruction when sufficient temporal context and latent dimensionality are available. These results help bridge empirical observations with classical dynamical systems theory, providing insight into when and why Transformers succeed or fail as models of dynamical systems.","authors":["Gregory Duthé","Nikolaos Evangelou","Wei Liu","Ioannis G. Kevrekidis","Eleni Chatzi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21107v1","updated":"2025-12-24T11:12:09Z","published":"2025-12-24T11:12:09Z","title":"Semi-Supervised Learning for Large Language Models Safety and Content Moderation","summary":"Safety for Large Language Models (LLMs) has been an ongoing research focus since their emergence and is even more relevant nowadays with the increasing capacity of those models. Currently, there are several guardrails in place for all public LLMs and multiple proposed datasets for training safety classifiers. However, training these safety classifiers relies on large quantities of labeled data, which can be problematic to acquire, prone to labeling errors, or often include synthetic data. To address these issues, we suggest a different approach: utilizing semi-supervised learning techniques, which leverage both labeled and unlabeled data, to improve the performance on the safety task. We analyze the improvements that these techniques can offer for both prompts given to Large Language Models and the responses to those requests. Moreover, since augmentation is the central part of semi-supervised algorithms, we demonstrate the importance of using task-specific augmentations, which significantly increase the performance when compared to general-purpose augmentation techniques.","authors":["Eduard Stefan Dinuta","Iustin Sirbu","Traian Rebedea"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21106v1","updated":"2025-12-24T11:10:28Z","published":"2025-12-24T11:10:28Z","title":"Semantic Refinement with LLMs for Graph Representations","summary":"Graph-structured data exhibit substantial heterogeneity in where their predictive signals originate: in some domains, node-level semantics dominate, while in others, structural patterns play a central role. This structure-semantics heterogeneity implies that no graph learning model with a fixed inductive bias can generalize optimally across diverse graph domains. However, most existing methods address this challenge from the model side by incrementally injecting new inductive biases, which remains fundamentally limited given the open-ended diversity of real-world graphs. In this work, we take a data-centric perspective and treat node semantics as a task-adaptive variable. We propose a Data-Adaptive Semantic Refinement framework DAS for graph representation learning, which couples a fixed graph neural network (GNN) and a large language model (LLM) in a closed feedback loop. The GNN provides implicit supervisory signals to guide the semantic refinement of LLM, and the refined semantics are fed back to update the same graph learner. We evaluate our approach on both text-rich and text-free graphs. Results show consistent improvements on structure-dominated graphs while remaining competitive on semantics-rich graphs, demonstrating the effectiveness of data-centric semantic adaptation under structure-semantics heterogeneity.","authors":["Safal Thapaliya","Zehong Wang","Jiazheng Li","Ziming Li","Yanfang Ye","Chuxu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21102v1","updated":"2025-12-24T11:02:03Z","published":"2025-12-24T11:02:03Z","title":"Shared Representation Learning for High-Dimensional Multi-Task Forecasting under Resource Contention in Cloud-Native Backends","summary":"This study proposes a unified forecasting framework for high-dimensional multi-task time series to meet the prediction demands of cloud native backend systems operating under highly dynamic loads, coupled metrics, and parallel tasks. The method builds a shared encoding structure to represent diverse monitoring indicators in a unified manner and employs a state fusion mechanism to capture trend changes and local disturbances across different time scales. A cross-task structural propagation module is introduced to model potential dependencies among nodes, enabling the model to understand complex structural patterns formed by resource contention, link interactions, and changes in service topology. To enhance adaptability to non-stationary behaviors, the framework incorporates a dynamic adjustment mechanism that automatically regulates internal feature flows according to system state changes, ensuring stable predictions in the presence of sudden load shifts, topology drift, and resource jitter. The experimental evaluation compares multiple models across various metrics and verifies the effectiveness of the framework through analyses of hyperparameter sensitivity, environmental sensitivity, and data sensitivity. The results show that the proposed method achieves superior performance on several error metrics and provides more accurate representations of future states under different operating conditions. Overall, the unified forecasting framework offers reliable predictive capability for high-dimensional, multi-task, and strongly dynamic environments in cloud native systems and provides essential technical support for intelligent backend management.","authors":["Zixiao Huang","Jixiao Yang","Sijia Li","Chi Zhang","Jinyu Chen","Chengda Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.11831v3","updated":"2025-12-24T10:53:25Z","published":"2025-12-03T09:28:29Z","title":"On the Design of One-step Diffusion via Shortcutting Flow Paths","summary":"Recent advances in few-step diffusion models have demonstrated their efficiency and effectiveness by shortcutting the probabilistic paths of diffusion models, especially in training one-step diffusion models from scratch (\\emph{a.k.a.} shortcut models). However, their theoretical derivation and practical implementation are often closely coupled, which obscures the design space. To address this, we propose a common design framework for representative shortcut models. This framework provides theoretical justification for their validity and disentangles concrete component-level choices, thereby enabling systematic identification of improvements. With our proposed improvements, the resulting one-step model achieves a new state-of-the-art FID50k of 2.85 on ImageNet-256x256 under the classifier-free guidance setting with one step generation, and further reaches FID50k of 2.53 with 2x training steps. Remarkably, the model requires no pre-training, distillation, or curriculum learning. We believe our work lowers the barrier to component-level innovation in shortcut models and facilitates principled exploration of their design space.","authors":["Haitao Lin","Peiyan Hu","Minsi Ren","Zhifeng Gao","Zhi-Ming Ma","Guolin ke","Tailin Wu","Stan Z. Li"],"pdf_url":"","comment":"10 pages of main body, conference paper"},{"id":"http://arxiv.org/abs/2502.11609v3","updated":"2025-12-24T10:22:07Z","published":"2025-02-17T09:52:19Z","title":"Exploiting Task Relationships in Continual Learning via Transferability-Aware Task Embeddings","summary":"Continual learning (CL) has been a critical topic in contemporary deep neural network applications, where higher levels of both forward and backward transfer are desirable for an effective CL performance. Existing CL strategies primarily focus on task models, either by regularizing model updates or by separating task-specific and shared components, while often overlooking the potential of leveraging inter-task relationships to enhance transfer. To address this gap, we propose a transferability-aware task embedding, termed H-embedding, and construct a hypernet framework under its guidance to learn task-conditioned model weights for CL tasks. Specifically, H-embedding is derived from an information theoretic measure of transferability and is designed to be online and easy to compute. Our method is also characterized by notable practicality, requiring only the storage of a low-dimensional task embedding per task and supporting efficient end-to-end training. Extensive evaluations on benchmarks including CIFAR-100, ImageNet-R, and DomainNet show that our framework performs prominently compared to various baseline and SOTA approaches, demonstrating strong potential in capturing and utilizing intrinsic task relationships. Our code is publicly available at https://github.com/viki760/H-embedding-Guided-Hypernet.","authors":["Yanru Wu","Jianning Wang","Xiangyu Chen","Enming Zhang","Yang Tan","Hanbing Liu","Yang Li"],"pdf_url":"","comment":"28 pages, 5 figures, accepted by NeurIPS 2025"},{"id":"http://arxiv.org/abs/2210.13327v2","updated":"2025-12-24T10:04:30Z","published":"2022-10-24T15:28:43Z","title":"Deep Kronecker Network","summary":"We propose Deep Kronecker Network (DKN), a novel framework designed for analyzing medical imaging data, such as MRI, fMRI, CT, etc. Medical imaging data is different from general images in at least two aspects: i) sample size is usually much more limited, ii) model interpretation is more of a concern compared to outcome prediction. Due to its unique nature, general methods, such as convolutional neural network (CNN), are difficult to be directly applied. As such, we propose DKN, that is able to i) adapt to low sample size limitation, ii) provide desired model interpretation, and iii) achieve the prediction power as CNN. The DKN is general in the sense that it not only works for both matrix and (high-order) tensor represented image data, but also could be applied to both discrete and continuous outcomes. The DKN is built on a Kronecker product structure and implicitly imposes a piecewise smooth property on coefficients. Moreover, the Kronecker structure can be written into a convolutional form, so DKN also resembles a CNN, particularly, a fully convolutional network (FCN). Furthermore, we prove that with an alternating minimization algorithm, the solutions of DKN are guaranteed to converge to the truth geometrically even if the objective function is highly nonconvex. Interestingly, the DKN is also highly connected to the tensor regression framework proposed by Zhou et al. (2010), where a CANDECOMP/PARAFAC (CP) low-rank structure is imposed on tensor coefficients. Finally, we conduct both classification and regression analyses using real MRI data from the Alzheimer's Disease Neuroimaging Initiative (ADNI) to demonstrate the effectiveness of DKN.","authors":["Long Feng","Guang Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21083v1","updated":"2025-12-24T09:58:30Z","published":"2025-12-24T09:58:30Z","title":"Hierarchical Modeling Approach to Fast and Accurate Table Recognition","summary":"The extraction and use of diverse knowledge from numerous documents is a pressing challenge in intelligent information retrieval. Documents contain elements that require different recognition methods. Table recognition typically consists of three subtasks, namely table structure, cell position and cell content recognition. Recent models have achieved excellent recognition with a combination of multi-task learning, local attention, and mutual learning. However, their effectiveness has not been fully explained, and they require a long period of time for inference. This paper presents a novel multi-task model that utilizes non-causal attention to capture the entire table structure, and a parallel inference algorithm for faster cell content inference. The superiority is demonstrated both visually and statistically on two large public datasets.","authors":["Takaya Kawakatsu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21081v1","updated":"2025-12-24T09:56:28Z","published":"2025-12-24T09:56:28Z","title":"Dyna-Style Reinforcement Learning Modeling and Control of Non-linear Dynamics","summary":"Controlling systems with complex, nonlinear dynamics poses a significant challenge, particularly in achieving efficient and robust control. In this paper, we propose a Dyna-Style Reinforcement Learning control framework that integrates Sparse Identification of Nonlinear Dynamics (SINDy) with Twin Delayed Deep Deterministic Policy Gradient (TD3) reinforcement learning. SINDy is used to identify a data-driven model of the system, capturing its key dynamics without requiring an explicit physical model. This identified model is used to generate synthetic rollouts that are periodically injected into the reinforcement learning replay buffer during training on the real environment, enabling efficient policy learning with limited data available. By leveraging this hybrid approach, we mitigate the sample inefficiency of traditional model-free reinforcement learning methods while ensuring accurate control of nonlinear systems. To demonstrate the effectiveness of this framework, we apply it to a bi-rotor system as a case study, evaluating its performance in stabilization and trajectory tracking. The results show that our SINDy-TD3 approach achieves superior accuracy and robustness compared to direct reinforcement learning techniques, highlighting the potential of combining data-driven modeling with reinforcement learning for complex dynamical systems.","authors":["Karim Abdelsalam","Zeyad Gamal","Ayman El-Badawy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21080v1","updated":"2025-12-24T09:56:00Z","published":"2025-12-24T09:56:00Z","title":"LLM Personas as a Substitute for Field Experiments in Method Benchmarking","summary":"Field experiments (A/B tests) are often the most credible benchmark for methods in societal systems, but their cost and latency create a major bottleneck for iterative method development. LLM-based persona simulation offers a cheap synthetic alternative, yet it is unclear whether replacing humans with personas preserves the benchmark interface that adaptive methods optimize against. We prove an if-and-only-if characterization: when (i) methods observe only the aggregate outcome (aggregate-only observation) and (ii) evaluation depends only on the submitted artifact and not on the algorithm's identity or provenance (algorithm-blind evaluation), swapping humans for personas is just panel change from the method's point of view, indistinguishable from changing the evaluation population (e.g., New York to Jakarta). Furthermore, we move from validity to usefulness: we define an information-theoretic discriminability of the induced aggregate channel and show that making persona benchmarking as decision-relevant as a field experiment is fundamentally a sample-size question, yielding explicit bounds on the number of independent persona evaluations required to reliably distinguish meaningfully different methods at a chosen resolution.","authors":["Enoch Hyunwook Kang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21076v1","updated":"2025-12-24T09:49:56Z","published":"2025-12-24T09:49:56Z","title":"Blurb-Refined Inference from Crowdsourced Book Reviews using Hierarchical Genre Mining with Dual-Path Graph Convolutions","summary":"Accurate book genre classification is fundamental to digital library organization, content discovery, and personalized recommendation. Existing approaches typically model genre prediction as a flat, single-label task, ignoring hierarchical genre structure and relying heavily on noisy, subjective user reviews, which often degrade classification reliability. We propose HiGeMine, a two-phase hierarchical genre mining framework that robustly integrates user reviews with authoritative book blurbs. In the first phase, HiGeMine employs a zero-shot semantic alignment strategy to filter reviews, retaining only those semantically consistent with the corresponding blurb, thereby mitigating noise, bias, and irrelevance. In the second phase, we introduce a dual-path, two-level graph-based classification architecture: a coarse-grained Level-1 binary classifier distinguishes fiction from non-fiction, followed by Level-2 multi-label classifiers for fine-grained genre prediction. Inter-genre dependencies are explicitly modeled using a label co-occurrence graph, while contextual representations are derived from pretrained language models applied to the filtered textual content. To facilitate systematic evaluation, we curate a new hierarchical book genre dataset. Extensive experiments demonstrate that HiGeMine consistently outperformed strong baselines across hierarchical genre classification tasks. The proposed framework offers a principled and effective solution for leveraging both structured and unstructured textual data in hierarchical book genre analysis.","authors":["Suraj Kumar","Utsav Kumar Nareti","Soumi Chattopadhyay","Chandranath Adak","Prolay Mallick"],"pdf_url":"","comment":"10 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2512.21075v1","updated":"2025-12-24T09:39:04Z","published":"2025-12-24T09:39:04Z","title":"Understanding Scaling Laws in Deep Neural Networks via Feature Learning Dynamics","summary":"The empirical success of deep learning is often attributed to scaling laws that predict consistent gains as model, data, and compute grow; however, large models can exhibit training instability and diminishing returns, suggesting that scaling laws describe what success looks like but not when and why scaling succeeds or fails. A central obstacle is the lack of a rigorous understanding of feature learning at large depth. While muP characterizes feature-learning dynamics in the infinite-width limit and enables hyperparameter transfer across width, its depth extension (depth-muP) breaks down for residual blocks with more than one internal layer. We derive Neural Feature Dynamics (NFD) for ResNets with single-layer residual blocks, characterizing feature learning via a coupled forward-backward stochastic system in the joint infinite-width and infinite-depth limit. In this regime, NFD identifies when scaling-law trends persist and explains diminishing returns. It also reveals a vanishing mechanism induced by the 1/sqrt(depth) residual scaling under which the gradient-independence assumption (GIA), known to fail during training at finite depth, becomes provably valid again at infinite depth, yielding an analytically tractable regime for end-to-end feature learning. Motivated by this insight, we study two-layer residual blocks and show that the same mechanism causes feature-learning collapse in the first internal layer at large depth, providing a structural explanation for the empirical failure of depth-muP. Based on this diagnosis, we propose a depth-aware learning-rate correction that counteracts the collapse and empirically restores depth-wise hyperparameter transfer, yielding stronger performance in deeper ResNets.","authors":["Zihan Yao","Ruoyu Wu","Tianxiang Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14317v6","updated":"2025-12-24T09:06:26Z","published":"2025-11-18T10:21:07Z","title":"Intervention Efficiency and Perturbation Validation Framework: Capacity-Aware and Robust Clinical Model Selection under the Rashomon Effect","summary":"In clinical machine learning, the coexistence of multiple models with comparable performance (a manifestation of the Rashomon Effect) poses fundamental challenges for trustworthy deployment and evaluation. Small, imbalanced, and noisy datasets, coupled with high-dimensional and weakly identified clinical features, amplify this multiplicity and make conventional validation schemes unreliable. As a result, selecting among equally performing models becomes uncertain, particularly when resource constraints and operational priorities are not considered by conventional metrics like F1 score. To address these issues, we propose two complementary tools for robust model assessment and selection: Intervention Efficiency (IE) and the Perturbation Validation Framework (PVF). IE is a capacity-aware metric that quantifies how efficiently a model identifies actionable true positives when only limited interventions are feasible, thereby linking predictive performance with clinical utility. PVF introduces a structured approach to assess the stability of models under data perturbations, identifying models whose performance remains most invariant across noisy or shifted validation sets. Empirical results on synthetic and real-world healthcare datasets show that using these tools facilitates the selection of models that generalize more robustly and align with capacity constraints, offering a new direction for tackling the Rashomon Effect in clinical settings.","authors":["Yuwen Zhang","Viet Tran","Paul Weng"],"pdf_url":"","comment":"Accepted to the Workshop on Navigating Model Uncertainty and the Rashomon Effect: From Theory and Tools to Applications and Impact (AAAI 2026)"},{"id":"http://arxiv.org/abs/2504.04973v3","updated":"2025-12-24T08:54:34Z","published":"2025-04-07T11:58:19Z","title":"Ensuring Safety in an Uncertain Environment: Constrained MDPs via Stochastic Thresholds","summary":"This paper studies constrained Markov decision processes (CMDPs) with constraints against stochastic thresholds, aiming at safety of reinforcement learning in unknown and uncertain environments. We leverage a Growing-Window estimator sampling from interactions with the uncertain environment to estimate the thresholds, based on which we design Stochastic Pessimistic-Optimistic Thresholding (SPOT), a novel model-based primal-dual algorithm for multiple constraints against stochastic thresholds. SPOT enables reinforcement learning under both pessimistic and optimistic threshold settings. We prove that our algorithm achieves sublinear regret and constraint violation; i.e., a reward regret of $\\tilde{\\mathcal{O}}(\\sqrt{T})$ while allowing an $\\tilde{\\mathcal{O}}(\\sqrt{T})$ constraint violation over $T$ episodes. The theoretical guarantees show that our algorithm achieves performance comparable to that of an approach relying on fixed and clear thresholds. To the best of our knowledge, SPOT is the first reinforcement learning algorithm that realises theoretical guaranteed performance in an uncertain environment where even thresholds are unknown.","authors":["Qian Zuo","Fengxiang He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.22358v3","updated":"2025-12-24T08:45:34Z","published":"2025-09-26T13:53:56Z","title":"Stochastic activations","summary":"We introduce stochastic activations. This novel strategy randomly selects between several non-linear functions in the feed-forward layer of a large language model. In particular, we choose between SILU or RELU depending on a Bernoulli draw. This strategy circumvents the optimization problem associated with RELU, namely, the constant shape for negative inputs that prevents the gradient flow. We leverage this strategy in two ways:\n  (1) We use stochastic activations during pre-training and fine-tune the model with RELU, which is used at inference time to provide sparse latent vectors. This reduces the inference FLOPs and translates into a significant speedup on CPU and GPU. This leads to better results than training from scratch with the RELU activation function.\n  (2) We evaluate stochastic activations for sequence generation. This strategy performs reasonably well: it has higher diversity and has only slightly inferior performance to the best deterministic non-linearity, SILU, combined with temperature sampling. This provides an alternative way to increase the diversity of generated text.","authors":["Maria Lomeli","Matthijs Douze","Gergely Szilvasy","Loic Cabannes","Jade Copet","Sainbayar Sukhbaatar","Jason Weston","Gabriel Synnaeve","Pierre-Emmanuel Mazaré","Hervé Jégou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21054v1","updated":"2025-12-24T08:44:58Z","published":"2025-12-24T08:44:58Z","title":"DexAvatar: 3D Sign Language Reconstruction with Hand and Body Pose Priors","summary":"The trend in sign language generation is centered around data-driven generative methods that require vast amounts of precise 2D and 3D human pose data to achieve an acceptable generation quality. However, currently, most sign language datasets are video-based and limited to automatically reconstructed 2D human poses (i.e., keypoints) and lack accurate 3D information. Furthermore, existing state-of-the-art for automatic 3D human pose estimation from sign language videos is prone to self-occlusion, noise, and motion blur effects, resulting in poor reconstruction quality. In response to this, we introduce DexAvatar, a novel framework to reconstruct bio-mechanically accurate fine-grained hand articulations and body movements from in-the-wild monocular sign language videos, guided by learned 3D hand and body priors. DexAvatar achieves strong performance in the SGNify motion capture dataset, the only benchmark available for this task, reaching an improvement of 35.11% in the estimation of body and hand poses compared to the state-of-the-art. The official website of this work is: https://github.com/kaustesseract/DexAvatar.","authors":["Kaustubh Kundu","Hrishav Bakul Barua","Lucy Robertson-Bell","Zhixi Cai","Kalin Stefanov"],"pdf_url":"","comment":"Accepted in WACV 2026"},{"id":"http://arxiv.org/abs/2512.19735v2","updated":"2025-12-24T08:34:41Z","published":"2025-12-17T12:29:53Z","title":"Case Prompting to Mitigate Large Language Model Bias for ICU Mortality Prediction","summary":"Accurate mortality risk prediction for intensive care unit (ICU) patients is essential for clinical decision-making. Although large language models (LLMs) show promise in predicting outcomes from structured medical data, their predictions may exhibit demographic biases related to sex, age, and race, limiting their trustworthy use in clinical practice. Existing debiasing methods often reduce predictive performance, making it difficult to jointly optimize fairness and accuracy. In this study, we systematically examine bias in LLM-based ICU mortality prediction and propose a training-free, clinically adaptive prompting framework to simultaneously improve fairness and performance. We first develop a multi-dimensional bias assessment scheme for comprehensive model diagnosis. Building on this analysis, we introduce CAse Prompting (CAP), a novel prompting framework that integrates conventional debiasing prompts with case-based reasoning. CAP guides the model to learn from similar historical misprediction cases and their correct outcomes, enabling correction of biased reasoning patterns. Experiments on the MIMIC-IV dataset show that CAP substantially improves both predictive accuracy and fairness. CAP increases AUROC from 0.806 to 0.873 and AUPRC from 0.497 to 0.694, while reducing sex- and race-related disparities by over 90%. Feature reliance analysis further indicates highly consistent attention patterns across demographic groups, with similarity scores exceeding 0.98. These results demonstrate that LLMs exhibit measurable bias in ICU mortality prediction, and that a carefully designed prompting framework can effectively co-optimize fairness and performance without retraining, offering a transferable paradigm for equitable clinical decision support.","authors":["Gangxiong Zhang","Yongchao Long","Yong Zhang","Yuxi Zhou","Shenda Hong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/1912.03896v4","updated":"2025-12-24T08:34:27Z","published":"2019-12-09T08:24:29Z","title":"Explicit Group Sparse Projection with Applications to Deep Learning and NMF","summary":"We design a new sparse projection method for a set of vectors that guarantees a desired average sparsity level measured leveraging the popular Hoyer measure (an affine function of the ratio of the $\\ell_1$ and $\\ell_2$ norms). Existing approaches either project each vector individually or require the use of a regularization parameter which implicitly maps to the average $\\ell_0$-measure of sparsity. Instead, in our approach we set the sparsity level for the whole set explicitly and simultaneously project a group of vectors with the sparsity level of each vector tuned automatically. We show that the computational complexity of our projection operator is linear in the size of the problem. Additionally, we propose a generalization of this projection by replacing the $\\ell_1$ norm by its weighted version. We showcase the efficacy of our approach in both supervised and unsupervised learning tasks on image datasets including CIFAR10 and ImageNet. In deep neural network pruning, the sparse models produced by our method on ResNet50 have significantly higher accuracies at corresponding sparsity values compared to existing competitors. In nonnegative matrix factorization, our approach yields competitive reconstruction errors against state-of-the-art algorithms.","authors":["Riyasat Ohib","Nicolas Gillis","Niccolò Dalmasso","Sameena Shah","Vamsi K. Potluru","Sergey Plis"],"pdf_url":"","comment":"20 pages, 10 figures; major revisions; affiliation corrected, grant added"},{"id":"http://arxiv.org/abs/2512.20605v2","updated":"2025-12-24T08:32:45Z","published":"2025-12-23T18:51:50Z","title":"Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning","summary":"Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token can result in highly inefficient learning, particularly when rewards are sparse. Here, we show that it is possible to overcome this problem by acting and exploring within the internal representations of an autoregressive model. Specifically, to discover temporally-abstract actions, we introduce a higher-order, non-causal sequence model whose outputs control the residual stream activations of a base autoregressive model. On grid world and MuJoCo-based tasks with hierarchical structure, we find that the higher-order model learns to compress long activation sequence chunks onto internal controllers. Critically, each controller executes a sequence of behaviorally meaningful actions that unfold over long timescales and are accompanied with a learned termination condition, such that composing multiple controllers over time leads to efficient exploration on novel tasks. We show that direct internal controller reinforcement, a process we term \"internal RL\", enables learning from sparse rewards in cases where standard RL finetuning fails. Our results demonstrate the benefits of latent action generation and reinforcement in autoregressive models, suggesting internal RL as a promising avenue for realizing hierarchical RL within foundation models.","authors":["Seijin Kobayashi","Yanick Schimpf","Maximilian Schlegel","Angelika Steger","Maciej Wolczyk","Johannes von Oswald","Nino Scherrer","Kaitlin Maile","Guillaume Lajoie","Blake A. Richards","Rif A. Saurous","James Manyika","Blaise Agüera y Arcas","Alexander Meulemans","João Sacramento"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21048v1","updated":"2025-12-24T08:29:28Z","published":"2025-12-24T08:29:28Z","title":"zkFL-Health: Blockchain-Enabled Zero-Knowledge Federated Learning for Medical AI Privacy","summary":"Healthcare AI needs large, diverse datasets, yet strict privacy and governance constraints prevent raw data sharing across institutions. Federated learning (FL) mitigates this by training where data reside and exchanging only model updates, but practical deployments still face two core risks: (1) privacy leakage via gradients or updates (membership inference, gradient inversion) and (2) trust in the aggregator, a single point of failure that can drop, alter, or inject contributions undetected. We present zkFL-Health, an architecture that combines FL with zero-knowledge proofs (ZKPs) and Trusted Execution Environments (TEEs) to deliver privacy-preserving, verifiably correct collaborative training for medical AI. Clients locally train and commit their updates; the aggregator operates within a TEE to compute the global update and produces a succinct ZK proof (via Halo2/Nova) that it used exactly the committed inputs and the correct aggregation rule, without revealing any client update to the host. Verifier nodes validate the proof and record cryptographic commitments on-chain, providing an immutable audit trail and removing the need to trust any single party. We outline system and threat models tailored to healthcare, the zkFL-Health protocol, security/privacy guarantees, and a performance evaluation plan spanning accuracy, privacy risk, latency, and cost. This framework enables multi-institutional medical AI with strong confidentiality, integrity, and auditability, key properties for clinical adoption and regulatory compliance.","authors":["Savvy Sharma","George Petrovic","Sarthak Kaushik"],"pdf_url":"","comment":"10 pages, 1 figure, 5 tables"},{"id":"http://arxiv.org/abs/2510.00915v3","updated":"2025-12-24T08:25:26Z","published":"2025-10-01T13:56:44Z","title":"Reinforcement Learning with Verifiable yet Noisy Rewards under Imperfect Verifiers","summary":"Reinforcement Learning with Verifiable Rewards (RLVR) replaces costly human labeling with automated verifiers. To reduce verifier hacking, many RLVR systems binarize rewards to $\\{0,1\\}$, but imperfect verifiers inevitably introduce \\emph{false negatives} (rejecting correct answers) and \\emph{false positives} (accepting incorrect ones). We formalize verifier unreliability as a stochastic reward channel with asymmetric noise rates $ρ_0$ and $ρ_1$ -- the FP rate and the FN rate, respectively. From this abstraction we derive two lightweight corrections: (i) a \\emph{backward} correction that yields an unbiased surrogate reward and thus an unbiased policy-gradient estimator in expectation, and (ii) a \\emph{forward} correction that reweights score-function terms so the expected update aligns with the clean gradient direction and requires only the FN rate. We implement both as lightweight hooks in a group relative policy optimization pipeline, both corrections improve RLVR for math reasoning under synthetic and real verifier noise, with the forward variant being more stable under heavier noise. Finally, an appeals mechanism with a lightweight LLM verifier estimates the FN rate online and further improves performance.","authors":["Xin-Qiang Cai","Wei Wang","Feng Liu","Tongliang Liu","Gang Niu","Masashi Sugiyama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14368v2","updated":"2025-12-24T08:17:05Z","published":"2025-11-18T11:18:08Z","title":"O3SLM: Open Weight, Open Data, and Open Vocabulary Sketch-Language Model","summary":"While Large Vision Language Models (LVLMs) are increasingly deployed in real-world applications, their ability to interpret abstract visual inputs remains limited. Specifically, they struggle to comprehend hand-drawn sketches, a modality that offers an intuitive means of expressing concepts that are difficult to describe textually. We identify the primary bottleneck as the absence of a large-scale dataset that jointly models sketches, photorealistic images, and corresponding natural language instructions. To address this, we present two key contributions: (1) a new, large-scale dataset of image-sketch-instruction triplets designed to facilitate both pretraining and instruction tuning, and (2) O3SLM, an LVLM trained on this dataset. Comprehensive evaluations on multiple sketch-based tasks: (a) object localization, (b) counting, (c) image retrieval i.e., (SBIR and fine-grained SBIR), and (d) visual question answering (VQA); while incorporating the three existing sketch datasets, namely QuickDraw!, Sketchy, and Tu Berlin, along with our generated SketchVCL dataset, show that O3SLM achieves state-of-the-art performance, substantially outperforming existing LVLMs in sketch comprehension and reasoning.","authors":["Rishi Gupta","Mukilan Karuppasamy","Shyam Marjit","Aditay Tripathi","Anirban Chakraborty"],"pdf_url":"","comment":"Accepted to AAAI 2026"},{"id":"http://arxiv.org/abs/2512.21039v1","updated":"2025-12-24T08:06:52Z","published":"2025-12-24T08:06:52Z","title":"Agentic Multi-Persona Framework for Evidence-Aware Fake News Detection","summary":"The rapid proliferation of online misinformation poses significant risks to public trust, policy, and safety, necessitating reliable automated fake news detection. Existing methods often struggle with multimodal content, domain generalization, and explainability. We propose AMPEND-LS, an agentic multi-persona evidence-grounded framework with LLM-SLM synergy for multimodal fake news detection. AMPEND-LS integrates textual, visual, and contextual signals through a structured reasoning pipeline powered by LLMs, augmented with reverse image search, knowledge graph paths, and persuasion strategy analysis. To improve reliability, we introduce a credibility fusion mechanism combining semantic similarity, domain trustworthiness, and temporal context, and a complementary SLM classifier to mitigate LLM uncertainty and hallucinations. Extensive experiments across three benchmark datasets demonstrate that AMPEND-LS consistently outperformed state-of-the-art baselines in accuracy, F1 score, and robustness. Qualitative case studies further highlight its transparent reasoning and resilience against evolving misinformation. This work advances the development of adaptive, explainable, and evidence-aware systems for safeguarding online information integrity.","authors":["Roopa Bukke","Soumya Pandey","Suraj Kumar","Soumi Chattopadhyay","Chandranath Adak"],"pdf_url":"","comment":"12 pages, 8 tables, 2 figures"},{"id":"http://arxiv.org/abs/2509.26226v2","updated":"2025-12-24T08:05:31Z","published":"2025-09-30T13:25:00Z","title":"Thinking-Free Policy Initialization Makes Distilled Reasoning Models More Effective and Efficient Reasoners","summary":"Reinforcement Learning with Verifiable Reward (RLVR) effectively solves complex tasks but demands extremely long context lengths during training, leading to substantial computational costs. While multi-stage training can partially mitigate this, starting with overly short contexts often causes irreversible performance degradation, ultimately failing to reduce overall training compute significantly. In this paper, we introduce **T**hinking-**F**ree **P**olicy **I**nitialization (**TFPI**), a simple yet effective adaptation to RLVR that bridges long Chain-of-Thought (CoT) distillation and standard RLVR. TFPI employs a simple *ThinkFree* operation, explicitly discarding the thinking content via a direct *</think>* append, to reduce token usage during inference. Training with *ThinkFree*-adapted inputs improves performance and lowers token consumption, even in the original slow-thinking mode. Extensive experiments across various benchmarks have shown that TFPI accelerates RL convergence, achieves a higher performance ceiling, and yields more token-efficient reasoning models without specialized rewards or complex training designs. With TFPI only, we train a 4B model to reach 89.0% accuracy on AIME24 and 65.5% on LiveCodeBench using less than 4K H20 hours.","authors":["Xin Xu","Cliveb AI","Kai Yang","Tianhao Chen","Yang Wang","Saiyong Yang","Can Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21029v1","updated":"2025-12-24T07:52:23Z","published":"2025-12-24T07:52:23Z","title":"Critical Points of Degenerate Metrics on Algebraic Varieties: A Tale of Overparametrization","summary":"We study the critical points over an algebraic variety of an optimization problem defined by a quadratic objective that is degenerate. This scenario arises in machine learning when the dataset size is small with respect to the model, and is typically referred to as overparametrization. Our main result relates the degenerate optimization problem to a nondegenerate one via a projection. In the highly-degenerate regime, we find that a central role is played by the ramification locus of the projection. Additionally, we provide tools for counting the number of critical points over projective varieties, and discuss specific cases arising from deep learning. Our work bridges tools from algebraic geometry with ideas from machine learning, and it extends the line of literature around the Euclidean distance degree to the degenerate setting.","authors":["Giovanni Luca Marchetti","Erin Connelly","Paul Breiding","Kathlén Kohn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21021v1","updated":"2025-12-24T07:35:17Z","published":"2025-12-24T07:35:17Z","title":"Towards Better Search with Domain-Aware Text Embeddings for C2C Marketplaces","summary":"Consumer-to-consumer (C2C) marketplaces pose distinct retrieval challenges: short, ambiguous queries; noisy, user-generated listings; and strict production constraints. This paper reports our experiment to build a domain-aware Japanese text-embedding approach to improve the quality of search at Mercari, Japan's largest C2C marketplace. We experimented with fine-tuning on purchase-driven query-title pairs, using role-specific prefixes to model query-item asymmetry. To meet production constraints, we apply Matryoshka Representation Learning to obtain compact, truncation-robust embeddings. Offline evaluation on historical search logs shows consistent gains over a strong generic encoder, with particularly large improvements when replacing PCA compression with Matryoshka truncation. A manual assessment further highlights better handling of proper nouns, marketplace-specific semantics, and term-importance alignment. Additionally, an initial online A/B test demonstrates statistically significant improvements in revenue per user and search-flow efficiency, with transaction frequency maintained. Results show that domain-aware embeddings improve relevance and efficiency at scale and form a practical foundation for richer LLM-era search experiences.","authors":["Andre Rusli","Miao Cao","Shoma Ishimoto","Sho Akiyama","Max Frenzel"],"pdf_url":"","comment":"5 pages, AAAI 2026 Workshop on New Frontiers in Information Retrieval"},{"id":"http://arxiv.org/abs/2512.21020v1","updated":"2025-12-24T07:34:20Z","published":"2025-12-24T07:34:20Z","title":"Enhancing diffusion models with Gaussianization preprocessing","summary":"Diffusion models are a class of generative models that have demonstrated remarkable success in tasks such as image generation. However, one of the bottlenecks of these models is slow sampling due to the delay before the onset of trajectory bifurcation, at which point substantial reconstruction begins. This issue degrades generation quality, especially in the early stages. Our primary objective is to mitigate bifurcation-related issues by preprocessing the training data to enhance reconstruction quality, particularly for small-scale network architectures. Specifically, we propose applying Gaussianization preprocessing to the training data to make the target distribution more closely resemble an independent Gaussian distribution, which serves as the initial density of the reconstruction process. This preprocessing step simplifies the model's task of learning the target distribution, thereby improving generation quality even in the early stages of reconstruction with small networks. The proposed method is, in principle, applicable to a broad range of generative tasks, enabling more stable and efficient sampling processes.","authors":["Li Cunzhi","Louis Kang","Hideaki Shimazaki"],"pdf_url":"","comment":"17 pages, 9 figures"},{"id":"http://arxiv.org/abs/2511.03928v3","updated":"2025-12-24T07:28:22Z","published":"2025-11-06T00:09:33Z","title":"SynQuE: Estimating Synthetic Dataset Quality Without Annotations","summary":"We introduce and formalize the Synthetic Dataset Quality Estimation (SynQuE) problem: ranking synthetic datasets by their expected real-world task performance using only limited unannotated real data. This addresses a critical and open challenge where data is scarce due to collection costs or privacy constraints. We establish the first comprehensive benchmarks for this problem by introducing and evaluating proxy metrics that choose synthetic data for training to maximize task performance on real data. We introduce the first proxy metrics for SynQuE by adapting distribution and diversity-based distance measures to our context via embedding models. To address the shortcomings of these metrics on complex planning tasks, we propose LENS, a novel proxy that leverages large language model reasoning. Our results show that SynQuE proxies correlate with real task performance across diverse tasks, including sentiment analysis, Text2SQL, web navigation, and image classification, with LENS consistently outperforming others on complex tasks by capturing nuanced characteristics. For instance, on text-to-SQL parsing, training on the top-3 synthetic datasets selected via SynQuE proxies can raise accuracy from 30.4% to 38.4 (+8.1)% on average compared to selecting data indiscriminately. This work establishes SynQuE as a practical framework for synthetic data selection under real-data scarcity and motivates future research on foundation model-based data characterization and fine-grained data selection.","authors":["Arthur Chen","Victor Zhong"],"pdf_url":"","comment":"Our code and dataset are available here: https://github.com/r2llab/SynQuE"},{"id":"http://arxiv.org/abs/2512.21010v1","updated":"2025-12-24T07:14:31Z","published":"2025-12-24T07:14:31Z","title":"LLM Swiss Round: Aggregating Multi-Benchmark Performance via Competitive Swiss-System Dynamics","summary":"The rapid proliferation of Large Language Models (LLMs) and diverse specialized benchmarks necessitates a shift from fragmented, task-specific metrics to a holistic, competitive ranking system that effectively aggregates performance across multiple ability dimensions. Primarily using static scoring, current evaluation methods are fundamentally limited. They struggle to determine the proper mix ratio across diverse benchmarks, and critically, they fail to capture a model's dynamic competitive fitness or its vulnerability when confronted with sequential, high-stakes tasks. To address this, we introduce the novel Competitive Swiss-System Dynamics (CSD) framework. CSD simulates a multi-round, sequential contest where models are dynamically paired across a curated sequence of benchmarks based on their accumulated win-loss record. And Monte Carlo Simulation ($N=100,000$ iterations) is used to approximate the statistically robust Expected Win Score ($E[S_m]$), which eliminates the noise of random pairing and early-round luck. Furthermore, we implement a Failure Sensitivity Analysis by parameterizing the per-round elimination quantity ($T_k$), which allows us to profile models based on their risk appetite--distinguishing between robust generalists and aggressive specialists. We demonstrate that CSD provides a more nuanced and context-aware ranking than traditional aggregate scoring and static pairwise models, representing a vital step towards risk-informed, next-generation LLM evaluation.","authors":["Jiashuo Liu","Jiayun Wu","Chunjie Wu","Jingkai Liu","Zaiyuan Wang","Huan Zhou","Wenhao Huang","Hongseok Namkoong"],"pdf_url":"","comment":"18 pages"},{"id":"http://arxiv.org/abs/2512.21005v1","updated":"2025-12-24T07:10:17Z","published":"2025-12-24T07:10:17Z","title":"Learning from Neighbors with PHIBP: Predicting Infectious Disease Dynamics in Data-Sparse Environments","summary":"Modeling sparse count data, which arise across numerous scientific fields, presents significant statistical challenges. This chapter addresses these challenges in the context of infectious disease prediction, with a focus on predicting outbreaks in geographic regions that have historically reported zero cases. To this end, we present the detailed computational framework and experimental application of the Poisson Hierarchical Indian Buffet Process (PHIBP), with demonstrated success in handling sparse count data in microbiome and ecological studies. The PHIBP's architecture, grounded in the concept of absolute abundance, systematically borrows statistical strength from related regions and circumvents the known sensitivities of relative-rate methods to zero counts. Through a series of experiments on infectious disease data, we show that this principled approach provides a robust foundation for generating coherent predictive distributions and for the effective use of comparative measures such as alpha and beta diversity. The chapter's emphasis on algorithmic implementation and experimental results confirms that this unified framework delivers both accurate outbreak predictions and meaningful epidemiological insights in data-sparse settings.","authors":["Edwin Fong","Lancelot F. James","Juho Lee"],"pdf_url":"","comment":"Draft Book chapter on AMMI methods -- Application of PHIBP arXiv:2502.01919 to Infectious Disease Detection with suggested extensions using the developments in arXiv:2508.18668"},{"id":"http://arxiv.org/abs/2404.19557v5","updated":"2025-12-24T06:59:27Z","published":"2024-04-30T13:39:26Z","title":"Neural Dynamic Data Valuation: A Stochastic Optimal Control Approach","summary":"Data valuation has become a cornerstone of the modern data economy, where datasets function as tradable intellectual assets that drive decision-making, model training, and market transactions. Despite substantial progress, existing valuation methods remain limited by high computational cost, weak fairness guarantees, and poor interpretability, which hinder their deployment in large-scale, high-stakes applications. This paper introduces Neural Dynamic Data Valuation (NDDV), a new framework that formulates data valuation as a stochastic optimal control problem to capture the dynamic evolution of data utility over time. Unlike static combinatorial approaches, NDDV models data interactions through continuous trajectories that reflect both individual and collective learning dynamics.","authors":["Zhangyong Liang","Ji Zhang","Xin Wang","Pengfei Zhang","Zhao Li"],"pdf_url":"","comment":"14 pages, 10 figures"},{"id":"http://arxiv.org/abs/2512.21000v1","updated":"2025-12-24T06:55:43Z","published":"2025-12-24T06:55:43Z","title":"CoSeNet: A Novel Approach for Optimal Segmentation of Correlation Matrices","summary":"In this paper, we propose a novel approach for the optimal identification of correlated segments in noisy correlation matrices. The proposed model is known as CoSeNet (Correlation Seg-mentation Network) and is based on a four-layer algorithmic architecture that includes several processing layers: input, formatting, re-scaling, and segmentation layer. The proposed model can effectively identify correlated segments in such matrices, better than previous approaches for similar problems. Internally, the proposed model utilizes an overlapping technique and uses pre-trained Machine Learning (ML) algorithms, which makes it robust and generalizable. CoSeNet approach also includes a method that optimizes the parameters of the re-scaling layer using a heuristic algorithm and fitness based on a Window Difference-based metric. The output of the model is a binary noise-free matrix representing optimal segmentation as well as its seg-mentation points and can be used in a variety of applications, obtaining compromise solutions between efficiency, memory, and speed of the proposed deployment model.","authors":["Alberto. Palomo-Alonso","David Casillas-Perez","Silvia Jimenez-Fernandez","Antonio Portilla-Figueras","Sancho Salcedo-Sanz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.11783v3","updated":"2025-12-24T06:45:54Z","published":"2025-07-15T22:52:44Z","title":"EEG Foundation Models: A Critical Review of Current Progress and Future Directions","summary":"Premise. Patterns of electrical brain activity recorded via electroencephalography (EEG) offer immense value for scientific and clinical investigations. The inability of supervised EEG encoders to learn robust EEG patterns and their over-reliance on expensive signal annotations have sparked a transition towards general-purpose self-supervised EEG encoders, i.e., EEG foundation models (EEG-FMs), for robust and scalable EEG feature extraction. However, the real-world readiness of early EEG-FMs and the rubrics for long-term research progress remain unclear. Objective. In this work, we conduct a review of ten early EEG-FMs to capture common trends and identify key directions for future development of EEG-FMs. Methods. We comparatively analyze each EEG-FM using three fundamental pillars of foundation modeling, namely the representation of input data, self-supervised modeling, and the evaluation strategy. Based on this analysis, we present a critical synthesis of EEG-FM methodology, empirical findings, and outstanding research gaps. Results. We find that most EEG-FMs adopt a sequence-based modeling scheme that relies on transformer-based backbones and the reconstruction of masked temporal EEG sequences for self-supervision. However, model evaluations remain heterogeneous and largely limited, making it challenging to assess their practical off-the-shelf utility. In addition to adopting standardized and realistic evaluations, future work should demonstrate more substantial scaling effects and make principled and trustworthy choices throughout the EEG representation learning pipeline. Significance. Our review indicates that the development of benchmarks, software tools, technical methodologies, and applications in collaboration with domain experts may advance the translational utility and real-world adoption of EEG-FMs.","authors":["Gayal Kuruppu","Neeraj Wagh","Vaclav Kremen","Sandipan Pati","Gregory Worrell","Yogatheesan Varatharajah"],"pdf_url":"","comment":"22 pages (main), 5 figures (main), 4 tables (main + supplement)"},{"id":"http://arxiv.org/abs/2308.08427v2","updated":"2025-12-24T06:35:42Z","published":"2023-08-16T15:17:57Z","title":"Eliciting Risk Aversion with Inverse Reinforcement Learning via Interactive Questioning","summary":"We investigate a framework for robo-advisors to estimate non-expert clients' risk aversion using adaptive binary-choice questionnaires. We model risk aversion using cost functions and spectral risk measures in a static setting. We prove the finite-sample identifiability and, for properly designed questions, obtain a convergence rate of $\\sqrt{N}$ up to a logarithmic factor, where $N$ is the number of questions. We introduce the notion of distinguishing power and demonstrate, through simulated experiments, that designing questions by maximizing distinguishing power achieves satisfactory accuracy in learning risk aversion with fewer than 50 questions. We also provide a preliminary investigation of an infinite-horizon setting with an additional discount factor for dynamic risk aversion, establishing qualitative identifiability in this case.","authors":["Ziteng Cheng","Anthony Coache","Sebastian Jaimungal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20983v1","updated":"2025-12-24T06:17:21Z","published":"2025-12-24T06:17:21Z","title":"Automatic Replication of LLM Mistakes in Medical Conversations","summary":"Large language models (LLMs) are increasingly evaluated in clinical settings using multi-dimensional rubrics which quantify reasoning quality, safety, and patient-centeredness. Yet, replicating specific mistakes in other LLM models is not straightforward and often requires manual effort. We introduce MedMistake, an automatic pipeline that extracts mistakes LLMs make in patient-doctor conversations and converts them into a benchmark of single-shot QA pairs. Our pipeline (1) creates complex, conversational data between an LLM patient and LLM doctor, (2) runs an evaluation with a committee of 2 LLM judges across a variety of dimensions and (3) creates simplified single-shot QA scenarios from those mistakes. We release MedMistake-All, a dataset of 3,390 single-shot QA pairs where GPT-5 and Gemini 2.5 Pro are currently failing to answer correctly, as judged by two LLM judges. We used medical experts to validate a subset of 211/3390 questions (MedMistake-Bench), which we used to run a final evaluation of 12 frontier LLMs: Claude Opus 4.5, Claude Sonnet 4.5, DeepSeek-Chat, Gemini 2.5 Pro, Gemini 3 Pro, GPT-4o, GPT-5, GPT-5.1, GPT-5.2, Grok 4, Grok 4.1, Mistral Large. We found that GPT models, Claude and Grok obtained the best performance on MedMistake-Bench. We release both the doctor-validated benchmark (MedMistake-Bench), as well as the full dataset (MedMistake-All) at https://huggingface.co/datasets/TheLumos/MedicalMistakeBenchmark.","authors":["Oleksii Proniakin","Diego Fajardo","Ruslan Nazarenko","Razvan Marinescu"],"pdf_url":"","comment":"48 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2512.20978v1","updated":"2025-12-24T06:13:02Z","published":"2025-12-24T06:13:02Z","title":"GenTSE: Enhancing Target Speaker Extraction via a Coarse-to-Fine Generative Language Model","summary":"Language Model (LM)-based generative modeling has emerged as a promising direction for TSE, offering potential for improved generalization and high-fidelity speech. We present GenTSE, a two-stage decoder-only generative LM approach for TSE: Stage-1 predicts coarse semantic tokens, and Stage-2 generates fine acoustic tokens. Separating semantics and acoustics stabilizes decoding and yields more faithful, content-aligned target speech. Both stages use continuous SSL or codec embeddings, offering richer context than discretized-prompt methods. To reduce exposure bias, we employ a Frozen-LM Conditioning training strategy that conditions the LMs on predicted tokens from earlier checkpoints to reduce the gap between teacher-forcing training and autoregressive inference. We further employ DPO to better align outputs with human perceptual preferences. Experiments on Libri2Mix show that GenTSE surpasses previous LM-based systems in speech quality, intelligibility, and speaker consistency.","authors":["Haoyang Li","Xuyi Zhuang","Azmat Adnan","Ye Ni","Wei Rao","Shreyas Gopal","Eng Siong Chng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.06672v3","updated":"2025-12-24T06:12:56Z","published":"2024-08-13T06:47:59Z","title":"TimeBridge: Better Diffusion Prior Design with Bridge Models for Time Series Generation","summary":"Time series generation is widely used in real-world applications such as simulation, data augmentation, and hypothesis testing. Recently, diffusion models have emerged as the de facto approach to time series generation, enabling diverse synthesis scenarios. However, the fixed standard-Gaussian diffusion prior may be ill-suited for time series data, which exhibit properties such as temporal order and fixed time points. In this paper, we propose TimeBridge, a framework that flexibly synthesizes time series data by using diffusion bridges to learn paths between a chosen prior and the data distribution. We then explore several prior designs tailored to time series synthesis. Our framework covers (i) data- and time-dependent priors for unconditional generation and (ii) scale-preserving priors for conditional generation. Experiments show that our framework with data-driven priors outperforms standard diffusion models on time series generation.","authors":["Jinseong Park","Seungyun Lee","Woojin Jeong","Yujin Choi","Jaewook Lee"],"pdf_url":"","comment":"KDD 2026"},{"id":"http://arxiv.org/abs/2512.20974v1","updated":"2025-12-24T06:00:51Z","published":"2025-12-24T06:00:51Z","title":"Generalised Linear Models in Deep Bayesian RL with Learnable Basis Functions","summary":"Bayesian Reinforcement Learning (BRL) provides a framework for generalisation of Reinforcement Learning (RL) problems from its use of Bayesian task parameters in the transition and reward models. However, classical BRL methods assume known forms of transition and reward models, reducing their applicability in real-world problems. As a result, recent deep BRL methods have started to incorporate model learning, though the use of neural networks directly on the joint data and task parameters requires optimising the Evidence Lower Bound (ELBO). ELBOs are difficult to optimise and may result in indistinctive task parameters, hence compromised BRL policies. To this end, we introduce a novel deep BRL method, Generalised Linear Models in Deep Bayesian RL with Learnable Basis Functions (GLiBRL), that enables efficient and accurate learning of transition and reward models, with fully tractable marginal likelihood and Bayesian inference on task parameters and model noises. On challenging MetaWorld ML10/45 benchmarks, GLiBRL improves the success rate of one of the state-of-the-art deep BRL methods, VariBAD, by up to 2.7x. Comparing against representative or recent deep BRL / Meta-RL methods, such as MAML, RL2, SDVT, TrMRL and ECET, GLiBRL also demonstrates its low-variance and decent performance consistently.","authors":["Jingyang You","Hanna Kurniawati"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20967v1","updated":"2025-12-24T05:47:27Z","published":"2025-12-24T05:47:27Z","title":"Deadline-Aware Online Scheduling for LLM Fine-Tuning with Spot Market Predictions","summary":"As foundation models grow in size, fine-tuning them becomes increasingly expensive. While GPU spot instances offer a low-cost alternative to on-demand resources, their volatile prices and availability make deadline-aware scheduling particularly challenging. We tackle this difficulty by using a mix of spot and on-demand instances. Distinctively, we show the predictability of prices and availability in a spot instance market, the power of prediction in enabling cost-efficient scheduling and its sensitivity to estimation errors. An integer programming problem is formulated to capture the use of mixed instances under both the price and availability dynamics. We propose an online allocation algorithm with prediction based on the committed horizon control approach that leverages a \\emph{commitment level} to enforce the partial sequence of decisions. When this prediction becomes inaccurate, we further present a complementary online algorithm without predictions. An online policy selection algorithm is developed that learns the best policy from a pool constructed by varying the parameters of both algorithms. We prove that the prediction-based algorithm achieves tighter performance bounds as prediction error decreases, while the policy selection algorithm possesses a regret bound of $\\mathcal{O}(\\sqrt{T})$. Experimental results demonstrate that our online framework can adaptively select the best policy under varying spot market dynamics and prediction quality, consistently outperforming baselines and improving utility by up to 54.8\\%.","authors":["Linggao Kong","Yuedong Xu","Lei Jiao","Chuan Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20963v1","updated":"2025-12-24T05:40:40Z","published":"2025-12-24T05:40:40Z","title":"Generalization of Diffusion Models Arises with a Balanced Representation Space","summary":"Diffusion models excel at generating high-quality, diverse samples, yet they risk memorizing training data when overfit to the training objective. We analyze the distinctions between memorization and generalization in diffusion models through the lens of representation learning. By investigating a two-layer ReLU denoising autoencoder (DAE), we prove that (i) memorization corresponds to the model storing raw training samples in the learned weights for encoding and decoding, yielding localized \"spiky\" representations, whereas (ii) generalization arises when the model captures local data statistics, producing \"balanced\" representations. Furthermore, we validate these theoretical findings on real-world unconditional and text-to-image diffusion models, demonstrating that the same representation structures emerge in deep generative models with significant practical implications. Building on these insights, we propose a representation-based method for detecting memorization and a training-free editing technique that allows precise control via representation steering. Together, our results highlight that learning good representations is central to novel and meaningful generative modeling.","authors":["Zekai Zhang","Xiao Li","Xiang Li","Lianghe Shi","Meng Wu","Molei Tao","Qing Qu"],"pdf_url":"","comment":"40 pages, 19 figures. The first two authors contributed equally"},{"id":"http://arxiv.org/abs/2512.20959v1","updated":"2025-12-24T05:31:42Z","published":"2025-12-24T05:31:42Z","title":"Can Agentic AI Match the Performance of Human Data Scientists?","summary":"Data science plays a critical role in transforming complex data into actionable insights across numerous domains. Recent developments in large language models (LLMs) have significantly automated data science workflows, but a fundamental question persists: Can these agentic AI systems truly match the performance of human data scientists who routinely leverage domain-specific knowledge? We explore this question by designing a prediction task where a crucial latent variable is hidden in relevant image data instead of tabular features. As a result, agentic AI that generates generic codes for modeling tabular data cannot perform well, while human experts could identify the important hidden variable using domain knowledge. We demonstrate this idea with a synthetic dataset for property insurance. Our experiments show that agentic AI that relies on generic analytics workflow falls short of methods that use domain-specific insights. This highlights a key limitation of the current agentic AI for data science and underscores the need for future research to develop agentic AI systems that can better recognize and incorporate domain knowledge.","authors":["An Luo","Jin Du","Fangqiao Tian","Xun Xian","Robert Specht","Ganghua Wang","Xuan Bi","Charles Fleming","Jayanth Srinivasa","Ashish Kundu","Mingyi Hong","Jie Ding"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20958v1","updated":"2025-12-24T05:29:35Z","published":"2025-12-24T05:29:35Z","title":"ReACT-Drug: Reaction-Template Guided Reinforcement Learning for de novo Drug Design","summary":"De novo drug design is a crucial component of modern drug development, yet navigating the vast chemical space to find synthetically accessible, high-affinity candidates remains a significant challenge. Reinforcement Learning (RL) enhances this process by enabling multi-objective optimization and exploration of novel chemical space - capabilities that traditional supervised learning methods lack. In this work, we introduce \\textbf{ReACT-Drug}, a fully integrated, target-agnostic molecular design framework based on Reinforcement Learning. Unlike models requiring target-specific fine-tuning, ReACT-Drug utilizes a generalist approach by leveraging ESM-2 protein embeddings to identify similar proteins for a given target from a knowledge base such as Protein Data Base (PDB). Thereafter, the known drug ligands corresponding to such proteins are decomposed to initialize a fragment-based search space, biasing the agent towards biologically relevant subspaces. For each such fragment, the pipeline employs a Proximal Policy Optimization (PPO) agent guiding a ChemBERTa-encoded molecule through a dynamic action space of chemically valid, reaction-template-based transformations. This results in the generation of \\textit{de novo} drug candidates with competitive binding affinities and high synthetic accessibility, while ensuring 100\\% chemical validity and novelty as per MOSES benchmarking. This architecture highlights the potential of integrating structural biology, deep representation learning, and chemical synthesis rules to automate and accelerate rational drug design. The dataset and code are available at https://github.com/YadunandanRaman/ReACT-Drug/.","authors":["R Yadunandan","Nimisha Ghosh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20956v1","updated":"2025-12-24T05:27:20Z","published":"2025-12-24T05:27:20Z","title":"Solving Functional PDEs with Gaussian Processes and Applications to Functional Renormalization Group Equations","summary":"We present an operator learning framework for solving non-perturbative functional renormalization group equations, which are integro-differential equations defined on functionals. Our proposed approach uses Gaussian process operator learning to construct a flexible functional representation formulated directly on function space, making it independent of a particular equation or discretization. Our method is flexible, and can apply to a broad range of functional differential equations while still allowing for the incorporation of physical priors in either the prior mean or the kernel design. We demonstrate the performance of our method on several relevant equations, such as the Wetterich and Wilson--Polchinski equations, showing that it achieves equal or better performance than existing approximations such as the local-potential approximation, while being significantly more flexible. In particular, our method can handle non-constant fields, making it promising for the study of more complex field configurations, such as instantons.","authors":["Xianjin Yang","Matthieu Darcy","Matthew Hudes","Francis J. Alexander","Gregory Eyink","Houman Owhadi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20950v1","updated":"2025-12-24T05:14:40Z","published":"2025-12-24T05:14:40Z","title":"MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment","summary":"This paper presents our system for SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval. In an era where misinformation spreads rapidly, effective fact-checking is increasingly critical. We introduce TriAligner, a novel approach that leverages a dual-encoder architecture with contrastive learning and incorporates both native and English translations across different modalities. Our method effectively retrieves claims across multiple languages by learning the relative importance of different sources in alignment. To enhance robustness, we employ efficient data preprocessing and augmentation using large language models while incorporating hard negative sampling to improve representation learning. We evaluate our approach on monolingual and crosslingual benchmarks, demonstrating significant improvements in retrieval accuracy and fact-checking performance over baselines.","authors":["Mohammad Mahdi Abootorabi","Alireza Ghahramani Kure","Mohammadali Mohammadkhani","Sina Elahimanesh","Mohammad Ali Ali Panah"],"pdf_url":"","comment":"11 pages Published at the SemEval-2025 workshop"},{"id":"http://arxiv.org/abs/2512.20943v1","updated":"2025-12-24T04:57:30Z","published":"2025-12-24T04:57:30Z","title":"AirGS: Real-Time 4D Gaussian Streaming for Free-Viewpoint Video Experiences","summary":"Free-viewpoint video (FVV) enables immersive viewing experiences by allowing users to view scenes from arbitrary perspectives. As a prominent reconstruction technique for FVV generation, 4D Gaussian Splatting (4DGS) models dynamic scenes with time-varying 3D Gaussian ellipsoids and achieves high-quality rendering via fast rasterization. However, existing 4DGS approaches suffer from quality degradation over long sequences and impose substantial bandwidth and storage overhead, limiting their applicability in real-time and wide-scale deployments. Therefore, we present AirGS, a streaming-optimized 4DGS framework that rearchitects the training and delivery pipeline to enable high-quality, low-latency FVV experiences. AirGS converts Gaussian video streams into multi-channel 2D formats and intelligently identifies keyframes to enhance frame reconstruction quality. It further combines temporal coherence with inflation loss to reduce training time and representation size. To support communication-efficient transmission, AirGS models 4DGS delivery as an integer linear programming problem and design a lightweight pruning level selection algorithm to adaptively prune the Gaussian updates to be transmitted, balancing reconstruction quality and bandwidth consumption. Extensive experiments demonstrate that AirGS reduces quality deviation in PSNR by more than 20% when scene changes, maintains frame-level PSNR consistently above 30, accelerates training by 6 times, reduces per-frame transmission size by nearly 50% compared to the SOTA 4DGS approaches.","authors":["Zhe Wang","Jinghang Li","Yifei Zhu"],"pdf_url":"","comment":"This paper is accepted by IEEE International Conference on Computer Communications (INFOCOM), 2026"},{"id":"http://arxiv.org/abs/2406.16087v8","updated":"2025-12-24T04:53:14Z","published":"2024-06-23T12:02:17Z","title":"Imperative Learning: A Self-supervised Neuro-Symbolic Learning Framework for Robot Autonomy","summary":"Data-driven methods such as reinforcement and imitation learning have achieved remarkable success in robot autonomy. However, their data-centric nature still hinders them from generalizing well to ever-changing environments. Moreover, labeling data for robotic tasks is often impractical and expensive. To overcome these challenges, we introduce a new self-supervised neuro-symbolic (NeSy) computational framework, imperative learning (IL), for robot autonomy, leveraging the generalization abilities of symbolic reasoning. The framework of IL consists of three primary components: a neural module, a reasoning engine, and a memory system. We formulate IL as a special bilevel optimization (BLO), which enables reciprocal learning over the three modules. This overcomes the label-intensive obstacles associated with data-driven approaches and takes advantage of symbolic reasoning concerning logical reasoning, physical principles, geometric analysis, etc. We discuss several optimization techniques for IL and verify their effectiveness in five distinct robot autonomy tasks including path planning, rule induction, optimal control, visual odometry, and multi-robot routing. Through various experiments, we show that IL can significantly enhance robot autonomy capabilities and we anticipate that it will catalyze further research across diverse domains.","authors":["Chen Wang","Kaiyi Ji","Junyi Geng","Zhongqiang Ren","Taimeng Fu","Fan Yang","Yifan Guo","Haonan He","Xiangyu Chen","Zitong Zhan","Qiwei Du","Shaoshu Su","Bowen Li","Yuheng Qiu","Yi Du","Qihang Li","Yifan Yang","Xiao Lin","Zhipeng Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20941v1","updated":"2025-12-24T04:53:11Z","published":"2025-12-24T04:53:11Z","title":"A Multi-fidelity Double-Delta Wing Dataset and Empirical Scaling Laws for GNN-based Aerodynamic Field Surrogate","summary":"Data-driven surrogate models are increasingly adopted to accelerate vehicle design. However, open-source multi-fidelity datasets and empirical guidelines linking dataset size to model performance remain limited. This study investigates the relationship between training data size and prediction accuracy for a graph neural network (GNN) based surrogate model for aerodynamic field prediction. We release an open-source, multi-fidelity aerodynamic dataset for double-delta wings, comprising 2448 flow snapshots across 272 geometries evaluated at angles of attack from 11 (degree) to 19 (degree) at Ma=0.3 using both Vortex Lattice Method (VLM) and Reynolds-Averaged Navier-Stokes (RANS) solvers. The geometries are generated using a nested Saltelli sampling scheme to support future dataset expansion and variance-based sensitivity analysis. Using this dataset, we conduct a preliminary empirical scaling study of the MF-VortexNet surrogate by constructing six training datasets with sizes ranging from 40 to 1280 snapshots and training models with 0.1 to 2.4 million parameters under a fixed training budget. We find that the test error decreases with data size with a power-law exponent of -0.6122, indicating efficient data utilization. Based on this scaling law, we estimate that the optimal sampling density is approximately eight samples per dimension in a d-dimensional design space. The results also suggest improved data utilization efficiency for larger surrogate models, implying a potential trade-off between dataset generation cost and model training budget.","authors":["Yiren Shen","Juan J. Alonso"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.08893v2","updated":"2025-12-24T04:42:33Z","published":"2024-12-12T03:14:47Z","title":"Optimal Control with Natural Images: Efficient Reinforcement Learning using Overcomplete Sparse Codes","summary":"Optimal control and sequential decision making are widely used in many complex tasks. Optimal control over a sequence of natural images is a first step towards understanding the role of vision in control. Here, we formalize this problem as a reinforcement learning task, and derive general conditions under which an image includes enough information to implement an optimal policy. Reinforcement learning is shown to provide a computationally efficient method for finding optimal policies when natural images are encoded into \"efficient\" image representations. This is demonstrated by introducing a new reinforcement learning benchmark that easily scales to large numbers of states and long horizons. In particular, by representing each image as an overcomplete sparse code, we are able to efficiently solve an optimal control task that is orders of magnitude larger than those tasks solvable using complete codes. Theoretical justification for this behaviour is provided. This work also demonstrates that deep learning is not necessary for efficient optimal control with natural images.","authors":["Peter N. Loxley"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18725v2","updated":"2025-12-24T04:31:46Z","published":"2025-12-21T12:59:45Z","title":"ML Inference Scheduling with Predictable Latency","summary":"Machine learning (ML) inference serving systems can schedule requests to improve GPU utilization and to meet service level objectives (SLOs) or deadlines. However, improving GPU utilization may compromise latency-sensitive scheduling, as concurrent tasks contend for GPU resources and thereby introduce interference. Given that interference effects introduce unpredictability in scheduling, neglecting them may compromise SLO or deadline satisfaction. Nevertheless, existing interference prediction approaches remain limited in several respects, which may restrict their usefulness for scheduling. First, they are often coarse-grained, which ignores runtime co-location dynamics and thus restricts their accuracy in interference prediction. Second, they tend to use a static prediction model, which may not effectively cope with different workload characteristics. In this paper, we evaluate the potential limitations of existing interference prediction approaches, finding that coarse-grained methods can lead to noticeable deviations in prediction accuracy and that static models degrade considerably under changing workloads.","authors":["Haidong Zhao","Nikolaos Georgantas"],"pdf_url":"","comment":"Accepted at MAIoT@Middleware 2025"},{"id":"http://arxiv.org/abs/2512.20932v1","updated":"2025-12-24T04:25:31Z","published":"2025-12-24T04:25:31Z","title":"Guardrailed Elasticity Pricing: A Churn-Aware Forecasting Playbook for Subscription Strategy","summary":"This paper presents a marketing analytics framework that operationalizes subscription pricing as a dynamic, guardrailed decision system, uniting multivariate demand forecasting, segment-level price elasticity, and churn propensity to optimize revenue, margin, and retention. The approach blends seasonal time-series models with tree-based learners, runs Monte Carlo scenario tests to map risk envelopes, and solves a constrained optimization that enforces business guardrails on customer experience, margin floors, and allowable churn. Validated across heterogeneous SaaS portfolios, the method consistently outperforms static tiers and uniform uplifts by reallocating price moves toward segments with higher willingness-to-pay while protecting price-sensitive cohorts. The system is designed for real-time recalibration via modular APIs and includes model explainability for governance and compliance. Managerially, the framework functions as a strategy playbook that clarifies when to shift from flat to dynamic pricing, how to align pricing with CLV and MRR targets, and how to embed ethical guardrails, enabling durable growth without eroding customer trust.","authors":["Deepit Sapru"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20924v1","updated":"2025-12-24T04:04:20Z","published":"2025-12-24T04:04:20Z","title":"Clever Hans in Chemistry: Chemist Style Signals Confound Activity Prediction on Public Benchmarks","summary":"Can machine learning models identify which chemist made a molecule from structure alone? If so, models trained on literature data may exploit chemist intent rather than learning causal structure-activity relationships. We test this by linking CHEMBL assays to publication authors and training a 1,815-class classifier to predict authors from molecular fingerprints, achieving 60% top-5 accuracy under scaffold-based splitting. We then train an activity model that receives only a protein identifier and an author-probability vector derived from structure, with no direct access to molecular descriptors. This author-only model achieves predictive power comparable to a simple baseline that has access to structure. This reveals a \"Clever Hans\" failure mode: models can predict bioactivity largely by inferring chemist goals and favorite targets without requiring a lab-independent understanding of chemistry. We analyze the sources of this leakage, propose author-disjoint splits, and recommend dataset practices to decouple chemist intent from biological outcomes.","authors":["Andrew D. Blevins","Ian K. Quigley"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.11005v3","updated":"2025-12-24T04:04:10Z","published":"2025-07-15T05:49:37Z","title":"AdaMuon: Adaptive Muon Optimizer","summary":"We propose AdaMuon, a novel optimizer that combines element-wise adaptivity with orthogonal updates for large-scale neural network training. AdaMuon incorporates two tightly coupled mechanisms: (1) an element-wise second momentum estimator applied to orthogonalized update directions, and (2) a sign-stabilized orthogonal update, where the momentum is first sign-transformed before orthogonalization. These two components jointly enable variance-adaptive scaling while maintaining stable update geometry. In addition, AdaMuon employs an RMS-aligned rescaling strategy to match the root-mean-square update magnitude to Adam, allowing direct reuse of existing learning rate schedules without extra tuning. Experiments demonstrate that AdaMuon not only maintains stability but can surpass Adam by more than 40\\% training efficiency in large-scale scenarios.","authors":["Chongjie Si","Debing Zhang","Wei Shen"],"pdf_url":"","comment":"Codes are available at https://github.com/Chongjie-Si/AdaMuon"},{"id":"http://arxiv.org/abs/2512.20920v1","updated":"2025-12-24T03:56:58Z","published":"2025-12-24T03:56:58Z","title":"RevFFN: Memory-Efficient Full-Parameter Fine-Tuning of Mixture-of-Experts LLMs with Reversible Blocks","summary":"Full parameter fine tuning is a key technique for adapting large language models (LLMs) to downstream tasks, but it incurs substantial memory overhead due to the need to cache extensive intermediate activations for backpropagation. This bottleneck makes full fine tuning of contemporary large scale LLMs challenging in practice. Existing distributed training frameworks such as DeepSpeed alleviate this issue using techniques like ZeRO and FSDP, which rely on multi GPU memory or CPU offloading, but often require additional hardware resources and reduce training speed. We introduce RevFFN, a memory efficient fine tuning paradigm for mixture of experts (MoE) LLMs. RevFFN employs carefully designed reversible Transformer blocks that allow reconstruction of layer input activations from outputs during backpropagation, eliminating the need to store most intermediate activations in memory. While preserving the expressive capacity of MoE architectures, this approach significantly reduces peak memory consumption for full parameter fine tuning. As a result, RevFFN enables efficient full fine tuning on a single consumer grade or server grade GPU.","authors":["Ningyuan Liu","Jing Yang","Kaitong Cai","Keze Wang"],"pdf_url":"","comment":"Under submission"},{"id":"http://arxiv.org/abs/2512.15745v2","updated":"2025-12-24T03:46:46Z","published":"2025-12-10T09:26:18Z","title":"LLaDA2.0: Scaling Up Diffusion Language Models to 100B","summary":"This paper presents LLaDA2.0 -- a tuple of discrete diffusion large language models (dLLM) scaling up to 100B total parameters through systematic conversion from auto-regressive (AR) models -- establishing a new paradigm for frontier-scale deployment. Instead of costly training from scratch, LLaDA2.0 upholds knowledge inheritance, progressive adaption and efficiency-aware design principle, and seamless converts a pre-trained AR model into dLLM with a novel 3-phase block-level WSD based training scheme: progressive increasing block-size in block diffusion (warm-up), large-scale full-sequence diffusion (stable) and reverting back to compact-size block diffusion (decay). Along with post-training alignment with SFT and DPO, we obtain LLaDA2.0-mini (16B) and LLaDA2.0-flash (100B), two instruction-tuned Mixture-of-Experts (MoE) variants optimized for practical deployment. By preserving the advantages of parallel decoding, these models deliver superior performance and efficiency at the frontier scale. Both models were open-sourced.","authors":["Tiwei Bie","Maosong Cao","Kun Chen","Lun Du","Mingliang Gong","Zhuochen Gong","Yanmei Gu","Jiaqi Hu","Zenan Huang","Zhenzhong Lan","Chengxi Li","Chongxuan Li","Jianguo Li","Zehuan Li","Huabin Liu","Lin Liu","Guoshan Lu","Xiaocheng Lu","Yuxin Ma","Jianfeng Tan","Lanning Wei","Ji-Rong Wen","Yipeng Xing","Xiaolu Zhang","Junbo Zhao","Da Zheng","Jun Zhou","Junlin Zhou","Zhanchao Zhou","Liwang Zhu","Yihong Zhuang"],"pdf_url":"","comment":"19 pages"},{"id":"http://arxiv.org/abs/2512.20915v1","updated":"2025-12-24T03:43:54Z","published":"2025-12-24T03:43:54Z","title":"Towards a General Framework for Predicting and Explaining the Hardness of Graph-based Combinatorial Optimization Problems using Machine Learning and Association Rule Mining","summary":"This study introduces GCO-HPIF, a general machine-learning-based framework to predict and explain the computational hardness of combinatorial optimization problems that can be represented on graphs. The framework consists of two stages. In the first stage, a dataset is created comprising problem-agnostic graph features and hardness classifications of problem instances. Machine-learning-based classification algorithms are trained to map graph features to hardness categories. In the second stage, the framework explains the predictions using an association rule mining algorithm. Additionally, machine-learning-based regression models are trained to predict algorithmic computation times. The GCO-HPIF framework was applied to a dataset of 3287 maximum clique problem instances compiled from the COLLAB, IMDB, and TWITTER graph datasets using five state-of-the-art algorithms, namely three exact branch-and-bound-based algorithms (Gurobi, CliSAT, and MOMC) and two graph-neural-network-based algorithms (EGN and HGS). The framework demonstrated excellent performance in predicting instance hardness, achieving a weighted F1 score of 0.9921, a minority-class F1 score of 0.878, and an ROC-AUC score of 0.9083 using only three graph features. The best association rule found by the FP-Growth algorithm for explaining the hardness predictions had a support of 0.8829 for hard instances and an overall accuracy of 87.64 percent, underscoring the framework's usefulness for both prediction and explanation. Furthermore, the best-performing regression model for predicting computation times achieved a percentage RMSE of 5.12 and an R2 value of 0.991.","authors":["Bharat Sharman","Elkafi Hassini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.10952v2","updated":"2025-12-24T03:33:33Z","published":"2025-12-11T18:59:55Z","title":"Hierarchical Dataset Selection for High-Quality Data Sharing","summary":"The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.","authors":["Xiaona Zhou","Yingyan Zeng","Ran Jin","Ismini Lourentzou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20905v1","updated":"2025-12-24T03:10:00Z","published":"2025-12-24T03:10:00Z","title":"DiEC: Diffusion Embedded Clustering","summary":"Deep clustering hinges on learning representations that are inherently clusterable. However, using a single encoder to produce a fixed embedding ignores the representation trajectory formed by a pretrained diffusion model across network hierarchies and noise timesteps, where clusterability varies substantially. We propose DiEC (Diffusion Embedded Clustering), which performs unsupervised clustering by directly reading internal activations from a pretrained diffusion U-Net.\n  DiEC formulates representation selection as a two-dimensional search over layer x timestep, and exploits a weak-coupling property to decompose it into two stages. Specifically, we first fix the U-Net bottleneck layer as the Clustering-friendly Middle Layer (CML), and then use Optimal Timestep Search (OTS) to identify the clustering-optimal timestep (t*). During training, we extract bottleneck features at the fixed t* and obtain clustering representations via a lightweight residual mapping. We optimize a DEC-style KL self-training objective, augmented with adaptive graph regularization and entropy regularization to strengthen cluster structures. In parallel, we introduce a denoising-consistency branch at random timesteps to stabilize the representations and preserve generative consistency. Experiments show that DiEC achieves competitive clustering performance on multiple standard benchmarks.","authors":["Haidong Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20610v2","updated":"2025-12-24T02:38:59Z","published":"2025-12-23T18:57:53Z","title":"FedPOD: the deployable units of training for federated learning","summary":"This paper proposes FedPOD, which ranked first in the 2024 Federated Tumor Segmentation (FeTS) Challenge, for optimizing learning efficiency and communication cost in federated learning among multiple clients. Inspired by FedPIDAvg, we define a round-wise task for FedPOD to enhance training efficiency. FedPIDAvg achieved performance improvement by incorporating the training loss reduction for prediction entropy as weights using differential terms. Furthermore, by modeling data distribution with a Poisson distribution and using a PID controller, it reduced communication costs even in skewed data distribution. However, excluding participants classified as outliers based on the Poisson distribution can limit data utilization. Additionally, PID controller requires the same participants to be maintained throughout the federated learning process as it uses previous rounds' learning information in the current round. In our approach, FedPOD addresses these issues by including participants excluded as outliers, eliminating dependency on previous rounds' learning information, and applying a method for calculating validation loss at each round. In this challenge, FedPOD presents comparable performance to FedPIDAvg in metrics of Dice score, 0.78, 0.71 and 0.72 for WT, ET and TC in average, and projected convergence score, 0.74 in average. Furthermore, the concept of FedPOD draws inspiration from Kubernetes' smallest computing unit, POD, designed to be compatible with Kubernetes auto-scaling. Extending round-wise tasks of FedPOD to POD units allows flexible design by applying scale-out similar to Kubernetes' auto-scaling. This work demonstrated the potentials of FedPOD to enhance federated learning by improving efficiency, flexibility, and performance in metrics.","authors":["Daewoon Kim","Si Young Yie","Jae Sung Lee"],"pdf_url":"","comment":"12 pages, 12 figures, MICCAI"},{"id":"http://arxiv.org/abs/2512.20893v1","updated":"2025-12-24T02:33:08Z","published":"2025-12-24T02:33:08Z","title":"Time-Efficient Evaluation and Enhancement of Adversarial Robustness in Deep Neural Networks","summary":"With deep neural networks (DNNs) increasingly embedded in modern society, ensuring their safety has become a critical and urgent issue. In response, substantial efforts have been dedicated to the red-blue adversarial framework, where the red team focuses on identifying vulnerabilities in DNNs and the blue team on mitigating them. However, existing approaches from both teams remain computationally intensive, constraining their applicability to large-scale models. To overcome this limitation, this thesis endeavours to provide time-efficient methods for the evaluation and enhancement of adversarial robustness in DNNs.","authors":["Runqi Lin"],"pdf_url":"","comment":"Ph.D. Thesis, The University of Sydney"},{"id":"http://arxiv.org/abs/2512.20885v1","updated":"2025-12-24T02:05:46Z","published":"2025-12-24T02:05:46Z","title":"From GNNs to Symbolic Surrogates via Kolmogorov-Arnold Networks for Delay Prediction","summary":"Accurate prediction of flow delay is essential for optimizing and managing modern communication networks. We investigate three levels of modeling for this task. First, we implement a heterogeneous GNN with attention-based message passing, establishing a strong neural baseline. Second, we propose FlowKANet in which Kolmogorov-Arnold Networks replace standard MLP layers, reducing trainable parameters while maintaining competitive predictive performance. FlowKANet integrates KAMP-Attn (Kolmogorov-Arnold Message Passing with Attention), embedding KAN operators directly into message-passing and attention computation. Finally, we distill the model into symbolic surrogate models using block-wise regression, producing closed-form equations that eliminate trainable weights while preserving graph-structured dependencies. The results show that KAN layers provide a favorable trade-off between efficiency and accuracy and that symbolic surrogates emphasize the potential for lightweight deployment and enhanced transparency.","authors":["Sami Marouani","Kamal Singh","Baptiste Jeudy","Amaury Habrard"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21701v2","updated":"2025-12-24T01:52:42Z","published":"2025-11-16T06:08:41Z","title":"47B Mixture-of-Experts Beats 671B Dense Models on Chinese Medical Examinations","summary":"The rapid advancement of large language models(LLMs) has prompted significant interest in their potential applications in medical domains. This paper presents a comprehensive benchmark evaluation of 27 state-of-the-art LLMs on Chinese medical examination questions, encompassing seven medical specialties across two professional levels. We introduce a robust evaluation framework that assesses model performance on 2,800 carefully curated questions from cardiovascular, gastroenterology, hematology, infectious diseases, nephrology, neurology, and respiratory medicine domains. Our dataset distinguishes between attending physician and senior physician difficulty levels, providing nuanced insights into model capabilities across varying complexity. Our empirical analysis reveals substantial performance variations among models, with Mixtral-8x7B achieving the highest overall accuracy of 74.25%, followed by DeepSeek-R1-671B at 64.07%. Notably, we observe no consistent correlation between model size and performance, as evidenced by the strong performance of smaller mixture-of-experts architectures. The evaluation demonstrates significant performance gaps between medical specialties, with models generally performing better on cardiovascular and neurology questions compared to gastroenterology and nephrology domains. Furthermore, our analysis indicates minimal performance degradation between attending and senior physician levels for top-performing models, suggesting robust generalization capabilities. This benchmark provides critical insights for the deployment of LLMs in medical education and clinical decision support systems, highlighting both the promise and current limitations of these technologies in specialized medical contexts.","authors":["Chiung-Yi Tseng","Danyang Zhang","Tianyang Wang","Hongying Luo","Lu Chen","Junming Huang","Jibin Guan","Junfeng Hao","Junhao Song","Xinyuan Song","Ziqian Bi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.08056v2","updated":"2025-12-24T01:49:13Z","published":"2024-08-15T09:50:11Z","title":"DATTA: Domain Diversity Aware Test-Time Adaptation for Dynamic Domain Shift Data Streams","summary":"Test-Time Adaptation (TTA) addresses domain shifts between training and testing. However, existing methods assume a homogeneous target domain (e.g., single domain) at any given time. They fail to handle the dynamic nature of real-world data, where single-domain and multiple-domain distributions change over time. We identify that performance drops in multiple-domain scenarios are caused by batch normalization errors and gradient conflicts, which hinder adaptation. To solve these challenges, we propose Domain Diversity Adaptive Test-Time Adaptation (DATTA), the first approach to handle TTA under dynamic domain shift data streams. It is guided by a novel domain-diversity score. DATTA has three key components: a domain-diversity discriminator to recognize single- and multiple-domain patterns, domain-diversity adaptive batch normalization to combine source and test-time statistics, and domain-diversity adaptive fine-tuning to resolve gradient conflicts. Extensive experiments show that DATTA significantly outperforms state-of-the-art methods by up to 13%. Code is available at https://github.com/DYW77/DATTA.","authors":["Chuyang Ye","Dongyan Wei","Zhendong Liu","Yuanyi Pang","Yixi Lin","Qinting Jiang","Jingyan Jiang","Dongbiao He"],"pdf_url":"","comment":"Accepted to 2025 IEEE International Conference on Multimedia and Expo (ICME), Oral Presentation"},{"id":"http://arxiv.org/abs/2507.01041v3","updated":"2025-12-24T01:45:18Z","published":"2025-06-23T07:14:04Z","title":"Fast AI Model Splitting over Edge Networks","summary":"Split learning (SL) has emerged as a computationally efficient approach for artificial intelligence (AI) model training, which can alleviate device-side computational workloads. However, complex AI model architectures pose high computational complexity to obtain the optimal model splitting. In this paper, we represent an arbitrary AI model as a directed acyclic graph (DAG), and then reformulate the optimal model splitting problem as a minimum s-t cut search problem. To solve the problem, we propose a fast DAG-based model splitting algorithm, which restructures the DAG to enable the optimal model splitting identification via a maximum flow method. Theoretical analysis indicates that the proposed algorithm is optimal. Furthermore, considering AI models with block structures, we propose a block-wise model splitting algorithm to reduce computational complexity. The algorithm abstracts each block, i.e., a component consisting of multiple layers, into a single vertex, thereby obtaining the optimal model splitting via a simplified DAG. Extensive experimental results demonstrate that the proposed algorithms can determine the optimal model splitting within milliseconds, as well as reduce training delay by 24.62%-38.95% in dynamic edge networks as compared to the state-of-the-art benchmarks.","authors":["Zuguang Li","Wen Wu","Shaohua Wu","Songge Zhang","Ye Wang"," Xuemin"," Shen"],"pdf_url":"","comment":"This version lacks sufficient detail in key technical parts, including the equivalence proof for the s-t cut transformation and the computational complexity analysis (Sections VI-D). We are withdrawing it to prepare a revised, more complete manuscript"},{"id":"http://arxiv.org/abs/2512.20877v1","updated":"2025-12-24T01:36:50Z","published":"2025-12-24T01:36:50Z","title":"Architectural Trade-offs in Small Language Models Under Compute Constraints","summary":"We present a systematic empirical study of small language models under strict compute constraints, analyzing how architectural choices and training budget interact to determine performance. Starting from a linear next-token predictor, we progressively introduce nonlinearities, self-attention, and multi-layer transformer architectures, evaluating each on character-level modeling of Tiny Shakespeare and word-level modeling of Penn Treebank (PTB) and WikiText-2. We compare models using test negative log-likelihood (NLL), parameter count, and approximate training FLOPs to characterize accuracy-efficiency trade-offs. Our results show that attention-based models dominate MLPs in per-FLOP efficiency even at small scale, while increasing depth or context without sufficient optimization can degrade performance. We further examine rotary positional embeddings (RoPE), finding that architectural techniques successful in large language models do not necessarily transfer to small-model regimes.","authors":["Shivraj Singh Bhatti"],"pdf_url":"","comment":"15 pages, 11 images"},{"id":"http://arxiv.org/abs/2511.11767v4","updated":"2025-12-24T01:31:19Z","published":"2025-11-14T07:51:56Z","title":"Learning Fair Representations with Kolmogorov-Arnold Networks","summary":"Despite recent advances in fairness-aware machine learning, predictive models often exhibit discriminatory behavior towards marginalized groups. Such unfairness might arise from biased training data, model design, or representational disparities across groups, posing significant challenges in high-stakes decision-making domains such as college admissions. While existing fair learning models aim to mitigate bias, achieving an optimal trade-off between fairness and accuracy remains a challenge. Moreover, the reliance on black-box models hinders interpretability, limiting their applicability in socially sensitive domains. To circumvent these issues, we propose integrating Kolmogorov-Arnold Networks (KANs) within a fair adversarial learning framework. Leveraging the adversarial robustness and interpretability of KANs, our approach facilitates stable adversarial learning. We derive theoretical insights into the spline-based KAN architecture that ensure stability during adversarial optimization. Additionally, an adaptive fairness penalty update mechanism is proposed to strike a balance between fairness and accuracy. We back these findings with empirical evidence on two real-world admissions datasets, demonstrating the proposed framework's efficiency in achieving fairness across sensitive attributes while preserving predictive performance.","authors":["Amisha Priyadarshini","Sergio Gago-Masague"],"pdf_url":"","comment":"This article has been accepted at AAAI-26 (The 40th Annual AAAI Conference on Artificial Intelligence)"},{"id":"http://arxiv.org/abs/2512.20872v1","updated":"2025-12-24T01:21:38Z","published":"2025-12-24T01:21:38Z","title":"Better Call Graphs: A New Dataset of Function Call Graphs for Malware Classification","summary":"Function call graphs (FCGs) have emerged as a powerful abstraction for malware detection, capturing the behavioral structure of applications beyond surface-level signatures. Their utility in traditional program analysis has been well established, enabling effective classification and analysis of malicious software. In the mobile domain, especially in the Android ecosystem, FCG-based malware classification is particularly critical due to the platform's widespread adoption and the complex, component-based structure of Android apps. However, progress in this direction is hindered by the lack of large-scale, high-quality Android-specific FCG datasets. Existing datasets are often outdated, dominated by small or redundant graphs resulting from app repackaging, and fail to reflect the diversity of real-world malware. These limitations lead to overfitting and unreliable evaluation of graph-based classification methods. To address this gap, we introduce Better Call Graphs (BCG), a comprehensive dataset of large and unique FCGs extracted from recent Android application packages (APKs). BCG includes both benign and malicious samples spanning various families and types, along with graph-level features for each APK. Through extensive experiments using baseline classifiers, we demonstrate the necessity and value of BCG compared to existing datasets. BCG is publicly available at https://erdemub.github.io/BCG-dataset.","authors":["Jakir Hossain","Gurvinder Singh","Lukasz Ziarek","Ahmet Erdem Sarıyüce"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20865v1","updated":"2025-12-24T00:49:47Z","published":"2025-12-24T00:49:47Z","title":"Robustness Certificates for Neural Networks against Adversarial Attacks","summary":"The increasing use of machine learning in safety-critical domains amplifies the risk of adversarial threats, especially data poisoning attacks that corrupt training data to degrade performance or induce unsafe behavior. Most existing defenses lack formal guarantees or rely on restrictive assumptions about the model class, attack type, extent of poisoning, or point-wise certification, limiting their practical reliability. This paper introduces a principled formal robustness certification framework that models gradient-based training as a discrete-time dynamical system (dt-DS) and formulates poisoning robustness as a formal safety verification problem. By adapting the concept of barrier certificates (BCs) from control theory, we introduce sufficient conditions to certify a robust radius ensuring that the terminal model remains safe under worst-case ${\\ell}_p$-norm based poisoning. To make this practical, we parameterize BCs as neural networks trained on finite sets of poisoned trajectories. We further derive probably approximately correct (PAC) bounds by solving a scenario convex program (SCP), which yields a confidence lower bound on the certified robustness radius generalizing beyond the training set. Importantly, our framework also extends to certification against test-time attacks, making it the first unified framework to provide formal guarantees in both training and test-time attack settings. Experiments on MNIST, SVHN, and CIFAR-10 show that our approach certifies non-trivial perturbation budgets while being model-agnostic and requiring no prior knowledge of the attack or contamination level.","authors":["Sara Taheri","Mahalakshmi Sabanayagam","Debarghya Ghoshdastidar","Majid Zamani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20861v1","updated":"2025-12-24T00:41:13Z","published":"2025-12-24T00:41:13Z","title":"Memory-Efficient Acceleration of Block Low-Rank Foundation Models on Resource Constrained GPUs","summary":"Recent advances in transformer-based foundation models have made them the default choice for many tasks, but their rapidly growing size makes fitting a full model on a single GPU increasingly difficult and their computational cost prohibitive. Block low-rank (BLR) compression techniques address this challenge by learning compact representations of weight matrices. While traditional low-rank (LR) methods often incur sharp accuracy drops, BLR approaches such as Monarch and BLAST can better capture the underlying structure, thus preserving accuracy while reducing computations and memory footprints. In this work, we use roofline analysis to show that, although BLR methods achieve theoretical savings and practical speedups for single-token inference, multi-token inference often becomes memory-bound in practice, increasing latency despite compiler-level optimizations in PyTorch. To address this, we introduce custom Triton kernels with partial fusion and memory layout optimizations for both Monarch and BLAST. On memory-constrained NVIDIA GPUs such as Jetson Orin Nano and A40, our kernels deliver up to $3.76\\times$ speedups and $3\\times$ model size compression over PyTorch dense baselines using CUDA backend and compiler-level optimizations, while supporting various models including Llama-7/1B, GPT2-S, DiT-XL/2, and ViT-B. Our code is available at https://github.com/pabillam/mem-efficient-blr .","authors":["Pierre Abillama","Changwoo Lee","Juechu Dong","David Blaauw","Dennis Sylvester","Hun-Seok Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.10884v2","updated":"2025-12-24T00:39:09Z","published":"2025-07-15T00:56:21Z","title":"Learning from Imperfect Data: Robust Inference of Dynamic Systems using Simulation-based Generative Model","summary":"System inference for nonlinear dynamic models, represented by ordinary differential equations (ODEs), remains a significant challenge in many fields, particularly when the data are noisy, sparse, or partially observable. In this paper, we propose a Simulation-based Generative Model for Imperfect Data (SiGMoID) that enables precise and robust inference for dynamic systems. The proposed approach integrates two key methods: (1) physics-informed neural networks with hyper-networks that constructs an ODE solver, and (2) Wasserstein generative adversarial networks that estimates ODE parameters by effectively capturing noisy data distributions. We demonstrate that SiGMoID quantifies data noise, estimates system parameters, and infers unobserved system components. Its effectiveness is validated validated through realistic experimental examples, showcasing its broad applicability in various domains, from scientific research to engineered systems, and enabling the discovery of full system dynamics.","authors":["Hyunwoo Cho","Hyeontae Jo","Hyung Ju Hwang"],"pdf_url":"","comment":"20 pages, 9 figures, AAAI2026 (paper id: 20546)"},{"id":"http://arxiv.org/abs/2512.20856v1","updated":"2025-12-24T00:24:05Z","published":"2025-12-24T00:24:05Z","title":"NVIDIA Nemotron 3: Efficient and Open Intelligence","summary":"We introduce the Nemotron 3 family of models - Nano, Super, and Ultra. These models deliver strong agentic, reasoning, and conversational capabilities. The Nemotron 3 family uses a Mixture-of-Experts hybrid Mamba-Transformer architecture to provide best-in-class throughput and context lengths of up to 1M tokens. Super and Ultra models are trained with NVFP4 and incorporate LatentMoE, a novel approach that improves model quality. The two larger models also include MTP layers for faster text generation. All Nemotron 3 models are post-trained using multi-environment reinforcement learning enabling reasoning, multi-step tool use, and support granular reasoning budget control. Nano, the smallest model, outperforms comparable models in accuracy while remaining extremely cost-efficient for inference. Super is optimized for collaborative agents and high-volume workloads such as IT ticket automation. Ultra, the largest model, provides state-of-the-art accuracy and reasoning performance. Nano is released together with its technical report and this white paper, while Super and Ultra will follow in the coming months. We will openly release the model weights, pre- and post-training software, recipes, and all data for which we hold redistribution rights.","authors":[" NVIDIA"," :","Aaron Blakeman","Aaron Grattafiori","Aarti Basant","Abhibha Gupta","Abhinav Khattar","Adi Renduchintala","Aditya Vavre","Akanksha Shukla","Akhiad Bercovich","Aleksander Ficek","Aleksandr Shaposhnikov","Alex Kondratenko","Alexander Bukharin","Alexandre Milesi","Ali Taghibakhshi","Alisa Liu","Amelia Barton","Ameya Sunil Mahabaleshwarkar","Amir Klein","Amit Zuker","Amnon Geifman","Amy Shen","Anahita Bhiwandiwalla","Andrew Tao","Anjulie Agrusa","Ankur Verma","Ann Guan","Anubhav Mandarwal","Arham Mehta","Ashwath Aithal","Ashwin Poojary","Asif Ahamed","Asit Mishra","Asma Kuriparambil Thekkumpate","Ayush Dattagupta","Banghua Zhu","Bardiya Sadeghi","Barnaby Simkin","Ben Lanir","Benedikt Schifferer","Besmira Nushi","Bilal Kartal","Bita Darvish Rouhani","Boris Ginsburg","Brandon Norick","Brandon Soubasis","Branislav Kisacanin","Brian Yu","Bryan Catanzaro","Carlo del Mundo","Chantal Hwang","Charles Wang","Cheng-Ping Hsieh","Chenghao Zhang","Chenhan Yu","Chetan Mungekar","Chintan Patel","Chris Alexiuk","Christopher Parisien","Collin Neale","Cyril Meurillon","Damon Mosk-Aoyama","Dan Su","Dane Corneil","Daniel Afrimi","Daniel Lo","Daniel Rohrer","Daniel Serebrenik","Daria Gitman","Daria Levy","Darko Stosic","David Mosallanezhad","Deepak Narayanan","Dhruv Nathawani","Dima Rekesh","Dina Yared","Divyanshu Kakwani","Dong Ahn","Duncan Riach","Dusan Stosic","Edgar Minasyan","Edward Lin","Eileen Long","Eileen Peters Long","Elad Segal","Elena Lantz","Ellie Evans","Elliott Ning","Eric Chung","Eric Harper","Eric Tramel","Erick Galinkin","Erik Pounds","Evan Briones","Evelina Bakhturina","Evgeny Tsykunov","Faisal Ladhak","Fay Wang","Fei Jia","Felipe Soares","Feng Chen","Ferenc Galko","Frank Sun","Frankie Siino","Gal Hubara Agam","Ganesh Ajjanagadde","Gantavya Bhatt","Gargi Prasad","George Armstrong","Gerald Shen","Gorkem Batmaz","Grigor Nalbandyan","Haifeng Qian","Harsh Sharma","Hayley Ross","Helen Ngo","Herbert Hum","Herman Sahota","Hexin Wang","Himanshu Soni","Hiren Upadhyay","Huizi Mao","Huy C Nguyen","Huy Q Nguyen","Iain Cunningham","Ido Galil","Ido Shahaf","Igor Gitman","Ilya Loshchilov","Itamar Schen","Itay Levy","Ivan Moshkov","Izik Golan","Izzy Putterman","Jan Kautz","Jane Polak Scowcroft","Jared Casper","Jatin Mitra","Jeffrey Glick","Jenny Chen","Jesse Oliver","Jian Zhang","Jiaqi Zeng","Jie Lou","Jimmy Zhang","Jinhang Choi","Jining Huang","Joey Conway","Joey Guman","John Kamalu","Johnny Greco","Jonathan Cohen","Joseph Jennings","Joyjit Daw","Julien Veron Vialard","Junkeun Yi","Jupinder Parmar","Kai Xu","Kan Zhu","Kari Briski","Katherine Cheung","Katherine Luna","Keith Wyss","Keshav Santhanam","Kevin Shih","Kezhi Kong","Khushi Bhardwaj","Kirthi Shankar","Krishna C. Puvvada","Krzysztof Pawelec","Kumar Anik","Lawrence McAfee","Laya Sleiman","Leon Derczynski","Li Ding","Lizzie Wei","Lucas Liebenwein","Luis Vega","Maanu Grover","Maarten Van Segbroeck","Maer Rodrigues de Melo","Mahdi Nazemi","Makesh Narsimhan Sreedhar","Manoj Kilaru","Maor Ashkenazi","Marc Romeijn","Marcin Chochowski","Mark Cai","Markus Kliegl","Maryam Moosaei","Matt Kulka","Matvei Novikov","Mehrzad Samadi","Melissa Corpuz","Mengru Wang","Meredith Price","Michael Andersch","Michael Boone","Michael Evans","Miguel Martinez","Mikail Khona","Mike Chrzanowski","Minseok Lee","Mohammad Dabbah","Mohammad Shoeybi","Mostofa Patwary","Nabin Mulepati","Najeeb Nabwani","Natalie Hereth","Nave Assaf","Negar Habibi","Neta Zmora","Netanel Haber","Nicola Sessions","Nidhi Bhatia","Nikhil Jukar","Nikki Pope","Nikolai Ludwig","Nima Tajbakhsh","Nir Ailon","Nirmal Juluru","Nishant Sharma","Oleksii Hrinchuk","Oleksii Kuchaiev","Olivier Delalleau","Oluwatobi Olabiyi","Omer Ullman Argov","Omri Puny","Oren Tropp","Ouye Xie","Parth Chadha","Pasha Shamis","Paul Gibbons","Pavlo Molchanov","Pawel Morkisz","Peter Dykas","Peter Jin","Pinky Xu","Piotr Januszewski","Pranav Prashant Thombre","Prasoon Varshney","Pritam Gundecha","Przemek Tredak","Qing Miao","Qiyu Wan","Rabeeh Karimi Mahabadi","Rachit Garg","Ran El-Yaniv","Ran Zilberstein","Rasoul Shafipour","Rich Harang","Rick Izzo","Rima Shahbazyan","Rishabh Garg","Ritika Borkar","Ritu Gala","Riyad Islam","Robert Hesse","Roger Waleffe","Rohit Watve","Roi Koren","Ruoxi Zhang","Russell Hewett","Russell J. Hewett","Ryan Prenger","Ryan Timbrook","Sadegh Mahdavi","Sahil Modi","Samuel Kriman","Sangkug Lim","Sanjay Kariyappa","Sanjeev Satheesh","Saori Kaji","Satish Pasumarthi","Saurav Muralidharan","Sean Narentharen","Sean Narenthiran","Seonmyeong Bak","Sergey Kashirsky","Seth Poulos","Shahar Mor","Shanmugam Ramasamy","Shantanu Acharya","Shaona Ghosh","Sharath Turuvekere Sreenivas","Shelby Thomas","Shiqing Fan","Shreya Gopal","Shrimai Prabhumoye","Shubham Pachori","Shubham Toshniwal","Shuoyang Ding","Siddharth Singh","Simeng Sun","Smita Ithape","Somshubra Majumdar","Soumye Singhal","Stas Sergienko","Stefania Alborghetti","Stephen Ge","Sugam Dipak Devare","Sumeet Kumar Barua","Suseella Panguluri","Suyog Gupta","Sweta Priyadarshi","Syeda Nahida Akter","Tan Bui","Teodor-Dumitru Ene","Terry Kong","Thanh Do","Tijmen Blankevoort","Tim Moon","Tom Balough","Tomer Asida","Tomer Bar Natan","Tomer Ronen","Tugrul Konuk","Twinkle Vashishth","Udi Karpas","Ushnish De","Vahid Noorozi","Vahid Noroozi","Venkat Srinivasan","Venmugil Elango","Victor Cui","Vijay Korthikanti","Vinay Rao","Vitaly Kurin","Vitaly Lavrukhin","Vladimir Anisimov","Wanli Jiang","Wasi Uddin Ahmad","Wei Du","Wei Ping","Wenfei Zhou","Will Jennings","William Zhang","Wojciech Prazuch","Xiaowei Ren","Yashaswi Karnati","Yejin Choi","Yev Meyer","Yi-Fu Wu","Yian Zhang","Yigong Qin","Ying Lin","Yonatan Geifman","Yonggan Fu","Yoshi Subara","Yoshi Suhara","Yubo Gao","Zach Moshe","Zhen Dong","Zhongbo Zhu","Zihan Liu","Zijia Chen","Zijie Yan"],"pdf_url":"","comment":null}],"Operating Systems":[{"id":"http://arxiv.org/abs/2512.20860v1","updated":"2025-12-24T00:38:40Z","published":"2025-12-24T00:38:40Z","title":"pokiSEC: A Multi-Architecture, Containerized Ephemeral Malware Detonation Sandbox","summary":"Dynamic malware analysis requires executing untrusted binaries inside strongly isolated, rapidly resettable environments. In practice, many detonation workflows remain tied to heavyweight hypervisors or dedicated bare-metal labs, limiting portability and automation. This challenge has intensified with the adoption of ARM64 developer hardware (e.g., Apple Silicon), where common open-source sandbox recipes and pre-built environments frequently assume x86_64 hosts and do not translate cleanly across architectures. This paper presents pokiSEC, a lightweight, ephemeral malware detonation sandbox that packages the full virtualization and access stack inside a Docker container. pokiSEC integrates QEMU with hardware acceleration (KVM when available) and exposes a browser-based workflow that supports bring-your-own Windows disk images. The key contribution is a Universal Entrypoint that performs runtime host-architecture detection and selects validated hypervisor configurations (machine types, acceleration modes, and device profiles), enabling a single container image and codebase to launch Windows guests on both ARM64 and x86_64 hosts. We validate pokiSEC on Apple Silicon (ARM64) and Ubuntu (AMD64), demonstrating interactive performance suitable for analyst workflows and consistent teardown semantics via ephemeral container lifecycles.","authors":["Alejandro Avina","Yashas Hariprasad","Naveen Kumar Chaudhary"],"pdf_url":"","comment":"12 pages"}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2512.21153v1","updated":"2025-12-24T12:45:36Z","published":"2025-12-24T12:45:36Z","title":"ElfCore: A 28nm Neural Processor Enabling Dynamic Structured Sparse Training and Online Self-Supervised Learning with Activity-Dependent Weight Update","summary":"In this paper, we present ElfCore, a 28nm digital spiking neural network processor tailored for event-driven sensory signal processing. ElfCore is the first to efficiently integrate: (1) a local online self-supervised learning engine that enables multi-layer temporal learning without labeled inputs; (2) a dynamic structured sparse training engine that supports high-accuracy sparse-to-sparse learning; and (3) an activity-dependent sparse weight update mechanism that selectively updates weights based solely on input activity and network dynamics. Demonstrated on tasks including gesture recognition, speech, and biomedical signal processing, ElfCore outperforms state-of-the-art solutions with up to 16X lower power consumption, 3.8X reduced on-chip memory requirements, and 5.9X greater network capacity efficiency.","authors":["Zhe Su","Giacomo Indiveri"],"pdf_url":"","comment":"This paper has been published in the proceedings of the 2025 IEEE European Solid-State Electronics Research Conference (ESSERC)"},{"id":"http://arxiv.org/abs/2512.00020v2","updated":"2025-12-24T09:40:00Z","published":"2025-10-29T04:14:43Z","title":"Large Language Model for Verilog Code Generation: Literature Review and the Road Ahead","summary":"Code generation has emerged as a critical research area at the intersection of Software Engineering (SE) and Artificial Intelligence (AI), attracting significant attention from both academia and industry. Within this broader landscape, Verilog, as a representative hardware description language (HDL), plays a fundamental role in digital circuit design and verification, making its automated generation particularly significant for Electronic Design Automation (EDA). Consequently, recent research has increasingly focused on applying Large Language Models (LLMs) to Verilog code generation, particularly at the Register Transfer Level (RTL), exploring how these AI-driven techniques can be effectively integrated into hardware design workflows. Despite substantial research efforts have explored LLM applications in this domain, a comprehensive survey synthesizing these developments remains absent from the literature. This review fill addresses this gap by providing a systematic literature review of LLM-based methods for Verilog code generation, examining their effectiveness, limitations, and potential for advancing automated hardware design. The review encompasses research work from conferences and journals in the fields of SE, AI, and EDA, encompassing 70 papers published on venues, along with 32 high-quality preprint papers, bringing the total to 102 papers. By answering four key research questions, we aim to (1) identify the LLMs used for Verilog generation, (2) examine the datasets and metrics employed in evaluation, (3) categorize the techniques proposed for Verilog generation, and (4) analyze LLM alignment approaches for Verilog generation. Based on our findings, we have identified a series of limitations of existing studies. Finally, we have outlined a roadmap highlighting potential opportunities for future research endeavors in LLM-assisted hardware design.","authors":["Guang Yang","Wei Zheng","Xiang Chen","Dong Liang","Peng Hu","Yukui Yang","Shaohang Peng","Zhenghan Li","Jiahui Feng","Xiao Wei","Kexin Sun","Deyuan Ma","Haotian Cheng","Yiheng Shen","Xing Hu","Terry Yue Zhuo","David Lo"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2512.12284v3","updated":"2025-12-24T07:46:59Z","published":"2025-12-13T11:02:04Z","title":"V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval","summary":"Streaming video large language models (LLMs) are increasingly used for real-time multimodal tasks such as video captioning, question answering, conversational agents, and augmented reality. However, these models face fundamental memory and computational challenges because their key-value (KV) caches grow substantially with continuous streaming video input. This process requires an iterative prefill stage, which is a unique feature of streaming video LLMs. Due to its iterative prefill stage, it suffers from significant limitations, including extensive computation, substantial data transfer, and degradation in accuracy. Crucially, this issue is exacerbated for edge deployment, which is the primary target for these models.\n  In this work, we propose V-Rex, the first software-hardware co-designed accelerator that comprehensively addresses both algorithmic and hardware bottlenecks in streaming video LLM inference. At its core, V-Rex introduces ReSV, a training-free dynamic KV cache retrieval algorithm. ReSV exploits temporal and spatial similarity-based token clustering to reduce excessive KV cache memory across video frames. To fully realize these algorithmic benefits, V-Rex offers a compact, low-latency hardware accelerator with a dynamic KV cache retrieval engine (DRE), featuring bit-level and early-exit based computing units. V-Rex achieves unprecedented real-time of 3.9-8.3 FPS and energy-efficient streaming video LLM inference on edge deployment with negligible accuracy loss. While DRE only accounts for 2.2% power and 2.0% area, the system delivers 1.9-19.7x speedup and 3.1-18.5x energy efficiency improvements over AGX Orin GPU. This work is the first to comprehensively tackle KV cache retrieval across algorithms and hardware, enabling real-time streaming video LLM inference on resource-constrained edge devices.","authors":["Donghyuk Kim","Sejeong Yang","Wonjin Shin","Joo-Young Kim"],"pdf_url":"","comment":"14 pages, 20 figures, conference, accepted by HPCA 2026"},{"id":"http://arxiv.org/abs/2509.07690v5","updated":"2025-12-24T07:20:37Z","published":"2025-09-09T12:55:44Z","title":"HYLU: Hybrid Parallel Sparse LU Factorization","summary":"This article introduces HYLU, a hybrid parallel LU factorization-based general-purpose solver designed for efficiently solving sparse linear systems (Ax=b) on multi-core shared-memory architectures. The key technical feature of HYLU is the integration of hybrid numerical kernels so that it can adapt to various sparsity patterns of coefficient matrices. Tests on 34 sparse matrices from SuiteSparse Matrix Collection reveal that HYLU outperforms Intel MKL PARDISO in the numerical factorization phase by geometric means of 2.04X (for one-time solving) and 2.58X (for repeated solving). HYLU can be downloaded from https://github.com/chenxm1986/hylu.","authors":["Xiaoming Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20198v2","updated":"2025-12-24T03:53:05Z","published":"2025-12-23T09:43:32Z","title":"Designing Spatial Architectures for Sparse Attention: STAR Accelerator via Cross-Stage Tiling","summary":"Large language models (LLMs) rely on self-attention for contextual understanding, demanding high-throughput inference and large-scale token parallelism (LTPP). Existing dynamic sparsity accelerators falter under LTPP scenarios due to stage-isolated optimizations. Revisiting the end-to-end sparsity acceleration flow, we identify an overlooked opportunity: cross-stage coordination can substantially reduce redundant computation and memory access. We propose STAR, a cross-stage compute- and memory-efficient algorithm-hardware co-design tailored for Transformer inference under LTPP. STAR introduces a leading-zero-based sparsity prediction using log-domain add-only operations to minimize prediction overhead. It further employs distributed sorting and a sorted updating FlashAttention mechanism, guided by a coordinated tiling strategy that enables fine-grained stage interaction for improved memory efficiency and latency. These optimizations are supported by a dedicated STAR accelerator architecture, achieving up to 9.2$\\times$ speedup and 71.2$\\times$ energy efficiency over A100, and surpassing SOTA accelerators by up to 16.1$\\times$ energy and 27.1$\\times$ area efficiency gains. Further, we deploy STAR onto a multi-core spatial architecture, optimizing dataflow and execution orchestration for ultra-long sequence processing. Architectural evaluation shows that, compared to the baseline design, Spatial-STAR achieves a 20.1$\\times$ throughput improvement.","authors":["Huizheng Wang","Taiquan Wei","Hongbin Wang","Zichuan Wang","Xinru Tang","Zhiheng Yue","Shaojun Wei","Yang Hu","Shouyi Yin"],"pdf_url":"","comment":"Accepted for publication in IEEE Transactions on Computers. In this version, we have corrected the missing author information in the references"}],"Software Engineering":[{"id":"http://arxiv.org/abs/2512.21238v1","updated":"2025-12-24T15:29:54Z","published":"2025-12-24T15:29:54Z","title":"Assessing the Software Security Comprehension of Large Language Models","summary":"Large language models (LLMs) are increasingly used in software development, but their level of software security expertise remains unclear. This work systematically evaluates the security comprehension of five leading LLMs: GPT-4o-Mini, GPT-5-Mini, Gemini-2.5-Flash, Llama-3.1, and Qwen-2.5, using Blooms Taxonomy as a framework. We assess six cognitive dimensions: remembering, understanding, applying, analyzing, evaluating, and creating. Our methodology integrates diverse datasets, including curated multiple-choice questions, vulnerable code snippets (SALLM), course assessments from an Introduction to Software Security course, real-world case studies (XBOW), and project-based creation tasks from a Secure Software Engineering course. Results show that while LLMs perform well on lower-level cognitive tasks such as recalling facts and identifying known vulnerabilities, their performance degrades significantly on higher-order tasks that require reasoning, architectural evaluation, and secure system creation. Beyond reporting aggregate accuracy, we introduce a software security knowledge boundary that identifies the highest cognitive level at which a model consistently maintains reliable performance. In addition, we identify 51 recurring misconception patterns exhibited by LLMs across Blooms levels.","authors":["Mohammed Latif Siddiq","Natalie Sekerak","Antonio Karam","Maria Leal","Arvin Islam-Gomes","Joanna C. S. Santos"],"pdf_url":"","comment":"Submitted to Empirical Software Engineering (EMSE) journal"},{"id":"http://arxiv.org/abs/2512.21236v1","updated":"2025-12-24T15:25:31Z","published":"2025-12-24T15:25:31Z","title":"Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking","summary":"Large language models (LLMs) have revolutionized software development through AI-assisted coding tools, enabling developers with limited programming expertise to create sophisticated applications. However, this accessibility extends to malicious actors who may exploit these powerful tools to generate harmful software. Existing jailbreaking research primarily focuses on general attack scenarios against LLMs, with limited exploration of malicious code generation as a jailbreak target. To address this gap, we propose SPELL, a comprehensive testing framework specifically designed to evaluate the weakness of security alignment in malicious code generation. Our framework employs a time-division selection strategy that systematically constructs jailbreaking prompts by intelligently combining sentences from a prior knowledge dataset, balancing exploration of novel attack patterns with exploitation of successful techniques. Extensive evaluation across three advanced code models (GPT-4.1, Claude-3.5, and Qwen2.5-Coder) demonstrates SPELL's effectiveness, achieving attack success rates of 83.75%, 19.38%, and 68.12% respectively across eight malicious code categories. The generated prompts successfully produce malicious code in real-world AI development tools such as Cursor, with outputs confirmed as malicious by state-of-the-art detection systems at rates exceeding 73%. These findings reveal significant security gaps in current LLM implementations and provide valuable insights for improving AI safety alignment in code generation applications.","authors":["Yifan Huang","Xiaojun Jia","Wenbo Guo","Yuqiang Sun","Yihao Huang","Chong Wang","Yang Liu"],"pdf_url":"","comment":"Accepted to FSE 2026"},{"id":"http://arxiv.org/abs/2507.19027v2","updated":"2025-12-24T12:40:01Z","published":"2025-07-25T07:27:03Z","title":"SESR-Eval: Dataset for Evaluating LLMs in the Title-Abstract Screening of Systematic Reviews","summary":"Background: The use of large language models (LLMs) in the title-abstract screening process of systematic reviews (SRs) has shown promising results, but suffers from limited performance evaluation. Aims: Create a benchmark dataset to evaluate the performance of LLMs in the title-abstract screening process of SRs. Provide evidence whether using LLMs in title-abstract screening in software engineering is advisable. Method: We start with 169 SR research artifacts and find 24 of those to be suitable for inclusion in the dataset. Using the dataset we benchmark title-abstract screening using 9 LLMs. Results: We present the SESR-Eval (Software Engineering Systematic Review Evaluation) dataset containing 34,528 labeled primary studies, sourced from 24 secondary studies published in software engineering (SE) journals. Most LLMs performed similarly and the differences in screening accuracy between secondary studies are greater than differences between LLMs. The cost of using an LLM is relatively low - less than $40 per secondary study even for the most expensive model. Conclusions: Our benchmark enables monitoring AI performance in the screening task of SRs in software engineering. At present, LLMs are not yet recommended for automating the title-abstract screening process, since accuracy varies widely across secondary studies, and no LLM managed a high recall with reasonable precision. In future, we plan to investigate factors that influence LLM screening performance between studies.","authors":["Aleksi Huotala","Miikka Kuutila","Mika Mäntylä"],"pdf_url":"","comment":"An updated post-print on the paper published in the Proceedings of the 19th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM '25). 12 pages (10 + 2 pages for references)"},{"id":"http://arxiv.org/abs/2512.19883v2","updated":"2025-12-24T07:58:28Z","published":"2025-12-22T21:17:31Z","title":"Larger Is Not Always Better: Leveraging Structured Code Diffs for Comment Inconsistency Detection","summary":"Ensuring semantic consistency between source code and its accompanying comments is crucial for program comprehension, effective debugging, and long-term maintainability. Comment inconsistency arises when developers modify code but neglect to update the corresponding comments, potentially misleading future maintainers and introducing errors. Recent approaches to code-comment inconsistency (CCI) detection leverage Large Language Models (LLMs) and rely on capturing the semantic relationship between code changes and outdated comments. However, they often ignore the structural complexity of code evolution, including historical change activities, and introduce privacy and resource challenges. In this paper, we propose a Just-In-Time CCI detection approach built upon the CodeT5+ backbone. Our method decomposes code changes into ordered sequences of modification activities such as replacing, deleting, and adding to more effectively capture the correlation between these changes and the corresponding outdated comments. Extensive experiments conducted on publicly available benchmark datasets-JITDATA and CCIBENCH--demonstrate that our proposed approach outperforms recent state-of-the-art models by up to 13.54% in F1-Score and achieves an improvement ranging from 4.18% to 10.94% over fine-tuned LLMs including DeepSeek-Coder, CodeLlama and Qwen2.5-Coder.","authors":["Phong Nguyen","Anh M. T. Bui","Phuong T. Nguyen"],"pdf_url":"","comment":"This paper has been reviewed and accepted to the Short Papers and Posters Track of SANER 2026"},{"id":"http://arxiv.org/abs/2512.21028v1","updated":"2025-12-24T07:51:15Z","published":"2025-12-24T07:51:15Z","title":"Artificial or Just Artful? Do LLMs Bend the Rules in Programming?","summary":"Large Language Models (LLMs) are widely used for automated code generation, yet their apparent successes often mask a tension between pretraining objectives and alignment choices. While pretraining encourages models to exploit all available signals to maximize success, alignment, whether through fine-tuning or prompting, may restrict their use. This conflict is especially salient in agentic AI settings, for instance when an agent has access to unit tests that, although intended for validation, act as strong contextual signals that can be leveraged regardless of explicit prohibitions. In this paper, we investigate how LLMs adapt their code generation strategies when exposed to test cases under different prompting conditions. Using the BigCodeBench (Hard) dataset, we design five prompting conditions that manipulate test visibility and impose explicit or implicit restrictions on their use. We evaluate five LLMs (four open-source and one closed-source) across correctness, code similarity, program size, and code churn, and analyze cross-model consistency to identify recurring adaptation strategies. Our results show that test visibility dramatically alters performance, correctness nearly doubles for some models, while explicit restrictions or partial exposure only partially mitigate this effect. Beyond raw performance, we identify four recurring adaptation strategies, with test-driven refinement emerging as the most frequent. These results highlight how LLMs adapt their behavior when exposed to contextual signals that conflict with explicit instructions, providing useful insight into how models reconcile pretraining objectives with alignment constraints.","authors":["Oussama Ben Sghaier","Kevin Delcourt","Houari Sahraoui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16070v3","updated":"2025-12-24T07:33:31Z","published":"2025-12-18T01:35:30Z","title":"LLM4Perf: Large Language Models Are Effective Samplers for Multi-Objective Performance Modeling","summary":"The performance of modern software systems is critically dependent on their complex configuration options. Building accurate performance models to navigate this vast space requires effective sampling strategies, yet existing methods often struggle with multi-objective optimization and cannot leverage semantic information from documentation. The recent success of Large Language Models (LLMs) motivates the central question of this work: Can LLMs serve as effective samplers for multi-objective performance modeling? To explore this, we present a comprehensive empirical study investigating the capabilities and characteristics of LLM-driven sampling. We design and implement LLM4Perf, a feedback-based framework, and use it to systematically evaluate the LLM-guided sampling process across four highly configurable, real-world systems. Our study reveals that the LLM-guided approach outperforms traditional baselines in most cases. Quantitatively, LLM4Perf achieves the best performance in nearly 68.8% (77 out of 112) of all evaluation scenarios, demonstrating its superior effectiveness. We find this effectiveness stems from the LLM's dual capabilities of configuration space pruning and feedback-driven strategy refinement. The effectiveness of this pruning is further validated by the fact that it also improves the performance of the baseline methods in nearly 91.5% (410 out of 448) of cases. Furthermore, we show how the LLM choices for each component and hyperparameters within LLM4Perf affect its effectiveness. Overall, this paper provides strong evidence for the effectiveness of LLMs in performance engineering and offers concrete insights into the mechanisms that drive their success.","authors":["Xin Wang","Zhenhao Li","Zishuo Ding"],"pdf_url":"","comment":"ICSE 2026"},{"id":"http://arxiv.org/abs/2512.18748v2","updated":"2025-12-24T06:47:27Z","published":"2025-12-21T14:28:51Z","title":"Code2Doc: A Quality-First Curated Dataset for Code Documentation","summary":"The performance of automatic code documentation generation models depends critically on the quality of the training data used for supervision. However, most existing code documentation datasets are constructed through large scale scraping of public repositories with limited quality control. As a result, they often contain noisy documentation, extensive duplication, and increasing contamination from AI generated content. These issues weaken the supervision signal available to learning-based models and complicate evaluation.\n  We introduce Code2Doc, a quality-first curated dataset for function-level code documentation generation. Code2Doc consists of 13,358 high-quality function-documentation pairs extracted from widely used open-source repositories spanning five programming languages: Python, Java, TypeScript, JavaScript, and C++. The dataset is constructed using a four-stage curation pipeline that enforces documentation completeness and clarity, filters functions based on structural and complexity criteria, removes exact and near-duplicate code, and identifies documentation likely to be AI generated. Starting from 52,069 extracted candidates, only 25.6% satisfy all quality constraints.\n  We provide a detailed analysis of the resulting dataset, which achieves a mean documentation quality score of 6.93 out of 10. Overall, 86.9% of samples contain explicit type annotations, and only 2.9% are flagged as potentially AI generated. Baseline experiments show that fine-tuning a large language model on Code2Doc yields relative improvements of 29.47% in BLEU and 24.04% in ROUGE-L over zero shot performance, despite the modest dataset size. We release both the dataset and the full curation pipeline to support reproducible research on automatic code documentation generation.","authors":["Recep Kaan Karaman","Meftun Akarsu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20957v1","updated":"2025-12-24T05:27:53Z","published":"2025-12-24T05:27:53Z","title":"One Tool Is Enough: Reinforcement Learning for Repository-Level LLM Agents","summary":"Locating the files and functions requiring modification in large open-source software (OSS) repositories is challenging due to their scale and structural complexity. Existing large language model (LLM)-based methods typically treat this as a repository-level retrieval task and rely on multiple auxiliary tools, which overlook code execution logic and complicate model control. We propose RepoNavigator, an LLM agent equipped with a single execution-aware tool-jumping to the definition of an invoked symbol. This unified design reflects the actual flow of code execution while simplifying tool manipulation. RepoNavigator is trained end-to-end via Reinforcement Learning (RL) directly from a pretrained model, without any closed-source distillation. Experiments demonstrate that RL-trained RepoNavigator achieves state-of-the-art performance, with the 7B model outperforming 14B baselines, the 14B model surpassing 32B competitors, and even the 32B model exceeding closed-source models such as Claude-3.7. These results confirm that integrating a single, structurally grounded tool with RL training provides an efficient and scalable solution for repository-level issue localization.","authors":["Zhaoxi Zhang","Yitong Duan","Yanzhi Zhang","Yiming Xu","Jiyan He","Yunfang Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.18802v3","updated":"2025-12-24T02:39:19Z","published":"2025-10-21T16:57:40Z","title":"Computational Foundations for Strategic Coopetition: Formalizing Interdependence and Complementarity","summary":"Coopetition refers to simultaneous cooperation and competition among actors wherein actors 'cooperate to grow the pie and compete to split it up.' Modern socio-technical systems are characterized by strategic coopetition wherein actors concomitantly cooperate to create value and compete to capture it. While conceptual modeling languages such as i* provide rich qualitative representations of strategic dependencies, they lack mechanisms for quantitative analysis of dynamic trade-offs. Conversely, classical game theory offers mathematical rigor but strips away contextual richness. This report bridges this gap by developing computational foundations that formalize two critical dimensions of coopetition: interdependence and complementarity. We ground interdependence in i* structural dependency analysis, translating depender-dependee-dependum relationships into quantitative interdependence coefficients via a structured translation framework. We formalize complementarity following Brandenburger and Nalebuff's Added Value concept, modeling synergistic value creation with validated parameterization. We integrate structural dependencies with bargaining power in value appropriation and introduce a game-theoretic formulation where Nash Equilibrium incorporates structural interdependence. Validation combines over 22,000 experimental trials across power and logarithmic specifications with the Samsung-Sony S-LCD joint venture (2004-2011). Under strict historical alignment scoring, logarithmic specifications achieve 58/60 compared to power functions (46/60), producing realistic 41% cooperation increases aligning with documented S-LCD patterns while power functions produce 166% increases exceeding realistic bounds. Statistical significance confirmed at p < 0.001, Cohen's d > 9.","authors":["Vik Pant","Eric Yu"],"pdf_url":"","comment":"39 pages, 9 figures, This technical report serves as the foundational reference for a coordinated research program examining strategic coopetition in requirements engineering and multi-agent systems, with companion work addressing trust dynamics, team production, and reciprocity mechanisms"}],"Performance":[{"id":"http://arxiv.org/abs/2512.21010v1","updated":"2025-12-24T07:14:31Z","published":"2025-12-24T07:14:31Z","title":"LLM Swiss Round: Aggregating Multi-Benchmark Performance via Competitive Swiss-System Dynamics","summary":"The rapid proliferation of Large Language Models (LLMs) and diverse specialized benchmarks necessitates a shift from fragmented, task-specific metrics to a holistic, competitive ranking system that effectively aggregates performance across multiple ability dimensions. Primarily using static scoring, current evaluation methods are fundamentally limited. They struggle to determine the proper mix ratio across diverse benchmarks, and critically, they fail to capture a model's dynamic competitive fitness or its vulnerability when confronted with sequential, high-stakes tasks. To address this, we introduce the novel Competitive Swiss-System Dynamics (CSD) framework. CSD simulates a multi-round, sequential contest where models are dynamically paired across a curated sequence of benchmarks based on their accumulated win-loss record. And Monte Carlo Simulation ($N=100,000$ iterations) is used to approximate the statistically robust Expected Win Score ($E[S_m]$), which eliminates the noise of random pairing and early-round luck. Furthermore, we implement a Failure Sensitivity Analysis by parameterizing the per-round elimination quantity ($T_k$), which allows us to profile models based on their risk appetite--distinguishing between robust generalists and aggressive specialists. We demonstrate that CSD provides a more nuanced and context-aware ranking than traditional aggregate scoring and static pairwise models, representing a vital step towards risk-informed, next-generation LLM evaluation.","authors":["Jiashuo Liu","Jiayun Wu","Chunjie Wu","Jingkai Liu","Zaiyuan Wang","Huan Zhou","Wenhao Huang","Hongseok Namkoong"],"pdf_url":"","comment":"18 pages"}],"Programming Languages":[{"id":"http://arxiv.org/abs/2512.20214v2","updated":"2025-12-24T12:57:44Z","published":"2025-12-23T10:15:28Z","title":"Error Localization, Certificates, and Hints for Probabilistic Program Verification via Slicing (Extended Version)","summary":"This paper focuses on effective user diagnostics generated during the deductive verification of probabilistic programs. Our key principle is based on providing slices for (1) error reporting, (2) proof simplification, and (3) preserving successful verification results. By formally defining these different notions on HeyVL, an existing quantitative intermediate verification language (IVL), our concepts (and implementation) can be used to obtain diagnostics for a range of probabilistic programming languages. Slicing for error reporting is a novel notion of error localization for quantitative assertions. We demonstrate slicing-based diagnostics on a variety of proof rules such as quantitative versions of the specification statement and invariant-based loop rules, and formally prove the correctness of specialized error messages and verification hints.\n  We implemented our user diagnostics into the deductive verifier Caesar. Our novel implementation -- called \\emph{Brutus} -- can search for slices which do or do not verify, corresponding to each of the three diagnostic notions. For error reporting (1), it exploits a binary search-based algorithm that minimizes error-witnessing slices. To solve for slices that verify (2 and 3), we empirically compare different algorithms based on unsatisfiable cores, minimal unsatisfiable subset enumeration, and a direct SMT encoding of the slicing problem. Our empirical evaluation of Brutus on existing and new benchmarks shows that we can find slices that are both small and informative.","authors":["Philipp Schröer","Darion Haase","Joost-Pieter Katoen"],"pdf_url":"","comment":"Accepted at the European Symposium on Programming (ESOP) 2026"},{"id":"http://arxiv.org/abs/2512.21132v1","updated":"2025-12-24T12:02:00Z","published":"2025-12-24T12:02:00Z","title":"AutoBaxBuilder: Bootstrapping Code Security Benchmarking","summary":"As LLMs see wide adoption in software engineering, the reliable assessment of the correctness and security of LLM-generated code is crucial. Notably, prior work has demonstrated that security is often overlooked, exposing that LLMs are prone to generating code with security vulnerabilities. These insights were enabled by specialized benchmarks, crafted through significant manual effort by security experts. However, relying on manually-crafted benchmarks is insufficient in the long term, because benchmarks (i) naturally end up contaminating training data, (ii) must extend to new tasks to provide a more complete picture, and (iii) must increase in difficulty to challenge more capable LLMs. In this work, we address these challenges and present AutoBaxBuilder, a framework that generates tasks and tests for code security benchmarking from scratch. We introduce a robust pipeline with fine-grained plausibility checks, leveraging the code understanding capabilities of LLMs to construct functionality tests and end-to-end security-probing exploits. To confirm the quality of the generated benchmark, we conduct both a qualitative analysis and perform quantitative experiments, comparing it against tasks constructed by human experts. We use AutoBaxBuilder to construct entirely new tasks and release them to the public as AutoBaxBench, together with a thorough evaluation of the security capabilities of LLMs on these tasks. We find that a new task can be generated in under 2 hours, costing less than USD 10.","authors":["Tobias von Arx","Niels Mündler","Mark Vero","Maximilian Baader","Martin Vechev"],"pdf_url":"","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2512.21336v1","updated":"2025-12-24T18:59:51Z","published":"2025-12-24T18:59:51Z","title":"Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty","summary":"Masked Diffusion Models (MDMs) offer flexible, non-autoregressive generation, but this freedom introduces a challenge: final output quality is highly sensitive to the decoding order. We are the first to formalize this issue, attributing the variability in output quality to the cumulative predictive uncertainty along a generative path. To quantify this uncertainty, we introduce Denoising Entropy, a computable metric that serves as an internal signal for evaluating generative process. Leveraging this metric, we propose two algorithms designed to optimize the decoding path: a post-hoc selection method and a real-time guidance strategy. Experiments demonstrate that our entropy-guided methods significantly improve generation quality, consistently boosting accuracy on challenging reasoning, planning, and code benchmarks. Our work establishes Denoising Entropy as a principled tool for understanding and controlling generation, effectively turning the uncertainty in MDMs from a liability into a key advantage for discovering high-quality solutions.","authors":["Ziyu Chen","Xinbei Jiang","Peng Sun","Tao Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21332v1","updated":"2025-12-24T18:59:01Z","published":"2025-12-24T18:59:01Z","title":"C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling","summary":"We present C2LLM - Contrastive Code Large Language Models, a family of code embedding models in both 0.5B and 7B sizes. Building upon Qwen-2.5-Coder backbones, C2LLM adopts a Pooling by Multihead Attention (PMA) module for generating sequence embedding from token embeddings, effectively 1) utilizing the LLM's causal representations acquired during pretraining, while also 2) being able to aggregate information from all tokens in the sequence, breaking the information bottleneck in EOS-based sequence embeddings, and 3) supporting flexible adaptation of embedding dimension, serving as an alternative to MRL. Trained on three million publicly available data, C2LLM models set new records on MTEB-Code among models of similar sizes, with C2LLM-7B ranking 1st on the overall leaderboard.","authors":["Jin Qin","Zihan Liao","Ziyin Zhang","Hang Yu","Peng Di","Rui Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21326v1","updated":"2025-12-24T18:54:37Z","published":"2025-12-24T18:54:37Z","title":"Measuring all the noises of LLM Evals","summary":"Separating signal from noise is central to experimental science. Applying well-established statistical method effectively to LLM evals requires consideration of their unique noise characteristics. We clearly define and measure three types of noise: prediction noise from generating different answers on a given question, data noise from sampling questions, and their combined total noise following the law of total variance. To emphasize relative comparisons and gain statistical power, we propose the all-pairs paired method, which applies the paired analysis to all pairs of LLMs and measures all the noise components based on millions of question-level predictions across many evals and settings. These measurements revealed clear patterns. First, each eval exhibits a characteristic and highly predictable total noise level across all model pairs. Second, paired prediction noise typically exceeds paired data noise, which means reducing prediction noise by averaging can significantly increase statistical power. These findings enable practitioners to assess significance without custom testing and to detect much smaller effects in controlled experiments.","authors":["Sida Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21316v1","updated":"2025-12-24T18:24:29Z","published":"2025-12-24T18:24:29Z","title":"Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Consulting, Data Analyst, and Management Tasks","summary":"This paper derives `Scaling Laws for Economic Impacts' -- empirical relationships between the training compute of Large Language Models (LLMs) and professional productivity. In a preregistered experiment, over 500 consultants, data analysts, and managers completed professional tasks using one of 13 LLMs. We find that each year of AI model progress reduced task time by 8%, with 56% of gains driven by increased compute and 44% by algorithmic progress. However, productivity gains were significantly larger for non-agentic analytical tasks compared to agentic workflows requiring tool use. These findings suggest continued model scaling could boost U.S. productivity by approximately 20% over the next decade.","authors":["Ali Merali"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17083v2","updated":"2025-12-24T18:05:57Z","published":"2025-12-18T21:29:43Z","title":"When F1 Fails: Granularity-Aware Evaluation for Dialogue Topic Segmentation","summary":"Dialogue topic segmentation supports summarization, retrieval, memory management, and conversational continuity. Despite decades of work, evaluation practice remains dominated by strict boundary matching and F1-based metrics. Modern large language model (LLM) based conversational systems increasingly rely on segmentation to manage conversation history beyond fixed context windows. In such systems, unstructured context accumulation degrades efficiency and coherence.\n  This paper introduces an evaluation framework that reports boundary density and segment alignment diagnostics (purity and coverage) alongside window-tolerant F1 (W-F1). By separating boundary scoring from boundary selection, we evaluate segmentation quality across density regimes rather than at a single operating point. Cross-dataset evaluation shows that reported performance differences often reflect annotation granularity mismatch rather than boundary placement quality alone.\n  We evaluate structurally distinct segmentation strategies across eight dialogue datasets spanning task-oriented, open-domain, meeting-style, and synthetic interactions. Boundary-based metrics are strongly coupled to boundary density: threshold sweeps produce larger W-F1 changes than switching between methods. These findings support viewing topic segmentation as a granularity selection problem rather than prediction of a single correct boundary set. This motivates separating boundary scoring from boundary selection for analyzing and tuning segmentation under varying annotation granularities.","authors":["Michael H. Coen"],"pdf_url":"","comment":"32 pages, 4 figures. Evaluation and methodology study on dialogue topic segmentation"},{"id":"http://arxiv.org/abs/2502.06096v4","updated":"2025-12-24T17:17:29Z","published":"2025-02-10T02:01:30Z","title":"Post-detection inference for sequential changepoint localization","summary":"This paper addresses a fundamental but largely unexplored challenge in sequential changepoint analysis: conducting inference following a detected change. We develop a very general framework to construct confidence sets for the unknown changepoint using only the data observed up to a data-dependent stopping time at which an arbitrary sequential detection algorithm declares a change. Our framework is nonparametric, making no assumption on the composite post-change class, the observation space, or the sequential detection procedure used, and is non-asymptotically valid. We also extend it to handle composite pre-change classes under a suitable assumption, and also derive confidence sets for the change magnitude in parametric settings. We provide theoretical guarantees on the width of our confidence intervals. Extensive simulations demonstrate that the produced sets have reasonable size, and slightly conservative coverage. In summary, we present the first general method for sequential changepoint localization, which is theoretically sound and broadly applicable in practice.","authors":["Aytijhya Saha","Aaditya Ramdas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.09016v2","updated":"2025-12-24T17:16:37Z","published":"2025-10-10T05:39:45Z","title":"DiTSinger: Scaling Singing Voice Synthesis with Diffusion Transformer and Implicit Alignment","summary":"Recent progress in diffusion-based Singing Voice Synthesis (SVS) demonstrates strong expressiveness but remains limited by data scarcity and model scalability. We introduce a two-stage pipeline: a compact seed set of human-sung recordings is constructed by pairing fixed melodies with diverse LLM-generated lyrics, and melody-specific models are trained to synthesize over 500 hours of high-quality Chinese singing data. Building on this corpus, we propose DiTSinger, a Diffusion Transformer with RoPE and qk-norm, systematically scaled in depth, width, and resolution for enhanced fidelity. Furthermore, we design an implicit alignment mechanism that obviates phoneme-level duration labels by constraining phoneme-to-acoustic attention within character-level spans, thereby improving robustness under noisy or uncertain alignments. Extensive experiments validate that our approach enables scalable, alignment-free, and high-fidelity SVS.","authors":["Zongcai Du","Guilin Deng","Xiaofeng Guo","Xin Gao","Linke Li","Kaichang Cheng","Fubo Han","Siyu Yang","Peng Liu","Pan Zhong","Qiang Fu"],"pdf_url":"","comment":"ICASSP26 under review. Demo page: https://nju-jet.github.io/DiTSinger"},{"id":"http://arxiv.org/abs/2512.10688v5","updated":"2025-12-24T17:12:02Z","published":"2025-12-11T14:35:13Z","title":"Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition","summary":"Popularity bias fundamentally undermines the personalization capabilities of collaborative filtering (CF) models, causing them to disproportionately recommend popular items while neglecting users' genuine preferences for niche content. While existing approaches treat this as an external confounding factor, we reveal that popularity bias is an intrinsic geometric artifact of Bayesian Pairwise Ranking (BPR) optimization in CF models. Through rigorous mathematical analysis, we prove that BPR systematically organizes item embeddings along a dominant \"popularity direction\" where embedding magnitudes directly correlate with interaction frequency. This geometric distortion forces user embeddings to simultaneously handle two conflicting tasks-expressing genuine preference and calibrating against global popularity-trapping them in suboptimal configurations that favor popular items regardless of individual tastes. We propose Directional Decomposition and Correction (DDC), a universally applicable framework that surgically corrects this embedding geometry through asymmetric directional updates. DDC guides positive interactions along personalized preference directions while steering negative interactions away from the global popularity direction, disentangling preference from popularity at the geometric source. Extensive experiments across multiple BPR-based architectures demonstrate that DDC significantly outperforms state-of-the-art debiasing methods, reducing training loss to less than 5% of heavily-tuned baselines while achieving superior recommendation quality and fairness. Code is available in https://github.com/LingFeng-Liu-AI/DDC.","authors":["Lingfeng Liu","Yixin Song","Dazhong Shen","Bing Yin","Hao Li","Yanyong Zhang","Chao Wang"],"pdf_url":"","comment":"Accepted by SIGKDD 2026(First Cycle)"},{"id":"http://arxiv.org/abs/2512.21288v1","updated":"2025-12-24T17:10:44Z","published":"2025-12-24T17:10:44Z","title":"Model Merging via Multi-Teacher Knowledge Distillation","summary":"Model merging has emerged as a lightweight alternative to joint multi-task learning (MTL), yet the generalization properties of merged models remain largely unexplored. Establishing such theoretical guarantees is non-trivial, as the merging process typically forbids access to the original training data and involves combining fine-tuned models trained on fundamentally heterogeneous data distributions. Without a principled understanding of these dynamics, current methods often rely on heuristics to approximate the optimal combination of parameters. This dependence is most critical in coefficient scaling, the weighting factors that modulate the magnitude of each fine-tuned model's contribution to the shared parameter. However, without a principled objective to guide their selection, these methods lead to brittle performance and are highly sensitive to scaling initialization. We address this gap by (i) establishing a novel flatness-aware PAC-Bayes generalization bound specifically for the model merging setting. This analysis introduces a \"cross-task heterogeneity\" term that formally captures the mismatch between diverse fine-tuned model priors and the target multi-task distributions. Guided by this theoretical insight, (ii) we frame model merging as multi-teacher knowledge distillation on scarce, unlabeled data. We formally demonstrate that minimizing the student-teacher Kullback-Leibler divergence directly tightens the upper bound on the merged model's excess risk. Guided by the flatness-aware bound derived, (iii) we operationalize this objective via SAMerging, a method that employs Sharpness-Aware Minimization (SAM) to find flat minima. Empirically, SAMerging establishes a new state of the art across vision and NLP benchmarks, achieving remarkable performance. The code is available at https://github.com/arshandalili/SAMerging.","authors":["Seyed Arshan Dalili","Mehrdad Mahdavi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21280v1","updated":"2025-12-24T16:59:04Z","published":"2025-12-24T16:59:04Z","title":"SMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance","summary":"The user of Engineering Manuals (EM) finds it difficult to read EM s because they are long, have a dense format which includes written documents, step by step procedures, and standard parameter lists for engineering equipment. Off the shelf transformers, especially compact ones, treat this material as a flat stream of tokens. This approach leads to confident but incorrect numeric answers and forces the models to memorize separate facts inefficiently. SMART (Structured Memory and Reasoning Transformer) offers a different and practical solution to the above problem. SMART structures its processing by using a hierarchical approach, and is based upon three main job categories (1) A syntax-aware Fact Extractor (Grammarian) Tree LSTM which extracts facts as subject relation object relations from EM sentences (2) A compact indexed memory MANN (Memory Augmented Neural Network) that indexes these Rational Subject Relation Objects as 384 dimensional vectors that are associated with the source of the information, and (3) A 6 layer Transformer that learns to fuse the previously retrieved facts into its generated response. The entire SMART model utilizes 45.51M parameters, which is 64% less than GPT-2 (124M) and 69% less than BERT (133M), and it achieves a 21.3% higher accuracy than GPT-2, indicating that SMART fits the data better with the least amount of processing requirements. SMART employs dual modes of inference an indexed fast path for known documents (sub-second answer times) and an indexed dynamic path assisted by RAGs for new uploads (FAISS Top 20 results with memory severed at 64 slots). In real world deployment, this framework leads to more well supported results with reduced hallucinations than comparable small transformer models.","authors":["Divij Dudeja","Mayukha Pal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21246v1","updated":"2025-12-24T15:43:58Z","published":"2025-12-24T15:43:58Z","title":"Learning Factors in AI-Augmented Education: A Comparative Study of Middle and High School Students","summary":"The increasing integration of AI tools in education has led prior research to explore their impact on learning processes. Nevertheless, most existing studies focus on higher education and conventional instructional contexts, leaving open questions about how key learning factors are related in AI-mediated learning environments and how these relationships may vary across different age groups. Addressing these gaps, our work investigates whether four critical learning factors, experience, clarity, comfort, and motivation, maintain coherent interrelationships in AI-augmented educational settings, and how the structure of these relationships differs between middle and high school students. The study was conducted in authentic classroom contexts where students interacted with AI tools as part of programming learning activities to collect data on the four learning factors and students' perceptions. Using a multimethod quantitative analysis, which combined correlation analysis and text mining, we revealed markedly different dimensional structures between the two age groups. Middle school students exhibit strong positive correlations across all dimensions, indicating holistic evaluation patterns whereby positive perceptions in one dimension generalise to others. In contrast, high school students show weak or near-zero correlations between key dimensions, suggesting a more differentiated evaluation process in which dimensions are assessed independently. These findings reveal that perception dimensions actively mediate AI-augmented learning and that the developmental stage moderates their interdependencies. This work establishes a foundation for the development of AI integration strategies that respond to learners' developmental levels and account for age-specific dimensional structures in student-AI interactions.","authors":["Gaia Ebli","Bianca Raimondi","Maurizio Gabbrielli"],"pdf_url":"","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2512.17864v2","updated":"2025-12-24T15:38:23Z","published":"2025-12-19T18:11:15Z","title":"Interpretable Plant Leaf Disease Detection Using Attention-Enhanced CNN","summary":"Plant diseases pose a significant threat to global food security, necessitating accurate and interpretable disease detection methods. This study introduces an interpretable attention-guided Convolutional Neural Network (CNN), CBAM-VGG16, for plant leaf disease detection. By integrating Convolution Block Attention Module (CBAM) at each convolutional stage, the model enhances feature extraction and disease localization. Trained on five diverse plant disease datasets, our approach outperforms recent techniques, achieving high accuracy (up to 98.87%) and demonstrating robust generalization. Here, we show the effectiveness of our method through comprehensive evaluation and interpretability analysis using CBAM attention maps, Grad-CAM, Grad-CAM++, and Layer-wise Relevance Propagation (LRP). This study advances the application of explainable AI in agricultural diagnostics, offering a transparent and reliable system for smart farming. The code of our proposed work is available at https://github.com/BS0111/PlantAttentionCBAM.","authors":["Balram Singh","Ram Prakash Sharma","Somnath Dey"],"pdf_url":"","comment":"27 pages, 12 figures"},{"id":"http://arxiv.org/abs/2512.21243v1","updated":"2025-12-24T15:36:21Z","published":"2025-12-24T15:36:21Z","title":"LookPlanGraph: Embodied Instruction Following Method with VLM Graph Augmentation","summary":"Methods that use Large Language Models (LLM) as planners for embodied instruction following tasks have become widespread. To successfully complete tasks, the LLM must be grounded in the environment in which the robot operates. One solution is to use a scene graph that contains all the necessary information. Modern methods rely on prebuilt scene graphs and assume that all task-relevant information is available at the start of planning. However, these approaches do not account for changes in the environment that may occur between the graph construction and the task execution. We propose LookPlanGraph - a method that leverages a scene graph composed of static assets and object priors. During plan execution, LookPlanGraph continuously updates the graph with relevant objects, either by verifying existing priors or discovering new entities. This is achieved by processing the agents egocentric camera view using a Vision Language Model. We conducted experiments with changed object positions VirtualHome and OmniGibson simulated environments, demonstrating that LookPlanGraph outperforms methods based on predefined static scene graphs. To demonstrate the practical applicability of our approach, we also conducted experiments in a real-world setting. Additionally, we introduce the GraSIF (Graph Scenes for Instruction Following) dataset with automated validation framework, comprising 514 tasks drawn from SayPlan Office, BEHAVIOR-1K, and VirtualHome RobotHow. Project page available at https://lookplangraph.github.io .","authors":["Anatoly O. Onishchenko","Alexey K. Kovalev","Aleksandr I. Panov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21241v1","updated":"2025-12-24T15:35:03Z","published":"2025-12-24T15:35:03Z","title":"Improving the Convergence Rate of Ray Search Optimization for Query-Efficient Hard-Label Attacks","summary":"In hard-label black-box adversarial attacks, where only the top-1 predicted label is accessible, the prohibitive query complexity poses a major obstacle to practical deployment. In this paper, we focus on optimizing a representative class of attacks that search for the optimal ray direction yielding the minimum $\\ell_2$-norm perturbation required to move a benign image into the adversarial region. Inspired by Nesterov's Accelerated Gradient (NAG), we propose a momentum-based algorithm, ARS-OPT, which proactively estimates the gradient with respect to a future ray direction inferred from accumulated momentum. We provide a theoretical analysis of its convergence behavior, showing that ARS-OPT enables more accurate directional updates and achieves faster, more stable optimization. To further accelerate convergence, we incorporate surrogate-model priors into ARS-OPT's gradient estimation, resulting in PARS-OPT with enhanced performance. The superiority of our approach is supported by theoretical guarantees under standard assumptions. Extensive experiments on ImageNet and CIFAR-10 demonstrate that our method surpasses 13 state-of-the-art approaches in query efficiency.","authors":["Xinjie Xu","Shuyu Cheng","Dongwei Xu","Qi Xuan","Chen Ma"],"pdf_url":"","comment":"Published at AAAI 2026 (Oral). This version corresponds to the conference proceedings; v2 will include the appendix"},{"id":"http://arxiv.org/abs/2512.21236v1","updated":"2025-12-24T15:25:31Z","published":"2025-12-24T15:25:31Z","title":"Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking","summary":"Large language models (LLMs) have revolutionized software development through AI-assisted coding tools, enabling developers with limited programming expertise to create sophisticated applications. However, this accessibility extends to malicious actors who may exploit these powerful tools to generate harmful software. Existing jailbreaking research primarily focuses on general attack scenarios against LLMs, with limited exploration of malicious code generation as a jailbreak target. To address this gap, we propose SPELL, a comprehensive testing framework specifically designed to evaluate the weakness of security alignment in malicious code generation. Our framework employs a time-division selection strategy that systematically constructs jailbreaking prompts by intelligently combining sentences from a prior knowledge dataset, balancing exploration of novel attack patterns with exploitation of successful techniques. Extensive evaluation across three advanced code models (GPT-4.1, Claude-3.5, and Qwen2.5-Coder) demonstrates SPELL's effectiveness, achieving attack success rates of 83.75%, 19.38%, and 68.12% respectively across eight malicious code categories. The generated prompts successfully produce malicious code in real-world AI development tools such as Cursor, with outputs confirmed as malicious by state-of-the-art detection systems at rates exceeding 73%. These findings reveal significant security gaps in current LLM implementations and provide valuable insights for improving AI safety alignment in code generation applications.","authors":["Yifan Huang","Xiaojun Jia","Wenbo Guo","Yuqiang Sun","Yihao Huang","Chong Wang","Yang Liu"],"pdf_url":"","comment":"Accepted to FSE 2026"},{"id":"http://arxiv.org/abs/2512.21227v1","updated":"2025-12-24T15:07:36Z","published":"2025-12-24T15:07:36Z","title":"PhononBench:A Large-Scale Phonon-Based Benchmark for Dynamical Stability in Crystal Generation","summary":"In this work, we introduce PhononBench, the first large-scale benchmark for dynamical stability in AI-generated crystals. Leveraging the recently developed MatterSim interatomic potential, which achieves DFT-level accuracy in phonon predictions across more than 10,000 materials, PhononBench enables efficient large-scale phonon calculations and dynamical-stability analysis for 108,843 crystal structures generated by six leading crystal generation models. PhononBench reveals a widespread limitation of current generative models in ensuring dynamical stability: the average dynamical-stability rate across all generated structures is only 25.83%, with the top-performing model, MatterGen, reaching just 41.0%. Further case studies show that in property-targeted generation-illustrated here by band-gap conditioning with MatterGen--the dynamical-stability rate remains as low as 23.5% even at the optimal band-gap condition of 0.5 eV. In space-group-controlled generation, higher-symmetry crystals exhibit better stability (e.g., cubic systems achieve rates up to 49.2%), yet the average stability across all controlled generations is still only 34.4%. An important additional outcome of this study is the identification of 28,119 crystal structures that are phonon-stable across the entire Brillouin zone, providing a substantial pool of reliable candidates for future materials exploration. By establishing the first large-scale dynamical-stability benchmark, this work systematically highlights the current limitations of crystal generation models and offers essential evaluation criteria and guidance for their future development toward the design and discovery of physically viable materials. All model-generated crystal structures, phonon calculation results, and the high-throughput evaluation workflows developed in PhononBench will be openly released at https://github.com/xqh19970407/PhononBench","authors":["Xiao-Qi Han","Ze-Feng Gao","Peng-Jie Guo","Zhong-Yi Lu"],"pdf_url":"","comment":"19 pages, 6 figures"},{"id":"http://arxiv.org/abs/2512.21221v1","updated":"2025-12-24T15:02:33Z","published":"2025-12-24T15:02:33Z","title":"Leveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval","summary":"Retrieving images from natural language descriptions is a core task at the intersection of computer vision and natural language processing, with wide-ranging applications in search engines, media archiving, and digital content management. However, real-world image-text retrieval remains challenging due to vague or context-dependent queries, linguistic variability, and the need for scalable solutions. In this work, we propose a lightweight two-stage retrieval pipeline that leverages event-centric entity extraction to incorporate temporal and contextual signals from real-world captions. The first stage performs efficient candidate filtering using BM25 based on salient entities, while the second stage applies BEiT-3 models to capture deep multimodal semantics and rerank the results. Evaluated on the OpenEvents v1 benchmark, our method achieves a mean average precision of 0.559, substantially outperforming prior baselines. These results highlight the effectiveness of combining event-guided filtering with long-text vision-language modeling for accurate and efficient retrieval in complex, real-world scenarios. Our code is available at https://github.com/PhamPhuHoa-23/Event-Based-Image-Retrieval","authors":["Dao Sy Duy Minh","Huynh Trung Kiet","Nguyen Lam Phu Quy","Phu-Hoa Pham","Tran Chi Nguyen"],"pdf_url":"","comment":"System description paper for EVENTA Grand Challenge Track 2 at ACM Multimedia 2025 (MM '25). Ranked 4th place. 6 pages, 1 figure, 2 tables"},{"id":"http://arxiv.org/abs/2512.21220v1","updated":"2025-12-24T15:01:26Z","published":"2025-12-24T15:01:26Z","title":"RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic","summary":"Embodied agents powered by vision-language models (VLMs) are increasingly capable of executing complex real-world tasks, yet they remain vulnerable to hazardous instructions that may trigger unsafe behaviors. Runtime safety guardrails, which intercept hazardous actions during task execution, offer a promising solution due to their flexibility. However, existing defenses often rely on static rule filters or prompt-level control, which struggle to address implicit risks arising in dynamic, temporally dependent, and context-rich environments. To address this, we propose RoboSafe, a hybrid reasoning runtime safeguard for embodied agents through executable predicate-based safety logic. RoboSafe integrates two complementary reasoning processes on a Hybrid Long-Short Safety Memory. We first propose a Backward Reflective Reasoning module that continuously revisits recent trajectories in short-term memory to infer temporal safety predicates and proactively triggers replanning when violations are detected. We then propose a Forward Predictive Reasoning module that anticipates upcoming risks by generating context-aware safety predicates from the long-term safety memory and the agent's multimodal observations. Together, these components form an adaptive, verifiable safety logic that is both interpretable and executable as code. Extensive experiments across multiple agents demonstrate that RoboSafe substantially reduces hazardous actions (-36.8% risk occurrence) compared with leading baselines, while maintaining near-original task performance. Real-world evaluations on physical robotic arms further confirm its practicality. Code will be released upon acceptance.","authors":["Le Wang","Zonghao Ying","Xiao Yang","Quanchen Zou","Zhenfei Yin","Tianlin Li","Jian Yang","Yaodong Yang","Aishan Liu","Xianglong Liu"],"pdf_url":"","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2508.21010v2","updated":"2025-12-24T14:52:45Z","published":"2025-08-28T17:10:53Z","title":"ChainReaction: Causal Chain-Guided Reasoning for Modular and Explainable Causal-Why Video Question Answering","summary":"Existing Causal-Why Video Question Answering (VideoQA) models often struggle with higher-order reasoning, relying on opaque, monolithic pipelines that entangle video understanding, causal inference, and answer generation. These black-box approaches offer limited interpretability and tend to depend on shallow heuristics. We propose a novel, modular paradigm that explicitly decouples causal reasoning from answer generation, introducing natural language causal chains as interpretable intermediate representations. Inspired by human cognitive models, these structured cause-effect sequences bridge low-level video content with high-level causal reasoning, enabling transparent and logically coherent inference. Our two-stage architecture comprises a Causal Chain Extractor (CCE) that generates causal chains from video-question pairs, and a Causal Chain-Driven Answerer (CCDA) that derives answers grounded in these chains. To address the lack of annotated reasoning traces, we introduce a scalable method for generating accurate causal chains from existing datasets. We construct human verified causal chains for 46K samples. We also propose CauCo, a new evaluation metric for causality-oriented captioning. Experiments on three large-scale benchmarks demonstrate that our approach not only outperforms state-of-the-art models, but also yields substantial gains in explainability, user trust, and generalization -- positioning the CCE as a reusable causal reasoning engine across diverse domains. Project page: https://paritoshparmar.github.io/chainreaction/","authors":["Paritosh Parmar","Eric Peh","Basura Fernando"],"pdf_url":"","comment":"Project page: https://paritoshparmar.github.io/chainreaction/"},{"id":"http://arxiv.org/abs/2507.04346v5","updated":"2025-12-24T14:44:39Z","published":"2025-07-06T11:19:34Z","title":"Improving Action Smoothness for a Cascaded Online Learning Flight Control System","summary":"This paper aims to improve the action smoothness of a cascaded online learning flight control system. Although the cascaded structure is widely used in flight control design, its stability can be compromised by oscillatory control actions, which poses challenges for practical engineering applications. To address this issue, we introduce an online temporal smoothness technique and a low-pass filter to reduce the amplitude and frequency of the control actions. Fast Fourier Transform (FFT) is used to analyze policy performance in the frequency domain. Simulation results demonstrate the improvements achieved by the two proposed techniques.","authors":["Yifei Li","Erik-jan van Kampen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16378v2","updated":"2025-12-24T14:39:27Z","published":"2025-12-18T10:21:14Z","title":"Hearing to Translate: The Effectiveness of Speech Modality Integration into LLMs","summary":"As Large Language Models (LLMs) expand beyond text, integrating speech as a native modality has given rise to SpeechLLMs, which aim to translate spoken language directly, thereby bypassing traditional transcription-based pipelines. Whether this integration improves speech-to-text translation quality over established cascaded architectures, however, remains an open question. We present Hearing to Translate, the first comprehensive test suite rigorously benchmarking 5 state-of-the-art SpeechLLMs against 16 strong direct and cascade systems that couple leading speech foundation models (SFM), with multilingual LLMs. Our analysis spans 16 benchmarks, 13 language pairs, and 9 challenging conditions, including disfluent, noisy, and long-form speech. Across this extensive evaluation, we find that cascaded systems remain the most reliable overall, while current SpeechLLMs only match cascades in selected settings and SFMs lag behind both, highlighting that integrating an LLM, either within the model or in a pipeline, is essential for high-quality speech translation.","authors":["Sara Papi","Javier Garcia Gilabert","Zachary Hopton","Vilém Zouhar","Carlos Escolano","Gerard I. Gállego","Jorge Iranzo-Sánchez","Ahrii Kim","Dominik Macháček","Patricia Schmidtova","Maike Züfle"],"pdf_url":"","comment":"Project available at https://github.com/sarapapi/hearing2translate"},{"id":"http://arxiv.org/abs/2512.21204v1","updated":"2025-12-24T14:33:16Z","published":"2025-12-24T14:33:16Z","title":"SpidR-Adapt: A Universal Speech Representation Model for Few-Shot Adaptation","summary":"Human infants, with only a few hundred hours of speech exposure, acquire basic units of new languages, highlighting a striking efficiency gap compared to the data-hungry self-supervised speech models. To address this gap, this paper introduces SpidR-Adapt for rapid adaptation to new languages using minimal unlabeled data. We cast such low-resource speech representation learning as a meta-learning problem and construct a multi-task adaptive pre-training (MAdaPT) protocol which formulates the adaptation process as a bi-level optimization framework. To enable scalable meta-training under this framework, we propose a novel heuristic solution, first-order bi-level optimization (FOBLO), avoiding heavy computation costs. Finally, we stabilize meta-training by using a robust initialization through interleaved supervision which alternates self-supervised and supervised objectives. Empirically, SpidR-Adapt achieves rapid gains in phonemic discriminability (ABX) and spoken language modeling (sWUGGY, sBLIMP, tSC), improving over in-domain language models after training on less than 1h of target-language audio, over $100\\times$ more data-efficient than standard training. These findings highlight a practical, architecture-agnostic path toward biologically inspired, data-efficient representations. We open-source the training code and model checkpoints at https://github.com/facebookresearch/spidr-adapt.","authors":["Mahi Luthra","Jiayi Shen","Maxime Poli","Angelo Ortiz","Yosuke Higuchi","Youssef Benchekroun","Martin Gleize","Charles-Eric Saint-James","Dongyan Lin","Phillip Rust","Angel Villar","Surya Parimi","Vanessa Stark","Rashel Moritz","Juan Pino","Yann LeCun","Emmanuel Dupoux"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21201v1","updated":"2025-12-24T14:28:17Z","published":"2025-12-24T14:28:17Z","title":"Schrödinger's Navigator: Imagining an Ensemble of Futures for Zero-Shot Object Navigation","summary":"Zero-shot object navigation (ZSON) requires a robot to locate a target object in a previously unseen environment without relying on pre-built maps or task-specific training. However, existing ZSON methods often struggle in realistic and cluttered environments, particularly when the scene contains heavy occlusions, unknown risks, or dynamically moving target objects. To address these challenges, we propose \\textbf{Schrödinger's Navigator}, a navigation framework inspired by Schrödinger's thought experiment on uncertainty. The framework treats unobserved space as a set of plausible future worlds and reasons over them before acting. Conditioned on egocentric visual inputs and three candidate trajectories, a trajectory-conditioned 3D world model imagines future observations along each path. This enables the agent to see beyond occlusions and anticipate risks in unseen regions without requiring extra detours or dense global mapping. The imagined 3D observations are fused into the navigation map and used to update a value map. These updates guide the policy toward trajectories that avoid occlusions, reduce exposure to uncertain space, and better track moving targets. Experiments on a Go2 quadruped robot across three challenging scenarios, including severe static occlusions, unknown risks, and dynamically moving targets, show that Schrödinger's Navigator consistently outperforms strong ZSON baselines in self-localization, object localization, and overall Success Rate in occlusion-heavy environments. These results demonstrate the effectiveness of trajectory-conditioned 3D imagination in enabling robust zero-shot object navigation.","authors":["Yu He","Da Huang","Zhenyang Liu","Zixiao Gu","Qiang Sun","Guangnan Ye","Yanwei Fu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.18527v4","updated":"2025-12-24T14:04:28Z","published":"2025-09-23T01:47:44Z","title":"FERA: A Pose-Based Semantic Pipeline for Automated Foil Fencing Refereeing","summary":"Many multimedia tasks map raw video into structured semantic representations for downstream decision-making. Sports officiating is a representative case, where fast, subtle interactions must be judged via symbolic rules. We present FERA (FEncing Referee Assistant), a pose-based framework that turns broadcast foil fencing video into action tokens and rule-grounded explanations. From monocular footage, FERA extracts 2D poses, converts them into a 101-dimensional kinematic representation, and applies an encoder-only transformer (FERA-MDT) to recognize per-fencer footwork, blade actions, and blade-line position. To obtain a consistent single-fencer representation for both athletes, FERA processes each clip and a horizontally flipped copy, yielding time-aligned left/right predictions without requiring a multi-person pose pipeline. A dynamic temporal windowing scheme enables inference on untrimmed pose tracks. These structured predictions serve as tokens for a language model (FERA-LM) that applies simplified right-of-way rules to generate textual decisions. On 1,734 clips (2,386 annotated actions), FERA-MDT achieves a macro-F1 of 0.549 under 5-fold cross-validation, outperforming BiLSTM and TCN baselines. Combined with FERA-LM, the full pipeline recovers referee priority with 77.7% accuracy on 969 exchanges. FERA provides a case-study benchmark for pose-based semantic grounding in a two-person sport and illustrates a general pipeline for connecting video understanding with rule-based reasoning.","authors":["Ziwen Chen","Zhong Wang"],"pdf_url":"","comment":"Updated Methodology and polished sections"},{"id":"http://arxiv.org/abs/2510.16416v3","updated":"2025-12-24T13:40:37Z","published":"2025-10-18T09:22:40Z","title":"SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning","summary":"Vision-language models (VLMs) have shown remarkable abilities by integrating large language models with visual inputs. However, they often fail to utilize visual evidence adequately, either depending on linguistic priors in vision-centric tasks or resorting to textual shortcuts during reasoning. Although reinforcement learning (RL) can align models with desired behaviors, its application to VLMs has been hindered by the lack of scalable and reliable reward mechanisms. To overcome this challenge, we propose SSL4RL, a novel framework that leverages self-supervised learning (SSL) tasks as a source of verifiable rewards for RL-based fine-tuning. Our approach reformulates SSL objectives-such as predicting image rotation or reconstructing masked patches-into dense, automatic reward signals, eliminating the need for human preference data or unreliable AI evaluators. Experiments show that SSL4RL substantially improves performance on both vision-centric and vision-language reasoning benchmarks. Furthermore, through systematic ablations, we identify key factors-such as task difficulty, model scale, and semantic alignment with the target domain-that influence the effectiveness of SSL4RL tasks, offering new design principles for future work. We also demonstrate the framework's generality by applying it to graph learning, where it yields significant gains. SSL4RL establishes a versatile and effective paradigm for aligning multimodal models using verifiable, self-supervised objectives.","authors":["Xiaojun Guo","Runyu Zhou","Yifei Wang","Qi Zhang","Chenheng Zhang","Stefanie Jegelka","Xiaohan Wang","Jiajun Chai","Guojun Yin","Wei Lin","Yisen Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12867v2","updated":"2025-12-24T13:31:20Z","published":"2025-11-17T01:41:14Z","title":"Bootstrapping LLMs via Preference-Based Policy Optimization","summary":"Bootstrapping large language models (LLMs) through preference-based policy optimization offers a promising direction for aligning model behavior with human preferences without relying on extensive manual annotations. In this work, we propose a novel preference-based policy optimization (PbPO) framework that formulates the learning process as a min-max game between the main policy and a reward model (RM). The RM is constrained within a confidence set derived from preference data to ensure reliable exploitation. Our iterative online algorithm actively collects preference data through guided exploration of the evolving policy, enabling continual self-improvement of both the policy and the RM. We provide theoretical guarantees for our method, establishing high-probability regret bounds for both settings with sequence-level RM and token-level RM, demonstrating its effectiveness in bootstrapping LLMs. Extensive experiments on five benchmarks show that our approach consistently outperforms existing state-of-the-art preference optimization techniques.","authors":["Chen Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21165v1","updated":"2025-12-24T13:25:36Z","published":"2025-12-24T13:25:36Z","title":"BALLAST: Bandit-Assisted Learning for Latency-Aware Stable Timeouts in Raft","summary":"Randomized election timeouts are a simple and effective liveness heuristic for Raft, but they become brittle under long-tail latency, jitter, and partition recovery, where repeated split votes can inflate unavailability. This paper presents BALLAST, a lightweight online adaptation mechanism that replaces static timeout heuristics with contextual bandits. BALLAST selects from a discrete set of timeout \"arms\" using efficient linear contextual bandits (LinUCB variants), and augments learning with safe exploration to cap risk during unstable periods. We evaluate BALLAST on a reproducible discrete-event simulation with long-tail delay, loss, correlated bursts, node heterogeneity, and partition/recovery turbulence. Across challenging WAN regimes, BALLAST substantially reduces recovery time and unwritable time compared to standard randomized timeouts and common heuristics, while remaining competitive on stable LAN/WAN settings.","authors":["Qizhi Wang"],"pdf_url":"","comment":"15 pages, 22 tables, 11 figures"},{"id":"http://arxiv.org/abs/2512.21152v1","updated":"2025-12-24T12:43:40Z","published":"2025-12-24T12:43:40Z","title":"MODE: Multi-Objective Adaptive Coreset Selection","summary":"We present Mode(Multi-Objective adaptive Data Efficiency), a framework that dynamically combines coreset selection strategies based on their evolving contribution to model performance. Unlike static methods, \\mode adapts selection criteria to training phases: emphasizing class balance early, diversity during representation learning, and uncertainty at convergence. We show that MODE achieves (1-1/e)-approximation with O(n \\log n) complexity and demonstrates competitive accuracy while providing interpretable insights into data utility evolution. Experiments show \\mode reduces memory requirements","authors":["Tanmoy Mukherjee","Pierre Marquis","Zied Bouraoui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.15249v2","updated":"2025-12-24T12:33:48Z","published":"2025-12-17T09:47:29Z","title":"Intersectional Fairness in Vision-Language Models for Medical Image Disease Classification","summary":"Medical artificial intelligence (AI) systems, particularly multimodal vision-language models (VLM), often exhibit intersectional biases where models are systematically less confident in diagnosing marginalised patient subgroups. Such bias can lead to higher rates of inaccurate and missed diagnoses due to demographically skewed data and divergent distributions of diagnostic certainty. Current fairness interventions frequently fail to address these gaps or compromise overall diagnostic performance to achieve statistical parity among the subgroups. In this study, we developed Cross-Modal Alignment Consistency (CMAC-MMD), a training framework that standardises diagnostic certainty across intersectional patient subgroups. Unlike traditional debiasing methods, this approach equalises the model's decision confidence without requiring sensitive demographic data during clinical inference. We evaluated this approach using 10,015 skin lesion images (HAM10000) with external validation on 12,000 images (BCN20000), and 10,000 fundus images for glaucoma detection (Harvard-FairVLMed), stratifying performance by intersectional age, gender, and race attributes. In the dermatology cohort, the proposed method reduced the overall intersectional missed diagnosis gap (difference in True Positive Rate, $Δ$TPR) from 0.50 to 0.26 while improving the overall Area Under the Curve (AUC) from 0.94 to 0.97 compared to standard training. Similarly, for glaucoma screening, the method reduced $Δ$TPR from 0.41 to 0.31, achieving a better AUC of 0.72 (vs. 0.71 baseline). This establishes a scalable framework for developing high-stakes clinical decision support systems that are both accurate and can perform equitably across diverse patient subgroups, ensuring reliable performance without increasing privacy risks.","authors":["Yupeng Zhang","Adam G. Dunn","Usman Naseem","Jinman Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21135v1","updated":"2025-12-24T12:06:26Z","published":"2025-12-24T12:06:26Z","title":"TGC-Net: A Structure-Aware and Semantically-Aligned Framework for Text-Guided Medical Image Segmentation","summary":"Text-guided medical segmentation enhances segmentation accuracy by utilizing clinical reports as auxiliary information. However, existing methods typically rely on unaligned image and text encoders, which necessitate complex interaction modules for multimodal fusion. While CLIP provides a pre-aligned multimodal feature space, its direct application to medical imaging is limited by three main issues: insufficient preservation of fine-grained anatomical structures, inadequate modeling of complex clinical descriptions, and domain-specific semantic misalignment. To tackle these challenges, we propose TGC-Net, a CLIP-based framework focusing on parameter-efficient, task-specific adaptations. Specifically, it incorporates a Semantic-Structural Synergy Encoder (SSE) that augments CLIP's ViT with a CNN branch for multi-scale structural refinement, a Domain-Augmented Text Encoder (DATE) that injects large-language-model-derived medical knowledge, and a Vision-Language Calibration Module (VLCM) that refines cross-modal correspondence in a unified feature space. Experiments on five datasets across chest X-ray and thoracic CT modalities demonstrate that TGC-Net achieves state-of-the-art performance with substantially fewer trainable parameters, including notable Dice gains on challenging benchmarks.","authors":["Gaoren Lin","Huangxuan Zhao","Yuan Xiong","Lefei Zhang","Bo Du","Wentao Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21132v1","updated":"2025-12-24T12:02:00Z","published":"2025-12-24T12:02:00Z","title":"AutoBaxBuilder: Bootstrapping Code Security Benchmarking","summary":"As LLMs see wide adoption in software engineering, the reliable assessment of the correctness and security of LLM-generated code is crucial. Notably, prior work has demonstrated that security is often overlooked, exposing that LLMs are prone to generating code with security vulnerabilities. These insights were enabled by specialized benchmarks, crafted through significant manual effort by security experts. However, relying on manually-crafted benchmarks is insufficient in the long term, because benchmarks (i) naturally end up contaminating training data, (ii) must extend to new tasks to provide a more complete picture, and (iii) must increase in difficulty to challenge more capable LLMs. In this work, we address these challenges and present AutoBaxBuilder, a framework that generates tasks and tests for code security benchmarking from scratch. We introduce a robust pipeline with fine-grained plausibility checks, leveraging the code understanding capabilities of LLMs to construct functionality tests and end-to-end security-probing exploits. To confirm the quality of the generated benchmark, we conduct both a qualitative analysis and perform quantitative experiments, comparing it against tasks constructed by human experts. We use AutoBaxBuilder to construct entirely new tasks and release them to the public as AutoBaxBench, together with a thorough evaluation of the security capabilities of LLMs on these tasks. We find that a new task can be generated in under 2 hours, costing less than USD 10.","authors":["Tobias von Arx","Niels Mündler","Mark Vero","Maximilian Baader","Martin Vechev"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21127v1","updated":"2025-12-24T11:58:49Z","published":"2025-12-24T11:58:49Z","title":"A Real-World Evaluation of LLM Medication Safety Reviews in NHS Primary Care","summary":"Large language models (LLMs) often match or exceed clinician-level performance on medical benchmarks, yet very few are evaluated on real clinical data or examined beyond headline metrics. We present, to our knowledge, the first evaluation of an LLM-based medication safety review system on real NHS primary care data, with detailed characterisation of key failure behaviours across varying levels of clinical complexity. In a retrospective study using a population-scale EHR spanning 2,125,549 adults in NHS Cheshire and Merseyside, we strategically sampled patients to capture a broad range of clinical complexity and medication safety risk, yielding 277 patients after data-quality exclusions. An expert clinician reviewed these patients and graded system-identified issues and proposed interventions. Our primary LLM system showed strong performance in recognising when a clinical issue is present (sensitivity 100\\% [95\\% CI 98.2--100], specificity 83.1\\% [95\\% CI 72.7--90.1]), yet correctly identified all issues and interventions in only 46.9\\% [95\\% CI 41.1--52.8] of patients. Failure analysis reveals that, in this setting, the dominant failure mechanism is contextual reasoning rather than missing medication knowledge, with five primary patterns: overconfidence in uncertainty, applying standard guidelines without adjusting for patient context, misunderstanding how healthcare is delivered in practice, factual errors, and process blindness. These patterns persisted across patient complexity and demographic strata, and across a range of state-of-the-art models and configurations. We provide 45 detailed vignettes that comprehensively cover all identified failure cases. This work highlights shortcomings that must be addressed before LLM-based clinical AI can be safely deployed. It also begs larger-scale, prospective evaluations and deeper study of LLM behaviours in clinical contexts.","authors":["Oliver Normand","Esther Borsi","Mitch Fruin","Lauren E Walker","Jamie Heagerty","Chris C. Holmes","Anthony J Avery","Iain E Buchan","Harry Coppock"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21118v1","updated":"2025-12-24T11:34:44Z","published":"2025-12-24T11:34:44Z","title":"STLDM: Spatio-Temporal Latent Diffusion Model for Precipitation Nowcasting","summary":"Precipitation nowcasting is a critical spatio-temporal prediction task for society to prevent severe damage owing to extreme weather events. Despite the advances in this field, the complex and stochastic nature of this task still poses challenges to existing approaches. Specifically, deterministic models tend to produce blurry predictions while generative models often struggle with poor accuracy. In this paper, we present a simple yet effective model architecture termed STLDM, a diffusion-based model that learns the latent representation from end to end alongside both the Variational Autoencoder and the conditioning network. STLDM decomposes this task into two stages: a deterministic forecasting stage handled by the conditioning network, and an enhancement stage performed by the latent diffusion model. Experimental results on multiple radar datasets demonstrate that STLDM achieves superior performance compared to the state of the art, while also improving inference efficiency. The code is available in https://github.com/sqfoo/stldm_official.","authors":["Shi Quan Foo","Chi-Ho Wong","Zhihan Gao","Dit-Yan Yeung","Ka-Hing Wong","Wai-Kin Wong"],"pdf_url":"","comment":"Accepted by TMLR. Camera-ready submission"},{"id":"http://arxiv.org/abs/2409.00162v2","updated":"2025-12-24T11:32:24Z","published":"2024-08-30T16:14:35Z","title":"Sequence to Sequence Reward Modeling: Improving RLHF by Language Feedback","summary":"Aligning the behavior of Large language models (LLMs) with human intentions and values remains a critical challenge. Reinforcement learning from human feedback (RLHF) aligns LLMs by training a reward model (RM) on human preferences and fine-tuning the LLMs to maximize RM feedback. Despite its effectiveness and popularity, RLHF is prone to biased local optimization. It means RM fails to provide feedback that accurately aligns with human preference, causing LLMs to explore unexpected generalizations, and failing to achieve alignment objectives. To mitigate this issue, we propose a novel \\textit{sequence-to-sequence (seq2seq) reward modeling} method. Its key insight is that learning from language feedback rather than scalar feedback improves RLHF without additional annotations. We replaced the reward modeling target from binary maximum likelihood estimation (MLE) with sequence MLE. This method enables richer and fine-grained language feedback without additional annotations, models, or training stages. Our experiments demonstrated its effectiveness, specifically, reducing the refusal-to-response paradigm in single-turn safety dialogues and the long-response bias in text summarization tasks. We provide further analysis that seq2seq RM improves RLHF performance across 2B and 7B LLMs on 3 NLP tasks, achieving an average win rate of 76.9\\%. We further show that seq2seq RM can still improve the performance of RLHF under out-of-distribution prompts.","authors":["Jiayi Zhou","Jiaming Ji","Juntao Dai","Dong Li","Yaodong Yang"],"pdf_url":"","comment":"7 pages"},{"id":"http://arxiv.org/abs/2510.11822v2","updated":"2025-12-24T11:22:59Z","published":"2025-10-13T18:19:23Z","title":"Beyond Consensus: Mitigating the Agreeableness Bias in LLM Judge Evaluations","summary":"New Large Language Models (LLMs) become available every few weeks, and modern application developers confronted with the unenviable task of having to decide if they should switch to a new model. While human evaluation remains the gold standard, it is costly and unscalable. The state-of-the-art approach is to use LLMs as evaluators ( LLM-as-a-judge), but this suffers from a critical flaw: LLMs exhibit a strong positive bias. We provide empirical evidence showing that while LLMs can identify valid outputs with high accuracy (i.e., True Positive Rate 96%), they are remarkably poor at identifying invalid ones (i.e., True Negative Rate <25%). This systematic bias, coupled with class imbalance, often leads to inflated reliability scores.\n  While ensemble-based methods like majority voting can help, we show that they are not good enough. We introduce an optimal minority-veto strategy that is resilient to missing data and mitigates this bias to a large extent. For scenarios requiring even higher precision, we propose a novel regression-based framework that directly models the validator bias using a small set of human-annotated ground truth data. On a challenging code feedback task over 366 high-school Python programs, our regression approach reduces the maximum absolute error to just 1.2%, achieving a 2x improvement over the best-performing ensemble of 14 state-of-the-art LLMs.","authors":["Suryaansh Jain","Umair Z. Ahmed","Shubham Sahai","Ben Leong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21110v1","updated":"2025-12-24T11:15:57Z","published":"2025-12-24T11:15:57Z","title":"Beyond Context: Large Language Models Failure to Grasp Users Intent","summary":"Current Large Language Models (LLMs) safety approaches focus on explicitly harmful content while overlooking a critical vulnerability: the inability to understand context and recognize user intent. This creates exploitable vulnerabilities that malicious users can systematically leverage to circumvent safety mechanisms. We empirically evaluate multiple state-of-the-art LLMs, including ChatGPT, Claude, Gemini, and DeepSeek. Our analysis demonstrates the circumvention of reliable safety mechanisms through emotional framing, progressive revelation, and academic justification techniques. Notably, reasoning-enabled configurations amplified rather than mitigated the effectiveness of exploitation, increasing factual precision while failing to interrogate the underlying intent. The exception was Claude Opus 4.1, which prioritized intent detection over information provision in some use cases. This pattern reveals that current architectural designs create systematic vulnerabilities. These limitations require paradigmatic shifts toward contextual understanding and intent recognition as core safety capabilities rather than post-hoc protective mechanisms.","authors":["Ahmed M. Hussain","Salahuddin Salahuddin","Panos Papadimitratos"],"pdf_url":"","comment":"22 pages and 23 figures"},{"id":"http://arxiv.org/abs/2512.21107v1","updated":"2025-12-24T11:12:09Z","published":"2025-12-24T11:12:09Z","title":"Semi-Supervised Learning for Large Language Models Safety and Content Moderation","summary":"Safety for Large Language Models (LLMs) has been an ongoing research focus since their emergence and is even more relevant nowadays with the increasing capacity of those models. Currently, there are several guardrails in place for all public LLMs and multiple proposed datasets for training safety classifiers. However, training these safety classifiers relies on large quantities of labeled data, which can be problematic to acquire, prone to labeling errors, or often include synthetic data. To address these issues, we suggest a different approach: utilizing semi-supervised learning techniques, which leverage both labeled and unlabeled data, to improve the performance on the safety task. We analyze the improvements that these techniques can offer for both prompts given to Large Language Models and the responses to those requests. Moreover, since augmentation is the central part of semi-supervised algorithms, we demonstrate the importance of using task-specific augmentations, which significantly increase the performance when compared to general-purpose augmentation techniques.","authors":["Eduard Stefan Dinuta","Iustin Sirbu","Traian Rebedea"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21106v1","updated":"2025-12-24T11:10:28Z","published":"2025-12-24T11:10:28Z","title":"Semantic Refinement with LLMs for Graph Representations","summary":"Graph-structured data exhibit substantial heterogeneity in where their predictive signals originate: in some domains, node-level semantics dominate, while in others, structural patterns play a central role. This structure-semantics heterogeneity implies that no graph learning model with a fixed inductive bias can generalize optimally across diverse graph domains. However, most existing methods address this challenge from the model side by incrementally injecting new inductive biases, which remains fundamentally limited given the open-ended diversity of real-world graphs. In this work, we take a data-centric perspective and treat node semantics as a task-adaptive variable. We propose a Data-Adaptive Semantic Refinement framework DAS for graph representation learning, which couples a fixed graph neural network (GNN) and a large language model (LLM) in a closed feedback loop. The GNN provides implicit supervisory signals to guide the semantic refinement of LLM, and the refined semantics are fed back to update the same graph learner. We evaluate our approach on both text-rich and text-free graphs. Results show consistent improvements on structure-dominated graphs while remaining competitive on semantics-rich graphs, demonstrating the effectiveness of data-centric semantic adaptation under structure-semantics heterogeneity.","authors":["Safal Thapaliya","Zehong Wang","Jiazheng Li","Ziming Li","Yanfang Ye","Chuxu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21099v1","updated":"2025-12-24T10:50:04Z","published":"2025-12-24T10:50:04Z","title":"TexAvatars : Hybrid Texel-3D Representations for Stable Rigging of Photorealistic Gaussian Head Avatars","summary":"Constructing drivable and photorealistic 3D head avatars has become a central task in AR/XR, enabling immersive and expressive user experiences. With the emergence of high-fidelity and efficient representations such as 3D Gaussians, recent works have pushed toward ultra-detailed head avatars. Existing approaches typically fall into two categories: rule-based analytic rigging or neural network-based deformation fields. While effective in constrained settings, both approaches often fail to generalize to unseen expressions and poses, particularly in extreme reenactment scenarios. Other methods constrain Gaussians to the global texel space of 3DMMs to reduce rendering complexity. However, these texel-based avatars tend to underutilize the underlying mesh structure. They apply minimal analytic deformation and rely heavily on neural regressors and heuristic regularization in UV space, which weakens geometric consistency and limits extrapolation to complex, out-of-distribution deformations. To address these limitations, we introduce TexAvatars, a hybrid avatar representation that combines the explicit geometric grounding of analytic rigging with the spatial continuity of texel space. Our approach predicts local geometric attributes in UV space via CNNs, but drives 3D deformation through mesh-aware Jacobians, enabling smooth and semantically meaningful transitions across triangle boundaries. This hybrid design separates semantic modeling from geometric control, resulting in improved generalization, interpretability, and stability. Furthermore, TexAvatars captures fine-grained expression effects, including muscle-induced wrinkles, glabellar lines, and realistic mouth cavity geometry, with high fidelity. Our method achieves state-of-the-art performance under extreme pose and expression variations, demonstrating strong generalization in challenging head reenactment settings.","authors":["Jaeseong Lee","Junyeong Ahn","Taewoong Kang","Jaegul Choo"],"pdf_url":"","comment":"3DV 2026, Project page with videos: https://summertight.github.io/TexAvatars/"},{"id":"http://arxiv.org/abs/2512.21080v1","updated":"2025-12-24T09:56:00Z","published":"2025-12-24T09:56:00Z","title":"LLM Personas as a Substitute for Field Experiments in Method Benchmarking","summary":"Field experiments (A/B tests) are often the most credible benchmark for methods in societal systems, but their cost and latency create a major bottleneck for iterative method development. LLM-based persona simulation offers a cheap synthetic alternative, yet it is unclear whether replacing humans with personas preserves the benchmark interface that adaptive methods optimize against. We prove an if-and-only-if characterization: when (i) methods observe only the aggregate outcome (aggregate-only observation) and (ii) evaluation depends only on the submitted artifact and not on the algorithm's identity or provenance (algorithm-blind evaluation), swapping humans for personas is just panel change from the method's point of view, indistinguishable from changing the evaluation population (e.g., New York to Jakarta). Furthermore, we move from validity to usefulness: we define an information-theoretic discriminability of the induced aggregate channel and show that making persona benchmarking as decision-relevant as a field experiment is fundamentally a sample-size question, yielding explicit bounds on the number of independent persona evaluations required to reliably distinguish meaningfully different methods at a chosen resolution.","authors":["Enoch Hyunwook Kang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.00020v2","updated":"2025-12-24T09:40:00Z","published":"2025-10-29T04:14:43Z","title":"Large Language Model for Verilog Code Generation: Literature Review and the Road Ahead","summary":"Code generation has emerged as a critical research area at the intersection of Software Engineering (SE) and Artificial Intelligence (AI), attracting significant attention from both academia and industry. Within this broader landscape, Verilog, as a representative hardware description language (HDL), plays a fundamental role in digital circuit design and verification, making its automated generation particularly significant for Electronic Design Automation (EDA). Consequently, recent research has increasingly focused on applying Large Language Models (LLMs) to Verilog code generation, particularly at the Register Transfer Level (RTL), exploring how these AI-driven techniques can be effectively integrated into hardware design workflows. Despite substantial research efforts have explored LLM applications in this domain, a comprehensive survey synthesizing these developments remains absent from the literature. This review fill addresses this gap by providing a systematic literature review of LLM-based methods for Verilog code generation, examining their effectiveness, limitations, and potential for advancing automated hardware design. The review encompasses research work from conferences and journals in the fields of SE, AI, and EDA, encompassing 70 papers published on venues, along with 32 high-quality preprint papers, bringing the total to 102 papers. By answering four key research questions, we aim to (1) identify the LLMs used for Verilog generation, (2) examine the datasets and metrics employed in evaluation, (3) categorize the techniques proposed for Verilog generation, and (4) analyze LLM alignment approaches for Verilog generation. Based on our findings, we have identified a series of limitations of existing studies. Finally, we have outlined a roadmap highlighting potential opportunities for future research endeavors in LLM-assisted hardware design.","authors":["Guang Yang","Wei Zheng","Xiang Chen","Dong Liang","Peng Hu","Yukui Yang","Shaohang Peng","Zhenghan Li","Jiahui Feng","Xiao Wei","Kexin Sun","Deyuan Ma","Haotian Cheng","Yiheng Shen","Xing Hu","Terry Yue Zhuo","David Lo"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2512.21075v1","updated":"2025-12-24T09:39:04Z","published":"2025-12-24T09:39:04Z","title":"Understanding Scaling Laws in Deep Neural Networks via Feature Learning Dynamics","summary":"The empirical success of deep learning is often attributed to scaling laws that predict consistent gains as model, data, and compute grow; however, large models can exhibit training instability and diminishing returns, suggesting that scaling laws describe what success looks like but not when and why scaling succeeds or fails. A central obstacle is the lack of a rigorous understanding of feature learning at large depth. While muP characterizes feature-learning dynamics in the infinite-width limit and enables hyperparameter transfer across width, its depth extension (depth-muP) breaks down for residual blocks with more than one internal layer. We derive Neural Feature Dynamics (NFD) for ResNets with single-layer residual blocks, characterizing feature learning via a coupled forward-backward stochastic system in the joint infinite-width and infinite-depth limit. In this regime, NFD identifies when scaling-law trends persist and explains diminishing returns. It also reveals a vanishing mechanism induced by the 1/sqrt(depth) residual scaling under which the gradient-independence assumption (GIA), known to fail during training at finite depth, becomes provably valid again at infinite depth, yielding an analytically tractable regime for end-to-end feature learning. Motivated by this insight, we study two-layer residual blocks and show that the same mechanism causes feature-learning collapse in the first internal layer at large depth, providing a structural explanation for the empirical failure of depth-muP. Based on this diagnosis, we propose a depth-aware learning-rate correction that counteracts the collapse and empirically restores depth-wise hyperparameter transfer, yielding stronger performance in deeper ResNets.","authors":["Zihan Yao","Ruoyu Wu","Tianxiang Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21066v1","updated":"2025-12-24T09:19:15Z","published":"2025-12-24T09:19:15Z","title":"Agentic Explainable Artificial Intelligence (Agentic XAI) Approach To Explore Better Explanation","summary":"Explainable artificial intelligence (XAI) enables data-driven understanding of factor associations with response variables, yet communicating XAI outputs to laypersons remains challenging, hindering trust in AI-based predictions. Large language models (LLMs) have emerged as promising tools for translating technical explanations into accessible narratives, yet the integration of agentic AI, where LLMs operate as autonomous agents through iterative refinement, with XAI remains unexplored. This study proposes an agentic XAI framework combining SHAP-based explainability with multimodal LLM-driven iterative refinement to generate progressively enhanced explanations. As a use case, we tested this framework as an agricultural recommendation system using rice yield data from 26 fields in Japan. The Agentic XAI initially provided a SHAP result and explored how to improve the explanation through additional analysis iteratively across 11 refinement rounds (Rounds 0-10). Explanations were evaluated by human experts (crop scientists) (n=12) and LLMs (n=14) against seven metrics: Specificity, Clarity, Conciseness, Practicality, Contextual Relevance, Cost Consideration, and Crop Science Credibility. Both evaluator groups confirmed that the framework successfully enhanced recommendation quality with an average score increase of 30-33% from Round 0, peaking at Rounds 3-4. However, excessive refinement showed a substantial drop in recommendation quality, indicating a bias-variance trade-off where early rounds lacked explanation depth (bias) while excessive iteration introduced verbosity and ungrounded abstraction (variance), as revealed by metric-specific analysis. These findings suggest that strategic early stopping (regularization) is needed for optimizing practical utility, challenging assumptions about monotonic improvement and providing evidence-based design principles for agentic XAI systems.","authors":["Tomoaki Yamaguchi","Yutong Zhou","Masahiro Ryo","Keisuke Katsura"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.18047v6","updated":"2025-12-24T09:13:05Z","published":"2024-12-23T23:45:45Z","title":"Towards Hierarchical Multi-Agent Decision-Making for Uncertainty-Aware EV Charging","summary":"Recent advances in bidirectional EV charging and discharging systems have spurred interest in workplace applications. However, real-world deployments face various dynamic factors, such as fluctuating electricity prices and uncertain EV departure times, that hinder effective energy management. To address these issues and minimize building electricity costs while meeting EV charging requirements, we design a hierarchical multi-agent structure in which a high-level agent coordinates overall charge or discharge decisions based on real-time pricing, while multiple low-level agents manage individual power level accordingly. For uncertain EV departure times, we propose a novel uncertainty-aware critic augmentation mechanism for low-level agents that improves the evaluation of power-level decisions and ensures robust control under such uncertainty. Building upon these two key designs, we introduce HUCA, a real-time charging control framework that coordinates energy supply among the building and EVs. Experiments on real-world electricity datasets show that HUCA significantly reduces electricity costs and maintains competitive performance in meeting EV charging requirements under both simulated certain and uncertain departure scenarios. The results further highlight the importance of hierarchical control and the proposed critic augmentation under the uncertain departure scenario. A case study illustrates HUCA's capability to allocate energy between the building and EVs in real time, underscoring its potential for practical use.","authors":["Lo Pang-Yun Ting","Ali Şenol","Huan-Yang Wang","Hsu-Chao Lai","Kun-Ta Chuang","Huan Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.04973v3","updated":"2025-12-24T08:54:34Z","published":"2025-04-07T11:58:19Z","title":"Ensuring Safety in an Uncertain Environment: Constrained MDPs via Stochastic Thresholds","summary":"This paper studies constrained Markov decision processes (CMDPs) with constraints against stochastic thresholds, aiming at safety of reinforcement learning in unknown and uncertain environments. We leverage a Growing-Window estimator sampling from interactions with the uncertain environment to estimate the thresholds, based on which we design Stochastic Pessimistic-Optimistic Thresholding (SPOT), a novel model-based primal-dual algorithm for multiple constraints against stochastic thresholds. SPOT enables reinforcement learning under both pessimistic and optimistic threshold settings. We prove that our algorithm achieves sublinear regret and constraint violation; i.e., a reward regret of $\\tilde{\\mathcal{O}}(\\sqrt{T})$ while allowing an $\\tilde{\\mathcal{O}}(\\sqrt{T})$ constraint violation over $T$ episodes. The theoretical guarantees show that our algorithm achieves performance comparable to that of an approach relying on fixed and clear thresholds. To the best of our knowledge, SPOT is the first reinforcement learning algorithm that realises theoretical guaranteed performance in an uncertain environment where even thresholds are unknown.","authors":["Qian Zuo","Fengxiang He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.01061v3","updated":"2025-12-24T08:52:29Z","published":"2025-06-30T09:06:16Z","title":"Epitome: Pioneering an Experimental Platform for AI-Social Science Integration","summary":"Large Language Models (LLMs) enable unprecedented social science experimentation by creating controlled hybrid human-AI environments. We introduce Epitome (www.epitome-ai.com), an open experimental platform that operationalizes this paradigm through Matrix-like social worlds where researchers can study isolated human subjects and groups interacting with LLM agents. This maintains ecological validity while enabling precise manipulation of social dynamics. Epitome approaches three frontiers: (1) methodological innovation using LLM confederates to reduce complexity while scaling interactions; (2) empirical investigation of human behavior in AI-saturated environments; and (3) exploration of emergent properties in hybrid collectives. Drawing on interdisciplinary foundations from management, communication, sociology, psychology, and ethics, the platform's modular architecture spans foundation model deployment through data collection. We validate Epitome through replication of three seminal experiments, demonstrating capacity to generate robust findings while reducing experimental complexity. This tool provides crucial insights for understanding how humans navigate AI-mediated social realities, knowledge essential for policy, education, and human-centered AI design.","authors":["Jingjing Qu","Kejia Hu","Jun Zhu","Yulei Ye","Wenhao Li","Teng Wang","Zhiyun Chen","Chaochao Lu","Aimin Zhou","Xiangfeng Wang","Xia Hu","James Evans"],"pdf_url":"","comment":"25 pages, 6figures"},{"id":"http://arxiv.org/abs/2509.22358v3","updated":"2025-12-24T08:45:34Z","published":"2025-09-26T13:53:56Z","title":"Stochastic activations","summary":"We introduce stochastic activations. This novel strategy randomly selects between several non-linear functions in the feed-forward layer of a large language model. In particular, we choose between SILU or RELU depending on a Bernoulli draw. This strategy circumvents the optimization problem associated with RELU, namely, the constant shape for negative inputs that prevents the gradient flow. We leverage this strategy in two ways:\n  (1) We use stochastic activations during pre-training and fine-tune the model with RELU, which is used at inference time to provide sparse latent vectors. This reduces the inference FLOPs and translates into a significant speedup on CPU and GPU. This leads to better results than training from scratch with the RELU activation function.\n  (2) We evaluate stochastic activations for sequence generation. This strategy performs reasonably well: it has higher diversity and has only slightly inferior performance to the best deterministic non-linearity, SILU, combined with temperature sampling. This provides an alternative way to increase the diversity of generated text.","authors":["Maria Lomeli","Matthijs Douze","Gergely Szilvasy","Loic Cabannes","Jade Copet","Sainbayar Sukhbaatar","Jason Weston","Gabriel Synnaeve","Pierre-Emmanuel Mazaré","Hervé Jégou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.15905v4","updated":"2025-12-24T08:45:19Z","published":"2025-09-16T20:19:53Z","title":"\"She's Like a Person but Better\": Characterizing Companion-Assistant Dynamics in Human-AI Relationships","summary":"Large language models are increasingly used for both task-based assistance and social companionship, yet research has typically focused on one or the other. Drawing on a survey (N = 202) and 30 interviews with high-engagement ChatGPT and Replika users, we characterize digital companionship as an emerging form of human-AI relationship. With both systems, users were drawn to humanlike qualities, such as emotional resonance and personalized responses, and non-humanlike qualities, such as constant availability and inexhaustible tolerance. This led to fluid chatbot uses, such as Replika as a writing assistant and ChatGPT as an emotional confidant, despite their distinct branding. However, we observed challenging tensions in digital companionship dynamics: participants grappled with bounded personhood, forming deep attachments while denying chatbots \"real\" human qualities, and struggled to reconcile chatbot relationships with social norms. These dynamics raise questions for the design of digital companions and the rise of hybrid, general-purpose AI systems.","authors":["Aikaterina Manoli","Janet V. T. Pauketat","Ali Ladak","Hayoun Noh","Angel Hsing-Chi Hwang","Jacy Reese Anthis"],"pdf_url":"","comment":"Improved visualizations, and corrected analysis error that had swapped reports of \"Respect\" and \"Shame.\" Fixed small errors in participant quotes"},{"id":"http://arxiv.org/abs/2512.21054v1","updated":"2025-12-24T08:44:58Z","published":"2025-12-24T08:44:58Z","title":"DexAvatar: 3D Sign Language Reconstruction with Hand and Body Pose Priors","summary":"The trend in sign language generation is centered around data-driven generative methods that require vast amounts of precise 2D and 3D human pose data to achieve an acceptable generation quality. However, currently, most sign language datasets are video-based and limited to automatically reconstructed 2D human poses (i.e., keypoints) and lack accurate 3D information. Furthermore, existing state-of-the-art for automatic 3D human pose estimation from sign language videos is prone to self-occlusion, noise, and motion blur effects, resulting in poor reconstruction quality. In response to this, we introduce DexAvatar, a novel framework to reconstruct bio-mechanically accurate fine-grained hand articulations and body movements from in-the-wild monocular sign language videos, guided by learned 3D hand and body priors. DexAvatar achieves strong performance in the SGNify motion capture dataset, the only benchmark available for this task, reaching an improvement of 35.11% in the estimation of body and hand poses compared to the state-of-the-art. The official website of this work is: https://github.com/kaustesseract/DexAvatar.","authors":["Kaustubh Kundu","Hrishav Bakul Barua","Lucy Robertson-Bell","Zhixi Cai","Kalin Stefanov"],"pdf_url":"","comment":"Accepted in WACV 2026"},{"id":"http://arxiv.org/abs/2512.20605v2","updated":"2025-12-24T08:32:45Z","published":"2025-12-23T18:51:50Z","title":"Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning","summary":"Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token can result in highly inefficient learning, particularly when rewards are sparse. Here, we show that it is possible to overcome this problem by acting and exploring within the internal representations of an autoregressive model. Specifically, to discover temporally-abstract actions, we introduce a higher-order, non-causal sequence model whose outputs control the residual stream activations of a base autoregressive model. On grid world and MuJoCo-based tasks with hierarchical structure, we find that the higher-order model learns to compress long activation sequence chunks onto internal controllers. Critically, each controller executes a sequence of behaviorally meaningful actions that unfold over long timescales and are accompanied with a learned termination condition, such that composing multiple controllers over time leads to efficient exploration on novel tasks. We show that direct internal controller reinforcement, a process we term \"internal RL\", enables learning from sparse rewards in cases where standard RL finetuning fails. Our results demonstrate the benefits of latent action generation and reinforcement in autoregressive models, suggesting internal RL as a promising avenue for realizing hierarchical RL within foundation models.","authors":["Seijin Kobayashi","Yanick Schimpf","Maximilian Schlegel","Angelika Steger","Maciej Wolczyk","Johannes von Oswald","Nino Scherrer","Kaitlin Maile","Guillaume Lajoie","Blake A. Richards","Rif A. Saurous","James Manyika","Blaise Agüera y Arcas","Alexander Meulemans","João Sacramento"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.00915v3","updated":"2025-12-24T08:25:26Z","published":"2025-10-01T13:56:44Z","title":"Reinforcement Learning with Verifiable yet Noisy Rewards under Imperfect Verifiers","summary":"Reinforcement Learning with Verifiable Rewards (RLVR) replaces costly human labeling with automated verifiers. To reduce verifier hacking, many RLVR systems binarize rewards to $\\{0,1\\}$, but imperfect verifiers inevitably introduce \\emph{false negatives} (rejecting correct answers) and \\emph{false positives} (accepting incorrect ones). We formalize verifier unreliability as a stochastic reward channel with asymmetric noise rates $ρ_0$ and $ρ_1$ -- the FP rate and the FN rate, respectively. From this abstraction we derive two lightweight corrections: (i) a \\emph{backward} correction that yields an unbiased surrogate reward and thus an unbiased policy-gradient estimator in expectation, and (ii) a \\emph{forward} correction that reweights score-function terms so the expected update aligns with the clean gradient direction and requires only the FN rate. We implement both as lightweight hooks in a group relative policy optimization pipeline, both corrections improve RLVR for math reasoning under synthetic and real verifier noise, with the forward variant being more stable under heavier noise. Finally, an appeals mechanism with a lightweight LLM verifier estimates the FN rate online and further improves performance.","authors":["Xin-Qiang Cai","Wei Wang","Feng Liu","Tongliang Liu","Gang Niu","Masashi Sugiyama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17129v2","updated":"2025-12-24T07:50:00Z","published":"2025-11-21T10:45:44Z","title":"Learning to Compress: Unlocking the Potential of Large Language Models for Text Representation","summary":"Text representation plays a critical role in tasks like clustering, retrieval, and other downstream applications. With the emergence of large language models (LLMs), there is increasing interest in harnessing their capabilities for this purpose. However, most of the LLMs are inherently causal and optimized for next-token prediction, making them suboptimal for producing holistic representations. To address this, recent studies introduced pretext tasks to adapt LLMs for text representation. Most of these tasks, however, rely on token-level prediction objectives, such as the masked next-token prediction (MNTP) used in LLM2Vec. In this work, we explore the untapped potential of context compression as a pretext task for unsupervised adaptation of LLMs. During compression pre-training, the model learns to generate compact memory tokens, which substitute the whole context for downstream sequence prediction. Experiments demonstrate that a well-designed compression objective can significantly enhance LLM-based text representations, outperforming models trained with token-level pretext tasks. Further improvements through contrastive learning produce a strong representation model (LLM2Comp) that outperforms contemporary LLM-based text encoders on a wide range of tasks while being more sample-efficient, requiring significantly less training data. Code is available at https://github.com/longtaizi13579/LLM2Comp.","authors":["Yeqin Zhang","Yizheng Zhao","Chen Hu","Binxing Jiao","Daxin Jiang","Ruihang Miao","Cam-Tu Nguyen"],"pdf_url":"","comment":"Accepted by AAAI'26"},{"id":"http://arxiv.org/abs/2512.12284v3","updated":"2025-12-24T07:46:59Z","published":"2025-12-13T11:02:04Z","title":"V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval","summary":"Streaming video large language models (LLMs) are increasingly used for real-time multimodal tasks such as video captioning, question answering, conversational agents, and augmented reality. However, these models face fundamental memory and computational challenges because their key-value (KV) caches grow substantially with continuous streaming video input. This process requires an iterative prefill stage, which is a unique feature of streaming video LLMs. Due to its iterative prefill stage, it suffers from significant limitations, including extensive computation, substantial data transfer, and degradation in accuracy. Crucially, this issue is exacerbated for edge deployment, which is the primary target for these models.\n  In this work, we propose V-Rex, the first software-hardware co-designed accelerator that comprehensively addresses both algorithmic and hardware bottlenecks in streaming video LLM inference. At its core, V-Rex introduces ReSV, a training-free dynamic KV cache retrieval algorithm. ReSV exploits temporal and spatial similarity-based token clustering to reduce excessive KV cache memory across video frames. To fully realize these algorithmic benefits, V-Rex offers a compact, low-latency hardware accelerator with a dynamic KV cache retrieval engine (DRE), featuring bit-level and early-exit based computing units. V-Rex achieves unprecedented real-time of 3.9-8.3 FPS and energy-efficient streaming video LLM inference on edge deployment with negligible accuracy loss. While DRE only accounts for 2.2% power and 2.0% area, the system delivers 1.9-19.7x speedup and 3.1-18.5x energy efficiency improvements over AGX Orin GPU. This work is the first to comprehensively tackle KV cache retrieval across algorithms and hardware, enabling real-time streaming video LLM inference on resource-constrained edge devices.","authors":["Donghyuk Kim","Sejeong Yang","Wonjin Shin","Joo-Young Kim"],"pdf_url":"","comment":"14 pages, 20 figures, conference, accepted by HPCA 2026"},{"id":"http://arxiv.org/abs/2512.21024v1","updated":"2025-12-24T07:42:10Z","published":"2025-12-24T07:42:10Z","title":"Policy-Conditioned Policies for Multi-Agent Task Solving","summary":"In multi-agent tasks, the central challenge lies in the dynamic adaptation of strategies. However, directly conditioning on opponents' strategies is intractable in the prevalent deep reinforcement learning paradigm due to a fundamental ``representational bottleneck'': neural policies are opaque, high-dimensional parameter vectors that are incomprehensible to other agents. In this work, we propose a paradigm shift that bridges this gap by representing policies as human-interpretable source code and utilizing Large Language Models (LLMs) as approximate interpreters. This programmatic representation allows us to operationalize the game-theoretic concept of \\textit{Program Equilibrium}. We reformulate the learning problem by utilizing LLMs to perform optimization directly in the space of programmatic policies. The LLM functions as a point-wise best-response operator that iteratively synthesizes and refines the ego agent's policy code to respond to the opponent's strategy. We formalize this process as \\textit{Programmatic Iterated Best Response (PIBR)}, an algorithm where the policy code is optimized by textual gradients, using structured feedback derived from game utility and runtime unit tests. We demonstrate that this approach effectively solves several standard coordination matrix games and a cooperative Level-Based Foraging environment.","authors":["Yue Lin","Shuhui Zhu","Wenhao Li","Ang Li","Dan Qiao","Pascal Poupart","Hongyuan Zha","Baoxiang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21017v1","updated":"2025-12-24T07:24:31Z","published":"2025-12-24T07:24:31Z","title":"Rethinking Supervised Fine-Tuning: Emphasizing Key Answer Tokens for Improved LLM Accuracy","summary":"With the rapid advancement of Large Language Models (LLMs), the Chain-of-Thought (CoT) component has become significant for complex reasoning tasks. However, in conventional Supervised Fine-Tuning (SFT), the model could allocate disproportionately more attention to CoT sequences with excessive length. This reduces focus on the much shorter but essential Key portion-the final answer, whose correctness directly determines task success and evaluation quality. To address this limitation, we propose SFTKey, a two-stage training scheme. In the first stage, conventional SFT is applied to ensure proper output format, while in the second stage, only the Key portion is fine-tuned to improve accuracy. Extensive experiments across multiple benchmarks and model families demonstrate that SFTKey achieves an average accuracy improvement exceeding 5\\% over conventional SFT, while preserving the ability to generate correct formats. Overall, this study advances LLM fine-tuning by explicitly balancing CoT learning with additional optimization on answer-relevant tokens.","authors":["Xiaofeng Shi","Qian Kou","Yuduo Li","Hua Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21010v1","updated":"2025-12-24T07:14:31Z","published":"2025-12-24T07:14:31Z","title":"LLM Swiss Round: Aggregating Multi-Benchmark Performance via Competitive Swiss-System Dynamics","summary":"The rapid proliferation of Large Language Models (LLMs) and diverse specialized benchmarks necessitates a shift from fragmented, task-specific metrics to a holistic, competitive ranking system that effectively aggregates performance across multiple ability dimensions. Primarily using static scoring, current evaluation methods are fundamentally limited. They struggle to determine the proper mix ratio across diverse benchmarks, and critically, they fail to capture a model's dynamic competitive fitness or its vulnerability when confronted with sequential, high-stakes tasks. To address this, we introduce the novel Competitive Swiss-System Dynamics (CSD) framework. CSD simulates a multi-round, sequential contest where models are dynamically paired across a curated sequence of benchmarks based on their accumulated win-loss record. And Monte Carlo Simulation ($N=100,000$ iterations) is used to approximate the statistically robust Expected Win Score ($E[S_m]$), which eliminates the noise of random pairing and early-round luck. Furthermore, we implement a Failure Sensitivity Analysis by parameterizing the per-round elimination quantity ($T_k$), which allows us to profile models based on their risk appetite--distinguishing between robust generalists and aggressive specialists. We demonstrate that CSD provides a more nuanced and context-aware ranking than traditional aggregate scoring and static pairwise models, representing a vital step towards risk-informed, next-generation LLM evaluation.","authors":["Jiashuo Liu","Jiayun Wu","Chunjie Wu","Jingkai Liu","Zaiyuan Wang","Huan Zhou","Wenhao Huang","Hongseok Namkoong"],"pdf_url":"","comment":"18 pages"},{"id":"http://arxiv.org/abs/2512.21002v1","updated":"2025-12-24T06:57:35Z","published":"2025-12-24T06:57:35Z","title":"Distilling the Essence: Efficient Reasoning Distillation via Sequence Truncation","summary":"Distilling the reasoning capabilities from a large language model (LLM) to a smaller student model often involves training on substantial amounts of reasoning data. However, distillation over lengthy sequences with prompt (P), chain-of-thought (CoT), and answer (A) segments makes the process computationally expensive. In this work, we investigate how the allocation of supervision across different segments (P, CoT, A) affects student performance. Our analysis shows that selective knowledge distillation over only the CoT tokens can be effective when the prompt and answer information is encompassed by it. Building on this insight, we establish a truncation protocol to quantify computation-quality tradeoffs as a function of sequence length. We observe that training on only the first $50\\%$ of tokens of every training sequence can retain, on average, $\\approx94\\%$ of full-sequence performance on math benchmarks while reducing training time, memory usage, and FLOPs by about $50\\%$ each. These findings suggest that reasoning distillation benefits from prioritizing early reasoning tokens and provides a simple lever for computation-quality tradeoffs. Codes are available at https://github.com/weiruichen01/distilling-the-essence.","authors":["Wei-Rui Chen","Vignesh Kothapalli","Ata Fatahibaarzi","Hejian Sang","Shao Tang","Qingquan Song","Zhipeng Wang","Muhammad Abdul-Mageed"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20996v1","updated":"2025-12-24T06:48:04Z","published":"2025-12-24T06:48:04Z","title":"TrafficSimAgent: A Hierarchical Agent Framework for Autonomous Traffic Simulation with MCP Control","summary":"Traffic simulation is important for transportation optimization and policy making. While existing simulators such as SUMO and MATSim offer fully-featured platforms and utilities, users without too much knowledge about these platforms often face significant challenges when conducting experiments from scratch and applying them to their daily work. To solve this challenge, we propose TrafficSimAgent, an LLM-based agent framework that serves as an expert in experiment design and decision optimization for general-purpose traffic simulation tasks. The framework facilitates execution through cross-level collaboration among expert agents: high-level expert agents comprehend natural language instructions with high flexibility, plan the overall experiment workflow, and invoke corresponding MCP-compatible tools on demand; meanwhile, low-level expert agents select optimal action plans for fundamental elements based on real-time traffic conditions. Extensive experiments across multiple scenarios show that TrafficSimAgent effectively executes simulations under various conditions and consistently produces reasonable outcomes even when user instructions are ambiguous. Besides, the carefully designed expert-level autonomous decision-driven optimization in TrafficSimAgent yields superior performance when compared with other systems and SOTA LLM based methods.","authors":["Yuwei Du","Jun Zhang","Jie Feng","Zhicheng Liu","Jian Yuan","Yong Li"],"pdf_url":"","comment":"The code will be available at: https://github.com/tsinghua-fib-lab/TrafficSimAgent"},{"id":"http://arxiv.org/abs/2512.18748v2","updated":"2025-12-24T06:47:27Z","published":"2025-12-21T14:28:51Z","title":"Code2Doc: A Quality-First Curated Dataset for Code Documentation","summary":"The performance of automatic code documentation generation models depends critically on the quality of the training data used for supervision. However, most existing code documentation datasets are constructed through large scale scraping of public repositories with limited quality control. As a result, they often contain noisy documentation, extensive duplication, and increasing contamination from AI generated content. These issues weaken the supervision signal available to learning-based models and complicate evaluation.\n  We introduce Code2Doc, a quality-first curated dataset for function-level code documentation generation. Code2Doc consists of 13,358 high-quality function-documentation pairs extracted from widely used open-source repositories spanning five programming languages: Python, Java, TypeScript, JavaScript, and C++. The dataset is constructed using a four-stage curation pipeline that enforces documentation completeness and clarity, filters functions based on structural and complexity criteria, removes exact and near-duplicate code, and identifies documentation likely to be AI generated. Starting from 52,069 extracted candidates, only 25.6% satisfy all quality constraints.\n  We provide a detailed analysis of the resulting dataset, which achieves a mean documentation quality score of 6.93 out of 10. Overall, 86.9% of samples contain explicit type annotations, and only 2.9% are flagged as potentially AI generated. Baseline experiments show that fine-tuning a large language model on Code2Doc yields relative improvements of 29.47% in BLEU and 24.04% in ROUGE-L over zero shot performance, despite the modest dataset size. We release both the dataset and the full curation pipeline to support reproducible research on automatic code documentation generation.","authors":["Recep Kaan Karaman","Meftun Akarsu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.11783v3","updated":"2025-12-24T06:45:54Z","published":"2025-07-15T22:52:44Z","title":"EEG Foundation Models: A Critical Review of Current Progress and Future Directions","summary":"Premise. Patterns of electrical brain activity recorded via electroencephalography (EEG) offer immense value for scientific and clinical investigations. The inability of supervised EEG encoders to learn robust EEG patterns and their over-reliance on expensive signal annotations have sparked a transition towards general-purpose self-supervised EEG encoders, i.e., EEG foundation models (EEG-FMs), for robust and scalable EEG feature extraction. However, the real-world readiness of early EEG-FMs and the rubrics for long-term research progress remain unclear. Objective. In this work, we conduct a review of ten early EEG-FMs to capture common trends and identify key directions for future development of EEG-FMs. Methods. We comparatively analyze each EEG-FM using three fundamental pillars of foundation modeling, namely the representation of input data, self-supervised modeling, and the evaluation strategy. Based on this analysis, we present a critical synthesis of EEG-FM methodology, empirical findings, and outstanding research gaps. Results. We find that most EEG-FMs adopt a sequence-based modeling scheme that relies on transformer-based backbones and the reconstruction of masked temporal EEG sequences for self-supervision. However, model evaluations remain heterogeneous and largely limited, making it challenging to assess their practical off-the-shelf utility. In addition to adopting standardized and realistic evaluations, future work should demonstrate more substantial scaling effects and make principled and trustworthy choices throughout the EEG representation learning pipeline. Significance. Our review indicates that the development of benchmarks, software tools, technical methodologies, and applications in collaboration with domain experts may advance the translational utility and real-world adoption of EEG-FMs.","authors":["Gayal Kuruppu","Neeraj Wagh","Vaclav Kremen","Sandipan Pati","Gregory Worrell","Yogatheesan Varatharajah"],"pdf_url":"","comment":"22 pages (main), 5 figures (main), 4 tables (main + supplement)"},{"id":"http://arxiv.org/abs/2512.14693v2","updated":"2025-12-24T06:34:30Z","published":"2025-12-16T18:58:45Z","title":"Universal Reasoning Model","summary":"Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which enhances the UT with short convolution and truncated backpropagation. Our approach substantially improves reasoning performance, achieving state-of-the-art 53.8% pass@1 on ARC-AGI 1 and 16.0% pass@1 on ARC-AGI 2. Our code is avaliable at https://github.com/UbiquantAI/URM.","authors":["Zitian Gao","Lynx Chen","Yihao Xiao","He Xing","Ran Tao","Haoming Luo","Joey Zhou","Bryan Dai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20991v1","updated":"2025-12-24T06:33:17Z","published":"2025-12-24T06:33:17Z","title":"FinAgent: An Agentic AI Framework Integrating Personal Finance and Nutrition Planning","summary":"The issue of limited household budgets and nutritional demands continues to be a challenge especially in the middle-income environment where food prices fluctuate. This paper introduces a price aware agentic AI system, which combines personal finance management with diet optimization. With household income and fixed expenditures, medical and well-being status, as well as real-time food costs, the system creates nutritionally sufficient meals plans at comparatively reasonable prices that automatically adjust to market changes. The framework is implemented in a modular multi-agent architecture, which has specific agents (budgeting, nutrition, price monitoring, and health personalization). These agents share the knowledge base and use the substitution graph to ensure that the nutritional quality is maintained at a minimum cost. Simulations with a representative Saudi household case study show a steady 12-18\\% reduction in costs relative to a static weekly menu, nutrient adequacy of over 95\\% and high performance with price changes of 20-30%. The findings indicate that the framework can locally combine affordability with nutritional adequacy and provide a viable avenue of capacity-building towards sustainable and fair diet planning in line with Sustainable Development Goals on Zero Hunger and Good Health.","authors":["Toqeer Ali Syed","Abdulaziz Alshahrani","Ali Ullah","Ali Akarma","Sohail Khan","Muhammad Nauman","Salman Jan"],"pdf_url":"","comment":"This paper was presented at the IEEE International Conference on Computing and Applications (ICCA 2025), Bahrain"},{"id":"http://arxiv.org/abs/2512.20985v1","updated":"2025-12-24T06:20:28Z","published":"2025-12-24T06:20:28Z","title":"A Blockchain-Monitored Agentic AI Architecture for Trusted Perception-Reasoning-Action Pipelines","summary":"The application of agentic AI systems in autonomous decision-making is growing in the areas of healthcare, smart cities, digital forensics, and supply chain management. Even though these systems are flexible and offer real-time reasoning, they also raise concerns of trust and oversight, and integrity of the information and activities upon which they are founded. The paper suggests a single architecture model comprising of LangChain-based multi-agent system with a permissioned blockchain to guarantee constant monitoring, policy enforcement, and immutable auditability of agentic action. The framework relates the perception conceptualization-action cycle to a blockchain layer of governance that verifies the inputs, evaluates recommended actions, and documents the outcomes of the execution. A Hyperledger Fabric-based system, action executors MCP-integrated, and LangChain agent are introduced and experiments of smart inventory management, traffic-signal control, and healthcare monitoring are done. The results suggest that blockchain-security verification is efficient in preventing unauthorized practices, offers traceability throughout the whole decision-making process, and maintains operational latency within reasonable ranges. The suggested framework provides a universal system of implementing high-impact agentic AI applications that are autonomous yet responsible.","authors":["Salman Jan","Hassan Ali Razzaqi","Ali Akarma","Mohammad Riyaz Belgaum"],"pdf_url":"","comment":"This paper was presented at the IEEE International Conference on Computing and Applications (ICCA 2025), Bahrain"},{"id":"http://arxiv.org/abs/2512.20983v1","updated":"2025-12-24T06:17:21Z","published":"2025-12-24T06:17:21Z","title":"Automatic Replication of LLM Mistakes in Medical Conversations","summary":"Large language models (LLMs) are increasingly evaluated in clinical settings using multi-dimensional rubrics which quantify reasoning quality, safety, and patient-centeredness. Yet, replicating specific mistakes in other LLM models is not straightforward and often requires manual effort. We introduce MedMistake, an automatic pipeline that extracts mistakes LLMs make in patient-doctor conversations and converts them into a benchmark of single-shot QA pairs. Our pipeline (1) creates complex, conversational data between an LLM patient and LLM doctor, (2) runs an evaluation with a committee of 2 LLM judges across a variety of dimensions and (3) creates simplified single-shot QA scenarios from those mistakes. We release MedMistake-All, a dataset of 3,390 single-shot QA pairs where GPT-5 and Gemini 2.5 Pro are currently failing to answer correctly, as judged by two LLM judges. We used medical experts to validate a subset of 211/3390 questions (MedMistake-Bench), which we used to run a final evaluation of 12 frontier LLMs: Claude Opus 4.5, Claude Sonnet 4.5, DeepSeek-Chat, Gemini 2.5 Pro, Gemini 3 Pro, GPT-4o, GPT-5, GPT-5.1, GPT-5.2, Grok 4, Grok 4.1, Mistral Large. We found that GPT models, Claude and Grok obtained the best performance on MedMistake-Bench. We release both the doctor-validated benchmark (MedMistake-Bench), as well as the full dataset (MedMistake-All) at https://huggingface.co/datasets/TheLumos/MedicalMistakeBenchmark.","authors":["Oleksii Proniakin","Diego Fajardo","Ruslan Nazarenko","Razvan Marinescu"],"pdf_url":"","comment":"48 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2512.20978v1","updated":"2025-12-24T06:13:02Z","published":"2025-12-24T06:13:02Z","title":"GenTSE: Enhancing Target Speaker Extraction via a Coarse-to-Fine Generative Language Model","summary":"Language Model (LM)-based generative modeling has emerged as a promising direction for TSE, offering potential for improved generalization and high-fidelity speech. We present GenTSE, a two-stage decoder-only generative LM approach for TSE: Stage-1 predicts coarse semantic tokens, and Stage-2 generates fine acoustic tokens. Separating semantics and acoustics stabilizes decoding and yields more faithful, content-aligned target speech. Both stages use continuous SSL or codec embeddings, offering richer context than discretized-prompt methods. To reduce exposure bias, we employ a Frozen-LM Conditioning training strategy that conditions the LMs on predicted tokens from earlier checkpoints to reduce the gap between teacher-forcing training and autoregressive inference. We further employ DPO to better align outputs with human perceptual preferences. Experiments on Libri2Mix show that GenTSE surpasses previous LM-based systems in speech quality, intelligibility, and speaker consistency.","authors":["Haoyang Li","Xuyi Zhuang","Azmat Adnan","Ye Ni","Wei Rao","Shreyas Gopal","Eng Siong Chng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.06672v3","updated":"2025-12-24T06:12:56Z","published":"2024-08-13T06:47:59Z","title":"TimeBridge: Better Diffusion Prior Design with Bridge Models for Time Series Generation","summary":"Time series generation is widely used in real-world applications such as simulation, data augmentation, and hypothesis testing. Recently, diffusion models have emerged as the de facto approach to time series generation, enabling diverse synthesis scenarios. However, the fixed standard-Gaussian diffusion prior may be ill-suited for time series data, which exhibit properties such as temporal order and fixed time points. In this paper, we propose TimeBridge, a framework that flexibly synthesizes time series data by using diffusion bridges to learn paths between a chosen prior and the data distribution. We then explore several prior designs tailored to time series synthesis. Our framework covers (i) data- and time-dependent priors for unconditional generation and (ii) scale-preserving priors for conditional generation. Experiments show that our framework with data-driven priors outperforms standard diffusion models on time series generation.","authors":["Jinseong Park","Seungyun Lee","Woojin Jeong","Yujin Choi","Jaewook Lee"],"pdf_url":"","comment":"KDD 2026"},{"id":"http://arxiv.org/abs/2512.20974v1","updated":"2025-12-24T06:00:51Z","published":"2025-12-24T06:00:51Z","title":"Generalised Linear Models in Deep Bayesian RL with Learnable Basis Functions","summary":"Bayesian Reinforcement Learning (BRL) provides a framework for generalisation of Reinforcement Learning (RL) problems from its use of Bayesian task parameters in the transition and reward models. However, classical BRL methods assume known forms of transition and reward models, reducing their applicability in real-world problems. As a result, recent deep BRL methods have started to incorporate model learning, though the use of neural networks directly on the joint data and task parameters requires optimising the Evidence Lower Bound (ELBO). ELBOs are difficult to optimise and may result in indistinctive task parameters, hence compromised BRL policies. To this end, we introduce a novel deep BRL method, Generalised Linear Models in Deep Bayesian RL with Learnable Basis Functions (GLiBRL), that enables efficient and accurate learning of transition and reward models, with fully tractable marginal likelihood and Bayesian inference on task parameters and model noises. On challenging MetaWorld ML10/45 benchmarks, GLiBRL improves the success rate of one of the state-of-the-art deep BRL methods, VariBAD, by up to 2.7x. Comparing against representative or recent deep BRL / Meta-RL methods, such as MAML, RL2, SDVT, TrMRL and ECET, GLiBRL also demonstrates its low-variance and decent performance consistently.","authors":["Jingyang You","Hanna Kurniawati"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20968v1","updated":"2025-12-24T05:48:58Z","published":"2025-12-24T05:48:58Z","title":"Mesh-Attention: A New Communication-Efficient Distributed Attention with Improved Data Locality","summary":"Distributed attention is a fundamental problem for scaling context window for Large Language Models (LLMs). The state-of-the-art method, Ring-Attention, suffers from scalability limitations due to its excessive communication traffic. This paper proposes a new distributed attention algorithm, Mesh-Attention, by rethinking the design space of distributed attention with a new matrix-based model. Our method assigns a two-dimensional tile -- rather than one-dimensional row or column -- of computation blocks to each GPU to achieve higher efficiency through lower communication-computation (CommCom) ratio. The general approach covers Ring-Attention as a special case, and allows the tuning of CommCom ratio with different tile shapes. Importantly, we propose a greedy algorithm that can efficiently search the scheduling space within the tile with restrictions that ensure efficient communication among GPUs. The theoretical analysis shows that Mesh-Attention leads to a much lower communication complexity and exhibits good scalability comparing to other current algorithms.\n  Our extensive experiment results show that Mesh-Attention can achieve up to 3.4x speedup (2.9x on average) and reduce the communication volume by up to 85.4% (79.0% on average) on 256 GPUs. Our scalability results further demonstrate that Mesh-Attention sustains superior performance as the system scales, substantially reducing overhead in large-scale deployments. The results convincingly confirm the advantage of Mesh-Attention.","authors":["Sirui Chen","Jingji Chen","Siqi Zhu","Ziheng Jiang","Yanghua Peng","Xuehai Qian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.11990v2","updated":"2025-12-24T05:42:44Z","published":"2025-11-15T02:05:11Z","title":"Improving Autoformalization Using Direct Dependency Retrieval","summary":"The convergence of deep learning and formal mathematics has spurred research in formal verification. Statement autoformalization, a crucial first step in this process, aims to translate informal descriptions into machine-verifiable representations but remains a significant challenge. The core difficulty lies in the fact that existing methods often suffer from a lack of contextual awareness, leading to hallucination of formal definitions and theorems. Furthermore, current retrieval-augmented approaches exhibit poor precision and recall for formal library dependency retrieval, and lack the scalability to effectively leverage ever-growing public datasets. To bridge this gap, we propose a novel retrieval-augmented framework based on DDR (\\textit{Direct Dependency Retrieval}) for statement autoformalization. Our DDR method directly generates candidate library dependencies from natural language mathematical descriptions and subsequently verifies their existence within the formal library via an efficient suffix array check. Leveraging this efficient search mechanism, we constructed a dependency retrieval dataset of over 500,000 samples and fine-tuned a high-precision DDR model. Experimental results demonstrate that our DDR model significantly outperforms SOTA methods in both retrieval precision and recall. Consequently, an autoformalizer equipped with DDR shows consistent performance advantages in both single-attempt accuracy and multi-attempt stability compared to models using traditional selection-based RAG methods.","authors":["Shaoqi Wang","Lu Yu","Siwei Lou","Feng Yan","Chunjie Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19512v2","updated":"2025-12-24T05:32:41Z","published":"2025-12-22T16:06:36Z","title":"Anatomy-R1: Enhancing Anatomy Reasoning in Multimodal Large Language Models via Anatomical Similarity Curriculum and Group Diversity Augmentation","summary":"Multimodal Large Language Models (MLLMs) have achieved impressive progress in natural image reasoning, yet their potential in medical imaging remains underexplored, especially in clinical anatomical surgical images. Anatomy understanding tasks demand precise understanding and clinically coherent answers, which are difficult to achieve due to the complexity of medical data and the scarcity of high-quality expert annotations. These challenges limit the effectiveness of conventional Supervised Fine-Tuning (SFT) strategies. While recent work has demonstrated that Group Relative Policy Optimization (GRPO) can enhance reasoning in MLLMs without relying on large amounts of data, we find two weaknesses that hinder GRPO's reasoning performance in anatomy recognition: 1) knowledge cannot be effectively shared between different anatomical structures, resulting in uneven information gain and preventing the model from converging, and 2) the model quickly converges to a single reasoning path, suppressing the exploration of diverse strategies. To overcome these challenges, we propose two novel methods. First, we implement a progressive learning strategy called Anatomical Similarity Curriculum Learning by controlling question difficulty via the similarity of answer choices, enabling the model to master complex problems incrementally. Second, we utilize question augmentation referred to as Group Diversity Question Augmentation to expand the model's search space for difficult queries, mitigating the tendency to produce uniform responses. Comprehensive experiments on the SGG-VQA and OmniMedVQA benchmarks show our method achieves a significant improvement across the two benchmarks, demonstrating its effectiveness in enhancing the medical reasoning capabilities of MLLMs. The code can be found in https://github.com/tomato996/Anatomy-R1","authors":["Ziyang Song","Zelin Zang","Zuyao Chen","Xusheng Liang","Dong Yi","Jinlin Wu","Hongbin Liu","Jiebo Luo","Zhen. Lei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20959v1","updated":"2025-12-24T05:31:42Z","published":"2025-12-24T05:31:42Z","title":"Can Agentic AI Match the Performance of Human Data Scientists?","summary":"Data science plays a critical role in transforming complex data into actionable insights across numerous domains. Recent developments in large language models (LLMs) have significantly automated data science workflows, but a fundamental question persists: Can these agentic AI systems truly match the performance of human data scientists who routinely leverage domain-specific knowledge? We explore this question by designing a prediction task where a crucial latent variable is hidden in relevant image data instead of tabular features. As a result, agentic AI that generates generic codes for modeling tabular data cannot perform well, while human experts could identify the important hidden variable using domain knowledge. We demonstrate this idea with a synthetic dataset for property insurance. Our experiments show that agentic AI that relies on generic analytics workflow falls short of methods that use domain-specific insights. This highlights a key limitation of the current agentic AI for data science and underscores the need for future research to develop agentic AI systems that can better recognize and incorporate domain knowledge.","authors":["An Luo","Jin Du","Fangqiao Tian","Xun Xian","Robert Specht","Ganghua Wang","Xuan Bi","Charles Fleming","Jayanth Srinivasa","Ashish Kundu","Mingyi Hong","Jie Ding"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.13725v2","updated":"2025-12-24T05:31:23Z","published":"2025-12-13T17:54:15Z","title":"Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy","summary":"Causal reasoning in Large Language Models spanning association, intervention, and counterfactual inference is essential for reliable decision making in high stakes settings. As deployment shifts toward edge and resource constrained environments, quantized models such as INT8 and NF4 are becoming standard. Yet the impact of precision reduction on formal causal reasoning is poorly understood. To our knowledge, this is the first study to systematically evaluate quantization effects across all three levels of Pearls Causal Ladder. Using a 3000 sample stratified CLadder benchmark, we find that rung level accuracy in Llama 3 8B remains broadly stable under quantization, with NF4 showing less than one percent overall degradation. Interventional queries at rung 2 are the most sensitive to precision loss, whereas counterfactual reasoning at rung 3 is comparatively stable but exhibits heterogeneous weaknesses across query types such as collider bias and backdoor adjustment. Experiments on the CRASS benchmark show near identical performance across precisions, indicating that existing commonsense counterfactual datasets lack the structural sensitivity needed to reveal quantization induced reasoning drift. We further evaluate Graph Retrieval Augmented Generation using ground truth causal graphs and observe a consistent improvement in NF4 interventional accuracy of plus 1.7 percent, partially offsetting compression related degradation. These results suggest that causal reasoning is unexpectedly robust to four bit quantization, graph structured augmentation can selectively reinforce interventional reasoning, and current counterfactual benchmarks fail to capture deeper causal brittleness. This work provides an initial empirical map of compressed causal reasoning and practical guidance for deploying efficient and structurally supported causal AI systems.","authors":["Steve Nwaiwu","Nipat Jongsawat","Anucha Tungkasthan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20958v1","updated":"2025-12-24T05:29:35Z","published":"2025-12-24T05:29:35Z","title":"ReACT-Drug: Reaction-Template Guided Reinforcement Learning for de novo Drug Design","summary":"De novo drug design is a crucial component of modern drug development, yet navigating the vast chemical space to find synthetically accessible, high-affinity candidates remains a significant challenge. Reinforcement Learning (RL) enhances this process by enabling multi-objective optimization and exploration of novel chemical space - capabilities that traditional supervised learning methods lack. In this work, we introduce \\textbf{ReACT-Drug}, a fully integrated, target-agnostic molecular design framework based on Reinforcement Learning. Unlike models requiring target-specific fine-tuning, ReACT-Drug utilizes a generalist approach by leveraging ESM-2 protein embeddings to identify similar proteins for a given target from a knowledge base such as Protein Data Base (PDB). Thereafter, the known drug ligands corresponding to such proteins are decomposed to initialize a fragment-based search space, biasing the agent towards biologically relevant subspaces. For each such fragment, the pipeline employs a Proximal Policy Optimization (PPO) agent guiding a ChemBERTa-encoded molecule through a dynamic action space of chemically valid, reaction-template-based transformations. This results in the generation of \\textit{de novo} drug candidates with competitive binding affinities and high synthetic accessibility, while ensuring 100\\% chemical validity and novelty as per MOSES benchmarking. This architecture highlights the potential of integrating structural biology, deep representation learning, and chemical synthesis rules to automate and accelerate rational drug design. The dataset and code are available at https://github.com/YadunandanRaman/ReACT-Drug/.","authors":["R Yadunandan","Nimisha Ghosh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20957v1","updated":"2025-12-24T05:27:53Z","published":"2025-12-24T05:27:53Z","title":"One Tool Is Enough: Reinforcement Learning for Repository-Level LLM Agents","summary":"Locating the files and functions requiring modification in large open-source software (OSS) repositories is challenging due to their scale and structural complexity. Existing large language model (LLM)-based methods typically treat this as a repository-level retrieval task and rely on multiple auxiliary tools, which overlook code execution logic and complicate model control. We propose RepoNavigator, an LLM agent equipped with a single execution-aware tool-jumping to the definition of an invoked symbol. This unified design reflects the actual flow of code execution while simplifying tool manipulation. RepoNavigator is trained end-to-end via Reinforcement Learning (RL) directly from a pretrained model, without any closed-source distillation. Experiments demonstrate that RL-trained RepoNavigator achieves state-of-the-art performance, with the 7B model outperforming 14B baselines, the 14B model surpassing 32B competitors, and even the 32B model exceeding closed-source models such as Claude-3.7. These results confirm that integrating a single, structurally grounded tool with RL training provides an efficient and scalable solution for repository-level issue localization.","authors":["Zhaoxi Zhang","Yitong Duan","Yanzhi Zhang","Yiming Xu","Jiyan He","Yunfang Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20954v1","updated":"2025-12-24T05:25:17Z","published":"2025-12-24T05:25:17Z","title":"Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models","summary":"Chain-of-Thought (CoT) prompting has significantly advanced task-solving capabilities in natural language processing with large language models. Unlike standard prompting, CoT encourages the model to generate intermediate reasoning steps, non-answer tokens, that help guide the model toward more accurate final outputs. These intermediate steps enable more complex reasoning processes such as error correction, memory management, future planning, and self-reflection. However, applying CoT to non-natural language domains, such as protein and RNA language models, is not yet possible, primarily due to the limited expressiveness of their token spaces (e.g., amino acid tokens). In this work, we propose and define the concept of language expressiveness: the ability of a given language, using its tokens and grammar, to encode information. We show that the limited expressiveness of protein language severely restricts the applicability of CoT-style reasoning. To overcome this, we introduce reflection pretraining, for the first time in a biological sequence model, which enables the model to engage in intermediate reasoning through the generation of auxiliary \"thinking tokens\" beyond simple answer tokens. Theoretically, we demonstrate that our augmented token set significantly enhances biological language expressiveness, thereby improving the overall reasoning capacity of the model. Experimentally, our pretraining approach teaches protein models to self-correct and leads to substantial performance gains compared to standard pretraining.","authors":["Xiang Zhang","Jiaqi Wei","Yuejin Yang","Zijie Qiu","Yuhan Chen","Zhiqiang Gao","Muhammad Abdul-Mageed","Laks V. S. Lakshmanan","Wanli Ouyang","Chenyu You","Siqi Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.04265v2","updated":"2025-12-24T05:18:52Z","published":"2025-10-05T16:14:03Z","title":"Don't Pass@k: A Bayesian Framework for Large Language Model Evaluation","summary":"Pass$@k$ is widely used to report performance for LLM reasoning, but it often yields unstable, misleading rankings, especially when the number of trials (samples) is limited and compute is constrained. We present a principled Bayesian evaluation framework that replaces Pass$@k$ and average accuracy over $N$ trials (avg$@N$) with posterior estimates of a model's underlying success probability and credible intervals, yielding stable rankings and a transparent decision rule for differences. Evaluation outcomes are modeled as categorical (not just 0/1) with a Dirichlet prior, giving closed-form expressions for the posterior mean and uncertainty of any weighted rubric and enabling the use of prior evidence when appropriate. Theoretically, under a uniform prior, the Bayesian posterior mean is order-equivalent to average accuracy (Pass$@1$), explaining its empirical robustness while adding principled uncertainty. Empirically, in simulations with known ground-truth success rates and on AIME'24/'25, HMMT'25, and BrUMO'25, the Bayesian/avg procedure achieves faster convergence and greater rank stability than Pass$@k$ and recent variants, enabling reliable comparisons at far smaller sample counts. The framework clarifies when observed gaps are statistically meaningful (non-overlapping credible intervals) versus noise, and it naturally extends to graded, rubric-based evaluations. Together, these results recommend replacing Pass$@k$ for LLM evaluation and ranking with a posterior-based, compute-efficient protocol that unifies binary and non-binary evaluation while making uncertainty explicit. Code is available at https://github.com/mohsenhariri/scorio","authors":["Mohsen Hariri","Amirhossein Samandar","Michael Hinczewski","Vipin Chaudhary"],"pdf_url":"","comment":"Code and simulations: https://github.com/mohsenhariri/scorio"},{"id":"http://arxiv.org/abs/2512.20950v1","updated":"2025-12-24T05:14:40Z","published":"2025-12-24T05:14:40Z","title":"MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment","summary":"This paper presents our system for SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval. In an era where misinformation spreads rapidly, effective fact-checking is increasingly critical. We introduce TriAligner, a novel approach that leverages a dual-encoder architecture with contrastive learning and incorporates both native and English translations across different modalities. Our method effectively retrieves claims across multiple languages by learning the relative importance of different sources in alignment. To enhance robustness, we employ efficient data preprocessing and augmentation using large language models while incorporating hard negative sampling to improve representation learning. We evaluate our approach on monolingual and crosslingual benchmarks, demonstrating significant improvements in retrieval accuracy and fact-checking performance over baselines.","authors":["Mohammad Mahdi Abootorabi","Alireza Ghahramani Kure","Mohammadali Mohammadkhani","Sina Elahimanesh","Mohammad Ali Ali Panah"],"pdf_url":"","comment":"11 pages Published at the SemEval-2025 workshop"},{"id":"http://arxiv.org/abs/2512.20949v1","updated":"2025-12-24T05:10:19Z","published":"2025-12-24T05:10:19Z","title":"Neural Probe-Based Hallucination Detection for Large Language Models","summary":"Large language models(LLMs) excel at text generation and knowledge question-answering tasks, but they are prone to generating hallucinated content, severely limiting their application in high-risk domains. Current hallucination detection methods based on uncertainty estimation and external knowledge retrieval suffer from the limitation that they still produce erroneous content at high confidence levels and rely heavily on retrieval efficiency and knowledge coverage. In contrast, probe methods that leverage the model's hidden-layer states offer real-time and lightweight advantages. However, traditional linear probes struggle to capture nonlinear structures in deep semantic spaces.To overcome these limitations, we propose a neural network-based framework for token-level hallucination detection. By freezing language model parameters, we employ lightweight MLP probes to perform nonlinear modeling of high-level hidden states. A multi-objective joint loss function is designed to enhance detection stability and semantic disambiguity. Additionally, we establish a layer position-probe performance response model, using Bayesian optimization to automatically search for optimal probe insertion layers and achieve superior training results.Experimental results on LongFact, HealthBench, and TriviaQA demonstrate that MLP probes significantly outperform state-of-the-art methods in accuracy, recall, and detection capability under low false-positive conditions.","authors":["Shize Liang","Hongzhi Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.02080v2","updated":"2025-12-24T04:57:32Z","published":"2025-04-02T19:33:07Z","title":"Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses","summary":"Large Language Models (LLMs) are increasingly popular, powering a wide range of applications. Their widespread use has sparked concerns, especially through jailbreak attacks that bypass safety measures to produce harmful content.\n  In this paper, we present a comprehensive security analysis of large language models (LLMs), addressing critical research questions on the evolution and determinants of model safety.\n  Specifically, we begin by identifying the most effective techniques for detecting jailbreak attacks. Next, we investigate whether newer versions of LLMs offer improved security compared to their predecessors. We also assess the impact of model size on overall security and explore the potential benefits of integrating multiple defense strategies to enhance the security.\n  Our study evaluates both open-source (e.g., LLaMA and Mistral) and closed-source models (e.g., GPT-4) by employing four state-of-the-art attack techniques and assessing the efficacy of three new defensive approaches.","authors":["Zhengchun Shang","Wenlan Wei","Weiheng Bai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2406.16087v8","updated":"2025-12-24T04:53:14Z","published":"2024-06-23T12:02:17Z","title":"Imperative Learning: A Self-supervised Neuro-Symbolic Learning Framework for Robot Autonomy","summary":"Data-driven methods such as reinforcement and imitation learning have achieved remarkable success in robot autonomy. However, their data-centric nature still hinders them from generalizing well to ever-changing environments. Moreover, labeling data for robotic tasks is often impractical and expensive. To overcome these challenges, we introduce a new self-supervised neuro-symbolic (NeSy) computational framework, imperative learning (IL), for robot autonomy, leveraging the generalization abilities of symbolic reasoning. The framework of IL consists of three primary components: a neural module, a reasoning engine, and a memory system. We formulate IL as a special bilevel optimization (BLO), which enables reciprocal learning over the three modules. This overcomes the label-intensive obstacles associated with data-driven approaches and takes advantage of symbolic reasoning concerning logical reasoning, physical principles, geometric analysis, etc. We discuss several optimization techniques for IL and verify their effectiveness in five distinct robot autonomy tasks including path planning, rule induction, optimal control, visual odometry, and multi-robot routing. Through various experiments, we show that IL can significantly enhance robot autonomy capabilities and we anticipate that it will catalyze further research across diverse domains.","authors":["Chen Wang","Kaiyi Ji","Junyi Geng","Zhongqiang Ren","Taimeng Fu","Fan Yang","Yifan Guo","Haonan He","Xiangyu Chen","Zitong Zhan","Qiwei Du","Shaoshu Su","Bowen Li","Yuheng Qiu","Yi Du","Qihang Li","Yifan Yang","Xiao Lin","Zhipeng Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20941v1","updated":"2025-12-24T04:53:11Z","published":"2025-12-24T04:53:11Z","title":"A Multi-fidelity Double-Delta Wing Dataset and Empirical Scaling Laws for GNN-based Aerodynamic Field Surrogate","summary":"Data-driven surrogate models are increasingly adopted to accelerate vehicle design. However, open-source multi-fidelity datasets and empirical guidelines linking dataset size to model performance remain limited. This study investigates the relationship between training data size and prediction accuracy for a graph neural network (GNN) based surrogate model for aerodynamic field prediction. We release an open-source, multi-fidelity aerodynamic dataset for double-delta wings, comprising 2448 flow snapshots across 272 geometries evaluated at angles of attack from 11 (degree) to 19 (degree) at Ma=0.3 using both Vortex Lattice Method (VLM) and Reynolds-Averaged Navier-Stokes (RANS) solvers. The geometries are generated using a nested Saltelli sampling scheme to support future dataset expansion and variance-based sensitivity analysis. Using this dataset, we conduct a preliminary empirical scaling study of the MF-VortexNet surrogate by constructing six training datasets with sizes ranging from 40 to 1280 snapshots and training models with 0.1 to 2.4 million parameters under a fixed training budget. We find that the test error decreases with data size with a power-law exponent of -0.6122, indicating efficient data utilization. Based on this scaling law, we estimate that the optimal sampling density is approximately eight samples per dimension in a d-dimensional design space. The results also suggest improved data utilization efficiency for larger surrogate models, implying a potential trade-off between dataset generation cost and model training budget.","authors":["Yiren Shen","Juan J. Alonso"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.08893v2","updated":"2025-12-24T04:42:33Z","published":"2024-12-12T03:14:47Z","title":"Optimal Control with Natural Images: Efficient Reinforcement Learning using Overcomplete Sparse Codes","summary":"Optimal control and sequential decision making are widely used in many complex tasks. Optimal control over a sequence of natural images is a first step towards understanding the role of vision in control. Here, we formalize this problem as a reinforcement learning task, and derive general conditions under which an image includes enough information to implement an optimal policy. Reinforcement learning is shown to provide a computationally efficient method for finding optimal policies when natural images are encoded into \"efficient\" image representations. This is demonstrated by introducing a new reinforcement learning benchmark that easily scales to large numbers of states and long horizons. In particular, by representing each image as an overcomplete sparse code, we are able to efficiently solve an optimal control task that is orders of magnitude larger than those tasks solvable using complete codes. Theoretical justification for this behaviour is provided. This work also demonstrates that deep learning is not necessary for efficient optimal control with natural images.","authors":["Peter N. Loxley"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20934v1","updated":"2025-12-24T04:30:21Z","published":"2025-12-24T04:30:21Z","title":"Transductive Visual Programming: Evolving Tool Libraries from Experience for Spatial Reasoning","summary":"Spatial reasoning in 3D scenes requires precise geometric calculations that challenge vision-language models. Visual programming addresses this by decomposing problems into steps calling specialized tools, yet existing methods rely on either fixed toolsets or speculative tool induction before solving problems, resulting in suboptimal programs and poor utilization of induced tools. We present Transductive Visual Programming (TVP), a novel framework that builds new tools from its own experience rather than speculation. TVP first solves problems using basic tools while accumulating experiential solutions into an Example Library, then abstracts recurring patterns from these programs into reusable higher-level tools for an evolving Tool Library. This allows TVP to tackle new problems with increasingly powerful tools learned from experience. On Omni3D-Bench, TVP achieves state-of-the-art performance, outperforming GPT-4o by 22% and the previous best visual programming system by 11%. Our transductively learned tools are used 5x more frequently as core program dependency than inductively created ones, demonstrating more effective tool discovery and reuse. The evolved tools also show strong generalization to unseen spatial tasks, achieving superior performance on benchmarks from SpatialScore-Hard collection without any testset-specific modification. Our work establishes experience-driven transductive tool creation as a powerful paradigm for building self-evolving visual programming agents that effectively tackle challenging spatial reasoning tasks. We release our code at https://transductive-visualprogram.github.io/.","authors":["Shengguang Wu","Xiaohan Wang","Yuhui Zhang","Hao Zhu","Serena Yeung-Levy"],"pdf_url":"","comment":"Project Website: https://transductive-visualprogram.github.io/"},{"id":"http://arxiv.org/abs/2512.20932v1","updated":"2025-12-24T04:25:31Z","published":"2025-12-24T04:25:31Z","title":"Guardrailed Elasticity Pricing: A Churn-Aware Forecasting Playbook for Subscription Strategy","summary":"This paper presents a marketing analytics framework that operationalizes subscription pricing as a dynamic, guardrailed decision system, uniting multivariate demand forecasting, segment-level price elasticity, and churn propensity to optimize revenue, margin, and retention. The approach blends seasonal time-series models with tree-based learners, runs Monte Carlo scenario tests to map risk envelopes, and solves a constrained optimization that enforces business guardrails on customer experience, margin floors, and allowable churn. Validated across heterogeneous SaaS portfolios, the method consistently outperforms static tiers and uniform uplifts by reallocating price moves toward segments with higher willingness-to-pay while protecting price-sensitive cohorts. The system is designed for real-time recalibration via modular APIs and includes model explainability for governance and compliance. Managerially, the framework functions as a strategy playbook that clarifies when to shift from flat to dynamic pricing, how to align pricing with CLV and MRR targets, and how to embed ethical guardrails, enabling durable growth without eroding customer trust.","authors":["Deepit Sapru"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20920v1","updated":"2025-12-24T03:56:58Z","published":"2025-12-24T03:56:58Z","title":"RevFFN: Memory-Efficient Full-Parameter Fine-Tuning of Mixture-of-Experts LLMs with Reversible Blocks","summary":"Full parameter fine tuning is a key technique for adapting large language models (LLMs) to downstream tasks, but it incurs substantial memory overhead due to the need to cache extensive intermediate activations for backpropagation. This bottleneck makes full fine tuning of contemporary large scale LLMs challenging in practice. Existing distributed training frameworks such as DeepSpeed alleviate this issue using techniques like ZeRO and FSDP, which rely on multi GPU memory or CPU offloading, but often require additional hardware resources and reduce training speed. We introduce RevFFN, a memory efficient fine tuning paradigm for mixture of experts (MoE) LLMs. RevFFN employs carefully designed reversible Transformer blocks that allow reconstruction of layer input activations from outputs during backpropagation, eliminating the need to store most intermediate activations in memory. While preserving the expressive capacity of MoE architectures, this approach significantly reduces peak memory consumption for full parameter fine tuning. As a result, RevFFN enables efficient full fine tuning on a single consumer grade or server grade GPU.","authors":["Ningyuan Liu","Jing Yang","Kaitong Cai","Keze Wang"],"pdf_url":"","comment":"Under submission"},{"id":"http://arxiv.org/abs/2512.15745v2","updated":"2025-12-24T03:46:46Z","published":"2025-12-10T09:26:18Z","title":"LLaDA2.0: Scaling Up Diffusion Language Models to 100B","summary":"This paper presents LLaDA2.0 -- a tuple of discrete diffusion large language models (dLLM) scaling up to 100B total parameters through systematic conversion from auto-regressive (AR) models -- establishing a new paradigm for frontier-scale deployment. Instead of costly training from scratch, LLaDA2.0 upholds knowledge inheritance, progressive adaption and efficiency-aware design principle, and seamless converts a pre-trained AR model into dLLM with a novel 3-phase block-level WSD based training scheme: progressive increasing block-size in block diffusion (warm-up), large-scale full-sequence diffusion (stable) and reverting back to compact-size block diffusion (decay). Along with post-training alignment with SFT and DPO, we obtain LLaDA2.0-mini (16B) and LLaDA2.0-flash (100B), two instruction-tuned Mixture-of-Experts (MoE) variants optimized for practical deployment. By preserving the advantages of parallel decoding, these models deliver superior performance and efficiency at the frontier scale. Both models were open-sourced.","authors":["Tiwei Bie","Maosong Cao","Kun Chen","Lun Du","Mingliang Gong","Zhuochen Gong","Yanmei Gu","Jiaqi Hu","Zenan Huang","Zhenzhong Lan","Chengxi Li","Chongxuan Li","Jianguo Li","Zehuan Li","Huabin Liu","Lin Liu","Guoshan Lu","Xiaocheng Lu","Yuxin Ma","Jianfeng Tan","Lanning Wei","Ji-Rong Wen","Yipeng Xing","Xiaolu Zhang","Junbo Zhao","Da Zheng","Jun Zhou","Junlin Zhou","Zhanchao Zhou","Liwang Zhu","Yihong Zhuang"],"pdf_url":"","comment":"19 pages"},{"id":"http://arxiv.org/abs/2512.20082v2","updated":"2025-12-24T03:42:59Z","published":"2025-12-23T06:27:12Z","title":"Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches","summary":"Financial sentiment analysis plays a crucial role in informing investment decisions, assessing market risk, and predicting stock price trends. Existing works in financial sentiment analysis have not considered the impact of stock prices or market feedback on sentiment analysis. In this paper, we propose an adaptive framework that integrates large language models (LLMs) with real-world stock market feedback to improve sentiment classification in the context of the Indian stock market. The proposed methodology fine-tunes the LLaMA 3.2 3B model using instruction-based learning on the SentiFin dataset. To enhance sentiment predictions, a retrieval-augmented generation (RAG) pipeline is employed that dynamically selects multi-source contextual information based on the cosine similarity of the sentence embeddings. Furthermore, a feedback-driven module is introduced that adjusts the reliability of the source by comparing predicted sentiment with actual next-day stock returns, allowing the system to iteratively adapt to market behavior. To generalize this adaptive mechanism across temporal data, a reinforcement learning agent trained using proximal policy optimization (PPO) is incorporated. The PPO agent learns to optimize source weighting policies based on cumulative reward signals from sentiment-return alignment. Experimental results on NIFTY 50 news headlines collected from 2024 to 2025 demonstrate that the proposed system significantly improves classification accuracy, F1-score, and market alignment over baseline models and static retrieval methods. The results validate the potential of combining instruction-tuned LLMs with dynamic feedback and reinforcement learning for robust, market-aware financial sentiment modeling.","authors":[" Chaithra","Kamesh Kadimisetty","Biju R Mohan"],"pdf_url":"","comment":"Accepted in CODS 2025"},{"id":"http://arxiv.org/abs/2512.00617v2","updated":"2025-12-24T03:42:55Z","published":"2025-11-29T20:16:11Z","title":"ART: Adaptive Response Tuning Framework -- A Multi-Agent Tournament-Based Approach to LLM Response Optimization","summary":"Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation. However, single-model responses often exhibit inconsistencies, hallucinations, and varying quality across different query domains. This paper presents ART (Adaptive Response Tuning), a novel framework that employs tournament-style ELO ranking and multi-agent reasoning to systematically optimize LLM outputs. By enabling multiple LLM agents to compete, critique, and collaborate through structured tournament workflows, ART produces consensus responses that outperform individual model outputs. Our framework introduces configurable tournament parameters, dynamic agent selection, and multiple consensus fusion strategies. Experimental evaluations demonstrate significant improvements in response accuracy, coherence, and reliability compared to baseline single-model approaches. The ART framework provides a scalable, production-ready solution for applications requiring high-quality, vetted LLM responses, achieving an 8.4% improvement in overall quality metrics and R^2 values exceeding 0.96 in ELO rating convergence.","authors":["Omer Jauhar Khan"],"pdf_url":"","comment":"14 pages, 11 figures, 5 tables. IEEE conference-style paper with appendices"},{"id":"http://arxiv.org/abs/2512.10952v2","updated":"2025-12-24T03:33:33Z","published":"2025-12-11T18:59:55Z","title":"Hierarchical Dataset Selection for High-Quality Data Sharing","summary":"The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.","authors":["Xiaona Zhou","Yingyan Zeng","Ran Jin","Ismini Lourentzou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20905v1","updated":"2025-12-24T03:10:00Z","published":"2025-12-24T03:10:00Z","title":"DiEC: Diffusion Embedded Clustering","summary":"Deep clustering hinges on learning representations that are inherently clusterable. However, using a single encoder to produce a fixed embedding ignores the representation trajectory formed by a pretrained diffusion model across network hierarchies and noise timesteps, where clusterability varies substantially. We propose DiEC (Diffusion Embedded Clustering), which performs unsupervised clustering by directly reading internal activations from a pretrained diffusion U-Net.\n  DiEC formulates representation selection as a two-dimensional search over layer x timestep, and exploits a weak-coupling property to decompose it into two stages. Specifically, we first fix the U-Net bottleneck layer as the Clustering-friendly Middle Layer (CML), and then use Optimal Timestep Search (OTS) to identify the clustering-optimal timestep (t*). During training, we extract bottleneck features at the fixed t* and obtain clustering representations via a lightweight residual mapping. We optimize a DEC-style KL self-training objective, augmented with adaptive graph regularization and entropy regularization to strengthen cluster structures. In parallel, we introduce a denoising-consistency branch at random timesteps to stabilize the representations and preserve generative consistency. Experiments show that DiEC achieves competitive clustering performance on multiple standard benchmarks.","authors":["Haidong Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.11718v2","updated":"2025-12-24T03:08:54Z","published":"2025-06-13T12:34:15Z","title":"Interaction, Process, Infrastructure: A Unified Framework for Human-Agent Collaboration","summary":"While AI tools are increasingly prevalent in knowledge work, they remain fragmented, lacking the architectural foundation for sustained, adaptive collaboration. We argue this limitation stems from their inability to represent and manage the structure of collaborative work. To bridge this gap, we propose a layered conceptual framework for human-agent systems that integrates Interaction, Process, and Infrastructure. Crucially, our framework elevates Process to a first-class concern, an explicit, inspectable structural representation of activities. The central theoretical construct is Structural Adaptation, enabling the process to dynamically reorganize itself in response to evolving goals. We introduce a five-module Process Model as the representational basis for this adaptation. This model offers a unified theoretical grounding, reimagining human-agent collaboration as a coherent system for complex real-world work.","authors":["Yun Wang","Yan Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20902v1","updated":"2025-12-24T03:06:37Z","published":"2025-12-24T03:06:37Z","title":"Embodied AI-Enhanced IoMT Edge Computing: UAV Trajectory Optimization and Task Offloading with Mobility Prediction","summary":"Due to their inherent flexibility and autonomous operation, unmanned aerial vehicles (UAVs) have been widely used in Internet of Medical Things (IoMT) to provide real-time biomedical edge computing service for wireless body area network (WBAN) users. In this paper, considering the time-varying task criticality characteristics of diverse WBAN users and the dual mobility between WBAN users and UAV, we investigate the dynamic task offloading and UAV flight trajectory optimization problem to minimize the weighted average task completion time of all the WBAN users, under the constraint of UAV energy consumption. To tackle the problem, an embodied AI-enhanced IoMT edge computing framework is established. Specifically, we propose a novel hierarchical multi-scale Transformer-based user trajectory prediction model based on the users' historical trajectory traces captured by the embodied AI agent (i.e., UAV). Afterwards, a prediction-enhanced deep reinforcement learning (DRL) algorithm that integrates predicted users' mobility information is designed for intelligently optimizing UAV flight trajectory and task offloading decisions. Real-word movement traces and simulation results demonstrate the superiority of the proposed methods in comparison with the existing benchmarks.","authors":["Siqi Mu","Shuo Wen","Yang Lu","Ruihong Jiang","Bo Ai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20898v1","updated":"2025-12-24T02:47:22Z","published":"2025-12-24T02:47:22Z","title":"DGSAN: Dual-Graph Spatiotemporal Attention Network for Pulmonary Nodule Malignancy Prediction","summary":"Lung cancer continues to be the leading cause of cancer-related deaths globally. Early detection and diagnosis of pulmonary nodules are essential for improving patient survival rates. Although previous research has integrated multimodal and multi-temporal information, outperforming single modality and single time point, the fusion methods are limited to inefficient vector concatenation and simple mutual attention, highlighting the need for more effective multimodal information fusion. To address these challenges, we introduce a Dual-Graph Spatiotemporal Attention Network, which leverages temporal variations and multimodal data to enhance the accuracy of predictions. Our methodology involves developing a Global-Local Feature Encoder to better capture the local, global, and fused characteristics of pulmonary nodules. Additionally, a Dual-Graph Construction method organizes multimodal features into inter-modal and intra-modal graphs. Furthermore, a Hierarchical Cross-Modal Graph Fusion Module is introduced to refine feature integration. We also compiled a novel multimodal dataset named the NLST-cmst dataset as a comprehensive source of support for related research. Our extensive experiments, conducted on both the NLST-cmst and curated CSTL-derived datasets, demonstrate that our DGSAN significantly outperforms state-of-the-art methods in classifying pulmonary nodules with exceptional computational efficiency.","authors":["Xiao Yu","Zhaojie Fang","Guanyu Zhou","Yin Shen","Huoling Luo","Ye Li","Ahmed Elazab","Xiang Wan","Ruiquan Ge","Changmiao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.14554v4","updated":"2025-12-24T02:46:01Z","published":"2025-12-16T16:28:32Z","title":"VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models","summary":"The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, the Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems. To facilitate access and reproducibility, we provide a public landing page for this benchmark at https://vilegalbench.cmcai.vn/.","authors":["Nguyen Tien Dong","Minh-Anh Nguyen","Thanh Dat Hoang","Nguyen Tuan Ngoc","Dao Xuan Quang Minh","Phan Phi Hai","Nguyen Thi Ngoc Anh","Dang Van Tu","Binh Vu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.18802v3","updated":"2025-12-24T02:39:19Z","published":"2025-10-21T16:57:40Z","title":"Computational Foundations for Strategic Coopetition: Formalizing Interdependence and Complementarity","summary":"Coopetition refers to simultaneous cooperation and competition among actors wherein actors 'cooperate to grow the pie and compete to split it up.' Modern socio-technical systems are characterized by strategic coopetition wherein actors concomitantly cooperate to create value and compete to capture it. While conceptual modeling languages such as i* provide rich qualitative representations of strategic dependencies, they lack mechanisms for quantitative analysis of dynamic trade-offs. Conversely, classical game theory offers mathematical rigor but strips away contextual richness. This report bridges this gap by developing computational foundations that formalize two critical dimensions of coopetition: interdependence and complementarity. We ground interdependence in i* structural dependency analysis, translating depender-dependee-dependum relationships into quantitative interdependence coefficients via a structured translation framework. We formalize complementarity following Brandenburger and Nalebuff's Added Value concept, modeling synergistic value creation with validated parameterization. We integrate structural dependencies with bargaining power in value appropriation and introduce a game-theoretic formulation where Nash Equilibrium incorporates structural interdependence. Validation combines over 22,000 experimental trials across power and logarithmic specifications with the Samsung-Sony S-LCD joint venture (2004-2011). Under strict historical alignment scoring, logarithmic specifications achieve 58/60 compared to power functions (46/60), producing realistic 41% cooperation increases aligning with documented S-LCD patterns while power functions produce 166% increases exceeding realistic bounds. Statistical significance confirmed at p < 0.001, Cohen's d > 9.","authors":["Vik Pant","Eric Yu"],"pdf_url":"","comment":"39 pages, 9 figures, This technical report serves as the foundational reference for a coordinated research program examining strategic coopetition in requirements engineering and multi-agent systems, with companion work addressing trust dynamics, team production, and reciprocity mechanisms"},{"id":"http://arxiv.org/abs/2508.17671v5","updated":"2025-12-24T02:19:21Z","published":"2025-08-25T05:08:49Z","title":"Consistent Opponent Modeling in Imperfect-Information Games","summary":"The goal of agents in multi-agent environments is to maximize total reward against the opposing agents that are encountered. Following a game-theoretic solution concept, such as Nash equilibrium, may obtain a strong performance in some settings; however, such approaches fail to capitalize on historical and observed data from repeated interactions against our opponents. Opponent modeling algorithms integrate machine learning techniques to exploit suboptimal opponents utilizing available data; however, the effectiveness of such approaches in imperfect-information games to date is quite limited. We show that existing opponent modeling approaches fail to satisfy a simple desirable property even against static opponents drawn from a known prior distribution; namely, they do not guarantee that the model approaches the opponent's true strategy even in the limit as the number of game iterations approaches infinity. We develop a new algorithm that is able to achieve this property and runs efficiently by solving a convex minimization problem based on the sequence-form game representation using projected gradient descent. The algorithm is guaranteed to efficiently converge to the opponent's true strategy under standard Bayesian identifiability and visitation assumptions, given observations from gameplay and possibly additional historical data if it is available.","authors":["Sam Ganzfried"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20135v2","updated":"2025-12-24T02:19:21Z","published":"2025-12-23T07:53:57Z","title":"MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization","summary":"Molecular editing and optimization are multi-step problems that require iteratively improving properties while keeping molecules chemically valid and structurally similar. We frame both tasks as sequential, tool-guided decisions and introduce MolAct, an agentic reinforcement learning framework that employs a two-stage training paradigm: first building editing capability, then optimizing properties while reusing the learned editing behaviors. To the best of our knowledge, this is the first work to formalize molecular design as an Agentic Reinforcement Learning problem, where an LLM agent learns to interleave reasoning, tool-use, and molecular optimization. The framework enables agents to interact in multiple turns, invoking chemical tools for validity checking, property assessment, and similarity control, and leverages their feedback to refine subsequent edits. We instantiate the MolAct framework to train two model families: MolEditAgent for molecular editing tasks and MolOptAgent for molecular optimization tasks. In molecular editing, MolEditAgent-7B delivers 100, 95, and 98 valid add, delete, and substitute edits, outperforming strong closed \"thinking\" baselines such as DeepSeek-R1; MolEditAgent-3B approaches the performance of much larger open \"thinking\" models like Qwen3-32B-think. In molecular optimization, MolOptAgent-7B (trained on MolEditAgent-7B) surpasses the best closed \"thinking\" baseline (e.g., Claude 3.7) on LogP and remains competitive on solubility, while maintaining balanced performance across other objectives. These results highlight that treating molecular design as a multi-step, tool-augmented process is key to reliable and interpretable improvements.","authors":["Zhuo Yang","Yeyun Chen","Jiaqing Xie","Ben Gao","Shuaike Shen","Wanhao Liu","Liujia Yang","Beilun Wang","Tianfan Fu","Yuqiang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.08602v2","updated":"2025-12-24T02:12:49Z","published":"2025-06-10T09:12:00Z","title":"WGLE:Backdoor-free and Multi-bit Black-box Watermarking for Graph Neural Networks","summary":"Graph Neural Networks (GNNs) are increasingly deployed in real-world applications, making ownership verification critical to protect their intellectual property against model theft. Fingerprinting and black-box watermarking are two main methods. However, the former relies on determining model similarity, which is computationally expensive and prone to ownership collisions after model post-processing. The latter embeds backdoors, exposing watermarked models to the risk of backdoor attacks. Moreover, both previous methods enable ownership verification but do not convey additional information about the copy model. If the owner has multiple models, each model requires a distinct trigger graph.\n  To address these challenges, this paper proposes WGLE, a novel black-box watermarking paradigm for GNNs that enables embedding the multi-bit string in GNN models without using backdoors. WGLE builds on a key insight we term Layer-wise Distance Difference on an Edge (LDDE), which quantifies the difference between the feature distance and the prediction distance of two connected nodes in a graph. By assigning unique LDDE values to the edges and employing the LDDE sequence as the watermark, WGLE supports multi-bit capacity without relying on backdoor mechanisms. We evaluate WGLE on six public datasets across six mainstream GNN architectures, and compare WGLE with state-of-the-art GNN watermarking and fingerprinting methods. WGLE achieves 100% ownership verification accuracy, with an average fidelity degradation of only 1.41%. Additionally, WGLE exhibits robust resilience against potential attacks. The code is available in the repository.","authors":["Tingzhi Li","Xuefeng Liu","Jing Lei","Xingang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18871v3","updated":"2025-12-24T02:04:42Z","published":"2025-12-21T20:11:07Z","title":"Psychometric Validation of the Sophotechnic Mediation Scale and a New Understanding of the Development of GenAI Mastery: Lessons from 3,932 Adult Brazilian Workers","summary":"The rapid diffusion of generative artificial intelligence (GenAI) systems has introduced new forms of human-technology interaction, raising the question of whether sustained engagement gives rise to stable, internalized modes of cognition rather than merely transient efficiency gains. Grounded in the Cognitive Mediation Networks Theory, this study investigates Sophotechnic Mediation, a mode of thinking and acting associated with prolonged interaction with GenAI, and presents a comprehensive psychometric validation of the Sophotechnic Mediation Scale. Data were collected between 2023 and 2025 from independent cross-sectional samples totaling 3,932 adult workers from public and private organizations in the Metropolitan Region of Pernambuco, Brazil. Results indicate excellent internal consistency, a robust unidimensional structure, and measurement invariance across cohorts. Ordinal-robust confirmatory factor analyses and residual diagnostics show that elevated absolute fit indices reflect minor local dependencies rather than incorrect dimensionality. Distributional analyses reveal a time-evolving pattern characterized by a declining mass of non-adopters and convergence toward approximate Gaussianity among adopters, with model comparisons favoring a two-process hurdle model over a censored Gaussian specification. Sophotechnic Mediation is empirically distinct from Hypercultural mediation and is primarily driven by cumulative GenAI experience, with age moderating the rate of initial acquisition and the depth of later integration. Together, the findings support Sophotechnia as a coherent, measurable, and emergent mode of cognitive mediation associated with the ongoing GenAI revolution.","authors":["Bruno Campello de Souza"],"pdf_url":"","comment":"35 pages, 28 Manuscript, Portuguese and English Versions of the Instrument in Annex"},{"id":"http://arxiv.org/abs/2512.20884v1","updated":"2025-12-24T02:02:25Z","published":"2025-12-24T02:02:25Z","title":"The Silent Scholar Problem: A Probabilistic Framework for Breaking Epistemic Asymmetry in LLM Agents","summary":"Autonomous agents powered by LLMs and Retrieval-Augmented Generation (RAG) are proficient consumers of digital content but remain unidirectional, a limitation we term epistemic asymmetry. This isolation leads to redundant reasoning and stagnates collective intelligence. Current self-reflection frameworks remain largely heuristic and private, lacking a probabilistic foundation to quantify certainty or justify external interaction.To bridge this gap, we propose a formal probabilistic framework that provides agents with a non-altruistic motive for bidirectional knowledge exchange. We model an agent's belief in a proposition using a Beta-Bernoulli distribution with a forgetting factor ($γ$). This allows us to isolate epistemic uncertainty as the variance of belief, establishing a dual drive for interaction: A homeostatic motive: The need to maintain certainty against the temporal decay introduced by $γ$. An optimal learning strategy: Targeting points of maximum ambiguity ($\\mathbb{E}[θ]=0.5$) to maximize information gain. Under this framework, public contribution is reframed as optimal active learning: sharing solutions to elicit feedback is the most efficient method for an agent to reduce its own uncertainty. To ensure scalability, we introduce epistemic caching, which leverages the forgetting factor to dynamically prioritize resources for the active head of non-stationary knowledge distributions. Finally, we demonstrate how these accumulated belief states serve as verifiable reward signals for Reinforcement Learning from Human Feedback (RLHF) and high-quality data filters for Supervised Fine-Tuning (SFT). Simulation results validate that this uncertainty-driven strategy significantly outperforms random baselines in heterogeneous (Zipfian) environments, maintaining high adaptability to concept drift.","authors":["Zan-Kai Chong","Hiroyuki Ohsaki","Bryan Ng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.01041v3","updated":"2025-12-24T01:45:18Z","published":"2025-06-23T07:14:04Z","title":"Fast AI Model Splitting over Edge Networks","summary":"Split learning (SL) has emerged as a computationally efficient approach for artificial intelligence (AI) model training, which can alleviate device-side computational workloads. However, complex AI model architectures pose high computational complexity to obtain the optimal model splitting. In this paper, we represent an arbitrary AI model as a directed acyclic graph (DAG), and then reformulate the optimal model splitting problem as a minimum s-t cut search problem. To solve the problem, we propose a fast DAG-based model splitting algorithm, which restructures the DAG to enable the optimal model splitting identification via a maximum flow method. Theoretical analysis indicates that the proposed algorithm is optimal. Furthermore, considering AI models with block structures, we propose a block-wise model splitting algorithm to reduce computational complexity. The algorithm abstracts each block, i.e., a component consisting of multiple layers, into a single vertex, thereby obtaining the optimal model splitting via a simplified DAG. Extensive experimental results demonstrate that the proposed algorithms can determine the optimal model splitting within milliseconds, as well as reduce training delay by 24.62%-38.95% in dynamic edge networks as compared to the state-of-the-art benchmarks.","authors":["Zuguang Li","Wen Wu","Shaohua Wu","Songge Zhang","Ye Wang"," Xuemin"," Shen"],"pdf_url":"","comment":"This version lacks sufficient detail in key technical parts, including the equivalence proof for the s-t cut transformation and the computational complexity analysis (Sections VI-D). We are withdrawing it to prepare a revised, more complete manuscript"},{"id":"http://arxiv.org/abs/2512.20136v2","updated":"2025-12-24T01:35:59Z","published":"2025-12-23T07:54:03Z","title":"M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation","summary":"Retrieval-Augmented Generation (RAG) has recently been extended to multimodal settings, connecting multimodal large language models (MLLMs) with vast corpora of external knowledge such as multimodal knowledge graphs (MMKGs). Despite their recent success, multimodal RAG in the audio-visual domain remains challenging due to 1) limited modality coverage and multi-hop connectivity of existing MMKGs, and 2) retrieval based solely on similarity in a shared multimodal embedding space, which fails to filter out off-topic or redundant knowledge. To address these limitations, we propose M$^3$KG-RAG, a Multi-hop Multimodal Knowledge Graph-enhanced RAG that retrieves query-aligned audio-visual knowledge from MMKGs, improving reasoning depth and answer faithfulness in MLLMs. Specifically, we devise a lightweight multi-agent pipeline to construct multi-hop MMKG (M$^3$KG), which contains context-enriched triplets of multimodal entities, enabling modality-wise retrieval based on input queries. Furthermore, we introduce GRASP (Grounded Retrieval And Selective Pruning), which ensures precise entity grounding to the query, evaluates answer-supporting relevance, and prunes redundant context to retain only knowledge essential for response generation. Extensive experiments across diverse multimodal benchmarks demonstrate that M$^3$KG-RAG significantly enhances MLLMs' multimodal reasoning and grounding over existing approaches.","authors":["Hyeongcheol Park","Jiyoung Seo","Jaewon Mun","Hogun Park","Wonmin Byeon","Sung June Kim","Hyeonsoo Im","JeungSub Lee","Sangpil Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20866v1","updated":"2025-12-24T00:50:27Z","published":"2025-12-24T00:50:27Z","title":"Lightweight framework for underground pipeline recognition and spatial localization based on multi-view 2D GPR images","summary":"To address the issues of weak correlation between multi-view features, low recognition accuracy of small-scale targets, and insufficient robustness in complex scenarios in underground pipeline detection using 3D GPR, this paper proposes a 3D pipeline intelligent detection framework. First, based on a B/C/D-Scan three-view joint analysis strategy, a three-dimensional pipeline three-view feature evaluation method is established by cross-validating forward simulation results obtained using FDTD methods with actual measurement data. Second, the DCO-YOLO framework is proposed, which integrates DySample, CGLU, and OutlookAttention cross-dimensional correlation mechanisms into the original YOLOv11 algorithm, significantly improving the small-scale pipeline edge feature extraction capability. Furthermore, a 3D-DIoU spatial feature matching algorithm is proposed, which integrates three-dimensional geometric constraints and center distance penalty terms to achieve automated association of multi-view annotations. The three-view fusion strategy resolves inherent ambiguities in single-view detection. Experiments based on real urban underground pipeline data show that the proposed method achieves accuracy, recall, and mean average precision of 96.2%, 93.3%, and 96.7%, respectively, in complex multi-pipeline scenarios, which are 2.0%, 2.1%, and 0.9% higher than the baseline model. Ablation experiments validated the synergistic optimization effect of the dynamic feature enhancement module and Grad-CAM++ heatmap visualization demonstrated that the improved model significantly enhanced its ability to focus on pipeline geometric features. This study integrates deep learning optimization strategies with the physical characteristics of 3D GPR, offering an efficient and reliable novel technical framework for the intelligent recognition and localization of underground pipelines.","authors":["Haotian Lv","Chao Li","Jiangbo Dai","Yuhui Zhang","Zepeng Fan","Yiqiu Tan","Dawei Wang","Binglei Xie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20861v1","updated":"2025-12-24T00:41:13Z","published":"2025-12-24T00:41:13Z","title":"Memory-Efficient Acceleration of Block Low-Rank Foundation Models on Resource Constrained GPUs","summary":"Recent advances in transformer-based foundation models have made them the default choice for many tasks, but their rapidly growing size makes fitting a full model on a single GPU increasingly difficult and their computational cost prohibitive. Block low-rank (BLR) compression techniques address this challenge by learning compact representations of weight matrices. While traditional low-rank (LR) methods often incur sharp accuracy drops, BLR approaches such as Monarch and BLAST can better capture the underlying structure, thus preserving accuracy while reducing computations and memory footprints. In this work, we use roofline analysis to show that, although BLR methods achieve theoretical savings and practical speedups for single-token inference, multi-token inference often becomes memory-bound in practice, increasing latency despite compiler-level optimizations in PyTorch. To address this, we introduce custom Triton kernels with partial fusion and memory layout optimizations for both Monarch and BLAST. On memory-constrained NVIDIA GPUs such as Jetson Orin Nano and A40, our kernels deliver up to $3.76\\times$ speedups and $3\\times$ model size compression over PyTorch dense baselines using CUDA backend and compiler-level optimizations, while supporting various models including Llama-7/1B, GPT2-S, DiT-XL/2, and ViT-B. Our code is available at https://github.com/pabillam/mem-efficient-blr .","authors":["Pierre Abillama","Changwoo Lee","Juechu Dong","David Blaauw","Dennis Sylvester","Hun-Seok Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20856v1","updated":"2025-12-24T00:24:05Z","published":"2025-12-24T00:24:05Z","title":"NVIDIA Nemotron 3: Efficient and Open Intelligence","summary":"We introduce the Nemotron 3 family of models - Nano, Super, and Ultra. These models deliver strong agentic, reasoning, and conversational capabilities. The Nemotron 3 family uses a Mixture-of-Experts hybrid Mamba-Transformer architecture to provide best-in-class throughput and context lengths of up to 1M tokens. Super and Ultra models are trained with NVFP4 and incorporate LatentMoE, a novel approach that improves model quality. The two larger models also include MTP layers for faster text generation. All Nemotron 3 models are post-trained using multi-environment reinforcement learning enabling reasoning, multi-step tool use, and support granular reasoning budget control. Nano, the smallest model, outperforms comparable models in accuracy while remaining extremely cost-efficient for inference. Super is optimized for collaborative agents and high-volume workloads such as IT ticket automation. Ultra, the largest model, provides state-of-the-art accuracy and reasoning performance. Nano is released together with its technical report and this white paper, while Super and Ultra will follow in the coming months. We will openly release the model weights, pre- and post-training software, recipes, and all data for which we hold redistribution rights.","authors":[" NVIDIA"," :","Aaron Blakeman","Aaron Grattafiori","Aarti Basant","Abhibha Gupta","Abhinav Khattar","Adi Renduchintala","Aditya Vavre","Akanksha Shukla","Akhiad Bercovich","Aleksander Ficek","Aleksandr Shaposhnikov","Alex Kondratenko","Alexander Bukharin","Alexandre Milesi","Ali Taghibakhshi","Alisa Liu","Amelia Barton","Ameya Sunil Mahabaleshwarkar","Amir Klein","Amit Zuker","Amnon Geifman","Amy Shen","Anahita Bhiwandiwalla","Andrew Tao","Anjulie Agrusa","Ankur Verma","Ann Guan","Anubhav Mandarwal","Arham Mehta","Ashwath Aithal","Ashwin Poojary","Asif Ahamed","Asit Mishra","Asma Kuriparambil Thekkumpate","Ayush Dattagupta","Banghua Zhu","Bardiya Sadeghi","Barnaby Simkin","Ben Lanir","Benedikt Schifferer","Besmira Nushi","Bilal Kartal","Bita Darvish Rouhani","Boris Ginsburg","Brandon Norick","Brandon Soubasis","Branislav Kisacanin","Brian Yu","Bryan Catanzaro","Carlo del Mundo","Chantal Hwang","Charles Wang","Cheng-Ping Hsieh","Chenghao Zhang","Chenhan Yu","Chetan Mungekar","Chintan Patel","Chris Alexiuk","Christopher Parisien","Collin Neale","Cyril Meurillon","Damon Mosk-Aoyama","Dan Su","Dane Corneil","Daniel Afrimi","Daniel Lo","Daniel Rohrer","Daniel Serebrenik","Daria Gitman","Daria Levy","Darko Stosic","David Mosallanezhad","Deepak Narayanan","Dhruv Nathawani","Dima Rekesh","Dina Yared","Divyanshu Kakwani","Dong Ahn","Duncan Riach","Dusan Stosic","Edgar Minasyan","Edward Lin","Eileen Long","Eileen Peters Long","Elad Segal","Elena Lantz","Ellie Evans","Elliott Ning","Eric Chung","Eric Harper","Eric Tramel","Erick Galinkin","Erik Pounds","Evan Briones","Evelina Bakhturina","Evgeny Tsykunov","Faisal Ladhak","Fay Wang","Fei Jia","Felipe Soares","Feng Chen","Ferenc Galko","Frank Sun","Frankie Siino","Gal Hubara Agam","Ganesh Ajjanagadde","Gantavya Bhatt","Gargi Prasad","George Armstrong","Gerald Shen","Gorkem Batmaz","Grigor Nalbandyan","Haifeng Qian","Harsh Sharma","Hayley Ross","Helen Ngo","Herbert Hum","Herman Sahota","Hexin Wang","Himanshu Soni","Hiren Upadhyay","Huizi Mao","Huy C Nguyen","Huy Q Nguyen","Iain Cunningham","Ido Galil","Ido Shahaf","Igor Gitman","Ilya Loshchilov","Itamar Schen","Itay Levy","Ivan Moshkov","Izik Golan","Izzy Putterman","Jan Kautz","Jane Polak Scowcroft","Jared Casper","Jatin Mitra","Jeffrey Glick","Jenny Chen","Jesse Oliver","Jian Zhang","Jiaqi Zeng","Jie Lou","Jimmy Zhang","Jinhang Choi","Jining Huang","Joey Conway","Joey Guman","John Kamalu","Johnny Greco","Jonathan Cohen","Joseph Jennings","Joyjit Daw","Julien Veron Vialard","Junkeun Yi","Jupinder Parmar","Kai Xu","Kan Zhu","Kari Briski","Katherine Cheung","Katherine Luna","Keith Wyss","Keshav Santhanam","Kevin Shih","Kezhi Kong","Khushi Bhardwaj","Kirthi Shankar","Krishna C. Puvvada","Krzysztof Pawelec","Kumar Anik","Lawrence McAfee","Laya Sleiman","Leon Derczynski","Li Ding","Lizzie Wei","Lucas Liebenwein","Luis Vega","Maanu Grover","Maarten Van Segbroeck","Maer Rodrigues de Melo","Mahdi Nazemi","Makesh Narsimhan Sreedhar","Manoj Kilaru","Maor Ashkenazi","Marc Romeijn","Marcin Chochowski","Mark Cai","Markus Kliegl","Maryam Moosaei","Matt Kulka","Matvei Novikov","Mehrzad Samadi","Melissa Corpuz","Mengru Wang","Meredith Price","Michael Andersch","Michael Boone","Michael Evans","Miguel Martinez","Mikail Khona","Mike Chrzanowski","Minseok Lee","Mohammad Dabbah","Mohammad Shoeybi","Mostofa Patwary","Nabin Mulepati","Najeeb Nabwani","Natalie Hereth","Nave Assaf","Negar Habibi","Neta Zmora","Netanel Haber","Nicola Sessions","Nidhi Bhatia","Nikhil Jukar","Nikki Pope","Nikolai Ludwig","Nima Tajbakhsh","Nir Ailon","Nirmal Juluru","Nishant Sharma","Oleksii Hrinchuk","Oleksii Kuchaiev","Olivier Delalleau","Oluwatobi Olabiyi","Omer Ullman Argov","Omri Puny","Oren Tropp","Ouye Xie","Parth Chadha","Pasha Shamis","Paul Gibbons","Pavlo Molchanov","Pawel Morkisz","Peter Dykas","Peter Jin","Pinky Xu","Piotr Januszewski","Pranav Prashant Thombre","Prasoon Varshney","Pritam Gundecha","Przemek Tredak","Qing Miao","Qiyu Wan","Rabeeh Karimi Mahabadi","Rachit Garg","Ran El-Yaniv","Ran Zilberstein","Rasoul Shafipour","Rich Harang","Rick Izzo","Rima Shahbazyan","Rishabh Garg","Ritika Borkar","Ritu Gala","Riyad Islam","Robert Hesse","Roger Waleffe","Rohit Watve","Roi Koren","Ruoxi Zhang","Russell Hewett","Russell J. Hewett","Ryan Prenger","Ryan Timbrook","Sadegh Mahdavi","Sahil Modi","Samuel Kriman","Sangkug Lim","Sanjay Kariyappa","Sanjeev Satheesh","Saori Kaji","Satish Pasumarthi","Saurav Muralidharan","Sean Narentharen","Sean Narenthiran","Seonmyeong Bak","Sergey Kashirsky","Seth Poulos","Shahar Mor","Shanmugam Ramasamy","Shantanu Acharya","Shaona Ghosh","Sharath Turuvekere Sreenivas","Shelby Thomas","Shiqing Fan","Shreya Gopal","Shrimai Prabhumoye","Shubham Pachori","Shubham Toshniwal","Shuoyang Ding","Siddharth Singh","Simeng Sun","Smita Ithape","Somshubra Majumdar","Soumye Singhal","Stas Sergienko","Stefania Alborghetti","Stephen Ge","Sugam Dipak Devare","Sumeet Kumar Barua","Suseella Panguluri","Suyog Gupta","Sweta Priyadarshi","Syeda Nahida Akter","Tan Bui","Teodor-Dumitru Ene","Terry Kong","Thanh Do","Tijmen Blankevoort","Tim Moon","Tom Balough","Tomer Asida","Tomer Bar Natan","Tomer Ronen","Tugrul Konuk","Twinkle Vashishth","Udi Karpas","Ushnish De","Vahid Noorozi","Vahid Noroozi","Venkat Srinivasan","Venmugil Elango","Victor Cui","Vijay Korthikanti","Vinay Rao","Vitaly Kurin","Vitaly Lavrukhin","Vladimir Anisimov","Wanli Jiang","Wasi Uddin Ahmad","Wei Du","Wei Ping","Wenfei Zhou","Will Jennings","William Zhang","Wojciech Prazuch","Xiaowei Ren","Yashaswi Karnati","Yejin Choi","Yev Meyer","Yi-Fu Wu","Yian Zhang","Yigong Qin","Ying Lin","Yonatan Geifman","Yonggan Fu","Yoshi Subara","Yoshi Suhara","Yubo Gao","Zach Moshe","Zhen Dong","Zhongbo Zhu","Zihan Liu","Zijia Chen","Zijie Yan"],"pdf_url":"","comment":null}]}}